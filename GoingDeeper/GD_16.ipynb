{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba57a60",
   "metadata": {},
   "source": [
    "## 사용할 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4680ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "# 주의! ray를 tensorflow보다 먼저 import하면 오류가 발생할 수 있습니다\n",
    "import io, json, os, math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Add, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, MaxPool2D\n",
    "from tensorflow.keras.layers import UpSampling2D, ZeroPadding2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import ray\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_PATH = os.getenv('HOME') + '/aiffel/mpii'\n",
    "IMAGE_PATH = os.path.join(PROJECT_PATH, 'images')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'models1')\n",
    "TFRECORD_PATH = os.path.join(PROJECT_PATH, 'tfrecords_mpii')\n",
    "TRAIN_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'train.json')\n",
    "VALID_JSON = os.path.join(PROJECT_PATH, 'mpii_human_pose_v1_u12_2', 'validation.json')\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d1e51",
   "metadata": {},
   "source": [
    "## json 파싱하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322e711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    json_formatted_str = json.dumps(train_annos[0], indent=2)\n",
    "#     print(json_formatted_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452e5a04",
   "metadata": {},
   "source": [
    "##  json annotation 을 파싱하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e25d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_one_annotation(anno, image_dir):\n",
    "    filename = anno['image']\n",
    "    joints = anno['joints']\n",
    "    joints_visibility = anno['joints_vis']\n",
    "    annotation = {\n",
    "        'filename': filename,\n",
    "        'filepath': os.path.join(image_dir, filename),\n",
    "        'joints_visibility': joints_visibility,\n",
    "        'joints': joints,\n",
    "        'center': anno['center'],\n",
    "        'scale' : anno['scale']\n",
    "    }\n",
    "    return annotation\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d90ca",
   "metadata": {},
   "source": [
    "## parse_one_annotation()함수를 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "080ac139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': '015601864.jpg', 'filepath': '/aiffel/aiffel/mpii/images/015601864.jpg', 'joints_visibility': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'joints': [[620.0, 394.0], [616.0, 269.0], [573.0, 185.0], [647.0, 188.0], [661.0, 221.0], [656.0, 231.0], [610.0, 187.0], [647.0, 176.0], [637.0201, 189.8183], [695.9799, 108.1817], [606.0, 217.0], [553.0, 161.0], [601.0, 167.0], [692.0, 185.0], [693.0, 240.0], [688.0, 313.0]], 'center': [594.0, 257.0], 'scale': 3.021046}\n"
     ]
    }
   ],
   "source": [
    "with open(TRAIN_JSON) as train_json:\n",
    "    train_annos = json.load(train_json)\n",
    "    test = parse_one_annotation(train_annos[0], IMAGE_PATH)\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f78c6",
   "metadata": {},
   "source": [
    "## TFrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7306c9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def generate_tfexample(anno):\n",
    "\n",
    "    # byte 인코딩을 위한 함수\n",
    "    def _bytes_feature(value):\n",
    "        if isinstance(value, type(tf.constant(0))):\n",
    "            value = value.numpy()\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    filename = anno['filename']\n",
    "    filepath = anno['filepath']\n",
    "    with open(filepath, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = Image.open(filepath)\n",
    "    if image.format != 'JPEG' or image.mode != 'RGB':\n",
    "        image_rgb = image.convert('RGB')\n",
    "        with io.BytesIO() as output:\n",
    "            image_rgb.save(output, format=\"JPEG\", quality=95)\n",
    "            content = output.getvalue()\n",
    "\n",
    "    width, height = image.size\n",
    "    depth = 3\n",
    "\n",
    "    c_x = int(anno['center'][0])\n",
    "    c_y = int(anno['center'][1])\n",
    "    scale = anno['scale']\n",
    "\n",
    "    x = [\n",
    "        int(joint[0]) if joint[0] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "    y = [\n",
    "        int(joint[1]) if joint[1] >= 0 else int(joint[0]) \n",
    "        for joint in anno['joints']\n",
    "    ]\n",
    "\n",
    "    v = [0 if joint_v == 0 else 2 for joint_v in anno['joints_visibility']]\n",
    "\n",
    "    feature = {\n",
    "        'image/height':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'image/width':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'image/depth':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[depth])),\n",
    "        'image/object/parts/x':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
    "        'image/object/parts/y':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "        'image/object/center/x': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_x])),\n",
    "        'image/object/center/y': \n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=[c_y])),\n",
    "        'image/object/scale':\n",
    "        tf.train.Feature(float_list=tf.train.FloatList(value=[scale])),\n",
    "        'image/object/parts/v':\n",
    "        tf.train.Feature(int64_list=tf.train.Int64List(value=v)),\n",
    "        'image/encoded':\n",
    "        _bytes_feature(content),\n",
    "        'image/filename':\n",
    "        _bytes_feature(filename.encode())\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae001b3",
   "metadata": {},
   "source": [
    "## 얼마나 많은 TFRecord를 만들지 결정할 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa495da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def chunkify(l, n):\n",
    "    size = len(l) // n\n",
    "    start = 0\n",
    "    results = []\n",
    "    for i in range(n):\n",
    "        results.append(l[start:start + size])\n",
    "        start += size\n",
    "    return results\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b5fb60",
   "metadata": {},
   "source": [
    "## chunkify함수를 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c111d5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "64\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "test_chunks = chunkify([0] * 1000, 64)\n",
    "print(test_chunks)\n",
    "print(len(test_chunks))\n",
    "print(len(test_chunks[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff73a6b",
   "metadata": {},
   "source": [
    "## chunk를 TFRecord로 만들어 줄 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5af21ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "@ray.remote\n",
    "def build_single_tfrecord(chunk, path):\n",
    "    print('start to build tf records for ' + path)\n",
    "\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for anno in chunk:\n",
    "            tf_example = generate_tfexample(anno)\n",
    "            writer.write(tf_example.SerializeToString())\n",
    "\n",
    "    print('finished building tf records for ' + path)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02696c71",
   "metadata": {},
   "source": [
    "## 전체 데이터를 적당한 수의 TFRecord 파일로 만들어주는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ba15660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def build_tf_records(annotations, total_shards, split):\n",
    "    chunks = chunkify(annotations, total_shards)\n",
    "    futures = [\n",
    "        build_single_tfrecord.remote(\n",
    "            chunk, '{}/{}_{}_of_{}.tfrecords'.format(\n",
    "                TFRECORD_PATH,\n",
    "                split,\n",
    "                str(i + 1).zfill(4),\n",
    "                str(total_shards).zfill(4),\n",
    "            )) for i, chunk in enumerate(chunks)\n",
    "    ]\n",
    "    ray.get(futures)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5812ef5",
   "metadata": {},
   "source": [
    "##  데이터를 TFRecord로 만들어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff0c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_train_shards = 64\n",
    "# num_val_shards = 8\n",
    "\n",
    "# ray.init()\n",
    "\n",
    "# print('Start to parse annotations.')\n",
    "# if not os.path.exists(TFRECORD_PATH):\n",
    "#     os.makedirs(TFRECORD_PATH)\n",
    "\n",
    "# with open(TRAIN_JSON) as train_json:\n",
    "#     train_annos = json.load(train_json)\n",
    "#     train_annotations = [\n",
    "#         parse_one_annotation(anno, IMAGE_PATH)\n",
    "#         for anno in train_annos\n",
    "#     ]\n",
    "#     print('First train annotation: ', train_annotations[0])\n",
    "\n",
    "# with open(VALID_JSON) as val_json:\n",
    "#     val_annos = json.load(val_json)\n",
    "#     val_annotations = [\n",
    "#         parse_one_annotation(anno, IMAGE_PATH) \n",
    "#         for anno in val_annos\n",
    "#     ]\n",
    "#     print('First val annotation: ', val_annotations[0])\n",
    "    \n",
    "# print('Start to build TF Records.')\n",
    "# build_tf_records(train_annotations, num_train_shards, 'train')\n",
    "# build_tf_records(val_annotations, num_val_shards, 'val')\n",
    "\n",
    "# print('Successfully wrote {} annotations to TF Records.'.format(\n",
    "#     len(train_annotations) + len(val_annotations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5ecf7a",
   "metadata": {},
   "source": [
    "## TFRecord로 저장된 데이터를 모델에 학습에 필요한 데이터로 바꿔줄 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e5d2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_tfexample(example):\n",
    "    image_feature_description = {\n",
    "        'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "        'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "        'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "        'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    return tf.io.parse_single_example(example, image_feature_description)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac7d9b7",
   "metadata": {},
   "source": [
    "## 이렇게 얻은 image 와 label 을 이용해서 적절한 학습 형태로 변환합니다. 이미지를 그대로 사용하지 않고 적당히 정사각형으로 crop하여 사용합니다.\n",
    "\n",
    "우리가 알고 있는 것은 joints 의 위치, center 의 좌표, body height 값입니다. 균일하게 학습하기 위해 body width 를 적절히 정하는 것도 중요합니다. 이와 관련해서는 여러 방법이 있을 수 있겠지만 배우는 단계에서 더 중요하게 봐야 할 부분은 우리가 임의로 조정한 crop box 가 이미지 바깥으로 나가지 않는지 예외 처리를 잘 해주어야 한다는 점입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "036a63b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def crop_roi(image, features, margin=0.2):\n",
    "    img_shape = tf.shape(image)\n",
    "    img_height = img_shape[0]\n",
    "    img_width = img_shape[1]\n",
    "    img_depth = img_shape[2]\n",
    "\n",
    "    keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "    keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "    center_x = features['image/object/center/x']\n",
    "    center_y = features['image/object/center/y']\n",
    "    body_height = features['image/object/scale'] * 200.0\n",
    "\n",
    "    # keypoint 중 유효한값(visible = 1) 만 사용합니다.\n",
    "    masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "    masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "\n",
    "    # min, max 값을 찾습니다.\n",
    "    keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "    keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "    keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "    keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "\n",
    "    # 높이 값을 이용해서 x, y 위치를 재조정 합니다. 박스를 정사각형으로 사용하기 위해 아래와 같이 사용합니다.\n",
    "    xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "    ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "\n",
    "    # 이미지 크기를 벗어나는 점을 재조정 해줍니다.\n",
    "    effective_xmin = xmin if xmin > 0 else 0\n",
    "    effective_ymin = ymin if ymin > 0 else 0\n",
    "    effective_xmax = xmax if xmax < img_width else img_width\n",
    "    effective_ymax = ymax if ymax < img_height else img_height\n",
    "    effective_height = effective_ymax - effective_ymin\n",
    "    effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "    image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "    new_shape = tf.shape(image)\n",
    "    new_height = new_shape[0]\n",
    "    new_width = new_shape[1]\n",
    "\n",
    "    effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "    effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "\n",
    "    return image, effective_keypoint_x, effective_keypoint_y\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03c4db2",
   "metadata": {},
   "source": [
    "## 확률 분포로는 2차원 가우시안 분포를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92db4886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def generate_2d_guassian(height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "    heatmap = tf.zeros((height, width))\n",
    "\n",
    "    xmin = x0 - 3 * sigma\n",
    "    ymin = y0 - 3 * sigma\n",
    "    xmax = x0 + 3 * sigma\n",
    "    ymax = y0 + 3 * sigma\n",
    "    \n",
    "    if xmin >= width or ymin >= height or xmax < 0 or ymax < 0 or visibility == 0:\n",
    "        return heatmap\n",
    "\n",
    "    size = 6 * sigma + 1\n",
    "    x, y = tf.meshgrid(tf.range(0, 6 * sigma + 1, 1), tf.range(0, 6 * sigma + 1, 1), indexing='xy')\n",
    "\n",
    "    center_x = size // 2\n",
    "    center_y = size // 2\n",
    "\n",
    "    gaussian_patch = tf.cast(tf.math.exp(\n",
    "        -(tf.math.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale,\n",
    "                             dtype=tf.float32)\n",
    "\n",
    "    patch_xmin = tf.math.maximum(0, -xmin)\n",
    "    patch_ymin = tf.math.maximum(0, -ymin)\n",
    "    patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "    patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "    heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "    heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "    heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "    heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "    indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for j in tf.range(patch_ymin, patch_ymax):\n",
    "        for i in tf.range(patch_xmin, patch_xmax):\n",
    "            indices = indices.write(count, [heatmap_ymin + j, heatmap_xmin + i])\n",
    "            updates = updates.write(count, gaussian_patch[j][i])\n",
    "            count += 1\n",
    "\n",
    "    heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "    return heatmap\n",
    "\n",
    "def make_heatmaps(features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "    v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "    x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "    y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "\n",
    "    num_heatmap = heatmap_shape[2]\n",
    "    heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "    for i in range(num_heatmap):\n",
    "        gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "        heatmap_array = heatmap_array.write(i, gaussian)\n",
    "\n",
    "    heatmaps = heatmap_array.stack()\n",
    "    heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0])  # change to (64, 64, 16)\n",
    "\n",
    "    return heatmaps\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3574a1b6",
   "metadata": {},
   "source": [
    "## 지금까지 만든 함수들을 개별 함수로도 만들 수 있지만 객체 형태로 조합해 볼게요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70f8d41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class Preprocessor(object):\n",
    "    def __init__(self,\n",
    "                 image_shape=(256, 256, 3),\n",
    "                 heatmap_shape=(64, 64, 16),\n",
    "                 is_train=False):\n",
    "        self.is_train = is_train\n",
    "        self.image_shape = image_shape\n",
    "        self.heatmap_shape = heatmap_shape\n",
    "\n",
    "    def __call__(self, example):\n",
    "        features = self.parse_tfexample(example)\n",
    "        image = tf.io.decode_jpeg(features['image/encoded'])\n",
    "\n",
    "        if self.is_train:\n",
    "            random_margin = tf.random.uniform([1], 0.1, 0.3)[0]\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features, margin=random_margin)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "        else:\n",
    "            image, keypoint_x, keypoint_y = self.crop_roi(image, features)\n",
    "            image = tf.image.resize(image, self.image_shape[0:2])\n",
    "\n",
    "        image = tf.cast(image, tf.float32) / 127.5 - 1\n",
    "        heatmaps = self.make_heatmaps(features, keypoint_x, keypoint_y, self.heatmap_shape)\n",
    "\n",
    "        return image, heatmaps\n",
    "\n",
    "        \n",
    "    def crop_roi(self, image, features, margin=0.2):\n",
    "        img_shape = tf.shape(image)\n",
    "        img_height = img_shape[0]\n",
    "        img_width = img_shape[1]\n",
    "        img_depth = img_shape[2]\n",
    "\n",
    "        keypoint_x = tf.cast(tf.sparse.to_dense(features['image/object/parts/x']), dtype=tf.int32)\n",
    "        keypoint_y = tf.cast(tf.sparse.to_dense(features['image/object/parts/y']), dtype=tf.int32)\n",
    "        center_x = features['image/object/center/x']\n",
    "        center_y = features['image/object/center/y']\n",
    "        body_height = features['image/object/scale'] * 200.0\n",
    "        \n",
    "        masked_keypoint_x = tf.boolean_mask(keypoint_x, keypoint_x > 0)\n",
    "        masked_keypoint_y = tf.boolean_mask(keypoint_y, keypoint_y > 0)\n",
    "        \n",
    "        keypoint_xmin = tf.reduce_min(masked_keypoint_x)\n",
    "        keypoint_xmax = tf.reduce_max(masked_keypoint_x)\n",
    "        keypoint_ymin = tf.reduce_min(masked_keypoint_y)\n",
    "        keypoint_ymax = tf.reduce_max(masked_keypoint_y)\n",
    "        \n",
    "        xmin = keypoint_xmin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        xmax = keypoint_xmax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymin = keypoint_ymin - tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        ymax = keypoint_ymax + tf.cast(body_height * margin, dtype=tf.int32)\n",
    "        \n",
    "        effective_xmin = xmin if xmin > 0 else 0\n",
    "        effective_ymin = ymin if ymin > 0 else 0\n",
    "        effective_xmax = xmax if xmax < img_width else img_width\n",
    "        effective_ymax = ymax if ymax < img_height else img_height\n",
    "        effective_height = effective_ymax - effective_ymin\n",
    "        effective_width = effective_xmax - effective_xmin\n",
    "\n",
    "        image = image[effective_ymin:effective_ymax, effective_xmin:effective_xmax, :]\n",
    "        new_shape = tf.shape(image)\n",
    "        new_height = new_shape[0]\n",
    "        new_width = new_shape[1]\n",
    "        \n",
    "        effective_keypoint_x = (keypoint_x - effective_xmin) / new_width\n",
    "        effective_keypoint_y = (keypoint_y - effective_ymin) / new_height\n",
    "        \n",
    "        return image, effective_keypoint_x, effective_keypoint_y\n",
    "        \n",
    "    \n",
    "    def generate_2d_guassian(self, height, width, y0, x0, visibility=2, sigma=1, scale=12):\n",
    "        \n",
    "        heatmap = tf.zeros((height, width))\n",
    "\n",
    "        xmin = x0 - 3 * sigma\n",
    "        ymin = y0 - 3 * sigma\n",
    "        xmax = x0 + 3 * sigma\n",
    "        ymax = y0 + 3 * sigma\n",
    "\n",
    "        if xmin >= width or ymin >= height or xmax < 0 or ymax <0 or visibility == 0:\n",
    "            return heatmap\n",
    "\n",
    "        size = 6 * sigma + 1\n",
    "        x, y = tf.meshgrid(tf.range(0, 6*sigma+1, 1), tf.range(0, 6*sigma+1, 1), indexing='xy')\n",
    "\n",
    "        center_x = size // 2\n",
    "        center_y = size // 2\n",
    "\n",
    "        gaussian_patch = tf.cast(tf.math.exp(-(tf.square(x - center_x) + tf.math.square(y - center_y)) / (tf.math.square(sigma) * 2)) * scale, dtype=tf.float32)\n",
    "\n",
    "        patch_xmin = tf.math.maximum(0, -xmin)\n",
    "        patch_ymin = tf.math.maximum(0, -ymin)\n",
    "        patch_xmax = tf.math.minimum(xmax, width) - xmin\n",
    "        patch_ymax = tf.math.minimum(ymax, height) - ymin\n",
    "\n",
    "        heatmap_xmin = tf.math.maximum(0, xmin)\n",
    "        heatmap_ymin = tf.math.maximum(0, ymin)\n",
    "        heatmap_xmax = tf.math.minimum(xmax, width)\n",
    "        heatmap_ymax = tf.math.minimum(ymax, height)\n",
    "\n",
    "        indices = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "        updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for j in tf.range(patch_ymin, patch_ymax):\n",
    "            for i in tf.range(patch_xmin, patch_xmax):\n",
    "                indices = indices.write(count, [heatmap_ymin+j, heatmap_xmin+i])\n",
    "                updates = updates.write(count, gaussian_patch[j][i])\n",
    "                count += 1\n",
    "                \n",
    "        heatmap = tf.tensor_scatter_nd_update(heatmap, indices.stack(), updates.stack())\n",
    "\n",
    "        return heatmap\n",
    "\n",
    "\n",
    "    def make_heatmaps(self, features, keypoint_x, keypoint_y, heatmap_shape):\n",
    "        v = tf.cast(tf.sparse.to_dense(features['image/object/parts/v']), dtype=tf.float32)\n",
    "        x = tf.cast(tf.math.round(keypoint_x * heatmap_shape[0]), dtype=tf.int32)\n",
    "        y = tf.cast(tf.math.round(keypoint_y * heatmap_shape[1]), dtype=tf.int32)\n",
    "        \n",
    "        num_heatmap = heatmap_shape[2]\n",
    "        heatmap_array = tf.TensorArray(tf.float32, 16)\n",
    "\n",
    "        for i in range(num_heatmap):\n",
    "            gaussian = self.generate_2d_guassian(heatmap_shape[1], heatmap_shape[0], y[i], x[i], v[i])\n",
    "            heatmap_array = heatmap_array.write(i, gaussian)\n",
    "        \n",
    "        heatmaps = heatmap_array.stack()\n",
    "        heatmaps = tf.transpose(heatmaps, perm=[1, 2, 0]) # change to (64, 64, 16)\n",
    "        \n",
    "        return heatmaps\n",
    "\n",
    "    def parse_tfexample(self, example):\n",
    "        image_feature_description = {\n",
    "            'image/height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/parts/x': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/y': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/parts/v': tf.io.VarLenFeature(tf.int64),\n",
    "            'image/object/center/x': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/center/y': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'image/object/scale': tf.io.FixedLenFeature([], tf.float32),\n",
    "            'image/encoded': tf.io.FixedLenFeature([], tf.string),\n",
    "            'image/filename': tf.io.FixedLenFeature([], tf.string),\n",
    "        }\n",
    "        return tf.io.parse_single_example(example,\n",
    "                                          image_feature_description)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6e0ae0",
   "metadata": {},
   "source": [
    "## Hourglass 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "496d1210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def BottleneckBlock(inputs, filters, strides=1, downsample=False, name=None):\n",
    "    identity = inputs\n",
    "    if downsample:\n",
    "        identity = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=1,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(inputs)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(inputs)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters // 2,\n",
    "        kernel_size=3,\n",
    "        strides=strides,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(x)\n",
    "\n",
    "    x = Add()([identity, x])\n",
    "    return x\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af18a0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def HourglassModule(inputs, order, filters, num_residual):\n",
    "    \n",
    "    up1 = BottleneckBlock(inputs, filters, downsample=False)\n",
    "    for i in range(num_residual):\n",
    "        up1 = BottleneckBlock(up1, filters, downsample=False)\n",
    "\n",
    "    low1 = MaxPool2D(pool_size=2, strides=2)(inputs)\n",
    "    for i in range(num_residual):\n",
    "        low1 = BottleneckBlock(low1, filters, downsample=False)\n",
    "\n",
    "    low2 = low1\n",
    "    if order > 1:\n",
    "        low2 = HourglassModule(low1, order - 1, filters, num_residual)\n",
    "    else:\n",
    "        for i in range(num_residual):\n",
    "            low2 = BottleneckBlock(low2, filters, downsample=False)\n",
    "\n",
    "    low3 = low2\n",
    "    for i in range(num_residual):\n",
    "        low3 = BottleneckBlock(low3, filters, downsample=False)\n",
    "\n",
    "    up2 = UpSampling2D(size=2)(low3)\n",
    "\n",
    "    return up2 + up1\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "082afcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def LinearLayer(inputs, filters):\n",
    "    x = Conv2D(\n",
    "        filters=filters,\n",
    "        kernel_size=1,\n",
    "        strides=1,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de588ea6",
   "metadata": {},
   "source": [
    "## 지금까지 만든 hourglass 를 여러 층으로 쌓으면 stacked hourglass 가 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86f2f14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def StackedHourglassNetwork(\n",
    "        input_shape=(256, 256, 3), \n",
    "        num_stack=4, \n",
    "        num_residual=1,\n",
    "        num_heatmap=16):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        strides=2,\n",
    "        padding='same',\n",
    "        kernel_initializer='he_normal')(inputs)\n",
    "    x = BatchNormalization(momentum=0.9)(x)\n",
    "    x = ReLU()(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=True)\n",
    "    x = MaxPool2D(pool_size=2, strides=2)(x)\n",
    "    x = BottleneckBlock(x, 128, downsample=False)\n",
    "    x = BottleneckBlock(x, 256, downsample=True)\n",
    "\n",
    "    ys = []\n",
    "    for i in range(num_stack):\n",
    "        x = HourglassModule(x, order=4, filters=256, num_residual=num_residual)\n",
    "        for i in range(num_residual):\n",
    "            x = BottleneckBlock(x, 256, downsample=False)\n",
    "\n",
    "        x = LinearLayer(x, 256)\n",
    "\n",
    "        y = Conv2D(\n",
    "            filters=num_heatmap,\n",
    "            kernel_size=1,\n",
    "            strides=1,\n",
    "            padding='same',\n",
    "            kernel_initializer='he_normal')(x)\n",
    "        ys.append(y)\n",
    "\n",
    "        if i < num_stack - 1:\n",
    "            y_intermediate_1 = Conv2D(filters=256, kernel_size=1, strides=1)(x)\n",
    "            y_intermediate_2 = Conv2D(filters=256, kernel_size=1, strides=1)(y)\n",
    "            x = Add()([y_intermediate_1, y_intermediate_2])\n",
    "\n",
    "    return tf.keras.Model(inputs, ys, name='stacked_hourglass')\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d972a3c",
   "metadata": {},
   "source": [
    "## samplebaseline 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bd21b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_deconv_layer(num_deconv_layers):\n",
    "    seq_model = tf.keras.models.Sequential()\n",
    "    for i in range(num_deconv_layers):\n",
    "        seq_model.add(tf.keras.layers.Conv2DTranspose(256, kernel_size=(4,4), strides=(2,2), padding='same'))\n",
    "        seq_model.add(tf.keras.layers.BatchNormalization())\n",
    "        seq_model.add(tf.keras.layers.ReLU())\n",
    "    return seq_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Simplebaseline(input_shape=(256, 256, 3)):\n",
    "    resnet = tf.keras.applications.resnet.ResNet50(include_top=False, weights='imagenet')\n",
    "    upconv = _make_deconv_layer(3)\n",
    "    final_layer = tf.keras.layers.Conv2D(16, kernel_size=(1,1), padding='same')\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = resnet(inputs)\n",
    "    x = upconv(x)\n",
    "    out = final_layer(x)\n",
    "    model = tf.keras.Model(inputs, out, name='simple_baseline')\n",
    "  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba19a12",
   "metadata": {},
   "source": [
    "## GPU가 여러 개인 환경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4c49f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 epochs,\n",
    "                 global_batch_size,\n",
    "                 strategy,\n",
    "                 initial_learning_rate):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.strategy = strategy\n",
    "        self.global_batch_size = global_batch_size\n",
    "        self.loss_object = tf.keras.losses.MeanSquaredError(\n",
    "            reduction=tf.keras.losses.Reduction.NONE)\n",
    "        self.optimizer = tf.keras.optimizers.Adam(\n",
    "            learning_rate=initial_learning_rate)\n",
    "        self.model = model\n",
    "\n",
    "        self.current_learning_rate = initial_learning_rate\n",
    "        self.last_val_loss = math.inf\n",
    "        self.lowest_val_loss = math.inf\n",
    "        self.patience_count = 0\n",
    "        self.max_patience = 10\n",
    "        self.best_model = None\n",
    "\n",
    "    def lr_decay(self):\n",
    "        if self.patience_count >= self.max_patience:\n",
    "            self.current_learning_rate /= 10.0\n",
    "            self.patience_count = 0\n",
    "        elif self.last_val_loss == self.lowest_val_loss:\n",
    "            self.patience_count = 0\n",
    "        self.patience_count += 1\n",
    "\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def lr_decay_step(self, epoch):\n",
    "        if epoch == 25 or epoch == 50 or epoch == 75:\n",
    "            self.current_learning_rate /= 10.0\n",
    "        self.optimizer.learning_rate = self.current_learning_rate\n",
    "\n",
    "    def compute_loss(self, labels, outputs):\n",
    "        loss = 0.0\n",
    "        for output in outputs:\n",
    "            weights = tf.cast(labels > 0, dtype=tf.float32) * 81 + 1\n",
    "            # print(f'오류 출력 부 입니다. 가중치 : {weights},loss : {tf.math.square(labels - output) * weights}')\n",
    "            loss += tf.math.reduce_mean(\n",
    "                tf.math.square(labels - output) * weights) * (\n",
    "                    1. / self.global_batch_size)\n",
    "            \n",
    "\n",
    "        return loss\n",
    "\n",
    "    def train_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self.model(images, training=True)\n",
    "            loss = self.compute_loss(labels, outputs)\n",
    "            # print(f'computeloss출력값 입니다.: {loss}\\타입:{type(loss)}')\n",
    "\n",
    "        grads = tape.gradient(\n",
    "            target=loss, sources=self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def val_step(self, inputs):\n",
    "        images, labels = inputs\n",
    "        outputs = self.model(images, training=False)\n",
    "        loss = self.compute_loss(labels, outputs)\n",
    "        return loss\n",
    "\n",
    "    def run(self, train_dist_dataset, val_dist_dataset):\n",
    "        @tf.function\n",
    "        def distributed_train_epoch(dataset):\n",
    "            tf.print('Start distributed traininng...')\n",
    "            total_loss = 0.0\n",
    "            num_train_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.train_step, args=(one_batch, ))\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                total_loss += batch_loss\n",
    "                num_train_batches += 1\n",
    "                tf.print('Trained batch', num_train_batches, 'batch loss',\n",
    "                         batch_loss, 'epoch total loss', total_loss / num_train_batches)\n",
    "            return total_loss, num_train_batches\n",
    "\n",
    "        @tf.function\n",
    "        def distributed_val_epoch(dataset):\n",
    "            total_loss = 0.0\n",
    "            num_val_batches = 0.0\n",
    "            for one_batch in dataset:\n",
    "                per_replica_loss = self.strategy.run(\n",
    "                    self.val_step, args=(one_batch, ))\n",
    "                num_val_batches += 1\n",
    "                batch_loss = self.strategy.reduce(\n",
    "                    tf.distribute.ReduceOp.SUM, per_replica_loss, axis=None)\n",
    "                tf.print('Validated batch', num_val_batches, 'batch loss',\n",
    "                         batch_loss)\n",
    "                if not tf.math.is_nan(batch_loss):\n",
    "                    # TODO: Find out why the last validation batch loss become NaN\n",
    "                    total_loss += batch_loss\n",
    "                else:\n",
    "                    num_val_batches -= 1\n",
    "\n",
    "            return total_loss, num_val_batches\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            self.lr_decay()\n",
    "            print('Start epoch {} with learning rate {}'.format(\n",
    "                epoch, self.current_learning_rate))\n",
    "\n",
    "            train_total_loss, num_train_batches = distributed_train_epoch(\n",
    "                train_dist_dataset)\n",
    "            train_loss = train_total_loss / num_train_batches\n",
    "            print('Epoch {} train loss {}'.format(epoch, train_loss))\n",
    "\n",
    "            val_total_loss, num_val_batches = distributed_val_epoch(\n",
    "                val_dist_dataset)\n",
    "            val_loss = val_total_loss / num_val_batches\n",
    "            print('Epoch {} val loss {}'.format(epoch, val_loss))\n",
    "\n",
    "            # save model when reach a new lowest validation loss\n",
    "            if val_loss < self.lowest_val_loss:\n",
    "                self.save_model(epoch, val_loss)\n",
    "                self.lowest_val_loss = val_loss\n",
    "            self.last_val_loss = val_loss\n",
    "\n",
    "        return self.best_model\n",
    "\n",
    "    def save_model(self, epoch, loss):\n",
    "        model_name = MODEL_PATH + '/{}-epoch-{}-loss-{:.4f}.h5'.format(self.model.name,epoch, loss)\n",
    "        self.model.save_weights(model_name)\n",
    "        self.best_model = model_name\n",
    "        print(\"Model {} saved.\".format(model_name))\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e274d2f6",
   "metadata": {},
   "source": [
    "## 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7406da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (256, 256, 3)\n",
    "HEATMAP_SIZE = (64, 64)\n",
    "\n",
    "def create_dataset(tfrecords, batch_size, num_heatmap, is_train):\n",
    "    preprocess = Preprocessor(\n",
    "        IMAGE_SHAPE, (HEATMAP_SIZE[0], HEATMAP_SIZE[1], num_heatmap), is_train)\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(tfrecords)\n",
    "    dataset = tf.data.TFRecordDataset(dataset)\n",
    "    dataset = dataset.map(\n",
    "        preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if is_train:\n",
    "        dataset = dataset.shuffle(batch_size)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01e2b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def train(model_name, epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    global_batch_size = strategy.num_replicas_in_sync * batch_size\n",
    "    train_dataset = create_dataset(\n",
    "        train_tfrecords, global_batch_size, num_heatmap, is_train=True)\n",
    "    val_dataset = create_dataset(\n",
    "        val_tfrecords, global_batch_size, num_heatmap, is_train=False)\n",
    "\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        os.makedirs(MODEL_PATH)\n",
    "\n",
    "    with strategy.scope():\n",
    "        train_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            train_dataset)\n",
    "        val_dist_dataset = strategy.experimental_distribute_dataset(\n",
    "            val_dataset)\n",
    "        \n",
    "        if model_name == 'hourglass':\n",
    "            model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1, num_heatmap)\n",
    "        else:\n",
    "            model = Simplebaseline(IMAGE_SHAPE)\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model,\n",
    "            epochs,\n",
    "            global_batch_size,\n",
    "            strategy,\n",
    "            initial_learning_rate=learning_rate)\n",
    "\n",
    "        print('Start training...')\n",
    "#         print(f'출력 확인용 {train_dist_dataset},{val_dist_dataset}')\n",
    "#         print('출력확인용----------------------------------------------------------------------------------------------------')\n",
    "        return trainer.run(train_dist_dataset, val_dist_dataset)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db2a44",
   "metadata": {},
   "source": [
    "## StackedHourglassNetwork 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7019fbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Start training...\n",
      "Start epoch 1 with learning rate 0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:374: UserWarning: To make it possible to preserve tf.data options across serialization boundaries, their implementation has moved to be part of the TensorFlow graph. As a consequence, the options value is in general no longer known at graph construction time. Invoking this method in graph mode retains the legacy behavior of the original implementation, but note that the returned value might not reflect the actual value of the options.\n",
      "  warnings.warn(\"To make it possible to preserve tf.data options across \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 2.67813969 epoch total loss 2.67813969\n",
      "Trained batch 2 batch loss 2.50067186 epoch total loss 2.58940578\n",
      "Trained batch 3 batch loss 2.47201014 epoch total loss 2.5502739\n",
      "Trained batch 4 batch loss 2.40473533 epoch total loss 2.51388931\n",
      "Trained batch 5 batch loss 2.23392 epoch total loss 2.45789552\n",
      "Trained batch 6 batch loss 2.25848389 epoch total loss 2.42466021\n",
      "Trained batch 7 batch loss 2.20072985 epoch total loss 2.39267015\n",
      "Trained batch 8 batch loss 2.11750937 epoch total loss 2.35827518\n",
      "Trained batch 9 batch loss 2.0728817 epoch total loss 2.32656479\n",
      "Trained batch 10 batch loss 2.05813718 epoch total loss 2.29972219\n",
      "Trained batch 11 batch loss 2.01598263 epoch total loss 2.27392745\n",
      "Trained batch 12 batch loss 2.00051308 epoch total loss 2.25114298\n",
      "Trained batch 13 batch loss 2.02146602 epoch total loss 2.23347545\n",
      "Trained batch 14 batch loss 1.9406116 epoch total loss 2.2125566\n",
      "Trained batch 15 batch loss 1.97110319 epoch total loss 2.19645977\n",
      "Trained batch 16 batch loss 1.9453764 epoch total loss 2.18076706\n",
      "Trained batch 17 batch loss 1.96029389 epoch total loss 2.16779804\n",
      "Trained batch 18 batch loss 1.87588727 epoch total loss 2.15158081\n",
      "Trained batch 19 batch loss 2.01259971 epoch total loss 2.14426613\n",
      "Trained batch 20 batch loss 1.78692842 epoch total loss 2.12639928\n",
      "Trained batch 21 batch loss 1.7353282 epoch total loss 2.10777688\n",
      "Trained batch 22 batch loss 1.93938458 epoch total loss 2.10012269\n",
      "Trained batch 23 batch loss 1.98758101 epoch total loss 2.09522939\n",
      "Trained batch 24 batch loss 1.93272805 epoch total loss 2.08845854\n",
      "Trained batch 25 batch loss 1.94829798 epoch total loss 2.08285213\n",
      "Trained batch 26 batch loss 1.87012982 epoch total loss 2.07467055\n",
      "Trained batch 27 batch loss 1.95115507 epoch total loss 2.07009602\n",
      "Trained batch 28 batch loss 1.8921175 epoch total loss 2.06373954\n",
      "Trained batch 29 batch loss 1.92087388 epoch total loss 2.0588131\n",
      "Trained batch 30 batch loss 1.87846148 epoch total loss 2.05280137\n",
      "Trained batch 31 batch loss 1.91565633 epoch total loss 2.04837728\n",
      "Trained batch 32 batch loss 1.88134646 epoch total loss 2.04315758\n",
      "Trained batch 33 batch loss 1.88534868 epoch total loss 2.03837538\n",
      "Trained batch 34 batch loss 1.87909698 epoch total loss 2.03369069\n",
      "Trained batch 35 batch loss 1.85633373 epoch total loss 2.02862334\n",
      "Trained batch 36 batch loss 1.8241818 epoch total loss 2.02294445\n",
      "Trained batch 37 batch loss 1.80414653 epoch total loss 2.01703095\n",
      "Trained batch 38 batch loss 1.86277914 epoch total loss 2.01297164\n",
      "Trained batch 39 batch loss 1.84564018 epoch total loss 2.00868106\n",
      "Trained batch 40 batch loss 1.87797391 epoch total loss 2.00541353\n",
      "Trained batch 41 batch loss 1.81996465 epoch total loss 2.00089025\n",
      "Trained batch 42 batch loss 1.81540918 epoch total loss 1.99647391\n",
      "Trained batch 43 batch loss 1.76616275 epoch total loss 1.99111784\n",
      "Trained batch 44 batch loss 1.7569952 epoch total loss 1.98579681\n",
      "Trained batch 45 batch loss 1.69652867 epoch total loss 1.97936857\n",
      "Trained batch 46 batch loss 1.57996094 epoch total loss 1.97068584\n",
      "Trained batch 47 batch loss 1.56128287 epoch total loss 1.9619751\n",
      "Trained batch 48 batch loss 1.56515312 epoch total loss 1.95370805\n",
      "Trained batch 49 batch loss 1.69922936 epoch total loss 1.94851446\n",
      "Trained batch 50 batch loss 1.66014814 epoch total loss 1.94274724\n",
      "Trained batch 51 batch loss 1.76795924 epoch total loss 1.93932\n",
      "Trained batch 52 batch loss 1.7888577 epoch total loss 1.9364264\n",
      "Trained batch 53 batch loss 1.80075359 epoch total loss 1.9338665\n",
      "Trained batch 54 batch loss 1.85154653 epoch total loss 1.93234205\n",
      "Trained batch 55 batch loss 1.80445933 epoch total loss 1.93001699\n",
      "Trained batch 56 batch loss 1.82131505 epoch total loss 1.92807579\n",
      "Trained batch 57 batch loss 1.83119249 epoch total loss 1.9263761\n",
      "Trained batch 58 batch loss 1.71570432 epoch total loss 1.9227438\n",
      "Trained batch 59 batch loss 1.83675361 epoch total loss 1.92128634\n",
      "Trained batch 60 batch loss 1.86036468 epoch total loss 1.92027104\n",
      "Trained batch 61 batch loss 1.73151553 epoch total loss 1.91717672\n",
      "Trained batch 62 batch loss 1.75923848 epoch total loss 1.91462934\n",
      "Trained batch 63 batch loss 1.68540943 epoch total loss 1.91099083\n",
      "Trained batch 64 batch loss 1.57141781 epoch total loss 1.90568507\n",
      "Trained batch 65 batch loss 1.63767779 epoch total loss 1.90156186\n",
      "Trained batch 66 batch loss 1.62993598 epoch total loss 1.89744639\n",
      "Trained batch 67 batch loss 1.68964362 epoch total loss 1.89434481\n",
      "Trained batch 68 batch loss 1.63411725 epoch total loss 1.89051795\n",
      "Trained batch 69 batch loss 1.50311828 epoch total loss 1.88490343\n",
      "Trained batch 70 batch loss 1.58415306 epoch total loss 1.88060701\n",
      "Trained batch 71 batch loss 1.64241755 epoch total loss 1.8772521\n",
      "Trained batch 72 batch loss 1.57281947 epoch total loss 1.87302375\n",
      "Trained batch 73 batch loss 1.70405781 epoch total loss 1.87070918\n",
      "Trained batch 74 batch loss 1.7163763 epoch total loss 1.8686235\n",
      "Trained batch 75 batch loss 1.80203271 epoch total loss 1.86773562\n",
      "Trained batch 76 batch loss 1.77933 epoch total loss 1.86657238\n",
      "Trained batch 77 batch loss 1.73253572 epoch total loss 1.86483145\n",
      "Trained batch 78 batch loss 1.793033 epoch total loss 1.86391091\n",
      "Trained batch 79 batch loss 1.69054687 epoch total loss 1.86171651\n",
      "Trained batch 80 batch loss 1.54576564 epoch total loss 1.85776711\n",
      "Trained batch 81 batch loss 1.580755 epoch total loss 1.85434711\n",
      "Trained batch 82 batch loss 1.74637532 epoch total loss 1.85303032\n",
      "Trained batch 83 batch loss 1.74420321 epoch total loss 1.85171914\n",
      "Trained batch 84 batch loss 1.70697081 epoch total loss 1.84999597\n",
      "Trained batch 85 batch loss 1.72654223 epoch total loss 1.84854364\n",
      "Trained batch 86 batch loss 1.79815602 epoch total loss 1.84795773\n",
      "Trained batch 87 batch loss 1.6090064 epoch total loss 1.84521115\n",
      "Trained batch 88 batch loss 1.53122973 epoch total loss 1.84164321\n",
      "Trained batch 89 batch loss 1.61436987 epoch total loss 1.83908951\n",
      "Trained batch 90 batch loss 1.76529765 epoch total loss 1.83826971\n",
      "Trained batch 91 batch loss 1.65245521 epoch total loss 1.83622777\n",
      "Trained batch 92 batch loss 1.67517734 epoch total loss 1.83447719\n",
      "Trained batch 93 batch loss 1.71763873 epoch total loss 1.83322072\n",
      "Trained batch 94 batch loss 1.70934045 epoch total loss 1.83190286\n",
      "Trained batch 95 batch loss 1.79811156 epoch total loss 1.83154714\n",
      "Trained batch 96 batch loss 1.71355867 epoch total loss 1.83031809\n",
      "Trained batch 97 batch loss 1.77649355 epoch total loss 1.82976317\n",
      "Trained batch 98 batch loss 1.72472656 epoch total loss 1.82869148\n",
      "Trained batch 99 batch loss 1.68499756 epoch total loss 1.82724\n",
      "Trained batch 100 batch loss 1.73456 epoch total loss 1.82631314\n",
      "Trained batch 101 batch loss 1.76137018 epoch total loss 1.82567012\n",
      "Trained batch 102 batch loss 1.73104489 epoch total loss 1.82474244\n",
      "Trained batch 103 batch loss 1.74903274 epoch total loss 1.82400751\n",
      "Trained batch 104 batch loss 1.72125101 epoch total loss 1.8230195\n",
      "Trained batch 105 batch loss 1.7337271 epoch total loss 1.82216918\n",
      "Trained batch 106 batch loss 1.69660044 epoch total loss 1.82098448\n",
      "Trained batch 107 batch loss 1.74742544 epoch total loss 1.820297\n",
      "Trained batch 108 batch loss 1.72941899 epoch total loss 1.8194555\n",
      "Trained batch 109 batch loss 1.58936191 epoch total loss 1.81734443\n",
      "Trained batch 110 batch loss 1.65349507 epoch total loss 1.81585491\n",
      "Trained batch 111 batch loss 1.60710084 epoch total loss 1.81397414\n",
      "Trained batch 112 batch loss 1.6702435 epoch total loss 1.81269085\n",
      "Trained batch 113 batch loss 1.61146736 epoch total loss 1.81091011\n",
      "Trained batch 114 batch loss 1.59792662 epoch total loss 1.80904186\n",
      "Trained batch 115 batch loss 1.59738731 epoch total loss 1.80720139\n",
      "Trained batch 116 batch loss 1.68725371 epoch total loss 1.80616736\n",
      "Trained batch 117 batch loss 1.69694281 epoch total loss 1.80523384\n",
      "Trained batch 118 batch loss 1.55887413 epoch total loss 1.803146\n",
      "Trained batch 119 batch loss 1.38783014 epoch total loss 1.79965591\n",
      "Trained batch 120 batch loss 1.48715043 epoch total loss 1.79705179\n",
      "Trained batch 121 batch loss 1.63596535 epoch total loss 1.79572046\n",
      "Trained batch 122 batch loss 1.56700146 epoch total loss 1.79384577\n",
      "Trained batch 123 batch loss 1.61308384 epoch total loss 1.79237616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 124 batch loss 1.58649802 epoch total loss 1.79071581\n",
      "Trained batch 125 batch loss 1.65689039 epoch total loss 1.78964531\n",
      "Trained batch 126 batch loss 1.7111237 epoch total loss 1.78902209\n",
      "Trained batch 127 batch loss 1.59336448 epoch total loss 1.78748143\n",
      "Trained batch 128 batch loss 1.72284889 epoch total loss 1.78697658\n",
      "Trained batch 129 batch loss 1.8289088 epoch total loss 1.78730154\n",
      "Trained batch 130 batch loss 1.80223513 epoch total loss 1.78741646\n",
      "Trained batch 131 batch loss 1.73032904 epoch total loss 1.78698063\n",
      "Trained batch 132 batch loss 1.57320297 epoch total loss 1.78536105\n",
      "Trained batch 133 batch loss 1.6834445 epoch total loss 1.78459477\n",
      "Trained batch 134 batch loss 1.55167341 epoch total loss 1.78285646\n",
      "Trained batch 135 batch loss 1.71289825 epoch total loss 1.78233826\n",
      "Trained batch 136 batch loss 1.73194528 epoch total loss 1.78196776\n",
      "Trained batch 137 batch loss 1.7610575 epoch total loss 1.78181517\n",
      "Trained batch 138 batch loss 1.71946394 epoch total loss 1.78136337\n",
      "Trained batch 139 batch loss 1.70262742 epoch total loss 1.78079689\n",
      "Trained batch 140 batch loss 1.67056656 epoch total loss 1.78000951\n",
      "Trained batch 141 batch loss 1.64608574 epoch total loss 1.77905965\n",
      "Trained batch 142 batch loss 1.66310561 epoch total loss 1.77824306\n",
      "Trained batch 143 batch loss 1.65437865 epoch total loss 1.77737677\n",
      "Trained batch 144 batch loss 1.65886903 epoch total loss 1.77655387\n",
      "Trained batch 145 batch loss 1.68915129 epoch total loss 1.77595115\n",
      "Trained batch 146 batch loss 1.70221329 epoch total loss 1.77544606\n",
      "Trained batch 147 batch loss 1.71499872 epoch total loss 1.77503479\n",
      "Trained batch 148 batch loss 1.70912981 epoch total loss 1.77458954\n",
      "Trained batch 149 batch loss 1.6271987 epoch total loss 1.77360034\n",
      "Trained batch 150 batch loss 1.66063023 epoch total loss 1.77284729\n",
      "Trained batch 151 batch loss 1.62499261 epoch total loss 1.77186811\n",
      "Trained batch 152 batch loss 1.60311556 epoch total loss 1.77075803\n",
      "Trained batch 153 batch loss 1.66099763 epoch total loss 1.77004063\n",
      "Trained batch 154 batch loss 1.57787967 epoch total loss 1.76879287\n",
      "Trained batch 155 batch loss 1.6901412 epoch total loss 1.76828551\n",
      "Trained batch 156 batch loss 1.67862988 epoch total loss 1.7677108\n",
      "Trained batch 157 batch loss 1.63945842 epoch total loss 1.76689386\n",
      "Trained batch 158 batch loss 1.64896 epoch total loss 1.76614749\n",
      "Trained batch 159 batch loss 1.67964065 epoch total loss 1.7656033\n",
      "Trained batch 160 batch loss 1.62342453 epoch total loss 1.7647146\n",
      "Trained batch 161 batch loss 1.52992129 epoch total loss 1.76325619\n",
      "Trained batch 162 batch loss 1.62295842 epoch total loss 1.76239014\n",
      "Trained batch 163 batch loss 1.72277713 epoch total loss 1.76214707\n",
      "Trained batch 164 batch loss 1.63782465 epoch total loss 1.76138902\n",
      "Trained batch 165 batch loss 1.74289548 epoch total loss 1.76127684\n",
      "Trained batch 166 batch loss 1.68822372 epoch total loss 1.76083684\n",
      "Trained batch 167 batch loss 1.55884933 epoch total loss 1.75962734\n",
      "Trained batch 168 batch loss 1.64947367 epoch total loss 1.75897157\n",
      "Trained batch 169 batch loss 1.68007898 epoch total loss 1.75850487\n",
      "Trained batch 170 batch loss 1.65472293 epoch total loss 1.7578944\n",
      "Trained batch 171 batch loss 1.51286221 epoch total loss 1.75646138\n",
      "Trained batch 172 batch loss 1.6344285 epoch total loss 1.75575185\n",
      "Trained batch 173 batch loss 1.61518908 epoch total loss 1.75493944\n",
      "Trained batch 174 batch loss 1.64287007 epoch total loss 1.75429547\n",
      "Trained batch 175 batch loss 1.66493392 epoch total loss 1.75378489\n",
      "Trained batch 176 batch loss 1.62392867 epoch total loss 1.75304711\n",
      "Trained batch 177 batch loss 1.73860681 epoch total loss 1.75296557\n",
      "Trained batch 178 batch loss 1.81556654 epoch total loss 1.75331712\n",
      "Trained batch 179 batch loss 1.78379858 epoch total loss 1.75348759\n",
      "Trained batch 180 batch loss 1.71608543 epoch total loss 1.75327981\n",
      "Trained batch 181 batch loss 1.74944496 epoch total loss 1.75325859\n",
      "Trained batch 182 batch loss 1.64462566 epoch total loss 1.75266171\n",
      "Trained batch 183 batch loss 1.41379476 epoch total loss 1.75080991\n",
      "Trained batch 184 batch loss 1.66554391 epoch total loss 1.75034666\n",
      "Trained batch 185 batch loss 1.65169668 epoch total loss 1.74981344\n",
      "Trained batch 186 batch loss 1.68863177 epoch total loss 1.74948454\n",
      "Trained batch 187 batch loss 1.53544545 epoch total loss 1.74833977\n",
      "Trained batch 188 batch loss 1.57989156 epoch total loss 1.7474438\n",
      "Trained batch 189 batch loss 1.61868548 epoch total loss 1.74676251\n",
      "Trained batch 190 batch loss 1.58402061 epoch total loss 1.745906\n",
      "Trained batch 191 batch loss 1.58180332 epoch total loss 1.74504685\n",
      "Trained batch 192 batch loss 1.68186498 epoch total loss 1.74471772\n",
      "Trained batch 193 batch loss 1.62571144 epoch total loss 1.74410105\n",
      "Trained batch 194 batch loss 1.61243498 epoch total loss 1.74342239\n",
      "Trained batch 195 batch loss 1.69873214 epoch total loss 1.74319315\n",
      "Trained batch 196 batch loss 1.60095811 epoch total loss 1.7424674\n",
      "Trained batch 197 batch loss 1.62906015 epoch total loss 1.74189174\n",
      "Trained batch 198 batch loss 1.67192841 epoch total loss 1.74153841\n",
      "Trained batch 199 batch loss 1.69932759 epoch total loss 1.74132645\n",
      "Trained batch 200 batch loss 1.64334416 epoch total loss 1.7408365\n",
      "Trained batch 201 batch loss 1.69318223 epoch total loss 1.74059939\n",
      "Trained batch 202 batch loss 1.68897927 epoch total loss 1.74034381\n",
      "Trained batch 203 batch loss 1.66816795 epoch total loss 1.73998833\n",
      "Trained batch 204 batch loss 1.62450504 epoch total loss 1.7394222\n",
      "Trained batch 205 batch loss 1.69643974 epoch total loss 1.73921251\n",
      "Trained batch 206 batch loss 1.63536298 epoch total loss 1.7387085\n",
      "Trained batch 207 batch loss 1.67033684 epoch total loss 1.73837829\n",
      "Trained batch 208 batch loss 1.52869725 epoch total loss 1.73737013\n",
      "Trained batch 209 batch loss 1.73665702 epoch total loss 1.7373668\n",
      "Trained batch 210 batch loss 1.69092178 epoch total loss 1.73714554\n",
      "Trained batch 211 batch loss 1.68547773 epoch total loss 1.73690069\n",
      "Trained batch 212 batch loss 1.72187245 epoch total loss 1.73682976\n",
      "Trained batch 213 batch loss 1.85043514 epoch total loss 1.7373631\n",
      "Trained batch 214 batch loss 1.73497534 epoch total loss 1.73735201\n",
      "Trained batch 215 batch loss 1.75639367 epoch total loss 1.73744071\n",
      "Trained batch 216 batch loss 1.62900782 epoch total loss 1.7369386\n",
      "Trained batch 217 batch loss 1.65950072 epoch total loss 1.7365818\n",
      "Trained batch 218 batch loss 1.61342 epoch total loss 1.73601699\n",
      "Trained batch 219 batch loss 1.64964867 epoch total loss 1.73562264\n",
      "Trained batch 220 batch loss 1.65506124 epoch total loss 1.73525643\n",
      "Trained batch 221 batch loss 1.58960819 epoch total loss 1.73459733\n",
      "Trained batch 222 batch loss 1.44209218 epoch total loss 1.73327971\n",
      "Trained batch 223 batch loss 1.60859478 epoch total loss 1.73272049\n",
      "Trained batch 224 batch loss 1.64605319 epoch total loss 1.73233354\n",
      "Trained batch 225 batch loss 1.71810961 epoch total loss 1.73227036\n",
      "Trained batch 226 batch loss 1.60922849 epoch total loss 1.73172593\n",
      "Trained batch 227 batch loss 1.6183356 epoch total loss 1.73122644\n",
      "Trained batch 228 batch loss 1.5177958 epoch total loss 1.73029029\n",
      "Trained batch 229 batch loss 1.63614714 epoch total loss 1.72987914\n",
      "Trained batch 230 batch loss 1.53880644 epoch total loss 1.72904849\n",
      "Trained batch 231 batch loss 1.58663273 epoch total loss 1.72843194\n",
      "Trained batch 232 batch loss 1.63011312 epoch total loss 1.72800827\n",
      "Trained batch 233 batch loss 1.66494489 epoch total loss 1.72773767\n",
      "Trained batch 234 batch loss 1.70601165 epoch total loss 1.7276448\n",
      "Trained batch 235 batch loss 1.68655705 epoch total loss 1.72746992\n",
      "Trained batch 236 batch loss 1.73259473 epoch total loss 1.72749174\n",
      "Trained batch 237 batch loss 1.71192026 epoch total loss 1.72742605\n",
      "Trained batch 238 batch loss 1.60368633 epoch total loss 1.72690618\n",
      "Trained batch 239 batch loss 1.35342574 epoch total loss 1.72534347\n",
      "Trained batch 240 batch loss 1.4086659 epoch total loss 1.72402394\n",
      "Trained batch 241 batch loss 1.5077554 epoch total loss 1.72312653\n",
      "Trained batch 242 batch loss 1.52454114 epoch total loss 1.72230589\n",
      "Trained batch 243 batch loss 1.54962361 epoch total loss 1.72159529\n",
      "Trained batch 244 batch loss 1.63394749 epoch total loss 1.72123611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 245 batch loss 1.60906947 epoch total loss 1.72077823\n",
      "Trained batch 246 batch loss 1.57220376 epoch total loss 1.72017431\n",
      "Trained batch 247 batch loss 1.68672645 epoch total loss 1.72003889\n",
      "Trained batch 248 batch loss 1.57828903 epoch total loss 1.71946728\n",
      "Trained batch 249 batch loss 1.61731219 epoch total loss 1.71905696\n",
      "Trained batch 250 batch loss 1.55957532 epoch total loss 1.71841908\n",
      "Trained batch 251 batch loss 1.50781119 epoch total loss 1.71758\n",
      "Trained batch 252 batch loss 1.56393313 epoch total loss 1.71697032\n",
      "Trained batch 253 batch loss 1.50760508 epoch total loss 1.71614277\n",
      "Trained batch 254 batch loss 1.59319925 epoch total loss 1.71565866\n",
      "Trained batch 255 batch loss 1.66036749 epoch total loss 1.71544194\n",
      "Trained batch 256 batch loss 1.73453069 epoch total loss 1.71551645\n",
      "Trained batch 257 batch loss 1.59287596 epoch total loss 1.71503925\n",
      "Trained batch 258 batch loss 1.58290493 epoch total loss 1.71452713\n",
      "Trained batch 259 batch loss 1.45760214 epoch total loss 1.71353519\n",
      "Trained batch 260 batch loss 1.46462822 epoch total loss 1.71257782\n",
      "Trained batch 261 batch loss 1.50182176 epoch total loss 1.71177042\n",
      "Trained batch 262 batch loss 1.62069273 epoch total loss 1.7114228\n",
      "Trained batch 263 batch loss 1.64826119 epoch total loss 1.71118259\n",
      "Trained batch 264 batch loss 1.62372494 epoch total loss 1.71085131\n",
      "Trained batch 265 batch loss 1.54304945 epoch total loss 1.71021807\n",
      "Trained batch 266 batch loss 1.52209365 epoch total loss 1.7095108\n",
      "Trained batch 267 batch loss 1.53036559 epoch total loss 1.70883989\n",
      "Trained batch 268 batch loss 1.57940733 epoch total loss 1.70835698\n",
      "Trained batch 269 batch loss 1.59500039 epoch total loss 1.70793557\n",
      "Trained batch 270 batch loss 1.45258164 epoch total loss 1.70698977\n",
      "Trained batch 271 batch loss 1.55587 epoch total loss 1.7064321\n",
      "Trained batch 272 batch loss 1.62884951 epoch total loss 1.70614696\n",
      "Trained batch 273 batch loss 1.62547696 epoch total loss 1.70585144\n",
      "Trained batch 274 batch loss 1.57370281 epoch total loss 1.70536911\n",
      "Trained batch 275 batch loss 1.64411259 epoch total loss 1.70514643\n",
      "Trained batch 276 batch loss 1.54044938 epoch total loss 1.70454955\n",
      "Trained batch 277 batch loss 1.59694326 epoch total loss 1.70416117\n",
      "Trained batch 278 batch loss 1.54022741 epoch total loss 1.70357144\n",
      "Trained batch 279 batch loss 1.4898138 epoch total loss 1.70280528\n",
      "Trained batch 280 batch loss 1.56972265 epoch total loss 1.70233\n",
      "Trained batch 281 batch loss 1.61082959 epoch total loss 1.70200443\n",
      "Trained batch 282 batch loss 1.62330115 epoch total loss 1.70172524\n",
      "Trained batch 283 batch loss 1.60601771 epoch total loss 1.70138717\n",
      "Trained batch 284 batch loss 1.63698435 epoch total loss 1.70116043\n",
      "Trained batch 285 batch loss 1.55717778 epoch total loss 1.70065522\n",
      "Trained batch 286 batch loss 1.63772535 epoch total loss 1.70043516\n",
      "Trained batch 287 batch loss 1.6106174 epoch total loss 1.70012224\n",
      "Trained batch 288 batch loss 1.62588501 epoch total loss 1.69986451\n",
      "Trained batch 289 batch loss 1.53040755 epoch total loss 1.69927812\n",
      "Trained batch 290 batch loss 1.59818673 epoch total loss 1.69892943\n",
      "Trained batch 291 batch loss 1.56841564 epoch total loss 1.69848096\n",
      "Trained batch 292 batch loss 1.63372898 epoch total loss 1.69825923\n",
      "Trained batch 293 batch loss 1.57923079 epoch total loss 1.69785297\n",
      "Trained batch 294 batch loss 1.5707891 epoch total loss 1.69742084\n",
      "Trained batch 295 batch loss 1.59369755 epoch total loss 1.69706917\n",
      "Trained batch 296 batch loss 1.63211954 epoch total loss 1.6968497\n",
      "Trained batch 297 batch loss 1.64641678 epoch total loss 1.69668\n",
      "Trained batch 298 batch loss 1.68343067 epoch total loss 1.69663548\n",
      "Trained batch 299 batch loss 1.67760158 epoch total loss 1.69657183\n",
      "Trained batch 300 batch loss 1.64039099 epoch total loss 1.69638455\n",
      "Trained batch 301 batch loss 1.64754701 epoch total loss 1.69622231\n",
      "Trained batch 302 batch loss 1.63522911 epoch total loss 1.69602048\n",
      "Trained batch 303 batch loss 1.66069436 epoch total loss 1.6959039\n",
      "Trained batch 304 batch loss 1.64483976 epoch total loss 1.69573593\n",
      "Trained batch 305 batch loss 1.60481787 epoch total loss 1.69543779\n",
      "Trained batch 306 batch loss 1.6096617 epoch total loss 1.69515753\n",
      "Trained batch 307 batch loss 1.62055027 epoch total loss 1.69491446\n",
      "Trained batch 308 batch loss 1.54478097 epoch total loss 1.69442713\n",
      "Trained batch 309 batch loss 1.58096027 epoch total loss 1.69405985\n",
      "Trained batch 310 batch loss 1.60600257 epoch total loss 1.69377577\n",
      "Trained batch 311 batch loss 1.54773736 epoch total loss 1.69330621\n",
      "Trained batch 312 batch loss 1.57069802 epoch total loss 1.69291317\n",
      "Trained batch 313 batch loss 1.61987877 epoch total loss 1.69267976\n",
      "Trained batch 314 batch loss 1.62924194 epoch total loss 1.6924777\n",
      "Trained batch 315 batch loss 1.67182279 epoch total loss 1.69241202\n",
      "Trained batch 316 batch loss 1.68154025 epoch total loss 1.69237757\n",
      "Trained batch 317 batch loss 1.65931857 epoch total loss 1.69227326\n",
      "Trained batch 318 batch loss 1.6406405 epoch total loss 1.6921109\n",
      "Trained batch 319 batch loss 1.64866829 epoch total loss 1.69197476\n",
      "Trained batch 320 batch loss 1.60516667 epoch total loss 1.69170344\n",
      "Trained batch 321 batch loss 1.68565488 epoch total loss 1.6916846\n",
      "Trained batch 322 batch loss 1.73011255 epoch total loss 1.69180393\n",
      "Trained batch 323 batch loss 1.70581543 epoch total loss 1.69184732\n",
      "Trained batch 324 batch loss 1.64896381 epoch total loss 1.691715\n",
      "Trained batch 325 batch loss 1.59249103 epoch total loss 1.69140959\n",
      "Trained batch 326 batch loss 1.68977761 epoch total loss 1.69140458\n",
      "Trained batch 327 batch loss 1.70316029 epoch total loss 1.69144058\n",
      "Trained batch 328 batch loss 1.67130864 epoch total loss 1.69137931\n",
      "Trained batch 329 batch loss 1.58415318 epoch total loss 1.69105339\n",
      "Trained batch 330 batch loss 1.54637527 epoch total loss 1.69061506\n",
      "Trained batch 331 batch loss 1.48847783 epoch total loss 1.69000423\n",
      "Trained batch 332 batch loss 1.59429955 epoch total loss 1.68971598\n",
      "Trained batch 333 batch loss 1.60753167 epoch total loss 1.68946922\n",
      "Trained batch 334 batch loss 1.54224706 epoch total loss 1.68902838\n",
      "Trained batch 335 batch loss 1.64149499 epoch total loss 1.68888652\n",
      "Trained batch 336 batch loss 1.51942122 epoch total loss 1.68838215\n",
      "Trained batch 337 batch loss 1.5888834 epoch total loss 1.68808675\n",
      "Trained batch 338 batch loss 1.61412 epoch total loss 1.687868\n",
      "Trained batch 339 batch loss 1.66188741 epoch total loss 1.68779135\n",
      "Trained batch 340 batch loss 1.60872626 epoch total loss 1.68755865\n",
      "Trained batch 341 batch loss 1.65750384 epoch total loss 1.68747067\n",
      "Trained batch 342 batch loss 1.60584569 epoch total loss 1.6872319\n",
      "Trained batch 343 batch loss 1.60058117 epoch total loss 1.68697929\n",
      "Trained batch 344 batch loss 1.5811801 epoch total loss 1.68667173\n",
      "Trained batch 345 batch loss 1.53386259 epoch total loss 1.68622887\n",
      "Trained batch 346 batch loss 1.63567936 epoch total loss 1.68608284\n",
      "Trained batch 347 batch loss 1.55726445 epoch total loss 1.6857115\n",
      "Trained batch 348 batch loss 1.3349874 epoch total loss 1.68470359\n",
      "Trained batch 349 batch loss 1.38213527 epoch total loss 1.6838367\n",
      "Trained batch 350 batch loss 1.37901914 epoch total loss 1.68296576\n",
      "Trained batch 351 batch loss 1.62445676 epoch total loss 1.6827991\n",
      "Trained batch 352 batch loss 1.77359283 epoch total loss 1.68305707\n",
      "Trained batch 353 batch loss 1.66237545 epoch total loss 1.68299842\n",
      "Trained batch 354 batch loss 1.56502748 epoch total loss 1.68266511\n",
      "Trained batch 355 batch loss 1.42482376 epoch total loss 1.68193877\n",
      "Trained batch 356 batch loss 1.70624387 epoch total loss 1.68200696\n",
      "Trained batch 357 batch loss 1.65436888 epoch total loss 1.68192959\n",
      "Trained batch 358 batch loss 1.64695311 epoch total loss 1.68183196\n",
      "Trained batch 359 batch loss 1.64286304 epoch total loss 1.68172348\n",
      "Trained batch 360 batch loss 1.6139003 epoch total loss 1.68153501\n",
      "Trained batch 361 batch loss 1.65379477 epoch total loss 1.68145823\n",
      "Trained batch 362 batch loss 1.58532774 epoch total loss 1.68119264\n",
      "Trained batch 363 batch loss 1.61016774 epoch total loss 1.68099701\n",
      "Trained batch 364 batch loss 1.50883007 epoch total loss 1.68052399\n",
      "Trained batch 365 batch loss 1.64076495 epoch total loss 1.68041503\n",
      "Trained batch 366 batch loss 1.57015061 epoch total loss 1.68011379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 367 batch loss 1.61669695 epoch total loss 1.67994094\n",
      "Trained batch 368 batch loss 1.42198682 epoch total loss 1.67924\n",
      "Trained batch 369 batch loss 1.36734426 epoch total loss 1.67839479\n",
      "Trained batch 370 batch loss 1.62919784 epoch total loss 1.67826188\n",
      "Trained batch 371 batch loss 1.66391087 epoch total loss 1.67822337\n",
      "Trained batch 372 batch loss 1.52364373 epoch total loss 1.67780769\n",
      "Trained batch 373 batch loss 1.63295603 epoch total loss 1.67768741\n",
      "Trained batch 374 batch loss 1.55836368 epoch total loss 1.67736828\n",
      "Trained batch 375 batch loss 1.66024876 epoch total loss 1.67732275\n",
      "Trained batch 376 batch loss 1.54710603 epoch total loss 1.67697644\n",
      "Trained batch 377 batch loss 1.61202085 epoch total loss 1.67680407\n",
      "Trained batch 378 batch loss 1.62321281 epoch total loss 1.67666233\n",
      "Trained batch 379 batch loss 1.491431 epoch total loss 1.67617369\n",
      "Trained batch 380 batch loss 1.48141062 epoch total loss 1.67566109\n",
      "Trained batch 381 batch loss 1.60450232 epoch total loss 1.67547429\n",
      "Trained batch 382 batch loss 1.59395981 epoch total loss 1.6752609\n",
      "Trained batch 383 batch loss 1.56938362 epoch total loss 1.67498446\n",
      "Trained batch 384 batch loss 1.61783886 epoch total loss 1.67483568\n",
      "Trained batch 385 batch loss 1.58444369 epoch total loss 1.67460096\n",
      "Trained batch 386 batch loss 1.54081392 epoch total loss 1.67425442\n",
      "Trained batch 387 batch loss 1.52728927 epoch total loss 1.67387462\n",
      "Trained batch 388 batch loss 1.62570345 epoch total loss 1.67375052\n",
      "Trained batch 389 batch loss 1.67535472 epoch total loss 1.67375469\n",
      "Trained batch 390 batch loss 1.59441483 epoch total loss 1.67355132\n",
      "Trained batch 391 batch loss 1.54636371 epoch total loss 1.673226\n",
      "Trained batch 392 batch loss 1.57843065 epoch total loss 1.67298424\n",
      "Trained batch 393 batch loss 1.53145385 epoch total loss 1.67262399\n",
      "Trained batch 394 batch loss 1.67041373 epoch total loss 1.67261839\n",
      "Trained batch 395 batch loss 1.62522626 epoch total loss 1.67249846\n",
      "Trained batch 396 batch loss 1.69358444 epoch total loss 1.67255175\n",
      "Trained batch 397 batch loss 1.70560598 epoch total loss 1.67263508\n",
      "Trained batch 398 batch loss 1.48588037 epoch total loss 1.67216587\n",
      "Trained batch 399 batch loss 1.51212752 epoch total loss 1.67176485\n",
      "Trained batch 400 batch loss 1.48128939 epoch total loss 1.67128861\n",
      "Trained batch 401 batch loss 1.59198666 epoch total loss 1.67109084\n",
      "Trained batch 402 batch loss 1.53013599 epoch total loss 1.67074025\n",
      "Trained batch 403 batch loss 1.57598257 epoch total loss 1.67050517\n",
      "Trained batch 404 batch loss 1.61462307 epoch total loss 1.67036676\n",
      "Trained batch 405 batch loss 1.60161734 epoch total loss 1.67019701\n",
      "Trained batch 406 batch loss 1.58817458 epoch total loss 1.66999507\n",
      "Trained batch 407 batch loss 1.57223678 epoch total loss 1.66975498\n",
      "Trained batch 408 batch loss 1.602808 epoch total loss 1.66959083\n",
      "Trained batch 409 batch loss 1.61894369 epoch total loss 1.66946697\n",
      "Trained batch 410 batch loss 1.57737899 epoch total loss 1.6692425\n",
      "Trained batch 411 batch loss 1.55651951 epoch total loss 1.6689682\n",
      "Trained batch 412 batch loss 1.57969904 epoch total loss 1.6687516\n",
      "Trained batch 413 batch loss 1.64809525 epoch total loss 1.66870141\n",
      "Trained batch 414 batch loss 1.60073471 epoch total loss 1.66853726\n",
      "Trained batch 415 batch loss 1.58156013 epoch total loss 1.66832757\n",
      "Trained batch 416 batch loss 1.61665905 epoch total loss 1.66820335\n",
      "Trained batch 417 batch loss 1.63442969 epoch total loss 1.66812229\n",
      "Trained batch 418 batch loss 1.61801362 epoch total loss 1.66800249\n",
      "Trained batch 419 batch loss 1.61724401 epoch total loss 1.66788137\n",
      "Trained batch 420 batch loss 1.51935542 epoch total loss 1.66752768\n",
      "Trained batch 421 batch loss 1.51626968 epoch total loss 1.6671685\n",
      "Trained batch 422 batch loss 1.44315648 epoch total loss 1.66663766\n",
      "Trained batch 423 batch loss 1.44963491 epoch total loss 1.6661247\n",
      "Trained batch 424 batch loss 1.39917421 epoch total loss 1.66549516\n",
      "Trained batch 425 batch loss 1.39265513 epoch total loss 1.6648531\n",
      "Trained batch 426 batch loss 1.33306861 epoch total loss 1.6640743\n",
      "Trained batch 427 batch loss 1.29842961 epoch total loss 1.6632179\n",
      "Trained batch 428 batch loss 1.25191712 epoch total loss 1.66225684\n",
      "Trained batch 429 batch loss 1.51663756 epoch total loss 1.66191745\n",
      "Trained batch 430 batch loss 1.60327339 epoch total loss 1.66178107\n",
      "Trained batch 431 batch loss 1.67269278 epoch total loss 1.66180634\n",
      "Trained batch 432 batch loss 1.58172965 epoch total loss 1.66162097\n",
      "Trained batch 433 batch loss 1.57094359 epoch total loss 1.66141152\n",
      "Trained batch 434 batch loss 1.59544683 epoch total loss 1.66125953\n",
      "Trained batch 435 batch loss 1.51461577 epoch total loss 1.66092229\n",
      "Trained batch 436 batch loss 1.54832911 epoch total loss 1.66066408\n",
      "Trained batch 437 batch loss 1.61203885 epoch total loss 1.66055286\n",
      "Trained batch 438 batch loss 1.57499516 epoch total loss 1.66035759\n",
      "Trained batch 439 batch loss 1.59834564 epoch total loss 1.66021633\n",
      "Trained batch 440 batch loss 1.64294565 epoch total loss 1.66017711\n",
      "Trained batch 441 batch loss 1.57416594 epoch total loss 1.65998197\n",
      "Trained batch 442 batch loss 1.65286791 epoch total loss 1.65996599\n",
      "Trained batch 443 batch loss 1.63773429 epoch total loss 1.6599158\n",
      "Trained batch 444 batch loss 1.59836757 epoch total loss 1.65977728\n",
      "Trained batch 445 batch loss 1.49874592 epoch total loss 1.65941536\n",
      "Trained batch 446 batch loss 1.39412236 epoch total loss 1.65882051\n",
      "Trained batch 447 batch loss 1.44400918 epoch total loss 1.65834\n",
      "Trained batch 448 batch loss 1.46000838 epoch total loss 1.65789723\n",
      "Trained batch 449 batch loss 1.51046658 epoch total loss 1.65756881\n",
      "Trained batch 450 batch loss 1.5411582 epoch total loss 1.65731013\n",
      "Trained batch 451 batch loss 1.52276349 epoch total loss 1.65701175\n",
      "Trained batch 452 batch loss 1.47275496 epoch total loss 1.65660417\n",
      "Trained batch 453 batch loss 1.45505142 epoch total loss 1.65615928\n",
      "Trained batch 454 batch loss 1.46795166 epoch total loss 1.65574479\n",
      "Trained batch 455 batch loss 1.41720772 epoch total loss 1.65522063\n",
      "Trained batch 456 batch loss 1.49306691 epoch total loss 1.65486491\n",
      "Trained batch 457 batch loss 1.49361265 epoch total loss 1.65451205\n",
      "Trained batch 458 batch loss 1.56105125 epoch total loss 1.65430796\n",
      "Trained batch 459 batch loss 1.65678251 epoch total loss 1.65431333\n",
      "Trained batch 460 batch loss 1.62705255 epoch total loss 1.6542542\n",
      "Trained batch 461 batch loss 1.67128491 epoch total loss 1.65429103\n",
      "Trained batch 462 batch loss 1.6103344 epoch total loss 1.6541959\n",
      "Trained batch 463 batch loss 1.5713284 epoch total loss 1.65401697\n",
      "Trained batch 464 batch loss 1.55135965 epoch total loss 1.65379572\n",
      "Trained batch 465 batch loss 1.52370965 epoch total loss 1.65351593\n",
      "Trained batch 466 batch loss 1.59103274 epoch total loss 1.65338171\n",
      "Trained batch 467 batch loss 1.64039755 epoch total loss 1.65335393\n",
      "Trained batch 468 batch loss 1.66875052 epoch total loss 1.65338683\n",
      "Trained batch 469 batch loss 1.7297411 epoch total loss 1.65354967\n",
      "Trained batch 470 batch loss 1.70847845 epoch total loss 1.6536665\n",
      "Trained batch 471 batch loss 1.75260115 epoch total loss 1.65387666\n",
      "Trained batch 472 batch loss 1.65145063 epoch total loss 1.65387142\n",
      "Trained batch 473 batch loss 1.76460385 epoch total loss 1.65410554\n",
      "Trained batch 474 batch loss 1.70600319 epoch total loss 1.65421498\n",
      "Trained batch 475 batch loss 1.6759181 epoch total loss 1.65426064\n",
      "Trained batch 476 batch loss 1.62355947 epoch total loss 1.65419614\n",
      "Trained batch 477 batch loss 1.50194168 epoch total loss 1.6538769\n",
      "Trained batch 478 batch loss 1.48352551 epoch total loss 1.65352058\n",
      "Trained batch 479 batch loss 1.57312882 epoch total loss 1.65335262\n",
      "Trained batch 480 batch loss 1.5566777 epoch total loss 1.65315127\n",
      "Trained batch 481 batch loss 1.57755136 epoch total loss 1.65299416\n",
      "Trained batch 482 batch loss 1.60436082 epoch total loss 1.6528933\n",
      "Trained batch 483 batch loss 1.64839721 epoch total loss 1.65288401\n",
      "Trained batch 484 batch loss 1.50568318 epoch total loss 1.65257978\n",
      "Trained batch 485 batch loss 1.52667654 epoch total loss 1.65232027\n",
      "Trained batch 486 batch loss 1.4388622 epoch total loss 1.65188098\n",
      "Trained batch 487 batch loss 1.43428135 epoch total loss 1.65143406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 488 batch loss 1.51561069 epoch total loss 1.65115583\n",
      "Trained batch 489 batch loss 1.61517191 epoch total loss 1.65108228\n",
      "Trained batch 490 batch loss 1.64377892 epoch total loss 1.65106738\n",
      "Trained batch 491 batch loss 1.56653595 epoch total loss 1.65089524\n",
      "Trained batch 492 batch loss 1.52309537 epoch total loss 1.65063536\n",
      "Trained batch 493 batch loss 1.57587457 epoch total loss 1.65048373\n",
      "Trained batch 494 batch loss 1.59388125 epoch total loss 1.65036917\n",
      "Trained batch 495 batch loss 1.47957444 epoch total loss 1.65002406\n",
      "Trained batch 496 batch loss 1.53322637 epoch total loss 1.6497885\n",
      "Trained batch 497 batch loss 1.48887372 epoch total loss 1.64946473\n",
      "Trained batch 498 batch loss 1.61989212 epoch total loss 1.64940536\n",
      "Trained batch 499 batch loss 1.59402132 epoch total loss 1.64929426\n",
      "Trained batch 500 batch loss 1.53602087 epoch total loss 1.64906776\n",
      "Trained batch 501 batch loss 1.57188272 epoch total loss 1.64891374\n",
      "Trained batch 502 batch loss 1.50455916 epoch total loss 1.64862621\n",
      "Trained batch 503 batch loss 1.5037173 epoch total loss 1.64833808\n",
      "Trained batch 504 batch loss 1.38463414 epoch total loss 1.64781487\n",
      "Trained batch 505 batch loss 1.47366774 epoch total loss 1.64747012\n",
      "Trained batch 506 batch loss 1.5276885 epoch total loss 1.64723349\n",
      "Trained batch 507 batch loss 1.51440883 epoch total loss 1.64697146\n",
      "Trained batch 508 batch loss 1.42444241 epoch total loss 1.64653337\n",
      "Trained batch 509 batch loss 1.45149505 epoch total loss 1.64615023\n",
      "Trained batch 510 batch loss 1.39787149 epoch total loss 1.64566338\n",
      "Trained batch 511 batch loss 1.35014248 epoch total loss 1.6450851\n",
      "Trained batch 512 batch loss 1.41823149 epoch total loss 1.644642\n",
      "Trained batch 513 batch loss 1.52984631 epoch total loss 1.64441824\n",
      "Trained batch 514 batch loss 1.48962843 epoch total loss 1.64411712\n",
      "Trained batch 515 batch loss 1.547508 epoch total loss 1.64392948\n",
      "Trained batch 516 batch loss 1.55536485 epoch total loss 1.64375782\n",
      "Trained batch 517 batch loss 1.60135627 epoch total loss 1.6436758\n",
      "Trained batch 518 batch loss 1.63530111 epoch total loss 1.64365971\n",
      "Trained batch 519 batch loss 1.61857176 epoch total loss 1.64361131\n",
      "Trained batch 520 batch loss 1.59038424 epoch total loss 1.64350903\n",
      "Trained batch 521 batch loss 1.5797168 epoch total loss 1.6433866\n",
      "Trained batch 522 batch loss 1.53265953 epoch total loss 1.64317441\n",
      "Trained batch 523 batch loss 1.47085404 epoch total loss 1.64284492\n",
      "Trained batch 524 batch loss 1.55864871 epoch total loss 1.64268422\n",
      "Trained batch 525 batch loss 1.5539124 epoch total loss 1.64251506\n",
      "Trained batch 526 batch loss 1.63094831 epoch total loss 1.64249313\n",
      "Trained batch 527 batch loss 1.62129772 epoch total loss 1.64245284\n",
      "Trained batch 528 batch loss 1.51087236 epoch total loss 1.64220357\n",
      "Trained batch 529 batch loss 1.50287032 epoch total loss 1.64194024\n",
      "Trained batch 530 batch loss 1.5243572 epoch total loss 1.64171839\n",
      "Trained batch 531 batch loss 1.51117063 epoch total loss 1.64147246\n",
      "Trained batch 532 batch loss 1.60292482 epoch total loss 1.6414\n",
      "Trained batch 533 batch loss 1.50917792 epoch total loss 1.64115191\n",
      "Trained batch 534 batch loss 1.59388733 epoch total loss 1.64106333\n",
      "Trained batch 535 batch loss 1.54568565 epoch total loss 1.64088511\n",
      "Trained batch 536 batch loss 1.60322416 epoch total loss 1.64081478\n",
      "Trained batch 537 batch loss 1.59305584 epoch total loss 1.64072597\n",
      "Trained batch 538 batch loss 1.40588331 epoch total loss 1.64028943\n",
      "Trained batch 539 batch loss 1.50932837 epoch total loss 1.64004648\n",
      "Trained batch 540 batch loss 1.48636293 epoch total loss 1.63976192\n",
      "Trained batch 541 batch loss 1.67785883 epoch total loss 1.63983238\n",
      "Trained batch 542 batch loss 1.50582838 epoch total loss 1.63958502\n",
      "Trained batch 543 batch loss 1.34964073 epoch total loss 1.63905108\n",
      "Trained batch 544 batch loss 1.38422251 epoch total loss 1.63858271\n",
      "Trained batch 545 batch loss 1.5754894 epoch total loss 1.63846695\n",
      "Trained batch 546 batch loss 1.60378027 epoch total loss 1.63840342\n",
      "Trained batch 547 batch loss 1.58146739 epoch total loss 1.63829935\n",
      "Trained batch 548 batch loss 1.58157873 epoch total loss 1.63819587\n",
      "Trained batch 549 batch loss 1.67219067 epoch total loss 1.63825774\n",
      "Trained batch 550 batch loss 1.59311903 epoch total loss 1.63817573\n",
      "Trained batch 551 batch loss 1.55761993 epoch total loss 1.63802946\n",
      "Trained batch 552 batch loss 1.67384911 epoch total loss 1.63809431\n",
      "Trained batch 553 batch loss 1.66990829 epoch total loss 1.63815188\n",
      "Trained batch 554 batch loss 1.63166261 epoch total loss 1.6381402\n",
      "Trained batch 555 batch loss 1.53536344 epoch total loss 1.63795495\n",
      "Trained batch 556 batch loss 1.49837637 epoch total loss 1.6377039\n",
      "Trained batch 557 batch loss 1.36768055 epoch total loss 1.63721907\n",
      "Trained batch 558 batch loss 1.55585599 epoch total loss 1.63707328\n",
      "Trained batch 559 batch loss 1.56857 epoch total loss 1.63695061\n",
      "Trained batch 560 batch loss 1.51684594 epoch total loss 1.63673615\n",
      "Trained batch 561 batch loss 1.45865881 epoch total loss 1.63641882\n",
      "Trained batch 562 batch loss 1.58483481 epoch total loss 1.63632703\n",
      "Trained batch 563 batch loss 1.59259367 epoch total loss 1.6362493\n",
      "Trained batch 564 batch loss 1.44480205 epoch total loss 1.63590991\n",
      "Trained batch 565 batch loss 1.39635515 epoch total loss 1.63548601\n",
      "Trained batch 566 batch loss 1.40769815 epoch total loss 1.63508356\n",
      "Trained batch 567 batch loss 1.55114007 epoch total loss 1.6349355\n",
      "Trained batch 568 batch loss 1.56962419 epoch total loss 1.63482058\n",
      "Trained batch 569 batch loss 1.60570598 epoch total loss 1.63476932\n",
      "Trained batch 570 batch loss 1.5709914 epoch total loss 1.6346575\n",
      "Trained batch 571 batch loss 1.38266039 epoch total loss 1.63421619\n",
      "Trained batch 572 batch loss 1.44473171 epoch total loss 1.63388491\n",
      "Trained batch 573 batch loss 1.54384696 epoch total loss 1.63372767\n",
      "Trained batch 574 batch loss 1.58469331 epoch total loss 1.63364232\n",
      "Trained batch 575 batch loss 1.50765467 epoch total loss 1.63342321\n",
      "Trained batch 576 batch loss 1.53481555 epoch total loss 1.63325191\n",
      "Trained batch 577 batch loss 1.4593277 epoch total loss 1.63295054\n",
      "Trained batch 578 batch loss 1.52883852 epoch total loss 1.63277042\n",
      "Trained batch 579 batch loss 1.60810506 epoch total loss 1.63272774\n",
      "Trained batch 580 batch loss 1.53942263 epoch total loss 1.63256693\n",
      "Trained batch 581 batch loss 1.54496479 epoch total loss 1.63241613\n",
      "Trained batch 582 batch loss 1.5363996 epoch total loss 1.63225114\n",
      "Trained batch 583 batch loss 1.4714545 epoch total loss 1.63197529\n",
      "Trained batch 584 batch loss 1.48295557 epoch total loss 1.63172019\n",
      "Trained batch 585 batch loss 1.4886564 epoch total loss 1.63147557\n",
      "Trained batch 586 batch loss 1.64556098 epoch total loss 1.63149965\n",
      "Trained batch 587 batch loss 1.72720361 epoch total loss 1.63166273\n",
      "Trained batch 588 batch loss 1.63765824 epoch total loss 1.63167286\n",
      "Trained batch 589 batch loss 1.41836989 epoch total loss 1.63131082\n",
      "Trained batch 590 batch loss 1.4659543 epoch total loss 1.63103044\n",
      "Trained batch 591 batch loss 1.56051075 epoch total loss 1.63091111\n",
      "Trained batch 592 batch loss 1.5062499 epoch total loss 1.63070047\n",
      "Trained batch 593 batch loss 1.45166457 epoch total loss 1.63039863\n",
      "Trained batch 594 batch loss 1.48034 epoch total loss 1.63014591\n",
      "Trained batch 595 batch loss 1.54975104 epoch total loss 1.63001084\n",
      "Trained batch 596 batch loss 1.57731032 epoch total loss 1.62992239\n",
      "Trained batch 597 batch loss 1.61822391 epoch total loss 1.62990284\n",
      "Trained batch 598 batch loss 1.59260869 epoch total loss 1.62984049\n",
      "Trained batch 599 batch loss 1.53454518 epoch total loss 1.62968135\n",
      "Trained batch 600 batch loss 1.56791019 epoch total loss 1.62957847\n",
      "Trained batch 601 batch loss 1.50472093 epoch total loss 1.62937069\n",
      "Trained batch 602 batch loss 1.55141473 epoch total loss 1.62924111\n",
      "Trained batch 603 batch loss 1.53146935 epoch total loss 1.62907898\n",
      "Trained batch 604 batch loss 1.46026218 epoch total loss 1.62879956\n",
      "Trained batch 605 batch loss 1.43101215 epoch total loss 1.62847269\n",
      "Trained batch 606 batch loss 1.46188414 epoch total loss 1.62819779\n",
      "Trained batch 607 batch loss 1.43911862 epoch total loss 1.6278863\n",
      "Trained batch 608 batch loss 1.50508547 epoch total loss 1.62768435\n",
      "Trained batch 609 batch loss 1.50687075 epoch total loss 1.62748599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 610 batch loss 1.46869159 epoch total loss 1.62722564\n",
      "Trained batch 611 batch loss 1.48353696 epoch total loss 1.62699044\n",
      "Trained batch 612 batch loss 1.48725724 epoch total loss 1.62676215\n",
      "Trained batch 613 batch loss 1.46423805 epoch total loss 1.62649703\n",
      "Trained batch 614 batch loss 1.57093203 epoch total loss 1.62640655\n",
      "Trained batch 615 batch loss 1.30171835 epoch total loss 1.62587845\n",
      "Trained batch 616 batch loss 1.36046958 epoch total loss 1.62544763\n",
      "Trained batch 617 batch loss 1.18071294 epoch total loss 1.62472689\n",
      "Trained batch 618 batch loss 1.41278183 epoch total loss 1.62438393\n",
      "Trained batch 619 batch loss 1.53936112 epoch total loss 1.6242466\n",
      "Trained batch 620 batch loss 1.64424062 epoch total loss 1.62427878\n",
      "Trained batch 621 batch loss 1.60548306 epoch total loss 1.6242485\n",
      "Trained batch 622 batch loss 1.52357602 epoch total loss 1.62408662\n",
      "Trained batch 623 batch loss 1.49723506 epoch total loss 1.62388301\n",
      "Trained batch 624 batch loss 1.4668721 epoch total loss 1.62363136\n",
      "Trained batch 625 batch loss 1.41003895 epoch total loss 1.6232897\n",
      "Trained batch 626 batch loss 1.46983957 epoch total loss 1.62304449\n",
      "Trained batch 627 batch loss 1.48293877 epoch total loss 1.62282109\n",
      "Trained batch 628 batch loss 1.43476546 epoch total loss 1.62252152\n",
      "Trained batch 629 batch loss 1.57208729 epoch total loss 1.62244141\n",
      "Trained batch 630 batch loss 1.48665357 epoch total loss 1.62222576\n",
      "Trained batch 631 batch loss 1.50832593 epoch total loss 1.62204528\n",
      "Trained batch 632 batch loss 1.43781304 epoch total loss 1.62175369\n",
      "Trained batch 633 batch loss 1.55541646 epoch total loss 1.62164891\n",
      "Trained batch 634 batch loss 1.60711098 epoch total loss 1.6216259\n",
      "Trained batch 635 batch loss 1.5553869 epoch total loss 1.62152171\n",
      "Trained batch 636 batch loss 1.48329651 epoch total loss 1.62130427\n",
      "Trained batch 637 batch loss 1.45791638 epoch total loss 1.62104774\n",
      "Trained batch 638 batch loss 1.47725844 epoch total loss 1.62082243\n",
      "Trained batch 639 batch loss 1.43993437 epoch total loss 1.62053943\n",
      "Trained batch 640 batch loss 1.51141 epoch total loss 1.62036872\n",
      "Trained batch 641 batch loss 1.56344199 epoch total loss 1.62028\n",
      "Trained batch 642 batch loss 1.60590172 epoch total loss 1.62025774\n",
      "Trained batch 643 batch loss 1.65358233 epoch total loss 1.62030947\n",
      "Trained batch 644 batch loss 1.71870327 epoch total loss 1.62046242\n",
      "Trained batch 645 batch loss 1.67132366 epoch total loss 1.6205411\n",
      "Trained batch 646 batch loss 1.53191698 epoch total loss 1.62040389\n",
      "Trained batch 647 batch loss 1.46861911 epoch total loss 1.62016928\n",
      "Trained batch 648 batch loss 1.32979345 epoch total loss 1.61972117\n",
      "Trained batch 649 batch loss 1.27211714 epoch total loss 1.61918557\n",
      "Trained batch 650 batch loss 1.31392169 epoch total loss 1.618716\n",
      "Trained batch 651 batch loss 1.42679417 epoch total loss 1.6184212\n",
      "Trained batch 652 batch loss 1.50750327 epoch total loss 1.61825097\n",
      "Trained batch 653 batch loss 1.46912777 epoch total loss 1.61802256\n",
      "Trained batch 654 batch loss 1.51948619 epoch total loss 1.617872\n",
      "Trained batch 655 batch loss 1.5439899 epoch total loss 1.61775911\n",
      "Trained batch 656 batch loss 1.61721671 epoch total loss 1.61775827\n",
      "Trained batch 657 batch loss 1.58409214 epoch total loss 1.61770701\n",
      "Trained batch 658 batch loss 1.55149412 epoch total loss 1.6176064\n",
      "Trained batch 659 batch loss 1.48760533 epoch total loss 1.61740899\n",
      "Trained batch 660 batch loss 1.56647241 epoch total loss 1.61733198\n",
      "Trained batch 661 batch loss 1.65552592 epoch total loss 1.61738968\n",
      "Trained batch 662 batch loss 1.62108827 epoch total loss 1.61739528\n",
      "Trained batch 663 batch loss 1.49298811 epoch total loss 1.61720777\n",
      "Trained batch 664 batch loss 1.49359095 epoch total loss 1.61702144\n",
      "Trained batch 665 batch loss 1.48050749 epoch total loss 1.61681616\n",
      "Trained batch 666 batch loss 1.42041469 epoch total loss 1.61652124\n",
      "Trained batch 667 batch loss 1.45035052 epoch total loss 1.61627209\n",
      "Trained batch 668 batch loss 1.56401718 epoch total loss 1.61619377\n",
      "Trained batch 669 batch loss 1.54083693 epoch total loss 1.61608124\n",
      "Trained batch 670 batch loss 1.57029319 epoch total loss 1.61601293\n",
      "Trained batch 671 batch loss 1.47508109 epoch total loss 1.61580288\n",
      "Trained batch 672 batch loss 1.50531888 epoch total loss 1.61563849\n",
      "Trained batch 673 batch loss 1.38825941 epoch total loss 1.61530077\n",
      "Trained batch 674 batch loss 1.4812485 epoch total loss 1.61510181\n",
      "Trained batch 675 batch loss 1.42534351 epoch total loss 1.6148206\n",
      "Trained batch 676 batch loss 1.45981336 epoch total loss 1.61459136\n",
      "Trained batch 677 batch loss 1.59620798 epoch total loss 1.61456418\n",
      "Trained batch 678 batch loss 1.57230484 epoch total loss 1.61450171\n",
      "Trained batch 679 batch loss 1.54625547 epoch total loss 1.61440122\n",
      "Trained batch 680 batch loss 1.56604028 epoch total loss 1.61433017\n",
      "Trained batch 681 batch loss 1.62226486 epoch total loss 1.61434186\n",
      "Trained batch 682 batch loss 1.4706037 epoch total loss 1.61413109\n",
      "Trained batch 683 batch loss 1.52569818 epoch total loss 1.61400175\n",
      "Trained batch 684 batch loss 1.49271202 epoch total loss 1.61382437\n",
      "Trained batch 685 batch loss 1.39066982 epoch total loss 1.61349845\n",
      "Trained batch 686 batch loss 1.37684751 epoch total loss 1.61315346\n",
      "Trained batch 687 batch loss 1.52988899 epoch total loss 1.61303234\n",
      "Trained batch 688 batch loss 1.51654315 epoch total loss 1.61289215\n",
      "Trained batch 689 batch loss 1.56421018 epoch total loss 1.61282146\n",
      "Trained batch 690 batch loss 1.55681705 epoch total loss 1.61274028\n",
      "Trained batch 691 batch loss 1.44620907 epoch total loss 1.61249924\n",
      "Trained batch 692 batch loss 1.45034277 epoch total loss 1.61226487\n",
      "Trained batch 693 batch loss 1.46716404 epoch total loss 1.61205542\n",
      "Trained batch 694 batch loss 1.51005244 epoch total loss 1.61190844\n",
      "Trained batch 695 batch loss 1.55474401 epoch total loss 1.61182606\n",
      "Trained batch 696 batch loss 1.53450465 epoch total loss 1.61171508\n",
      "Trained batch 697 batch loss 1.57393432 epoch total loss 1.61166084\n",
      "Trained batch 698 batch loss 1.50234675 epoch total loss 1.6115042\n",
      "Trained batch 699 batch loss 1.4009769 epoch total loss 1.61120307\n",
      "Trained batch 700 batch loss 1.35952783 epoch total loss 1.61084354\n",
      "Trained batch 701 batch loss 1.454108 epoch total loss 1.6106199\n",
      "Trained batch 702 batch loss 1.39139569 epoch total loss 1.61030757\n",
      "Trained batch 703 batch loss 1.4868083 epoch total loss 1.61013186\n",
      "Trained batch 704 batch loss 1.41431177 epoch total loss 1.60985374\n",
      "Trained batch 705 batch loss 1.56250107 epoch total loss 1.60978663\n",
      "Trained batch 706 batch loss 1.48184288 epoch total loss 1.60960531\n",
      "Trained batch 707 batch loss 1.51796889 epoch total loss 1.60947561\n",
      "Trained batch 708 batch loss 1.5352937 epoch total loss 1.60937083\n",
      "Trained batch 709 batch loss 1.51679945 epoch total loss 1.60924041\n",
      "Trained batch 710 batch loss 1.45702076 epoch total loss 1.60902596\n",
      "Trained batch 711 batch loss 1.52603197 epoch total loss 1.60890925\n",
      "Trained batch 712 batch loss 1.48248732 epoch total loss 1.60873175\n",
      "Trained batch 713 batch loss 1.49922836 epoch total loss 1.60857821\n",
      "Trained batch 714 batch loss 1.61325192 epoch total loss 1.60858476\n",
      "Trained batch 715 batch loss 1.6353817 epoch total loss 1.60862231\n",
      "Trained batch 716 batch loss 1.55189991 epoch total loss 1.60854304\n",
      "Trained batch 717 batch loss 1.52846289 epoch total loss 1.60843134\n",
      "Trained batch 718 batch loss 1.63004065 epoch total loss 1.60846138\n",
      "Trained batch 719 batch loss 1.54426825 epoch total loss 1.60837209\n",
      "Trained batch 720 batch loss 1.65929818 epoch total loss 1.6084429\n",
      "Trained batch 721 batch loss 1.68404913 epoch total loss 1.60854781\n",
      "Trained batch 722 batch loss 1.51894712 epoch total loss 1.60842359\n",
      "Trained batch 723 batch loss 1.53859615 epoch total loss 1.60832703\n",
      "Trained batch 724 batch loss 1.45420384 epoch total loss 1.60811412\n",
      "Trained batch 725 batch loss 1.35022187 epoch total loss 1.6077584\n",
      "Trained batch 726 batch loss 1.3364265 epoch total loss 1.60738468\n",
      "Trained batch 727 batch loss 1.45823383 epoch total loss 1.60717952\n",
      "Trained batch 728 batch loss 1.19577944 epoch total loss 1.60661447\n",
      "Trained batch 729 batch loss 1.30040896 epoch total loss 1.6061945\n",
      "Trained batch 730 batch loss 1.28539705 epoch total loss 1.60575497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 731 batch loss 1.3275485 epoch total loss 1.60537446\n",
      "Trained batch 732 batch loss 1.36449337 epoch total loss 1.60504532\n",
      "Trained batch 733 batch loss 1.53801477 epoch total loss 1.60495377\n",
      "Trained batch 734 batch loss 1.56136608 epoch total loss 1.60489452\n",
      "Trained batch 735 batch loss 1.59506428 epoch total loss 1.60488117\n",
      "Trained batch 736 batch loss 1.61316454 epoch total loss 1.60489237\n",
      "Trained batch 737 batch loss 1.58485794 epoch total loss 1.60486519\n",
      "Trained batch 738 batch loss 1.47954607 epoch total loss 1.60469532\n",
      "Trained batch 739 batch loss 1.47561288 epoch total loss 1.60452056\n",
      "Trained batch 740 batch loss 1.45080447 epoch total loss 1.6043129\n",
      "Trained batch 741 batch loss 1.58921802 epoch total loss 1.60429251\n",
      "Trained batch 742 batch loss 1.38732088 epoch total loss 1.60400009\n",
      "Trained batch 743 batch loss 1.47344363 epoch total loss 1.60382438\n",
      "Trained batch 744 batch loss 1.36645389 epoch total loss 1.60350525\n",
      "Trained batch 745 batch loss 1.51016402 epoch total loss 1.60338\n",
      "Trained batch 746 batch loss 1.43508065 epoch total loss 1.6031543\n",
      "Trained batch 747 batch loss 1.54360294 epoch total loss 1.60307455\n",
      "Trained batch 748 batch loss 1.51616621 epoch total loss 1.60295832\n",
      "Trained batch 749 batch loss 1.4899044 epoch total loss 1.60280728\n",
      "Trained batch 750 batch loss 1.35035896 epoch total loss 1.60247076\n",
      "Trained batch 751 batch loss 1.51404262 epoch total loss 1.60235298\n",
      "Trained batch 752 batch loss 1.53520679 epoch total loss 1.60226357\n",
      "Trained batch 753 batch loss 1.53790665 epoch total loss 1.60217822\n",
      "Trained batch 754 batch loss 1.53601885 epoch total loss 1.60209048\n",
      "Trained batch 755 batch loss 1.49360538 epoch total loss 1.60194683\n",
      "Trained batch 756 batch loss 1.41142392 epoch total loss 1.6016947\n",
      "Trained batch 757 batch loss 1.45046449 epoch total loss 1.60149491\n",
      "Trained batch 758 batch loss 1.46412075 epoch total loss 1.60131371\n",
      "Trained batch 759 batch loss 1.43962717 epoch total loss 1.60110056\n",
      "Trained batch 760 batch loss 1.59154665 epoch total loss 1.60108805\n",
      "Trained batch 761 batch loss 1.47826457 epoch total loss 1.60092664\n",
      "Trained batch 762 batch loss 1.50294399 epoch total loss 1.60079801\n",
      "Trained batch 763 batch loss 1.36501217 epoch total loss 1.60048902\n",
      "Trained batch 764 batch loss 1.38779283 epoch total loss 1.60021067\n",
      "Trained batch 765 batch loss 1.51215959 epoch total loss 1.60009563\n",
      "Trained batch 766 batch loss 1.40805984 epoch total loss 1.59984493\n",
      "Trained batch 767 batch loss 1.3264327 epoch total loss 1.59948838\n",
      "Trained batch 768 batch loss 1.20134306 epoch total loss 1.59896994\n",
      "Trained batch 769 batch loss 1.32966375 epoch total loss 1.59861982\n",
      "Trained batch 770 batch loss 1.43063593 epoch total loss 1.59840167\n",
      "Trained batch 771 batch loss 1.29988885 epoch total loss 1.59801459\n",
      "Trained batch 772 batch loss 1.36713493 epoch total loss 1.5977155\n",
      "Trained batch 773 batch loss 1.46445799 epoch total loss 1.59754324\n",
      "Trained batch 774 batch loss 1.51346612 epoch total loss 1.59743452\n",
      "Trained batch 775 batch loss 1.41602969 epoch total loss 1.59720039\n",
      "Trained batch 776 batch loss 1.38245976 epoch total loss 1.59692371\n",
      "Trained batch 777 batch loss 1.41401041 epoch total loss 1.59668827\n",
      "Trained batch 778 batch loss 1.48964357 epoch total loss 1.5965507\n",
      "Trained batch 779 batch loss 1.53282499 epoch total loss 1.59646893\n",
      "Trained batch 780 batch loss 1.56084943 epoch total loss 1.59642315\n",
      "Trained batch 781 batch loss 1.51006651 epoch total loss 1.59631252\n",
      "Trained batch 782 batch loss 1.51271427 epoch total loss 1.59620559\n",
      "Trained batch 783 batch loss 1.53649461 epoch total loss 1.5961293\n",
      "Trained batch 784 batch loss 1.46470976 epoch total loss 1.59596169\n",
      "Trained batch 785 batch loss 1.55443668 epoch total loss 1.59590888\n",
      "Trained batch 786 batch loss 1.36215782 epoch total loss 1.59561145\n",
      "Trained batch 787 batch loss 1.33731198 epoch total loss 1.59528327\n",
      "Trained batch 788 batch loss 1.47323453 epoch total loss 1.59512842\n",
      "Trained batch 789 batch loss 1.52758992 epoch total loss 1.59504282\n",
      "Trained batch 790 batch loss 1.59102964 epoch total loss 1.59503782\n",
      "Trained batch 791 batch loss 1.56005108 epoch total loss 1.59499359\n",
      "Trained batch 792 batch loss 1.71826458 epoch total loss 1.59514916\n",
      "Trained batch 793 batch loss 1.54202604 epoch total loss 1.59508216\n",
      "Trained batch 794 batch loss 1.58846712 epoch total loss 1.59507382\n",
      "Trained batch 795 batch loss 1.59469414 epoch total loss 1.59507346\n",
      "Trained batch 796 batch loss 1.46247077 epoch total loss 1.59490693\n",
      "Trained batch 797 batch loss 1.50362873 epoch total loss 1.59479237\n",
      "Trained batch 798 batch loss 1.52179658 epoch total loss 1.59470105\n",
      "Trained batch 799 batch loss 1.62997234 epoch total loss 1.59474516\n",
      "Trained batch 800 batch loss 1.53584111 epoch total loss 1.59467161\n",
      "Trained batch 801 batch loss 1.47141469 epoch total loss 1.59451783\n",
      "Trained batch 802 batch loss 1.51607215 epoch total loss 1.59442008\n",
      "Trained batch 803 batch loss 1.53334928 epoch total loss 1.5943439\n",
      "Trained batch 804 batch loss 1.3997432 epoch total loss 1.59410191\n",
      "Trained batch 805 batch loss 1.47553551 epoch total loss 1.59395468\n",
      "Trained batch 806 batch loss 1.40309811 epoch total loss 1.59371793\n",
      "Trained batch 807 batch loss 1.32260501 epoch total loss 1.593382\n",
      "Trained batch 808 batch loss 1.4974817 epoch total loss 1.59326327\n",
      "Trained batch 809 batch loss 1.70567346 epoch total loss 1.59340215\n",
      "Trained batch 810 batch loss 1.59425426 epoch total loss 1.59340322\n",
      "Trained batch 811 batch loss 1.5999248 epoch total loss 1.59341133\n",
      "Trained batch 812 batch loss 1.51450086 epoch total loss 1.59331417\n",
      "Trained batch 813 batch loss 1.55701423 epoch total loss 1.59326947\n",
      "Trained batch 814 batch loss 1.54999077 epoch total loss 1.59321642\n",
      "Trained batch 815 batch loss 1.45148742 epoch total loss 1.59304261\n",
      "Trained batch 816 batch loss 1.48250675 epoch total loss 1.59290719\n",
      "Trained batch 817 batch loss 1.52267969 epoch total loss 1.59282124\n",
      "Trained batch 818 batch loss 1.520365 epoch total loss 1.59273267\n",
      "Trained batch 819 batch loss 1.47925341 epoch total loss 1.59259415\n",
      "Trained batch 820 batch loss 1.55071378 epoch total loss 1.59254301\n",
      "Trained batch 821 batch loss 1.43458533 epoch total loss 1.5923506\n",
      "Trained batch 822 batch loss 1.45308626 epoch total loss 1.59218121\n",
      "Trained batch 823 batch loss 1.4631654 epoch total loss 1.59202445\n",
      "Trained batch 824 batch loss 1.49897337 epoch total loss 1.59191155\n",
      "Trained batch 825 batch loss 1.5036087 epoch total loss 1.59180462\n",
      "Trained batch 826 batch loss 1.49258149 epoch total loss 1.59168446\n",
      "Trained batch 827 batch loss 1.45031643 epoch total loss 1.59151351\n",
      "Trained batch 828 batch loss 1.3744179 epoch total loss 1.59125125\n",
      "Trained batch 829 batch loss 1.33779895 epoch total loss 1.59094548\n",
      "Trained batch 830 batch loss 1.43538892 epoch total loss 1.59075809\n",
      "Trained batch 831 batch loss 1.47041094 epoch total loss 1.59061337\n",
      "Trained batch 832 batch loss 1.52400196 epoch total loss 1.59053338\n",
      "Trained batch 833 batch loss 1.47257125 epoch total loss 1.59039164\n",
      "Trained batch 834 batch loss 1.45245266 epoch total loss 1.59022617\n",
      "Trained batch 835 batch loss 1.45701647 epoch total loss 1.59006667\n",
      "Trained batch 836 batch loss 1.52440071 epoch total loss 1.58998811\n",
      "Trained batch 837 batch loss 1.53932989 epoch total loss 1.58992755\n",
      "Trained batch 838 batch loss 1.48804593 epoch total loss 1.58980608\n",
      "Trained batch 839 batch loss 1.4772191 epoch total loss 1.58967173\n",
      "Trained batch 840 batch loss 1.5185349 epoch total loss 1.58958709\n",
      "Trained batch 841 batch loss 1.39825082 epoch total loss 1.58935952\n",
      "Trained batch 842 batch loss 1.37302887 epoch total loss 1.58910263\n",
      "Trained batch 843 batch loss 1.48823202 epoch total loss 1.58898306\n",
      "Trained batch 844 batch loss 1.47951245 epoch total loss 1.58885336\n",
      "Trained batch 845 batch loss 1.4102273 epoch total loss 1.588642\n",
      "Trained batch 846 batch loss 1.39463162 epoch total loss 1.58841264\n",
      "Trained batch 847 batch loss 1.58176446 epoch total loss 1.58840489\n",
      "Trained batch 848 batch loss 1.52850461 epoch total loss 1.58833432\n",
      "Trained batch 849 batch loss 1.54963684 epoch total loss 1.58828878\n",
      "Trained batch 850 batch loss 1.51421309 epoch total loss 1.58820152\n",
      "Trained batch 851 batch loss 1.50838757 epoch total loss 1.58810782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 852 batch loss 1.52855229 epoch total loss 1.58803797\n",
      "Trained batch 853 batch loss 1.55135536 epoch total loss 1.58799493\n",
      "Trained batch 854 batch loss 1.61886013 epoch total loss 1.58803117\n",
      "Trained batch 855 batch loss 1.54334271 epoch total loss 1.58797884\n",
      "Trained batch 856 batch loss 1.48277509 epoch total loss 1.58785594\n",
      "Trained batch 857 batch loss 1.50140917 epoch total loss 1.5877552\n",
      "Trained batch 858 batch loss 1.47407472 epoch total loss 1.58762276\n",
      "Trained batch 859 batch loss 1.5054884 epoch total loss 1.58752716\n",
      "Trained batch 860 batch loss 1.52118587 epoch total loss 1.58745\n",
      "Trained batch 861 batch loss 1.41027331 epoch total loss 1.58724427\n",
      "Trained batch 862 batch loss 1.50469184 epoch total loss 1.58714843\n",
      "Trained batch 863 batch loss 1.50904655 epoch total loss 1.58705795\n",
      "Trained batch 864 batch loss 1.49081862 epoch total loss 1.58694661\n",
      "Trained batch 865 batch loss 1.48384464 epoch total loss 1.5868274\n",
      "Trained batch 866 batch loss 1.55724728 epoch total loss 1.5867933\n",
      "Trained batch 867 batch loss 1.57323122 epoch total loss 1.58677769\n",
      "Trained batch 868 batch loss 1.58343232 epoch total loss 1.58677375\n",
      "Trained batch 869 batch loss 1.38291669 epoch total loss 1.58653915\n",
      "Trained batch 870 batch loss 1.55014634 epoch total loss 1.58649731\n",
      "Trained batch 871 batch loss 1.58033848 epoch total loss 1.58649027\n",
      "Trained batch 872 batch loss 1.46068215 epoch total loss 1.58634603\n",
      "Trained batch 873 batch loss 1.48065734 epoch total loss 1.58622503\n",
      "Trained batch 874 batch loss 1.49976134 epoch total loss 1.58612609\n",
      "Trained batch 875 batch loss 1.45530021 epoch total loss 1.5859766\n",
      "Trained batch 876 batch loss 1.45150781 epoch total loss 1.58582306\n",
      "Trained batch 877 batch loss 1.51811767 epoch total loss 1.58574581\n",
      "Trained batch 878 batch loss 1.49419868 epoch total loss 1.5856415\n",
      "Trained batch 879 batch loss 1.51197147 epoch total loss 1.5855577\n",
      "Trained batch 880 batch loss 1.4382025 epoch total loss 1.58539021\n",
      "Trained batch 881 batch loss 1.43734717 epoch total loss 1.58522224\n",
      "Trained batch 882 batch loss 1.49954367 epoch total loss 1.58512509\n",
      "Trained batch 883 batch loss 1.54822302 epoch total loss 1.58508325\n",
      "Trained batch 884 batch loss 1.54409766 epoch total loss 1.58503687\n",
      "Trained batch 885 batch loss 1.51975703 epoch total loss 1.5849632\n",
      "Trained batch 886 batch loss 1.53203726 epoch total loss 1.58490336\n",
      "Trained batch 887 batch loss 1.33156514 epoch total loss 1.58461773\n",
      "Trained batch 888 batch loss 1.5200485 epoch total loss 1.58454502\n",
      "Trained batch 889 batch loss 1.5160073 epoch total loss 1.58446789\n",
      "Trained batch 890 batch loss 1.50949073 epoch total loss 1.58438361\n",
      "Trained batch 891 batch loss 1.3805598 epoch total loss 1.58415496\n",
      "Trained batch 892 batch loss 1.31504977 epoch total loss 1.58385324\n",
      "Trained batch 893 batch loss 1.28566706 epoch total loss 1.58351934\n",
      "Trained batch 894 batch loss 1.34285045 epoch total loss 1.58325016\n",
      "Trained batch 895 batch loss 1.34793484 epoch total loss 1.58298719\n",
      "Trained batch 896 batch loss 1.48396599 epoch total loss 1.5828768\n",
      "Trained batch 897 batch loss 1.3889364 epoch total loss 1.58266056\n",
      "Trained batch 898 batch loss 1.55799186 epoch total loss 1.58263302\n",
      "Trained batch 899 batch loss 1.43563795 epoch total loss 1.58246958\n",
      "Trained batch 900 batch loss 1.43644929 epoch total loss 1.58230722\n",
      "Trained batch 901 batch loss 1.43031013 epoch total loss 1.58213854\n",
      "Trained batch 902 batch loss 1.42630434 epoch total loss 1.5819658\n",
      "Trained batch 903 batch loss 1.52605963 epoch total loss 1.58190382\n",
      "Trained batch 904 batch loss 1.42289197 epoch total loss 1.58172786\n",
      "Trained batch 905 batch loss 1.15057743 epoch total loss 1.5812515\n",
      "Trained batch 906 batch loss 1.09645 epoch total loss 1.58071637\n",
      "Trained batch 907 batch loss 1.51163018 epoch total loss 1.5806402\n",
      "Trained batch 908 batch loss 1.63715565 epoch total loss 1.58070242\n",
      "Trained batch 909 batch loss 1.63230896 epoch total loss 1.58075929\n",
      "Trained batch 910 batch loss 1.62272811 epoch total loss 1.5808053\n",
      "Trained batch 911 batch loss 1.61234784 epoch total loss 1.58083987\n",
      "Trained batch 912 batch loss 1.64481652 epoch total loss 1.58091\n",
      "Trained batch 913 batch loss 1.42048848 epoch total loss 1.58073437\n",
      "Trained batch 914 batch loss 1.28750694 epoch total loss 1.58041346\n",
      "Trained batch 915 batch loss 1.3283428 epoch total loss 1.58013797\n",
      "Trained batch 916 batch loss 1.44909966 epoch total loss 1.57999492\n",
      "Trained batch 917 batch loss 1.53935921 epoch total loss 1.57995057\n",
      "Trained batch 918 batch loss 1.56950927 epoch total loss 1.57993913\n",
      "Trained batch 919 batch loss 1.48364937 epoch total loss 1.57983434\n",
      "Trained batch 920 batch loss 1.49520683 epoch total loss 1.57974243\n",
      "Trained batch 921 batch loss 1.50831616 epoch total loss 1.57966483\n",
      "Trained batch 922 batch loss 1.4745326 epoch total loss 1.57955074\n",
      "Trained batch 923 batch loss 1.44031525 epoch total loss 1.5794\n",
      "Trained batch 924 batch loss 1.3634522 epoch total loss 1.57916617\n",
      "Trained batch 925 batch loss 1.47878337 epoch total loss 1.57905757\n",
      "Trained batch 926 batch loss 1.46600544 epoch total loss 1.57893562\n",
      "Trained batch 927 batch loss 1.46715009 epoch total loss 1.57881498\n",
      "Trained batch 928 batch loss 1.52883601 epoch total loss 1.5787611\n",
      "Trained batch 929 batch loss 1.49514902 epoch total loss 1.5786711\n",
      "Trained batch 930 batch loss 1.47464025 epoch total loss 1.57855916\n",
      "Trained batch 931 batch loss 1.47480559 epoch total loss 1.57844782\n",
      "Trained batch 932 batch loss 1.51106262 epoch total loss 1.57837558\n",
      "Trained batch 933 batch loss 1.39870465 epoch total loss 1.57818294\n",
      "Trained batch 934 batch loss 1.36263955 epoch total loss 1.57795227\n",
      "Trained batch 935 batch loss 1.61490667 epoch total loss 1.57799172\n",
      "Trained batch 936 batch loss 1.50721622 epoch total loss 1.57791603\n",
      "Trained batch 937 batch loss 1.42864287 epoch total loss 1.57775676\n",
      "Trained batch 938 batch loss 1.41246963 epoch total loss 1.57758045\n",
      "Trained batch 939 batch loss 1.47606063 epoch total loss 1.57747245\n",
      "Trained batch 940 batch loss 1.47444403 epoch total loss 1.5773629\n",
      "Trained batch 941 batch loss 1.58742821 epoch total loss 1.5773735\n",
      "Trained batch 942 batch loss 1.52878296 epoch total loss 1.57732201\n",
      "Trained batch 943 batch loss 1.45430398 epoch total loss 1.57719159\n",
      "Trained batch 944 batch loss 1.53089273 epoch total loss 1.57714248\n",
      "Trained batch 945 batch loss 1.46236551 epoch total loss 1.57702112\n",
      "Trained batch 946 batch loss 1.42095566 epoch total loss 1.57685602\n",
      "Trained batch 947 batch loss 1.46151257 epoch total loss 1.5767343\n",
      "Trained batch 948 batch loss 1.55799806 epoch total loss 1.57671452\n",
      "Trained batch 949 batch loss 1.56758428 epoch total loss 1.57670498\n",
      "Trained batch 950 batch loss 1.64121675 epoch total loss 1.57677281\n",
      "Trained batch 951 batch loss 1.49776542 epoch total loss 1.57668984\n",
      "Trained batch 952 batch loss 1.3774761 epoch total loss 1.57648051\n",
      "Trained batch 953 batch loss 1.46710587 epoch total loss 1.57636583\n",
      "Trained batch 954 batch loss 1.53140378 epoch total loss 1.57631862\n",
      "Trained batch 955 batch loss 1.45156336 epoch total loss 1.57618797\n",
      "Trained batch 956 batch loss 1.38858676 epoch total loss 1.57599175\n",
      "Trained batch 957 batch loss 1.57111573 epoch total loss 1.57598662\n",
      "Trained batch 958 batch loss 1.55834258 epoch total loss 1.57596827\n",
      "Trained batch 959 batch loss 1.58725882 epoch total loss 1.57598007\n",
      "Trained batch 960 batch loss 1.56921613 epoch total loss 1.57597303\n",
      "Trained batch 961 batch loss 1.49195158 epoch total loss 1.57588553\n",
      "Trained batch 962 batch loss 1.45454049 epoch total loss 1.57575953\n",
      "Trained batch 963 batch loss 1.37640989 epoch total loss 1.57555258\n",
      "Trained batch 964 batch loss 1.42358136 epoch total loss 1.57539487\n",
      "Trained batch 965 batch loss 1.4771018 epoch total loss 1.57529294\n",
      "Trained batch 966 batch loss 1.58667421 epoch total loss 1.57530475\n",
      "Trained batch 967 batch loss 1.5426563 epoch total loss 1.57527089\n",
      "Trained batch 968 batch loss 1.60282993 epoch total loss 1.57529938\n",
      "Trained batch 969 batch loss 1.66482568 epoch total loss 1.57539165\n",
      "Trained batch 970 batch loss 1.65944791 epoch total loss 1.57547832\n",
      "Trained batch 971 batch loss 1.61500335 epoch total loss 1.57551908\n",
      "Trained batch 972 batch loss 1.52978861 epoch total loss 1.575472\n",
      "Trained batch 973 batch loss 1.54690516 epoch total loss 1.57544255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 974 batch loss 1.51449168 epoch total loss 1.57538009\n",
      "Trained batch 975 batch loss 1.55261612 epoch total loss 1.57535672\n",
      "Trained batch 976 batch loss 1.50755334 epoch total loss 1.57528722\n",
      "Trained batch 977 batch loss 1.63676465 epoch total loss 1.57535017\n",
      "Trained batch 978 batch loss 1.44497085 epoch total loss 1.57521677\n",
      "Trained batch 979 batch loss 1.47615409 epoch total loss 1.57511568\n",
      "Trained batch 980 batch loss 1.41122 epoch total loss 1.57494843\n",
      "Trained batch 981 batch loss 1.51492476 epoch total loss 1.57488716\n",
      "Trained batch 982 batch loss 1.46441984 epoch total loss 1.57477474\n",
      "Trained batch 983 batch loss 1.48081279 epoch total loss 1.57467926\n",
      "Trained batch 984 batch loss 1.40828538 epoch total loss 1.5745101\n",
      "Trained batch 985 batch loss 1.40411294 epoch total loss 1.57433712\n",
      "Trained batch 986 batch loss 1.51747537 epoch total loss 1.57427943\n",
      "Trained batch 987 batch loss 1.46662211 epoch total loss 1.57417035\n",
      "Trained batch 988 batch loss 1.46465564 epoch total loss 1.57405949\n",
      "Trained batch 989 batch loss 1.4607 epoch total loss 1.57394481\n",
      "Trained batch 990 batch loss 1.46009481 epoch total loss 1.57382989\n",
      "Trained batch 991 batch loss 1.32941282 epoch total loss 1.57358325\n",
      "Trained batch 992 batch loss 1.46678507 epoch total loss 1.5734756\n",
      "Trained batch 993 batch loss 1.53842044 epoch total loss 1.57344031\n",
      "Trained batch 994 batch loss 1.59434032 epoch total loss 1.57346141\n",
      "Trained batch 995 batch loss 1.54441381 epoch total loss 1.57343221\n",
      "Trained batch 996 batch loss 1.47297096 epoch total loss 1.57333136\n",
      "Trained batch 997 batch loss 1.36899436 epoch total loss 1.57312644\n",
      "Trained batch 998 batch loss 1.50346708 epoch total loss 1.57305658\n",
      "Trained batch 999 batch loss 1.47301865 epoch total loss 1.57295644\n",
      "Trained batch 1000 batch loss 1.45482469 epoch total loss 1.57283843\n",
      "Trained batch 1001 batch loss 1.52286315 epoch total loss 1.57278848\n",
      "Trained batch 1002 batch loss 1.59377158 epoch total loss 1.57280934\n",
      "Trained batch 1003 batch loss 1.52737653 epoch total loss 1.57276404\n",
      "Trained batch 1004 batch loss 1.46488643 epoch total loss 1.57265651\n",
      "Trained batch 1005 batch loss 1.42277694 epoch total loss 1.57250738\n",
      "Trained batch 1006 batch loss 1.43539286 epoch total loss 1.57237113\n",
      "Trained batch 1007 batch loss 1.47964287 epoch total loss 1.57227898\n",
      "Trained batch 1008 batch loss 1.54584146 epoch total loss 1.57225275\n",
      "Trained batch 1009 batch loss 1.53628659 epoch total loss 1.57221711\n",
      "Trained batch 1010 batch loss 1.58752966 epoch total loss 1.57223225\n",
      "Trained batch 1011 batch loss 1.54107594 epoch total loss 1.57220137\n",
      "Trained batch 1012 batch loss 1.60384464 epoch total loss 1.57223272\n",
      "Trained batch 1013 batch loss 1.58372486 epoch total loss 1.57224405\n",
      "Trained batch 1014 batch loss 1.51668143 epoch total loss 1.57218933\n",
      "Trained batch 1015 batch loss 1.50809598 epoch total loss 1.57212615\n",
      "Trained batch 1016 batch loss 1.45870352 epoch total loss 1.57201457\n",
      "Trained batch 1017 batch loss 1.52745414 epoch total loss 1.5719707\n",
      "Trained batch 1018 batch loss 1.46778214 epoch total loss 1.5718683\n",
      "Trained batch 1019 batch loss 1.48308408 epoch total loss 1.57178116\n",
      "Trained batch 1020 batch loss 1.58760214 epoch total loss 1.57179677\n",
      "Trained batch 1021 batch loss 1.55450368 epoch total loss 1.57177973\n",
      "Trained batch 1022 batch loss 1.5132786 epoch total loss 1.57172251\n",
      "Trained batch 1023 batch loss 1.41202784 epoch total loss 1.57156634\n",
      "Trained batch 1024 batch loss 1.443717 epoch total loss 1.57144153\n",
      "Trained batch 1025 batch loss 1.44846809 epoch total loss 1.57132161\n",
      "Trained batch 1026 batch loss 1.43780124 epoch total loss 1.57119143\n",
      "Trained batch 1027 batch loss 1.45028186 epoch total loss 1.57107365\n",
      "Trained batch 1028 batch loss 1.46751118 epoch total loss 1.57097292\n",
      "Trained batch 1029 batch loss 1.49555087 epoch total loss 1.57089972\n",
      "Trained batch 1030 batch loss 1.47064042 epoch total loss 1.57080233\n",
      "Trained batch 1031 batch loss 1.487252 epoch total loss 1.57072139\n",
      "Trained batch 1032 batch loss 1.50065279 epoch total loss 1.57065344\n",
      "Trained batch 1033 batch loss 1.60505295 epoch total loss 1.5706867\n",
      "Trained batch 1034 batch loss 1.59438229 epoch total loss 1.57070959\n",
      "Trained batch 1035 batch loss 1.64251876 epoch total loss 1.57077909\n",
      "Trained batch 1036 batch loss 1.4225961 epoch total loss 1.57063603\n",
      "Trained batch 1037 batch loss 1.33398497 epoch total loss 1.57040787\n",
      "Trained batch 1038 batch loss 1.56691241 epoch total loss 1.57040441\n",
      "Trained batch 1039 batch loss 1.54737902 epoch total loss 1.57038224\n",
      "Trained batch 1040 batch loss 1.51880693 epoch total loss 1.57033265\n",
      "Trained batch 1041 batch loss 1.57592249 epoch total loss 1.57033801\n",
      "Trained batch 1042 batch loss 1.53901637 epoch total loss 1.57030809\n",
      "Trained batch 1043 batch loss 1.54465961 epoch total loss 1.57028353\n",
      "Trained batch 1044 batch loss 1.46696675 epoch total loss 1.57018447\n",
      "Trained batch 1045 batch loss 1.48610425 epoch total loss 1.570104\n",
      "Trained batch 1046 batch loss 1.49134898 epoch total loss 1.57002866\n",
      "Trained batch 1047 batch loss 1.43385911 epoch total loss 1.56989861\n",
      "Trained batch 1048 batch loss 1.55308533 epoch total loss 1.56988263\n",
      "Trained batch 1049 batch loss 1.48762155 epoch total loss 1.56980419\n",
      "Trained batch 1050 batch loss 1.45887661 epoch total loss 1.56969857\n",
      "Trained batch 1051 batch loss 1.47310793 epoch total loss 1.56960666\n",
      "Trained batch 1052 batch loss 1.63900518 epoch total loss 1.5696727\n",
      "Trained batch 1053 batch loss 1.4247582 epoch total loss 1.56953514\n",
      "Trained batch 1054 batch loss 1.48114812 epoch total loss 1.56945133\n",
      "Trained batch 1055 batch loss 1.38129115 epoch total loss 1.56927299\n",
      "Trained batch 1056 batch loss 1.56757641 epoch total loss 1.56927145\n",
      "Trained batch 1057 batch loss 1.5617373 epoch total loss 1.56926429\n",
      "Trained batch 1058 batch loss 1.51542234 epoch total loss 1.56921339\n",
      "Trained batch 1059 batch loss 1.51207089 epoch total loss 1.56915951\n",
      "Trained batch 1060 batch loss 1.47722471 epoch total loss 1.56907272\n",
      "Trained batch 1061 batch loss 1.47660828 epoch total loss 1.56898546\n",
      "Trained batch 1062 batch loss 1.53341734 epoch total loss 1.56895208\n",
      "Trained batch 1063 batch loss 1.51441908 epoch total loss 1.5689007\n",
      "Trained batch 1064 batch loss 1.47358251 epoch total loss 1.56881118\n",
      "Trained batch 1065 batch loss 1.5658257 epoch total loss 1.56880832\n",
      "Trained batch 1066 batch loss 1.59099 epoch total loss 1.56882906\n",
      "Trained batch 1067 batch loss 1.54177749 epoch total loss 1.56880367\n",
      "Trained batch 1068 batch loss 1.48839676 epoch total loss 1.56872845\n",
      "Trained batch 1069 batch loss 1.46120417 epoch total loss 1.56862783\n",
      "Trained batch 1070 batch loss 1.55385053 epoch total loss 1.56861401\n",
      "Trained batch 1071 batch loss 1.50304556 epoch total loss 1.56855285\n",
      "Trained batch 1072 batch loss 1.53294647 epoch total loss 1.56851959\n",
      "Trained batch 1073 batch loss 1.50532913 epoch total loss 1.5684607\n",
      "Trained batch 1074 batch loss 1.51530898 epoch total loss 1.56841123\n",
      "Trained batch 1075 batch loss 1.48328185 epoch total loss 1.56833196\n",
      "Trained batch 1076 batch loss 1.50566483 epoch total loss 1.56827366\n",
      "Trained batch 1077 batch loss 1.60315728 epoch total loss 1.56830609\n",
      "Trained batch 1078 batch loss 1.43443823 epoch total loss 1.56818187\n",
      "Trained batch 1079 batch loss 1.50200331 epoch total loss 1.5681206\n",
      "Trained batch 1080 batch loss 1.47627938 epoch total loss 1.5680356\n",
      "Trained batch 1081 batch loss 1.43715763 epoch total loss 1.56791449\n",
      "Trained batch 1082 batch loss 1.46898174 epoch total loss 1.56782305\n",
      "Trained batch 1083 batch loss 1.36751437 epoch total loss 1.56763816\n",
      "Trained batch 1084 batch loss 1.28457463 epoch total loss 1.56737697\n",
      "Trained batch 1085 batch loss 1.64841092 epoch total loss 1.56745172\n",
      "Trained batch 1086 batch loss 1.61174321 epoch total loss 1.56749237\n",
      "Trained batch 1087 batch loss 1.47012532 epoch total loss 1.56740284\n",
      "Trained batch 1088 batch loss 1.5378617 epoch total loss 1.56737566\n",
      "Trained batch 1089 batch loss 1.52928734 epoch total loss 1.56734061\n",
      "Trained batch 1090 batch loss 1.57547939 epoch total loss 1.56734812\n",
      "Trained batch 1091 batch loss 1.51480246 epoch total loss 1.5673\n",
      "Trained batch 1092 batch loss 1.36350572 epoch total loss 1.56711328\n",
      "Trained batch 1093 batch loss 1.43199348 epoch total loss 1.56698966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1094 batch loss 1.44899631 epoch total loss 1.56688178\n",
      "Trained batch 1095 batch loss 1.50962532 epoch total loss 1.56682956\n",
      "Trained batch 1096 batch loss 1.52914333 epoch total loss 1.56679523\n",
      "Trained batch 1097 batch loss 1.55421972 epoch total loss 1.56678367\n",
      "Trained batch 1098 batch loss 1.56543648 epoch total loss 1.56678247\n",
      "Trained batch 1099 batch loss 1.59846628 epoch total loss 1.56681132\n",
      "Trained batch 1100 batch loss 1.49627709 epoch total loss 1.56674731\n",
      "Trained batch 1101 batch loss 1.42595816 epoch total loss 1.5666194\n",
      "Trained batch 1102 batch loss 1.46146452 epoch total loss 1.56652391\n",
      "Trained batch 1103 batch loss 1.41524231 epoch total loss 1.56638682\n",
      "Trained batch 1104 batch loss 1.46903682 epoch total loss 1.5662986\n",
      "Trained batch 1105 batch loss 1.4323864 epoch total loss 1.56617737\n",
      "Trained batch 1106 batch loss 1.35705328 epoch total loss 1.5659883\n",
      "Trained batch 1107 batch loss 1.44730139 epoch total loss 1.56588101\n",
      "Trained batch 1108 batch loss 1.43347991 epoch total loss 1.56576157\n",
      "Trained batch 1109 batch loss 1.48909616 epoch total loss 1.56569242\n",
      "Trained batch 1110 batch loss 1.54126859 epoch total loss 1.56567037\n",
      "Trained batch 1111 batch loss 1.50834155 epoch total loss 1.56561875\n",
      "Trained batch 1112 batch loss 1.4175024 epoch total loss 1.5654856\n",
      "Trained batch 1113 batch loss 1.3982904 epoch total loss 1.56533539\n",
      "Trained batch 1114 batch loss 1.45851231 epoch total loss 1.56523943\n",
      "Trained batch 1115 batch loss 1.53980446 epoch total loss 1.56521666\n",
      "Trained batch 1116 batch loss 1.50110686 epoch total loss 1.5651592\n",
      "Trained batch 1117 batch loss 1.42962 epoch total loss 1.56503785\n",
      "Trained batch 1118 batch loss 1.36195338 epoch total loss 1.56485617\n",
      "Trained batch 1119 batch loss 1.38417554 epoch total loss 1.56469464\n",
      "Trained batch 1120 batch loss 1.45720911 epoch total loss 1.56459868\n",
      "Trained batch 1121 batch loss 1.50031829 epoch total loss 1.56454134\n",
      "Trained batch 1122 batch loss 1.53480196 epoch total loss 1.56451476\n",
      "Trained batch 1123 batch loss 1.55563962 epoch total loss 1.56450689\n",
      "Trained batch 1124 batch loss 1.53380346 epoch total loss 1.56447959\n",
      "Trained batch 1125 batch loss 1.52078366 epoch total loss 1.56444073\n",
      "Trained batch 1126 batch loss 1.52091944 epoch total loss 1.5644021\n",
      "Trained batch 1127 batch loss 1.43074083 epoch total loss 1.56428349\n",
      "Trained batch 1128 batch loss 1.45778978 epoch total loss 1.56418908\n",
      "Trained batch 1129 batch loss 1.49228811 epoch total loss 1.56412542\n",
      "Trained batch 1130 batch loss 1.43070781 epoch total loss 1.56400728\n",
      "Trained batch 1131 batch loss 1.51458 epoch total loss 1.56396353\n",
      "Trained batch 1132 batch loss 1.36957359 epoch total loss 1.56379187\n",
      "Trained batch 1133 batch loss 1.48368526 epoch total loss 1.56372118\n",
      "Trained batch 1134 batch loss 1.37369585 epoch total loss 1.56355357\n",
      "Trained batch 1135 batch loss 1.4154458 epoch total loss 1.56342304\n",
      "Trained batch 1136 batch loss 1.42426336 epoch total loss 1.56330049\n",
      "Trained batch 1137 batch loss 1.51280725 epoch total loss 1.56325614\n",
      "Trained batch 1138 batch loss 1.45517182 epoch total loss 1.56316125\n",
      "Trained batch 1139 batch loss 1.54413199 epoch total loss 1.56314456\n",
      "Trained batch 1140 batch loss 1.4891243 epoch total loss 1.5630796\n",
      "Trained batch 1141 batch loss 1.5103085 epoch total loss 1.56303334\n",
      "Trained batch 1142 batch loss 1.51919031 epoch total loss 1.56299496\n",
      "Trained batch 1143 batch loss 1.58839369 epoch total loss 1.56301713\n",
      "Trained batch 1144 batch loss 1.47185016 epoch total loss 1.56293738\n",
      "Trained batch 1145 batch loss 1.50518179 epoch total loss 1.56288683\n",
      "Trained batch 1146 batch loss 1.41189408 epoch total loss 1.56275511\n",
      "Trained batch 1147 batch loss 1.41345358 epoch total loss 1.56262493\n",
      "Trained batch 1148 batch loss 1.40579522 epoch total loss 1.56248832\n",
      "Trained batch 1149 batch loss 1.32566702 epoch total loss 1.5622822\n",
      "Trained batch 1150 batch loss 1.52736545 epoch total loss 1.56225181\n",
      "Trained batch 1151 batch loss 1.46214724 epoch total loss 1.5621649\n",
      "Trained batch 1152 batch loss 1.39742017 epoch total loss 1.56202185\n",
      "Trained batch 1153 batch loss 1.38630509 epoch total loss 1.5618695\n",
      "Trained batch 1154 batch loss 1.51315153 epoch total loss 1.5618273\n",
      "Trained batch 1155 batch loss 1.43796778 epoch total loss 1.56172013\n",
      "Trained batch 1156 batch loss 1.40449822 epoch total loss 1.56158412\n",
      "Trained batch 1157 batch loss 1.45124471 epoch total loss 1.56148887\n",
      "Trained batch 1158 batch loss 1.54119253 epoch total loss 1.56147122\n",
      "Trained batch 1159 batch loss 1.49766493 epoch total loss 1.56141627\n",
      "Trained batch 1160 batch loss 1.561795 epoch total loss 1.56141651\n",
      "Trained batch 1161 batch loss 1.44898391 epoch total loss 1.56131971\n",
      "Trained batch 1162 batch loss 1.42783689 epoch total loss 1.56120479\n",
      "Trained batch 1163 batch loss 1.47753572 epoch total loss 1.56113291\n",
      "Trained batch 1164 batch loss 1.42003155 epoch total loss 1.56101167\n",
      "Trained batch 1165 batch loss 1.39340055 epoch total loss 1.56086779\n",
      "Trained batch 1166 batch loss 1.41161633 epoch total loss 1.56073987\n",
      "Trained batch 1167 batch loss 1.44511676 epoch total loss 1.56064069\n",
      "Trained batch 1168 batch loss 1.47007155 epoch total loss 1.56056321\n",
      "Trained batch 1169 batch loss 1.43818653 epoch total loss 1.56045854\n",
      "Trained batch 1170 batch loss 1.40265906 epoch total loss 1.56032372\n",
      "Trained batch 1171 batch loss 1.50249934 epoch total loss 1.56027424\n",
      "Trained batch 1172 batch loss 1.48718429 epoch total loss 1.5602119\n",
      "Trained batch 1173 batch loss 1.57527733 epoch total loss 1.56022477\n",
      "Trained batch 1174 batch loss 1.63449907 epoch total loss 1.56028807\n",
      "Trained batch 1175 batch loss 1.65161943 epoch total loss 1.5603658\n",
      "Trained batch 1176 batch loss 1.6729697 epoch total loss 1.56046152\n",
      "Trained batch 1177 batch loss 1.47129512 epoch total loss 1.56038582\n",
      "Trained batch 1178 batch loss 1.47404361 epoch total loss 1.56031251\n",
      "Trained batch 1179 batch loss 1.32836616 epoch total loss 1.56011569\n",
      "Trained batch 1180 batch loss 1.54039872 epoch total loss 1.56009901\n",
      "Trained batch 1181 batch loss 1.50148606 epoch total loss 1.56004941\n",
      "Trained batch 1182 batch loss 1.55078435 epoch total loss 1.56004155\n",
      "Trained batch 1183 batch loss 1.41435826 epoch total loss 1.5599184\n",
      "Trained batch 1184 batch loss 1.34263074 epoch total loss 1.55973482\n",
      "Trained batch 1185 batch loss 1.41100025 epoch total loss 1.55960941\n",
      "Trained batch 1186 batch loss 1.42682791 epoch total loss 1.55949748\n",
      "Trained batch 1187 batch loss 1.55225098 epoch total loss 1.55949128\n",
      "Trained batch 1188 batch loss 1.7059834 epoch total loss 1.55961466\n",
      "Trained batch 1189 batch loss 1.67611551 epoch total loss 1.55971265\n",
      "Trained batch 1190 batch loss 1.54651117 epoch total loss 1.55970156\n",
      "Trained batch 1191 batch loss 1.53205884 epoch total loss 1.55967832\n",
      "Trained batch 1192 batch loss 1.65999568 epoch total loss 1.55976248\n",
      "Trained batch 1193 batch loss 1.62041974 epoch total loss 1.55981338\n",
      "Trained batch 1194 batch loss 1.55273724 epoch total loss 1.55980742\n",
      "Trained batch 1195 batch loss 1.50943232 epoch total loss 1.55976522\n",
      "Trained batch 1196 batch loss 1.4850595 epoch total loss 1.55970275\n",
      "Trained batch 1197 batch loss 1.49725556 epoch total loss 1.55965066\n",
      "Trained batch 1198 batch loss 1.54619765 epoch total loss 1.55963945\n",
      "Trained batch 1199 batch loss 1.45969772 epoch total loss 1.55955601\n",
      "Trained batch 1200 batch loss 1.41907763 epoch total loss 1.55943894\n",
      "Trained batch 1201 batch loss 1.45465064 epoch total loss 1.55935168\n",
      "Trained batch 1202 batch loss 1.55069351 epoch total loss 1.55934441\n",
      "Trained batch 1203 batch loss 1.49831235 epoch total loss 1.55929375\n",
      "Trained batch 1204 batch loss 1.40894234 epoch total loss 1.55916882\n",
      "Trained batch 1205 batch loss 1.4065969 epoch total loss 1.55904222\n",
      "Trained batch 1206 batch loss 1.43545926 epoch total loss 1.5589397\n",
      "Trained batch 1207 batch loss 1.43026507 epoch total loss 1.55883312\n",
      "Trained batch 1208 batch loss 1.46808887 epoch total loss 1.55875802\n",
      "Trained batch 1209 batch loss 1.45732 epoch total loss 1.5586741\n",
      "Trained batch 1210 batch loss 1.43649614 epoch total loss 1.55857313\n",
      "Trained batch 1211 batch loss 1.35288596 epoch total loss 1.55840337\n",
      "Trained batch 1212 batch loss 1.3482852 epoch total loss 1.55822992\n",
      "Trained batch 1213 batch loss 1.48787618 epoch total loss 1.55817199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1214 batch loss 1.30572939 epoch total loss 1.55796409\n",
      "Trained batch 1215 batch loss 1.45946205 epoch total loss 1.55788302\n",
      "Trained batch 1216 batch loss 1.38232458 epoch total loss 1.55773866\n",
      "Trained batch 1217 batch loss 1.40081382 epoch total loss 1.55760968\n",
      "Trained batch 1218 batch loss 1.56881261 epoch total loss 1.55761886\n",
      "Trained batch 1219 batch loss 1.47549117 epoch total loss 1.5575515\n",
      "Trained batch 1220 batch loss 1.26182842 epoch total loss 1.55730915\n",
      "Trained batch 1221 batch loss 1.35918593 epoch total loss 1.55714679\n",
      "Trained batch 1222 batch loss 1.33649862 epoch total loss 1.5569663\n",
      "Trained batch 1223 batch loss 1.37058544 epoch total loss 1.55681396\n",
      "Trained batch 1224 batch loss 1.41757166 epoch total loss 1.55670011\n",
      "Trained batch 1225 batch loss 1.47346652 epoch total loss 1.55663228\n",
      "Trained batch 1226 batch loss 1.50259757 epoch total loss 1.55658817\n",
      "Trained batch 1227 batch loss 1.32491469 epoch total loss 1.55639935\n",
      "Trained batch 1228 batch loss 1.37647784 epoch total loss 1.55625284\n",
      "Trained batch 1229 batch loss 1.41621709 epoch total loss 1.55613899\n",
      "Trained batch 1230 batch loss 1.5760994 epoch total loss 1.55615509\n",
      "Trained batch 1231 batch loss 1.47117305 epoch total loss 1.55608606\n",
      "Trained batch 1232 batch loss 1.47636211 epoch total loss 1.55602133\n",
      "Trained batch 1233 batch loss 1.39543366 epoch total loss 1.55589104\n",
      "Trained batch 1234 batch loss 1.30449545 epoch total loss 1.55568731\n",
      "Trained batch 1235 batch loss 1.31979096 epoch total loss 1.55549634\n",
      "Trained batch 1236 batch loss 1.35363507 epoch total loss 1.55533302\n",
      "Trained batch 1237 batch loss 1.36858201 epoch total loss 1.55518198\n",
      "Trained batch 1238 batch loss 1.47598743 epoch total loss 1.55511796\n",
      "Trained batch 1239 batch loss 1.46073127 epoch total loss 1.55504179\n",
      "Trained batch 1240 batch loss 1.46015704 epoch total loss 1.55496526\n",
      "Trained batch 1241 batch loss 1.43716717 epoch total loss 1.55487037\n",
      "Trained batch 1242 batch loss 1.44021583 epoch total loss 1.55477798\n",
      "Trained batch 1243 batch loss 1.36959231 epoch total loss 1.55462909\n",
      "Trained batch 1244 batch loss 1.41957569 epoch total loss 1.55452049\n",
      "Trained batch 1245 batch loss 1.50480413 epoch total loss 1.55448055\n",
      "Trained batch 1246 batch loss 1.49374151 epoch total loss 1.5544318\n",
      "Trained batch 1247 batch loss 1.44834018 epoch total loss 1.5543468\n",
      "Trained batch 1248 batch loss 1.45939589 epoch total loss 1.55427063\n",
      "Trained batch 1249 batch loss 1.32612181 epoch total loss 1.554088\n",
      "Trained batch 1250 batch loss 1.44401431 epoch total loss 1.5539999\n",
      "Trained batch 1251 batch loss 1.35615158 epoch total loss 1.55384183\n",
      "Trained batch 1252 batch loss 1.42423654 epoch total loss 1.55373824\n",
      "Trained batch 1253 batch loss 1.33250988 epoch total loss 1.55356169\n",
      "Trained batch 1254 batch loss 1.40030575 epoch total loss 1.5534395\n",
      "Trained batch 1255 batch loss 1.34428906 epoch total loss 1.55327272\n",
      "Trained batch 1256 batch loss 1.43212152 epoch total loss 1.55317628\n",
      "Trained batch 1257 batch loss 1.45051551 epoch total loss 1.55309463\n",
      "Trained batch 1258 batch loss 1.451092 epoch total loss 1.55301356\n",
      "Trained batch 1259 batch loss 1.43997359 epoch total loss 1.55292368\n",
      "Trained batch 1260 batch loss 1.42012358 epoch total loss 1.55281842\n",
      "Trained batch 1261 batch loss 1.39352906 epoch total loss 1.55269206\n",
      "Trained batch 1262 batch loss 1.54037833 epoch total loss 1.55268228\n",
      "Trained batch 1263 batch loss 1.45615089 epoch total loss 1.55260587\n",
      "Trained batch 1264 batch loss 1.4571259 epoch total loss 1.55253041\n",
      "Trained batch 1265 batch loss 1.32730603 epoch total loss 1.55235231\n",
      "Trained batch 1266 batch loss 1.37039602 epoch total loss 1.55220854\n",
      "Trained batch 1267 batch loss 1.36931157 epoch total loss 1.55206418\n",
      "Trained batch 1268 batch loss 1.32129371 epoch total loss 1.55188215\n",
      "Trained batch 1269 batch loss 1.39328694 epoch total loss 1.55175722\n",
      "Trained batch 1270 batch loss 1.35776949 epoch total loss 1.55160451\n",
      "Trained batch 1271 batch loss 1.37773681 epoch total loss 1.55146766\n",
      "Trained batch 1272 batch loss 1.37132931 epoch total loss 1.55132604\n",
      "Trained batch 1273 batch loss 1.38882518 epoch total loss 1.55119836\n",
      "Trained batch 1274 batch loss 1.37662828 epoch total loss 1.55106127\n",
      "Trained batch 1275 batch loss 1.33600938 epoch total loss 1.55089271\n",
      "Trained batch 1276 batch loss 1.45881331 epoch total loss 1.55082059\n",
      "Trained batch 1277 batch loss 1.54840732 epoch total loss 1.55081868\n",
      "Trained batch 1278 batch loss 1.43764925 epoch total loss 1.55073011\n",
      "Trained batch 1279 batch loss 1.43791795 epoch total loss 1.55064189\n",
      "Trained batch 1280 batch loss 1.44134402 epoch total loss 1.55055642\n",
      "Trained batch 1281 batch loss 1.38428009 epoch total loss 1.55042672\n",
      "Trained batch 1282 batch loss 1.45274949 epoch total loss 1.55035043\n",
      "Trained batch 1283 batch loss 1.32515 epoch total loss 1.55017495\n",
      "Trained batch 1284 batch loss 1.40146399 epoch total loss 1.5500592\n",
      "Trained batch 1285 batch loss 1.45828819 epoch total loss 1.54998779\n",
      "Trained batch 1286 batch loss 1.48455048 epoch total loss 1.54993677\n",
      "Trained batch 1287 batch loss 1.46167445 epoch total loss 1.54986823\n",
      "Trained batch 1288 batch loss 1.41206717 epoch total loss 1.5497613\n",
      "Trained batch 1289 batch loss 1.40015411 epoch total loss 1.54964519\n",
      "Trained batch 1290 batch loss 1.32352638 epoch total loss 1.54947\n",
      "Trained batch 1291 batch loss 1.42982948 epoch total loss 1.5493772\n",
      "Trained batch 1292 batch loss 1.41601825 epoch total loss 1.54927397\n",
      "Trained batch 1293 batch loss 1.30716968 epoch total loss 1.54908669\n",
      "Trained batch 1294 batch loss 1.4472599 epoch total loss 1.54900801\n",
      "Trained batch 1295 batch loss 1.43193817 epoch total loss 1.54891753\n",
      "Trained batch 1296 batch loss 1.4707942 epoch total loss 1.54885733\n",
      "Trained batch 1297 batch loss 1.44877183 epoch total loss 1.54878008\n",
      "Trained batch 1298 batch loss 1.45283842 epoch total loss 1.54870629\n",
      "Trained batch 1299 batch loss 1.39681196 epoch total loss 1.54858935\n",
      "Trained batch 1300 batch loss 1.57699859 epoch total loss 1.54861116\n",
      "Trained batch 1301 batch loss 1.37053347 epoch total loss 1.54847431\n",
      "Trained batch 1302 batch loss 1.44702148 epoch total loss 1.54839635\n",
      "Trained batch 1303 batch loss 1.51585245 epoch total loss 1.54837143\n",
      "Trained batch 1304 batch loss 1.49348688 epoch total loss 1.54832935\n",
      "Trained batch 1305 batch loss 1.52173662 epoch total loss 1.54830897\n",
      "Trained batch 1306 batch loss 1.47229302 epoch total loss 1.54825079\n",
      "Trained batch 1307 batch loss 1.5696919 epoch total loss 1.54826713\n",
      "Trained batch 1308 batch loss 1.50133014 epoch total loss 1.54823136\n",
      "Trained batch 1309 batch loss 1.39676106 epoch total loss 1.54811561\n",
      "Trained batch 1310 batch loss 1.49313259 epoch total loss 1.54807365\n",
      "Trained batch 1311 batch loss 1.53108752 epoch total loss 1.54806066\n",
      "Trained batch 1312 batch loss 1.55287719 epoch total loss 1.54806435\n",
      "Trained batch 1313 batch loss 1.53087163 epoch total loss 1.54805124\n",
      "Trained batch 1314 batch loss 1.38811636 epoch total loss 1.54792953\n",
      "Trained batch 1315 batch loss 1.55785882 epoch total loss 1.54793704\n",
      "Trained batch 1316 batch loss 1.48584807 epoch total loss 1.54788983\n",
      "Trained batch 1317 batch loss 1.4415915 epoch total loss 1.54780924\n",
      "Trained batch 1318 batch loss 1.52546859 epoch total loss 1.54779232\n",
      "Trained batch 1319 batch loss 1.57175112 epoch total loss 1.54781044\n",
      "Trained batch 1320 batch loss 1.48425114 epoch total loss 1.54776227\n",
      "Trained batch 1321 batch loss 1.41219294 epoch total loss 1.54765975\n",
      "Trained batch 1322 batch loss 1.26716149 epoch total loss 1.54744756\n",
      "Trained batch 1323 batch loss 1.28081644 epoch total loss 1.54724598\n",
      "Trained batch 1324 batch loss 1.19576216 epoch total loss 1.5469805\n",
      "Trained batch 1325 batch loss 1.6147126 epoch total loss 1.54703164\n",
      "Trained batch 1326 batch loss 1.50464725 epoch total loss 1.54699969\n",
      "Trained batch 1327 batch loss 1.51052558 epoch total loss 1.54697216\n",
      "Trained batch 1328 batch loss 1.52238154 epoch total loss 1.54695368\n",
      "Trained batch 1329 batch loss 1.67400324 epoch total loss 1.54704928\n",
      "Trained batch 1330 batch loss 1.47690713 epoch total loss 1.54699647\n",
      "Trained batch 1331 batch loss 1.34118617 epoch total loss 1.54684174\n",
      "Trained batch 1332 batch loss 1.43865323 epoch total loss 1.54676068\n",
      "Trained batch 1333 batch loss 1.42111719 epoch total loss 1.54666638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1334 batch loss 1.39069009 epoch total loss 1.54654944\n",
      "Trained batch 1335 batch loss 1.45990562 epoch total loss 1.54648459\n",
      "Trained batch 1336 batch loss 1.52888715 epoch total loss 1.54647136\n",
      "Trained batch 1337 batch loss 1.48497367 epoch total loss 1.54642522\n",
      "Trained batch 1338 batch loss 1.50335562 epoch total loss 1.54639316\n",
      "Trained batch 1339 batch loss 1.48643851 epoch total loss 1.54634821\n",
      "Trained batch 1340 batch loss 1.59564137 epoch total loss 1.54638505\n",
      "Trained batch 1341 batch loss 1.56142974 epoch total loss 1.54639637\n",
      "Trained batch 1342 batch loss 1.49587929 epoch total loss 1.5463587\n",
      "Trained batch 1343 batch loss 1.51131094 epoch total loss 1.5463326\n",
      "Trained batch 1344 batch loss 1.49713731 epoch total loss 1.54629588\n",
      "Trained batch 1345 batch loss 1.42618477 epoch total loss 1.54620671\n",
      "Trained batch 1346 batch loss 1.53596795 epoch total loss 1.54619896\n",
      "Trained batch 1347 batch loss 1.39742935 epoch total loss 1.54608858\n",
      "Trained batch 1348 batch loss 1.36413896 epoch total loss 1.54595363\n",
      "Trained batch 1349 batch loss 1.48634362 epoch total loss 1.54590952\n",
      "Trained batch 1350 batch loss 1.2250433 epoch total loss 1.54567182\n",
      "Trained batch 1351 batch loss 1.32885802 epoch total loss 1.54551136\n",
      "Trained batch 1352 batch loss 1.59779751 epoch total loss 1.54555011\n",
      "Trained batch 1353 batch loss 1.55898571 epoch total loss 1.54556012\n",
      "Trained batch 1354 batch loss 1.38477755 epoch total loss 1.54544139\n",
      "Trained batch 1355 batch loss 1.38865459 epoch total loss 1.54532564\n",
      "Trained batch 1356 batch loss 1.35172784 epoch total loss 1.54518294\n",
      "Trained batch 1357 batch loss 1.32660699 epoch total loss 1.54502189\n",
      "Trained batch 1358 batch loss 1.32831502 epoch total loss 1.54486239\n",
      "Trained batch 1359 batch loss 1.26950049 epoch total loss 1.54465973\n",
      "Trained batch 1360 batch loss 1.31024361 epoch total loss 1.54448748\n",
      "Trained batch 1361 batch loss 1.39502835 epoch total loss 1.54437768\n",
      "Trained batch 1362 batch loss 1.41542888 epoch total loss 1.54428303\n",
      "Trained batch 1363 batch loss 1.45440125 epoch total loss 1.54421699\n",
      "Trained batch 1364 batch loss 1.50408 epoch total loss 1.54418766\n",
      "Trained batch 1365 batch loss 1.43235624 epoch total loss 1.54410577\n",
      "Trained batch 1366 batch loss 1.36903691 epoch total loss 1.54397762\n",
      "Trained batch 1367 batch loss 1.31390488 epoch total loss 1.54380941\n",
      "Trained batch 1368 batch loss 1.54551673 epoch total loss 1.54381061\n",
      "Trained batch 1369 batch loss 1.56066847 epoch total loss 1.54382277\n",
      "Trained batch 1370 batch loss 1.41237092 epoch total loss 1.5437268\n",
      "Trained batch 1371 batch loss 1.62482023 epoch total loss 1.54378593\n",
      "Trained batch 1372 batch loss 1.4448117 epoch total loss 1.54371381\n",
      "Trained batch 1373 batch loss 1.51687503 epoch total loss 1.54369426\n",
      "Trained batch 1374 batch loss 1.43630981 epoch total loss 1.54361606\n",
      "Trained batch 1375 batch loss 1.47550118 epoch total loss 1.54356658\n",
      "Trained batch 1376 batch loss 1.4542768 epoch total loss 1.54350173\n",
      "Trained batch 1377 batch loss 1.45217228 epoch total loss 1.54343545\n",
      "Trained batch 1378 batch loss 1.42263901 epoch total loss 1.54334772\n",
      "Trained batch 1379 batch loss 1.45672798 epoch total loss 1.54328489\n",
      "Trained batch 1380 batch loss 1.33913326 epoch total loss 1.54313695\n",
      "Trained batch 1381 batch loss 1.37198496 epoch total loss 1.5430131\n",
      "Trained batch 1382 batch loss 1.26459956 epoch total loss 1.54281175\n",
      "Trained batch 1383 batch loss 1.24612069 epoch total loss 1.54259717\n",
      "Trained batch 1384 batch loss 1.3848896 epoch total loss 1.54248333\n",
      "Trained batch 1385 batch loss 1.4814266 epoch total loss 1.54243922\n",
      "Trained batch 1386 batch loss 1.55801129 epoch total loss 1.54245055\n",
      "Trained batch 1387 batch loss 1.62073064 epoch total loss 1.54250705\n",
      "Trained batch 1388 batch loss 1.58241439 epoch total loss 1.5425359\n",
      "Epoch 1 train loss 1.5425359010696411\n",
      "Validated batch 1 batch loss 1.5071981\n",
      "Validated batch 2 batch loss 1.44141257\n",
      "Validated batch 3 batch loss 1.37139237\n",
      "Validated batch 4 batch loss 1.33592296\n",
      "Validated batch 5 batch loss 1.40555048\n",
      "Validated batch 6 batch loss 1.45802891\n",
      "Validated batch 7 batch loss 1.3762238\n",
      "Validated batch 8 batch loss 1.37633252\n",
      "Validated batch 9 batch loss 1.47156382\n",
      "Validated batch 10 batch loss 1.44598722\n",
      "Validated batch 11 batch loss 1.35222\n",
      "Validated batch 12 batch loss 1.3117187\n",
      "Validated batch 13 batch loss 1.4338063\n",
      "Validated batch 14 batch loss 1.46212077\n",
      "Validated batch 15 batch loss 1.54202461\n",
      "Validated batch 16 batch loss 1.49001122\n",
      "Validated batch 17 batch loss 1.41143143\n",
      "Validated batch 18 batch loss 1.53301322\n",
      "Validated batch 19 batch loss 1.45593655\n",
      "Validated batch 20 batch loss 1.41497898\n",
      "Validated batch 21 batch loss 1.50611556\n",
      "Validated batch 22 batch loss 1.20892286\n",
      "Validated batch 23 batch loss 1.48534274\n",
      "Validated batch 24 batch loss 1.47403896\n",
      "Validated batch 25 batch loss 1.42428529\n",
      "Validated batch 26 batch loss 1.36676085\n",
      "Validated batch 27 batch loss 1.35143566\n",
      "Validated batch 28 batch loss 1.4221071\n",
      "Validated batch 29 batch loss 1.48646772\n",
      "Validated batch 30 batch loss 1.31808186\n",
      "Validated batch 31 batch loss 1.44214463\n",
      "Validated batch 32 batch loss 1.48566008\n",
      "Validated batch 33 batch loss 1.41403234\n",
      "Validated batch 34 batch loss 1.41436648\n",
      "Validated batch 35 batch loss 1.30028188\n",
      "Validated batch 36 batch loss 1.57447219\n",
      "Validated batch 37 batch loss 1.34898782\n",
      "Validated batch 38 batch loss 1.45180333\n",
      "Validated batch 39 batch loss 1.42648518\n",
      "Validated batch 40 batch loss 1.47660422\n",
      "Validated batch 41 batch loss 1.28553283\n",
      "Validated batch 42 batch loss 1.39284158\n",
      "Validated batch 43 batch loss 1.39983916\n",
      "Validated batch 44 batch loss 1.40389478\n",
      "Validated batch 45 batch loss 1.40098739\n",
      "Validated batch 46 batch loss 1.41243339\n",
      "Validated batch 47 batch loss 1.4348892\n",
      "Validated batch 48 batch loss 1.35179663\n",
      "Validated batch 49 batch loss 1.38841927\n",
      "Validated batch 50 batch loss 1.35689104\n",
      "Validated batch 51 batch loss 1.43240345\n",
      "Validated batch 52 batch loss 1.4350884\n",
      "Validated batch 53 batch loss 1.48704994\n",
      "Validated batch 54 batch loss 1.40904236\n",
      "Validated batch 55 batch loss 1.43793762\n",
      "Validated batch 56 batch loss 1.46226144\n",
      "Validated batch 57 batch loss 1.53049207\n",
      "Validated batch 58 batch loss 1.48309636\n",
      "Validated batch 59 batch loss 1.40674853\n",
      "Validated batch 60 batch loss 1.36057341\n",
      "Validated batch 61 batch loss 1.47631347\n",
      "Validated batch 62 batch loss 1.44669878\n",
      "Validated batch 63 batch loss 1.51673257\n",
      "Validated batch 64 batch loss 1.47027171\n",
      "Validated batch 65 batch loss 1.38266242\n",
      "Validated batch 66 batch loss 1.51460457\n",
      "Validated batch 67 batch loss 1.40250254\n",
      "Validated batch 68 batch loss 1.4173373\n",
      "Validated batch 69 batch loss 1.45307839\n",
      "Validated batch 70 batch loss 1.38154876\n",
      "Validated batch 71 batch loss 1.34165549\n",
      "Validated batch 72 batch loss 1.44232845\n",
      "Validated batch 73 batch loss 1.3734653\n",
      "Validated batch 74 batch loss 1.39384794\n",
      "Validated batch 75 batch loss 1.49258375\n",
      "Validated batch 76 batch loss 1.47312605\n",
      "Validated batch 77 batch loss 1.50230408\n",
      "Validated batch 78 batch loss 1.49413931\n",
      "Validated batch 79 batch loss 1.44982898\n",
      "Validated batch 80 batch loss 1.42942858\n",
      "Validated batch 81 batch loss 1.51121306\n",
      "Validated batch 82 batch loss 1.44765651\n",
      "Validated batch 83 batch loss 1.54751873\n",
      "Validated batch 84 batch loss 1.52994144\n",
      "Validated batch 85 batch loss 1.48863459\n",
      "Validated batch 86 batch loss 1.49126279\n",
      "Validated batch 87 batch loss 1.31651497\n",
      "Validated batch 88 batch loss 1.41867316\n",
      "Validated batch 89 batch loss 1.45924401\n",
      "Validated batch 90 batch loss 1.48085165\n",
      "Validated batch 91 batch loss 1.45700479\n",
      "Validated batch 92 batch loss 1.41084337\n",
      "Validated batch 93 batch loss 1.33946085\n",
      "Validated batch 94 batch loss 1.49355197\n",
      "Validated batch 95 batch loss 1.50275552\n",
      "Validated batch 96 batch loss 1.41752887\n",
      "Validated batch 97 batch loss 1.47087681\n",
      "Validated batch 98 batch loss 1.54625046\n",
      "Validated batch 99 batch loss 1.3101871\n",
      "Validated batch 100 batch loss 1.4723959\n",
      "Validated batch 101 batch loss 1.38393223\n",
      "Validated batch 102 batch loss 1.4591279\n",
      "Validated batch 103 batch loss 1.48419118\n",
      "Validated batch 104 batch loss 1.34412515\n",
      "Validated batch 105 batch loss 1.25286317\n",
      "Validated batch 106 batch loss 1.43226552\n",
      "Validated batch 107 batch loss 1.43287182\n",
      "Validated batch 108 batch loss 1.43382776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 109 batch loss 1.42926371\n",
      "Validated batch 110 batch loss 1.4182663\n",
      "Validated batch 111 batch loss 1.43840885\n",
      "Validated batch 112 batch loss 1.50936687\n",
      "Validated batch 113 batch loss 1.44479895\n",
      "Validated batch 114 batch loss 1.46641803\n",
      "Validated batch 115 batch loss 1.33080864\n",
      "Validated batch 116 batch loss 1.50526345\n",
      "Validated batch 117 batch loss 1.41096413\n",
      "Validated batch 118 batch loss 1.42711294\n",
      "Validated batch 119 batch loss 1.41795063\n",
      "Validated batch 120 batch loss 1.36872983\n",
      "Validated batch 121 batch loss 1.45580125\n",
      "Validated batch 122 batch loss 1.41814208\n",
      "Validated batch 123 batch loss 1.37166417\n",
      "Validated batch 124 batch loss 1.38893473\n",
      "Validated batch 125 batch loss 1.40136993\n",
      "Validated batch 126 batch loss 1.45405173\n",
      "Validated batch 127 batch loss 1.44656599\n",
      "Validated batch 128 batch loss 1.41670179\n",
      "Validated batch 129 batch loss 1.34504247\n",
      "Validated batch 130 batch loss 1.39414406\n",
      "Validated batch 131 batch loss 1.44047546\n",
      "Validated batch 132 batch loss 1.43815494\n",
      "Validated batch 133 batch loss 1.44928181\n",
      "Validated batch 134 batch loss 1.54621923\n",
      "Validated batch 135 batch loss 1.64756477\n",
      "Validated batch 136 batch loss 1.59767723\n",
      "Validated batch 137 batch loss 1.43592203\n",
      "Validated batch 138 batch loss 1.33898425\n",
      "Validated batch 139 batch loss 1.34760416\n",
      "Validated batch 140 batch loss 1.48000896\n",
      "Validated batch 141 batch loss 1.40884209\n",
      "Validated batch 142 batch loss 1.24655902\n",
      "Validated batch 143 batch loss 1.37476206\n",
      "Validated batch 144 batch loss 1.50373697\n",
      "Validated batch 145 batch loss 1.32652402\n",
      "Validated batch 146 batch loss 1.36408639\n",
      "Validated batch 147 batch loss 1.41289723\n",
      "Validated batch 148 batch loss 1.4638083\n",
      "Validated batch 149 batch loss 1.37153137\n",
      "Validated batch 150 batch loss 1.47614872\n",
      "Validated batch 151 batch loss 1.35707974\n",
      "Validated batch 152 batch loss 1.44430494\n",
      "Validated batch 153 batch loss 1.47949278\n",
      "Validated batch 154 batch loss 1.55189836\n",
      "Validated batch 155 batch loss 1.39675403\n",
      "Validated batch 156 batch loss 1.54177094\n",
      "Validated batch 157 batch loss 1.35416758\n",
      "Validated batch 158 batch loss 1.33087575\n",
      "Validated batch 159 batch loss 1.44589019\n",
      "Validated batch 160 batch loss 1.43749857\n",
      "Validated batch 161 batch loss 1.52111793\n",
      "Validated batch 162 batch loss 1.45940328\n",
      "Validated batch 163 batch loss 1.46054\n",
      "Validated batch 164 batch loss 1.39183033\n",
      "Validated batch 165 batch loss 1.40646577\n",
      "Validated batch 166 batch loss 1.48368967\n",
      "Validated batch 167 batch loss 1.44794476\n",
      "Validated batch 168 batch loss 1.47009897\n",
      "Validated batch 169 batch loss 1.51984823\n",
      "Validated batch 170 batch loss 1.49970961\n",
      "Validated batch 171 batch loss 1.47754991\n",
      "Validated batch 172 batch loss 1.4806695\n",
      "Validated batch 173 batch loss 1.5316658\n",
      "Validated batch 174 batch loss 1.36510849\n",
      "Validated batch 175 batch loss 1.48648405\n",
      "Validated batch 176 batch loss 1.55291784\n",
      "Validated batch 177 batch loss 1.43780279\n",
      "Validated batch 178 batch loss 1.49925685\n",
      "Validated batch 179 batch loss 1.38840079\n",
      "Validated batch 180 batch loss 1.30922914\n",
      "Validated batch 181 batch loss 1.41312218\n",
      "Validated batch 182 batch loss 1.34648108\n",
      "Validated batch 183 batch loss 1.53190351\n",
      "Validated batch 184 batch loss 1.39351487\n",
      "Validated batch 185 batch loss 1.45629299\n",
      "Epoch 1 val loss 1.4326422214508057\n",
      "Model /aiffel/aiffel/mpii/models1/stacked_hourglass-epoch-1-loss-1.4326.h5 saved.\n",
      "Start epoch 2 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 1.45879865 epoch total loss 1.45879865\n",
      "Trained batch 2 batch loss 1.52900624 epoch total loss 1.49390244\n",
      "Trained batch 3 batch loss 1.63947129 epoch total loss 1.54242551\n",
      "Trained batch 4 batch loss 1.55729723 epoch total loss 1.54614341\n",
      "Trained batch 5 batch loss 1.55894184 epoch total loss 1.54870307\n",
      "Trained batch 6 batch loss 1.44858456 epoch total loss 1.53201675\n",
      "Trained batch 7 batch loss 1.47923434 epoch total loss 1.52447641\n",
      "Trained batch 8 batch loss 1.41341197 epoch total loss 1.51059341\n",
      "Trained batch 9 batch loss 1.43245196 epoch total loss 1.50191104\n",
      "Trained batch 10 batch loss 1.48521662 epoch total loss 1.50024164\n",
      "Trained batch 11 batch loss 1.42645 epoch total loss 1.49353337\n",
      "Trained batch 12 batch loss 1.43718946 epoch total loss 1.48883808\n",
      "Trained batch 13 batch loss 1.2855556 epoch total loss 1.47320092\n",
      "Trained batch 14 batch loss 1.32858181 epoch total loss 1.46287096\n",
      "Trained batch 15 batch loss 1.34914076 epoch total loss 1.45528901\n",
      "Trained batch 16 batch loss 1.5534904 epoch total loss 1.4614265\n",
      "Trained batch 17 batch loss 1.67289042 epoch total loss 1.47386551\n",
      "Trained batch 18 batch loss 1.58375728 epoch total loss 1.47997057\n",
      "Trained batch 19 batch loss 1.52984011 epoch total loss 1.48259532\n",
      "Trained batch 20 batch loss 1.52214551 epoch total loss 1.48457289\n",
      "Trained batch 21 batch loss 1.60375726 epoch total loss 1.49024832\n",
      "Trained batch 22 batch loss 1.33557439 epoch total loss 1.48321772\n",
      "Trained batch 23 batch loss 1.23779798 epoch total loss 1.47254729\n",
      "Trained batch 24 batch loss 1.32207477 epoch total loss 1.4662776\n",
      "Trained batch 25 batch loss 1.35521579 epoch total loss 1.46183515\n",
      "Trained batch 26 batch loss 1.38156009 epoch total loss 1.45874774\n",
      "Trained batch 27 batch loss 1.46935058 epoch total loss 1.4591403\n",
      "Trained batch 28 batch loss 1.362396 epoch total loss 1.45568526\n",
      "Trained batch 29 batch loss 1.38873386 epoch total loss 1.45337653\n",
      "Trained batch 30 batch loss 1.4574846 epoch total loss 1.4535135\n",
      "Trained batch 31 batch loss 1.45929432 epoch total loss 1.4537\n",
      "Trained batch 32 batch loss 1.39531982 epoch total loss 1.45187557\n",
      "Trained batch 33 batch loss 1.23863804 epoch total loss 1.44541383\n",
      "Trained batch 34 batch loss 1.41781 epoch total loss 1.44460201\n",
      "Trained batch 35 batch loss 1.32779682 epoch total loss 1.44126463\n",
      "Trained batch 36 batch loss 1.35534263 epoch total loss 1.43887794\n",
      "Trained batch 37 batch loss 1.39680827 epoch total loss 1.43774092\n",
      "Trained batch 38 batch loss 1.53287745 epoch total loss 1.44024456\n",
      "Trained batch 39 batch loss 1.54467833 epoch total loss 1.44292235\n",
      "Trained batch 40 batch loss 1.49340987 epoch total loss 1.44418454\n",
      "Trained batch 41 batch loss 1.32706857 epoch total loss 1.44132805\n",
      "Trained batch 42 batch loss 1.38095 epoch total loss 1.4398905\n",
      "Trained batch 43 batch loss 1.34991729 epoch total loss 1.43779802\n",
      "Trained batch 44 batch loss 1.395859 epoch total loss 1.43684494\n",
      "Trained batch 45 batch loss 1.44309306 epoch total loss 1.4369837\n",
      "Trained batch 46 batch loss 1.48142397 epoch total loss 1.43794978\n",
      "Trained batch 47 batch loss 1.38174927 epoch total loss 1.43675411\n",
      "Trained batch 48 batch loss 1.29803646 epoch total loss 1.43386412\n",
      "Trained batch 49 batch loss 1.30993104 epoch total loss 1.43133485\n",
      "Trained batch 50 batch loss 1.38119531 epoch total loss 1.43033206\n",
      "Trained batch 51 batch loss 1.41503727 epoch total loss 1.43003213\n",
      "Trained batch 52 batch loss 1.48460126 epoch total loss 1.43108165\n",
      "Trained batch 53 batch loss 1.45981216 epoch total loss 1.4316237\n",
      "Trained batch 54 batch loss 1.45746815 epoch total loss 1.4321022\n",
      "Trained batch 55 batch loss 1.42968047 epoch total loss 1.43205822\n",
      "Trained batch 56 batch loss 1.37106133 epoch total loss 1.430969\n",
      "Trained batch 57 batch loss 1.43223643 epoch total loss 1.43099117\n",
      "Trained batch 58 batch loss 1.37756491 epoch total loss 1.43007\n",
      "Trained batch 59 batch loss 1.39084661 epoch total loss 1.42940521\n",
      "Trained batch 60 batch loss 1.37238908 epoch total loss 1.428455\n",
      "Trained batch 61 batch loss 1.41925192 epoch total loss 1.42830408\n",
      "Trained batch 62 batch loss 1.42300677 epoch total loss 1.4282186\n",
      "Trained batch 63 batch loss 1.37753618 epoch total loss 1.42741406\n",
      "Trained batch 64 batch loss 1.36461711 epoch total loss 1.42643285\n",
      "Trained batch 65 batch loss 1.37619054 epoch total loss 1.42565989\n",
      "Trained batch 66 batch loss 1.39330876 epoch total loss 1.42516971\n",
      "Trained batch 67 batch loss 1.4300921 epoch total loss 1.42524326\n",
      "Trained batch 68 batch loss 1.45126951 epoch total loss 1.42562592\n",
      "Trained batch 69 batch loss 1.47968209 epoch total loss 1.42640936\n",
      "Trained batch 70 batch loss 1.56959367 epoch total loss 1.42845488\n",
      "Trained batch 71 batch loss 1.60731769 epoch total loss 1.43097413\n",
      "Trained batch 72 batch loss 1.59071124 epoch total loss 1.43319273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 73 batch loss 1.43518555 epoch total loss 1.43322\n",
      "Trained batch 74 batch loss 1.34939075 epoch total loss 1.43208718\n",
      "Trained batch 75 batch loss 1.37153077 epoch total loss 1.43127966\n",
      "Trained batch 76 batch loss 1.32358623 epoch total loss 1.42986262\n",
      "Trained batch 77 batch loss 1.34874594 epoch total loss 1.42880929\n",
      "Trained batch 78 batch loss 1.32923257 epoch total loss 1.42753255\n",
      "Trained batch 79 batch loss 1.41440344 epoch total loss 1.42736638\n",
      "Trained batch 80 batch loss 1.40091777 epoch total loss 1.42703581\n",
      "Trained batch 81 batch loss 1.29051387 epoch total loss 1.42535031\n",
      "Trained batch 82 batch loss 1.27506864 epoch total loss 1.4235177\n",
      "Trained batch 83 batch loss 1.37422955 epoch total loss 1.4229238\n",
      "Trained batch 84 batch loss 1.45145047 epoch total loss 1.42326343\n",
      "Trained batch 85 batch loss 1.355492 epoch total loss 1.42246616\n",
      "Trained batch 86 batch loss 1.33707309 epoch total loss 1.42147326\n",
      "Trained batch 87 batch loss 1.29748166 epoch total loss 1.42004812\n",
      "Trained batch 88 batch loss 1.3436265 epoch total loss 1.41917968\n",
      "Trained batch 89 batch loss 1.45451117 epoch total loss 1.41957664\n",
      "Trained batch 90 batch loss 1.43022263 epoch total loss 1.4196949\n",
      "Trained batch 91 batch loss 1.36944318 epoch total loss 1.41914272\n",
      "Trained batch 92 batch loss 1.42714 epoch total loss 1.41922963\n",
      "Trained batch 93 batch loss 1.40294433 epoch total loss 1.41905439\n",
      "Trained batch 94 batch loss 1.37847006 epoch total loss 1.41862261\n",
      "Trained batch 95 batch loss 1.35176444 epoch total loss 1.4179188\n",
      "Trained batch 96 batch loss 1.49885905 epoch total loss 1.41876185\n",
      "Trained batch 97 batch loss 1.33332992 epoch total loss 1.41788113\n",
      "Trained batch 98 batch loss 1.42921555 epoch total loss 1.41799676\n",
      "Trained batch 99 batch loss 1.3790524 epoch total loss 1.41760349\n",
      "Trained batch 100 batch loss 1.30985713 epoch total loss 1.41652608\n",
      "Trained batch 101 batch loss 1.39221716 epoch total loss 1.41628528\n",
      "Trained batch 102 batch loss 1.36319602 epoch total loss 1.41576481\n",
      "Trained batch 103 batch loss 1.36749518 epoch total loss 1.41529608\n",
      "Trained batch 104 batch loss 1.30047059 epoch total loss 1.41419208\n",
      "Trained batch 105 batch loss 1.39310718 epoch total loss 1.41399133\n",
      "Trained batch 106 batch loss 1.3771379 epoch total loss 1.4136436\n",
      "Trained batch 107 batch loss 1.34239292 epoch total loss 1.4129777\n",
      "Trained batch 108 batch loss 1.41106904 epoch total loss 1.41296\n",
      "Trained batch 109 batch loss 1.43357027 epoch total loss 1.41314912\n",
      "Trained batch 110 batch loss 1.38660777 epoch total loss 1.41290784\n",
      "Trained batch 111 batch loss 1.34657371 epoch total loss 1.41231024\n",
      "Trained batch 112 batch loss 1.41046059 epoch total loss 1.41229367\n",
      "Trained batch 113 batch loss 1.50597382 epoch total loss 1.41312265\n",
      "Trained batch 114 batch loss 1.49235332 epoch total loss 1.41381764\n",
      "Trained batch 115 batch loss 1.4736377 epoch total loss 1.41433787\n",
      "Trained batch 116 batch loss 1.47064114 epoch total loss 1.41482317\n",
      "Trained batch 117 batch loss 1.42993128 epoch total loss 1.41495228\n",
      "Trained batch 118 batch loss 1.45296097 epoch total loss 1.41527438\n",
      "Trained batch 119 batch loss 1.52678633 epoch total loss 1.41621137\n",
      "Trained batch 120 batch loss 1.38601208 epoch total loss 1.41595984\n",
      "Trained batch 121 batch loss 1.38129294 epoch total loss 1.41567326\n",
      "Trained batch 122 batch loss 1.44357634 epoch total loss 1.4159019\n",
      "Trained batch 123 batch loss 1.42384124 epoch total loss 1.41596651\n",
      "Trained batch 124 batch loss 1.20599556 epoch total loss 1.41427314\n",
      "Trained batch 125 batch loss 1.42260134 epoch total loss 1.4143399\n",
      "Trained batch 126 batch loss 1.44964778 epoch total loss 1.41462\n",
      "Trained batch 127 batch loss 1.43827105 epoch total loss 1.41480637\n",
      "Trained batch 128 batch loss 1.41062593 epoch total loss 1.4147737\n",
      "Trained batch 129 batch loss 1.34620762 epoch total loss 1.41424215\n",
      "Trained batch 130 batch loss 1.34711385 epoch total loss 1.41372573\n",
      "Trained batch 131 batch loss 1.33466 epoch total loss 1.41312218\n",
      "Trained batch 132 batch loss 1.48727155 epoch total loss 1.41368389\n",
      "Trained batch 133 batch loss 1.46956348 epoch total loss 1.41410398\n",
      "Trained batch 134 batch loss 1.46837211 epoch total loss 1.41450894\n",
      "Trained batch 135 batch loss 1.64236498 epoch total loss 1.41619682\n",
      "Trained batch 136 batch loss 1.61538363 epoch total loss 1.41766143\n",
      "Trained batch 137 batch loss 1.44049883 epoch total loss 1.4178282\n",
      "Trained batch 138 batch loss 1.39174426 epoch total loss 1.41763914\n",
      "Trained batch 139 batch loss 1.2249428 epoch total loss 1.41625285\n",
      "Trained batch 140 batch loss 1.16947532 epoch total loss 1.41449022\n",
      "Trained batch 141 batch loss 1.40619111 epoch total loss 1.41443133\n",
      "Trained batch 142 batch loss 1.27410412 epoch total loss 1.41344309\n",
      "Trained batch 143 batch loss 1.15960944 epoch total loss 1.41166806\n",
      "Trained batch 144 batch loss 1.17776346 epoch total loss 1.41004372\n",
      "Trained batch 145 batch loss 1.15357208 epoch total loss 1.40827489\n",
      "Trained batch 146 batch loss 1.29489815 epoch total loss 1.40749824\n",
      "Trained batch 147 batch loss 1.33439314 epoch total loss 1.40700102\n",
      "Trained batch 148 batch loss 1.44001007 epoch total loss 1.40722406\n",
      "Trained batch 149 batch loss 1.43116403 epoch total loss 1.40738475\n",
      "Trained batch 150 batch loss 1.50837803 epoch total loss 1.40805805\n",
      "Trained batch 151 batch loss 1.54771042 epoch total loss 1.40898299\n",
      "Trained batch 152 batch loss 1.37567258 epoch total loss 1.40876377\n",
      "Trained batch 153 batch loss 1.44291437 epoch total loss 1.40898705\n",
      "Trained batch 154 batch loss 1.42510879 epoch total loss 1.40909171\n",
      "Trained batch 155 batch loss 1.43843174 epoch total loss 1.40928102\n",
      "Trained batch 156 batch loss 1.46372128 epoch total loss 1.40963\n",
      "Trained batch 157 batch loss 1.4163785 epoch total loss 1.40967298\n",
      "Trained batch 158 batch loss 1.35182559 epoch total loss 1.40930676\n",
      "Trained batch 159 batch loss 1.41366482 epoch total loss 1.40933418\n",
      "Trained batch 160 batch loss 1.37690854 epoch total loss 1.40913153\n",
      "Trained batch 161 batch loss 1.42480946 epoch total loss 1.40922892\n",
      "Trained batch 162 batch loss 1.54851055 epoch total loss 1.41008866\n",
      "Trained batch 163 batch loss 1.40439224 epoch total loss 1.41005361\n",
      "Trained batch 164 batch loss 1.30887973 epoch total loss 1.4094367\n",
      "Trained batch 165 batch loss 1.27933717 epoch total loss 1.40864825\n",
      "Trained batch 166 batch loss 1.47208345 epoch total loss 1.40903044\n",
      "Trained batch 167 batch loss 1.43681753 epoch total loss 1.40919673\n",
      "Trained batch 168 batch loss 1.47232 epoch total loss 1.40957248\n",
      "Trained batch 169 batch loss 1.54835725 epoch total loss 1.41039371\n",
      "Trained batch 170 batch loss 1.51540077 epoch total loss 1.41101134\n",
      "Trained batch 171 batch loss 1.49639273 epoch total loss 1.41151071\n",
      "Trained batch 172 batch loss 1.41957843 epoch total loss 1.41155756\n",
      "Trained batch 173 batch loss 1.34897399 epoch total loss 1.41119576\n",
      "Trained batch 174 batch loss 1.41474247 epoch total loss 1.41121626\n",
      "Trained batch 175 batch loss 1.45159245 epoch total loss 1.41144693\n",
      "Trained batch 176 batch loss 1.40710592 epoch total loss 1.41142225\n",
      "Trained batch 177 batch loss 1.43403864 epoch total loss 1.41155\n",
      "Trained batch 178 batch loss 1.4418937 epoch total loss 1.41172051\n",
      "Trained batch 179 batch loss 1.43609273 epoch total loss 1.41185665\n",
      "Trained batch 180 batch loss 1.33017683 epoch total loss 1.41140294\n",
      "Trained batch 181 batch loss 1.41370761 epoch total loss 1.4114157\n",
      "Trained batch 182 batch loss 1.3646723 epoch total loss 1.4111588\n",
      "Trained batch 183 batch loss 1.34772849 epoch total loss 1.41081214\n",
      "Trained batch 184 batch loss 1.4545269 epoch total loss 1.41104972\n",
      "Trained batch 185 batch loss 1.43840766 epoch total loss 1.41119766\n",
      "Trained batch 186 batch loss 1.41616166 epoch total loss 1.41122437\n",
      "Trained batch 187 batch loss 1.44960642 epoch total loss 1.41142964\n",
      "Trained batch 188 batch loss 1.44794154 epoch total loss 1.41162384\n",
      "Trained batch 189 batch loss 1.49634051 epoch total loss 1.41207206\n",
      "Trained batch 190 batch loss 1.32749188 epoch total loss 1.41162694\n",
      "Trained batch 191 batch loss 1.26065838 epoch total loss 1.41083646\n",
      "Trained batch 192 batch loss 1.40645647 epoch total loss 1.41081369\n",
      "Trained batch 193 batch loss 1.42794251 epoch total loss 1.41090238\n",
      "Trained batch 194 batch loss 1.51997685 epoch total loss 1.41146469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 195 batch loss 1.44014931 epoch total loss 1.41161191\n",
      "Trained batch 196 batch loss 1.33343101 epoch total loss 1.41121304\n",
      "Trained batch 197 batch loss 1.43468487 epoch total loss 1.41133213\n",
      "Trained batch 198 batch loss 1.47261667 epoch total loss 1.41164172\n",
      "Trained batch 199 batch loss 1.40260828 epoch total loss 1.41159642\n",
      "Trained batch 200 batch loss 1.55510461 epoch total loss 1.41231394\n",
      "Trained batch 201 batch loss 1.48578238 epoch total loss 1.41267943\n",
      "Trained batch 202 batch loss 1.41751754 epoch total loss 1.41270339\n",
      "Trained batch 203 batch loss 1.35618615 epoch total loss 1.41242504\n",
      "Trained batch 204 batch loss 1.36432409 epoch total loss 1.41218925\n",
      "Trained batch 205 batch loss 1.37025023 epoch total loss 1.41198468\n",
      "Trained batch 206 batch loss 1.43452823 epoch total loss 1.41209412\n",
      "Trained batch 207 batch loss 1.46221721 epoch total loss 1.41233623\n",
      "Trained batch 208 batch loss 1.39032865 epoch total loss 1.41223037\n",
      "Trained batch 209 batch loss 1.53356075 epoch total loss 1.41281104\n",
      "Trained batch 210 batch loss 1.53609657 epoch total loss 1.41339815\n",
      "Trained batch 211 batch loss 1.55710912 epoch total loss 1.41407919\n",
      "Trained batch 212 batch loss 1.58885229 epoch total loss 1.41490364\n",
      "Trained batch 213 batch loss 1.44217145 epoch total loss 1.41503167\n",
      "Trained batch 214 batch loss 1.47429502 epoch total loss 1.41530859\n",
      "Trained batch 215 batch loss 1.53942442 epoch total loss 1.41588593\n",
      "Trained batch 216 batch loss 1.50797224 epoch total loss 1.41631222\n",
      "Trained batch 217 batch loss 1.37868023 epoch total loss 1.41613877\n",
      "Trained batch 218 batch loss 1.41964889 epoch total loss 1.41615486\n",
      "Trained batch 219 batch loss 1.45923698 epoch total loss 1.41635156\n",
      "Trained batch 220 batch loss 1.32636619 epoch total loss 1.41594255\n",
      "Trained batch 221 batch loss 1.25438881 epoch total loss 1.41521156\n",
      "Trained batch 222 batch loss 1.30699944 epoch total loss 1.41472411\n",
      "Trained batch 223 batch loss 1.36000371 epoch total loss 1.41447878\n",
      "Trained batch 224 batch loss 1.43610513 epoch total loss 1.41457534\n",
      "Trained batch 225 batch loss 1.38940024 epoch total loss 1.4144634\n",
      "Trained batch 226 batch loss 1.39815927 epoch total loss 1.41439128\n",
      "Trained batch 227 batch loss 1.36328804 epoch total loss 1.41416609\n",
      "Trained batch 228 batch loss 1.40115941 epoch total loss 1.41410911\n",
      "Trained batch 229 batch loss 1.43070126 epoch total loss 1.41418147\n",
      "Trained batch 230 batch loss 1.45214713 epoch total loss 1.41434658\n",
      "Trained batch 231 batch loss 1.38869357 epoch total loss 1.41423559\n",
      "Trained batch 232 batch loss 1.41625404 epoch total loss 1.41424429\n",
      "Trained batch 233 batch loss 1.33134985 epoch total loss 1.41388857\n",
      "Trained batch 234 batch loss 1.34838367 epoch total loss 1.41360867\n",
      "Trained batch 235 batch loss 1.27886498 epoch total loss 1.41303527\n",
      "Trained batch 236 batch loss 1.41807806 epoch total loss 1.41305673\n",
      "Trained batch 237 batch loss 1.35128069 epoch total loss 1.41279614\n",
      "Trained batch 238 batch loss 1.32560182 epoch total loss 1.41242969\n",
      "Trained batch 239 batch loss 1.34209919 epoch total loss 1.41213548\n",
      "Trained batch 240 batch loss 1.26325309 epoch total loss 1.411515\n",
      "Trained batch 241 batch loss 1.34168804 epoch total loss 1.4112252\n",
      "Trained batch 242 batch loss 1.38354063 epoch total loss 1.41111088\n",
      "Trained batch 243 batch loss 1.31617641 epoch total loss 1.41072011\n",
      "Trained batch 244 batch loss 1.33137989 epoch total loss 1.41039503\n",
      "Trained batch 245 batch loss 1.47320139 epoch total loss 1.41065133\n",
      "Trained batch 246 batch loss 1.43743849 epoch total loss 1.41076028\n",
      "Trained batch 247 batch loss 1.48865819 epoch total loss 1.41107559\n",
      "Trained batch 248 batch loss 1.42438126 epoch total loss 1.41112924\n",
      "Trained batch 249 batch loss 1.34251 epoch total loss 1.41085362\n",
      "Trained batch 250 batch loss 1.30476022 epoch total loss 1.41042924\n",
      "Trained batch 251 batch loss 1.28481293 epoch total loss 1.4099288\n",
      "Trained batch 252 batch loss 1.35012114 epoch total loss 1.40969145\n",
      "Trained batch 253 batch loss 1.33572543 epoch total loss 1.40939915\n",
      "Trained batch 254 batch loss 1.40222812 epoch total loss 1.4093709\n",
      "Trained batch 255 batch loss 1.37337494 epoch total loss 1.40922976\n",
      "Trained batch 256 batch loss 1.44657624 epoch total loss 1.40937555\n",
      "Trained batch 257 batch loss 1.30582213 epoch total loss 1.40897262\n",
      "Trained batch 258 batch loss 1.33918321 epoch total loss 1.40870202\n",
      "Trained batch 259 batch loss 1.32879233 epoch total loss 1.4083935\n",
      "Trained batch 260 batch loss 1.25671983 epoch total loss 1.40781021\n",
      "Trained batch 261 batch loss 1.32508111 epoch total loss 1.40749311\n",
      "Trained batch 262 batch loss 1.38515985 epoch total loss 1.40740788\n",
      "Trained batch 263 batch loss 1.39791489 epoch total loss 1.40737188\n",
      "Trained batch 264 batch loss 1.38162875 epoch total loss 1.40727425\n",
      "Trained batch 265 batch loss 1.43519425 epoch total loss 1.40737963\n",
      "Trained batch 266 batch loss 1.46631277 epoch total loss 1.40760112\n",
      "Trained batch 267 batch loss 1.82101488 epoch total loss 1.40914953\n",
      "Trained batch 268 batch loss 1.54406559 epoch total loss 1.40965295\n",
      "Trained batch 269 batch loss 1.57073736 epoch total loss 1.41025174\n",
      "Trained batch 270 batch loss 1.46542835 epoch total loss 1.41045606\n",
      "Trained batch 271 batch loss 1.52420294 epoch total loss 1.4108758\n",
      "Trained batch 272 batch loss 1.48403978 epoch total loss 1.41114485\n",
      "Trained batch 273 batch loss 1.39461517 epoch total loss 1.41108429\n",
      "Trained batch 274 batch loss 1.37493229 epoch total loss 1.41095233\n",
      "Trained batch 275 batch loss 1.42719769 epoch total loss 1.41101146\n",
      "Trained batch 276 batch loss 1.46456611 epoch total loss 1.41120541\n",
      "Trained batch 277 batch loss 1.4969002 epoch total loss 1.41151476\n",
      "Trained batch 278 batch loss 1.42055476 epoch total loss 1.4115473\n",
      "Trained batch 279 batch loss 1.39021015 epoch total loss 1.41147077\n",
      "Trained batch 280 batch loss 1.36657071 epoch total loss 1.41131043\n",
      "Trained batch 281 batch loss 1.35263932 epoch total loss 1.4111017\n",
      "Trained batch 282 batch loss 1.34304881 epoch total loss 1.4108603\n",
      "Trained batch 283 batch loss 1.30589664 epoch total loss 1.41048944\n",
      "Trained batch 284 batch loss 1.29653013 epoch total loss 1.41008818\n",
      "Trained batch 285 batch loss 1.32233524 epoch total loss 1.40978026\n",
      "Trained batch 286 batch loss 1.35170352 epoch total loss 1.40957725\n",
      "Trained batch 287 batch loss 1.44380617 epoch total loss 1.40969658\n",
      "Trained batch 288 batch loss 1.40497017 epoch total loss 1.40968013\n",
      "Trained batch 289 batch loss 1.4039402 epoch total loss 1.40966022\n",
      "Trained batch 290 batch loss 1.40298104 epoch total loss 1.40963721\n",
      "Trained batch 291 batch loss 1.43509459 epoch total loss 1.40972471\n",
      "Trained batch 292 batch loss 1.41745126 epoch total loss 1.40975118\n",
      "Trained batch 293 batch loss 1.44560313 epoch total loss 1.4098736\n",
      "Trained batch 294 batch loss 1.37857211 epoch total loss 1.40976715\n",
      "Trained batch 295 batch loss 1.29211986 epoch total loss 1.40936828\n",
      "Trained batch 296 batch loss 1.32809782 epoch total loss 1.40909374\n",
      "Trained batch 297 batch loss 1.43436408 epoch total loss 1.40917873\n",
      "Trained batch 298 batch loss 1.3404547 epoch total loss 1.40894818\n",
      "Trained batch 299 batch loss 1.48255229 epoch total loss 1.40919423\n",
      "Trained batch 300 batch loss 1.41755319 epoch total loss 1.40922213\n",
      "Trained batch 301 batch loss 1.4077816 epoch total loss 1.40921736\n",
      "Trained batch 302 batch loss 1.26243567 epoch total loss 1.40873122\n",
      "Trained batch 303 batch loss 1.3784647 epoch total loss 1.40863132\n",
      "Trained batch 304 batch loss 1.53132534 epoch total loss 1.40903497\n",
      "Trained batch 305 batch loss 1.50853944 epoch total loss 1.40936124\n",
      "Trained batch 306 batch loss 1.37280512 epoch total loss 1.40924168\n",
      "Trained batch 307 batch loss 1.46421742 epoch total loss 1.40942073\n",
      "Trained batch 308 batch loss 1.45602536 epoch total loss 1.40957201\n",
      "Trained batch 309 batch loss 1.4188683 epoch total loss 1.40960205\n",
      "Trained batch 310 batch loss 1.47253847 epoch total loss 1.40980506\n",
      "Trained batch 311 batch loss 1.41997862 epoch total loss 1.40983784\n",
      "Trained batch 312 batch loss 1.54604673 epoch total loss 1.41027439\n",
      "Trained batch 313 batch loss 1.33928514 epoch total loss 1.41004765\n",
      "Trained batch 314 batch loss 1.36901379 epoch total loss 1.409917\n",
      "Trained batch 315 batch loss 1.42428398 epoch total loss 1.40996253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 316 batch loss 1.43704426 epoch total loss 1.41004825\n",
      "Trained batch 317 batch loss 1.44067323 epoch total loss 1.41014493\n",
      "Trained batch 318 batch loss 1.29212105 epoch total loss 1.40977371\n",
      "Trained batch 319 batch loss 1.34624863 epoch total loss 1.40957463\n",
      "Trained batch 320 batch loss 1.25792265 epoch total loss 1.40910077\n",
      "Trained batch 321 batch loss 1.3147 epoch total loss 1.40880668\n",
      "Trained batch 322 batch loss 1.33936894 epoch total loss 1.40859091\n",
      "Trained batch 323 batch loss 1.304075 epoch total loss 1.40826738\n",
      "Trained batch 324 batch loss 1.22053039 epoch total loss 1.4076879\n",
      "Trained batch 325 batch loss 1.29489541 epoch total loss 1.40734088\n",
      "Trained batch 326 batch loss 1.53395128 epoch total loss 1.40772927\n",
      "Trained batch 327 batch loss 1.32044256 epoch total loss 1.40746236\n",
      "Trained batch 328 batch loss 1.25715554 epoch total loss 1.407004\n",
      "Trained batch 329 batch loss 1.26486504 epoch total loss 1.40657198\n",
      "Trained batch 330 batch loss 1.2606051 epoch total loss 1.40612972\n",
      "Trained batch 331 batch loss 1.3714354 epoch total loss 1.40602481\n",
      "Trained batch 332 batch loss 1.36269236 epoch total loss 1.4058944\n",
      "Trained batch 333 batch loss 1.32027709 epoch total loss 1.40563726\n",
      "Trained batch 334 batch loss 1.29513907 epoch total loss 1.40530646\n",
      "Trained batch 335 batch loss 1.41117787 epoch total loss 1.40532386\n",
      "Trained batch 336 batch loss 1.37390172 epoch total loss 1.4052304\n",
      "Trained batch 337 batch loss 1.37211442 epoch total loss 1.40513206\n",
      "Trained batch 338 batch loss 1.45224237 epoch total loss 1.40527141\n",
      "Trained batch 339 batch loss 1.24279249 epoch total loss 1.40479219\n",
      "Trained batch 340 batch loss 1.3269136 epoch total loss 1.40456307\n",
      "Trained batch 341 batch loss 1.33988595 epoch total loss 1.40437341\n",
      "Trained batch 342 batch loss 1.4055016 epoch total loss 1.40437663\n",
      "Trained batch 343 batch loss 1.5229857 epoch total loss 1.40472245\n",
      "Trained batch 344 batch loss 1.41160643 epoch total loss 1.40474248\n",
      "Trained batch 345 batch loss 1.40089524 epoch total loss 1.40473139\n",
      "Trained batch 346 batch loss 1.32776189 epoch total loss 1.40450895\n",
      "Trained batch 347 batch loss 1.32758272 epoch total loss 1.40428722\n",
      "Trained batch 348 batch loss 1.3825295 epoch total loss 1.40422475\n",
      "Trained batch 349 batch loss 1.38209486 epoch total loss 1.40416121\n",
      "Trained batch 350 batch loss 1.41256177 epoch total loss 1.4041853\n",
      "Trained batch 351 batch loss 1.48141301 epoch total loss 1.40440524\n",
      "Trained batch 352 batch loss 1.25849223 epoch total loss 1.40399075\n",
      "Trained batch 353 batch loss 1.30592072 epoch total loss 1.40371287\n",
      "Trained batch 354 batch loss 1.39826512 epoch total loss 1.40369749\n",
      "Trained batch 355 batch loss 1.38668156 epoch total loss 1.40364957\n",
      "Trained batch 356 batch loss 1.28352237 epoch total loss 1.40331209\n",
      "Trained batch 357 batch loss 1.22475 epoch total loss 1.40281188\n",
      "Trained batch 358 batch loss 1.33907104 epoch total loss 1.40263391\n",
      "Trained batch 359 batch loss 1.33219957 epoch total loss 1.40243781\n",
      "Trained batch 360 batch loss 1.29361796 epoch total loss 1.40213549\n",
      "Trained batch 361 batch loss 1.33417416 epoch total loss 1.40194714\n",
      "Trained batch 362 batch loss 1.32499123 epoch total loss 1.40173459\n",
      "Trained batch 363 batch loss 1.3935554 epoch total loss 1.40171206\n",
      "Trained batch 364 batch loss 1.39064097 epoch total loss 1.40168166\n",
      "Trained batch 365 batch loss 1.57385647 epoch total loss 1.40215337\n",
      "Trained batch 366 batch loss 1.51422358 epoch total loss 1.40245962\n",
      "Trained batch 367 batch loss 1.43453074 epoch total loss 1.402547\n",
      "Trained batch 368 batch loss 1.3071878 epoch total loss 1.40228784\n",
      "Trained batch 369 batch loss 1.50644195 epoch total loss 1.40257025\n",
      "Trained batch 370 batch loss 1.4158597 epoch total loss 1.40260601\n",
      "Trained batch 371 batch loss 1.32105839 epoch total loss 1.40238619\n",
      "Trained batch 372 batch loss 1.29289734 epoch total loss 1.40209186\n",
      "Trained batch 373 batch loss 1.21431649 epoch total loss 1.40158844\n",
      "Trained batch 374 batch loss 1.16867518 epoch total loss 1.40096569\n",
      "Trained batch 375 batch loss 1.64713359 epoch total loss 1.40162218\n",
      "Trained batch 376 batch loss 1.52523553 epoch total loss 1.40195096\n",
      "Trained batch 377 batch loss 1.42485571 epoch total loss 1.40201175\n",
      "Trained batch 378 batch loss 1.3780973 epoch total loss 1.40194845\n",
      "Trained batch 379 batch loss 1.38342893 epoch total loss 1.40189958\n",
      "Trained batch 380 batch loss 1.37715816 epoch total loss 1.40183437\n",
      "Trained batch 381 batch loss 1.33828783 epoch total loss 1.40166771\n",
      "Trained batch 382 batch loss 1.33833516 epoch total loss 1.40150189\n",
      "Trained batch 383 batch loss 1.40833139 epoch total loss 1.40151966\n",
      "Trained batch 384 batch loss 1.40530443 epoch total loss 1.40152967\n",
      "Trained batch 385 batch loss 1.36881506 epoch total loss 1.40144467\n",
      "Trained batch 386 batch loss 1.46835661 epoch total loss 1.40161812\n",
      "Trained batch 387 batch loss 1.36232352 epoch total loss 1.40151656\n",
      "Trained batch 388 batch loss 1.33111644 epoch total loss 1.40133512\n",
      "Trained batch 389 batch loss 1.37885952 epoch total loss 1.4012773\n",
      "Trained batch 390 batch loss 1.33940554 epoch total loss 1.40111864\n",
      "Trained batch 391 batch loss 1.30900455 epoch total loss 1.40088308\n",
      "Trained batch 392 batch loss 1.44429994 epoch total loss 1.40099382\n",
      "Trained batch 393 batch loss 1.53104401 epoch total loss 1.40132475\n",
      "Trained batch 394 batch loss 1.64569163 epoch total loss 1.40194499\n",
      "Trained batch 395 batch loss 1.68570471 epoch total loss 1.40266347\n",
      "Trained batch 396 batch loss 1.48479104 epoch total loss 1.40287089\n",
      "Trained batch 397 batch loss 1.50181592 epoch total loss 1.40312016\n",
      "Trained batch 398 batch loss 1.5202539 epoch total loss 1.40341449\n",
      "Trained batch 399 batch loss 1.361323 epoch total loss 1.40330899\n",
      "Trained batch 400 batch loss 1.32527542 epoch total loss 1.40311384\n",
      "Trained batch 401 batch loss 1.34132767 epoch total loss 1.4029597\n",
      "Trained batch 402 batch loss 1.44557667 epoch total loss 1.40306568\n",
      "Trained batch 403 batch loss 1.44901729 epoch total loss 1.40317976\n",
      "Trained batch 404 batch loss 1.37565672 epoch total loss 1.4031117\n",
      "Trained batch 405 batch loss 1.34551954 epoch total loss 1.40296948\n",
      "Trained batch 406 batch loss 1.38059461 epoch total loss 1.4029144\n",
      "Trained batch 407 batch loss 1.24663401 epoch total loss 1.40253043\n",
      "Trained batch 408 batch loss 1.29010665 epoch total loss 1.40225494\n",
      "Trained batch 409 batch loss 1.37561893 epoch total loss 1.40218973\n",
      "Trained batch 410 batch loss 1.34461892 epoch total loss 1.4020493\n",
      "Trained batch 411 batch loss 1.36776209 epoch total loss 1.40196586\n",
      "Trained batch 412 batch loss 1.3741293 epoch total loss 1.40189826\n",
      "Trained batch 413 batch loss 1.40262079 epoch total loss 1.4019\n",
      "Trained batch 414 batch loss 1.3673507 epoch total loss 1.40181673\n",
      "Trained batch 415 batch loss 1.55179882 epoch total loss 1.40217817\n",
      "Trained batch 416 batch loss 1.41223896 epoch total loss 1.40220237\n",
      "Trained batch 417 batch loss 1.39925766 epoch total loss 1.40219522\n",
      "Trained batch 418 batch loss 1.4170903 epoch total loss 1.40223086\n",
      "Trained batch 419 batch loss 1.44594026 epoch total loss 1.40233517\n",
      "Trained batch 420 batch loss 1.54944706 epoch total loss 1.4026854\n",
      "Trained batch 421 batch loss 1.39939427 epoch total loss 1.40267766\n",
      "Trained batch 422 batch loss 1.39218593 epoch total loss 1.40265286\n",
      "Trained batch 423 batch loss 1.42932916 epoch total loss 1.40271592\n",
      "Trained batch 424 batch loss 1.46007288 epoch total loss 1.40285122\n",
      "Trained batch 425 batch loss 1.42654014 epoch total loss 1.40290689\n",
      "Trained batch 426 batch loss 1.47304595 epoch total loss 1.4030714\n",
      "Trained batch 427 batch loss 1.41129589 epoch total loss 1.40309072\n",
      "Trained batch 428 batch loss 1.39402986 epoch total loss 1.40306962\n",
      "Trained batch 429 batch loss 1.48897433 epoch total loss 1.40326977\n",
      "Trained batch 430 batch loss 1.48167896 epoch total loss 1.40345216\n",
      "Trained batch 431 batch loss 1.33987761 epoch total loss 1.4033047\n",
      "Trained batch 432 batch loss 1.43758094 epoch total loss 1.40338409\n",
      "Trained batch 433 batch loss 1.19433379 epoch total loss 1.40290129\n",
      "Trained batch 434 batch loss 1.25352776 epoch total loss 1.40255713\n",
      "Trained batch 435 batch loss 1.21309173 epoch total loss 1.40212154\n",
      "Trained batch 436 batch loss 1.29802883 epoch total loss 1.40188277\n",
      "Trained batch 437 batch loss 1.35592031 epoch total loss 1.40177751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 438 batch loss 1.40718269 epoch total loss 1.40178978\n",
      "Trained batch 439 batch loss 1.40466511 epoch total loss 1.40179634\n",
      "Trained batch 440 batch loss 1.51076579 epoch total loss 1.40204394\n",
      "Trained batch 441 batch loss 1.4368881 epoch total loss 1.40212297\n",
      "Trained batch 442 batch loss 1.49743342 epoch total loss 1.40233862\n",
      "Trained batch 443 batch loss 1.55692887 epoch total loss 1.40268767\n",
      "Trained batch 444 batch loss 1.49054599 epoch total loss 1.40288556\n",
      "Trained batch 445 batch loss 1.3621012 epoch total loss 1.40279388\n",
      "Trained batch 446 batch loss 1.37552536 epoch total loss 1.40273285\n",
      "Trained batch 447 batch loss 1.38824129 epoch total loss 1.40270042\n",
      "Trained batch 448 batch loss 1.41861916 epoch total loss 1.40273595\n",
      "Trained batch 449 batch loss 1.39828598 epoch total loss 1.40272617\n",
      "Trained batch 450 batch loss 1.31541562 epoch total loss 1.4025321\n",
      "Trained batch 451 batch loss 1.29567432 epoch total loss 1.40229511\n",
      "Trained batch 452 batch loss 1.35566413 epoch total loss 1.402192\n",
      "Trained batch 453 batch loss 1.25513566 epoch total loss 1.40186727\n",
      "Trained batch 454 batch loss 1.38867378 epoch total loss 1.4018383\n",
      "Trained batch 455 batch loss 1.41223717 epoch total loss 1.40186107\n",
      "Trained batch 456 batch loss 1.43845046 epoch total loss 1.40194142\n",
      "Trained batch 457 batch loss 1.42683506 epoch total loss 1.40199578\n",
      "Trained batch 458 batch loss 1.3743248 epoch total loss 1.40193546\n",
      "Trained batch 459 batch loss 1.32285607 epoch total loss 1.4017632\n",
      "Trained batch 460 batch loss 1.48372519 epoch total loss 1.4019413\n",
      "Trained batch 461 batch loss 1.49031925 epoch total loss 1.40213299\n",
      "Trained batch 462 batch loss 1.34200621 epoch total loss 1.40200281\n",
      "Trained batch 463 batch loss 1.43048191 epoch total loss 1.40206432\n",
      "Trained batch 464 batch loss 1.5186336 epoch total loss 1.4023155\n",
      "Trained batch 465 batch loss 1.54255939 epoch total loss 1.40261698\n",
      "Trained batch 466 batch loss 1.45448017 epoch total loss 1.40272832\n",
      "Trained batch 467 batch loss 1.32872057 epoch total loss 1.40256989\n",
      "Trained batch 468 batch loss 1.28163373 epoch total loss 1.40231144\n",
      "Trained batch 469 batch loss 1.35413218 epoch total loss 1.40220869\n",
      "Trained batch 470 batch loss 1.3975569 epoch total loss 1.40219879\n",
      "Trained batch 471 batch loss 1.41607559 epoch total loss 1.40222824\n",
      "Trained batch 472 batch loss 1.39595652 epoch total loss 1.402215\n",
      "Trained batch 473 batch loss 1.32822132 epoch total loss 1.4020586\n",
      "Trained batch 474 batch loss 1.32545781 epoch total loss 1.40189695\n",
      "Trained batch 475 batch loss 1.31950557 epoch total loss 1.4017235\n",
      "Trained batch 476 batch loss 1.2785666 epoch total loss 1.40146482\n",
      "Trained batch 477 batch loss 1.38494992 epoch total loss 1.40143013\n",
      "Trained batch 478 batch loss 1.34969199 epoch total loss 1.40132189\n",
      "Trained batch 479 batch loss 1.28978026 epoch total loss 1.40108907\n",
      "Trained batch 480 batch loss 1.2985208 epoch total loss 1.40087533\n",
      "Trained batch 481 batch loss 1.39029288 epoch total loss 1.4008534\n",
      "Trained batch 482 batch loss 1.38915682 epoch total loss 1.4008292\n",
      "Trained batch 483 batch loss 1.46836901 epoch total loss 1.40096903\n",
      "Trained batch 484 batch loss 1.39346111 epoch total loss 1.40095341\n",
      "Trained batch 485 batch loss 1.34772205 epoch total loss 1.40084362\n",
      "Trained batch 486 batch loss 1.24969161 epoch total loss 1.40053272\n",
      "Trained batch 487 batch loss 1.32837498 epoch total loss 1.40038443\n",
      "Trained batch 488 batch loss 1.31115961 epoch total loss 1.40020168\n",
      "Trained batch 489 batch loss 1.32743669 epoch total loss 1.40005291\n",
      "Trained batch 490 batch loss 1.52669024 epoch total loss 1.40031123\n",
      "Trained batch 491 batch loss 1.40006673 epoch total loss 1.40031087\n",
      "Trained batch 492 batch loss 1.4298172 epoch total loss 1.40037072\n",
      "Trained batch 493 batch loss 1.37972903 epoch total loss 1.40032887\n",
      "Trained batch 494 batch loss 1.31850576 epoch total loss 1.40016317\n",
      "Trained batch 495 batch loss 1.33099222 epoch total loss 1.40002346\n",
      "Trained batch 496 batch loss 1.31873894 epoch total loss 1.39985955\n",
      "Trained batch 497 batch loss 1.34711 epoch total loss 1.39975333\n",
      "Trained batch 498 batch loss 1.41605318 epoch total loss 1.39978611\n",
      "Trained batch 499 batch loss 1.46070123 epoch total loss 1.39990819\n",
      "Trained batch 500 batch loss 1.37994313 epoch total loss 1.39986825\n",
      "Trained batch 501 batch loss 1.37978 epoch total loss 1.3998282\n",
      "Trained batch 502 batch loss 1.33797717 epoch total loss 1.39970493\n",
      "Trained batch 503 batch loss 1.39298654 epoch total loss 1.39969158\n",
      "Trained batch 504 batch loss 1.41393399 epoch total loss 1.39971983\n",
      "Trained batch 505 batch loss 1.31469226 epoch total loss 1.39955151\n",
      "Trained batch 506 batch loss 1.24575925 epoch total loss 1.39924765\n",
      "Trained batch 507 batch loss 1.24369514 epoch total loss 1.3989408\n",
      "Trained batch 508 batch loss 1.35510302 epoch total loss 1.39885449\n",
      "Trained batch 509 batch loss 1.34167922 epoch total loss 1.3987422\n",
      "Trained batch 510 batch loss 1.40048182 epoch total loss 1.39874554\n",
      "Trained batch 511 batch loss 1.3264395 epoch total loss 1.39860404\n",
      "Trained batch 512 batch loss 1.26729631 epoch total loss 1.3983475\n",
      "Trained batch 513 batch loss 1.33058703 epoch total loss 1.39821541\n",
      "Trained batch 514 batch loss 1.43312025 epoch total loss 1.39828324\n",
      "Trained batch 515 batch loss 1.47274554 epoch total loss 1.39842772\n",
      "Trained batch 516 batch loss 1.30069458 epoch total loss 1.39823842\n",
      "Trained batch 517 batch loss 1.33380115 epoch total loss 1.39811385\n",
      "Trained batch 518 batch loss 1.22365546 epoch total loss 1.39777696\n",
      "Trained batch 519 batch loss 1.19426322 epoch total loss 1.39738488\n",
      "Trained batch 520 batch loss 1.23194146 epoch total loss 1.39706671\n",
      "Trained batch 521 batch loss 1.32737386 epoch total loss 1.39693296\n",
      "Trained batch 522 batch loss 1.36371243 epoch total loss 1.3968693\n",
      "Trained batch 523 batch loss 1.25568628 epoch total loss 1.39659929\n",
      "Trained batch 524 batch loss 1.21155965 epoch total loss 1.39624619\n",
      "Trained batch 525 batch loss 1.15170538 epoch total loss 1.39578044\n",
      "Trained batch 526 batch loss 1.28791642 epoch total loss 1.3955754\n",
      "Trained batch 527 batch loss 1.28511393 epoch total loss 1.39536572\n",
      "Trained batch 528 batch loss 1.5850668 epoch total loss 1.39572501\n",
      "Trained batch 529 batch loss 1.51971054 epoch total loss 1.39595938\n",
      "Trained batch 530 batch loss 1.40684366 epoch total loss 1.39598\n",
      "Trained batch 531 batch loss 1.41481447 epoch total loss 1.39601541\n",
      "Trained batch 532 batch loss 1.43104255 epoch total loss 1.39608121\n",
      "Trained batch 533 batch loss 1.42288196 epoch total loss 1.3961314\n",
      "Trained batch 534 batch loss 1.37706542 epoch total loss 1.39609575\n",
      "Trained batch 535 batch loss 1.40194249 epoch total loss 1.3961066\n",
      "Trained batch 536 batch loss 1.54254055 epoch total loss 1.39637983\n",
      "Trained batch 537 batch loss 1.59173942 epoch total loss 1.39674366\n",
      "Trained batch 538 batch loss 1.47683263 epoch total loss 1.39689243\n",
      "Trained batch 539 batch loss 1.41150832 epoch total loss 1.39691949\n",
      "Trained batch 540 batch loss 1.42090166 epoch total loss 1.39696395\n",
      "Trained batch 541 batch loss 1.30376887 epoch total loss 1.3967917\n",
      "Trained batch 542 batch loss 1.38748085 epoch total loss 1.39677441\n",
      "Trained batch 543 batch loss 1.44240761 epoch total loss 1.39685845\n",
      "Trained batch 544 batch loss 1.3400538 epoch total loss 1.39675403\n",
      "Trained batch 545 batch loss 1.32904899 epoch total loss 1.39662969\n",
      "Trained batch 546 batch loss 1.24734569 epoch total loss 1.39635634\n",
      "Trained batch 547 batch loss 1.27988505 epoch total loss 1.39614344\n",
      "Trained batch 548 batch loss 1.47075737 epoch total loss 1.39627969\n",
      "Trained batch 549 batch loss 1.45803213 epoch total loss 1.39639211\n",
      "Trained batch 550 batch loss 1.46162438 epoch total loss 1.39651072\n",
      "Trained batch 551 batch loss 1.37708783 epoch total loss 1.39647543\n",
      "Trained batch 552 batch loss 1.37769628 epoch total loss 1.39644134\n",
      "Trained batch 553 batch loss 1.35963798 epoch total loss 1.39637482\n",
      "Trained batch 554 batch loss 1.34315777 epoch total loss 1.39627874\n",
      "Trained batch 555 batch loss 1.33227146 epoch total loss 1.39616334\n",
      "Trained batch 556 batch loss 1.40024233 epoch total loss 1.39617074\n",
      "Trained batch 557 batch loss 1.32789731 epoch total loss 1.39604819\n",
      "Trained batch 558 batch loss 1.33657622 epoch total loss 1.3959415\n",
      "Trained batch 559 batch loss 1.45366263 epoch total loss 1.39604485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 560 batch loss 1.36510921 epoch total loss 1.39598954\n",
      "Trained batch 561 batch loss 1.34932828 epoch total loss 1.39590633\n",
      "Trained batch 562 batch loss 1.40518165 epoch total loss 1.39592278\n",
      "Trained batch 563 batch loss 1.40636659 epoch total loss 1.39594138\n",
      "Trained batch 564 batch loss 1.42274284 epoch total loss 1.39598882\n",
      "Trained batch 565 batch loss 1.28381586 epoch total loss 1.39579034\n",
      "Trained batch 566 batch loss 1.39934516 epoch total loss 1.39579666\n",
      "Trained batch 567 batch loss 1.4488939 epoch total loss 1.39589024\n",
      "Trained batch 568 batch loss 1.27292764 epoch total loss 1.39567387\n",
      "Trained batch 569 batch loss 1.37936568 epoch total loss 1.39564526\n",
      "Trained batch 570 batch loss 1.41540456 epoch total loss 1.39567983\n",
      "Trained batch 571 batch loss 1.36176825 epoch total loss 1.39562047\n",
      "Trained batch 572 batch loss 1.3919816 epoch total loss 1.39561415\n",
      "Trained batch 573 batch loss 1.28987598 epoch total loss 1.39542949\n",
      "Trained batch 574 batch loss 1.16628015 epoch total loss 1.39503026\n",
      "Trained batch 575 batch loss 1.23099399 epoch total loss 1.39474499\n",
      "Trained batch 576 batch loss 1.33599019 epoch total loss 1.39464307\n",
      "Trained batch 577 batch loss 1.35986185 epoch total loss 1.39458275\n",
      "Trained batch 578 batch loss 1.27846909 epoch total loss 1.39438188\n",
      "Trained batch 579 batch loss 1.28779924 epoch total loss 1.3941977\n",
      "Trained batch 580 batch loss 1.38102448 epoch total loss 1.39417505\n",
      "Trained batch 581 batch loss 1.42601168 epoch total loss 1.39422989\n",
      "Trained batch 582 batch loss 1.4115833 epoch total loss 1.39425969\n",
      "Trained batch 583 batch loss 1.4327513 epoch total loss 1.39432561\n",
      "Trained batch 584 batch loss 1.59948516 epoch total loss 1.39467692\n",
      "Trained batch 585 batch loss 1.57251954 epoch total loss 1.39498091\n",
      "Trained batch 586 batch loss 1.47229671 epoch total loss 1.39511287\n",
      "Trained batch 587 batch loss 1.32586098 epoch total loss 1.39499485\n",
      "Trained batch 588 batch loss 1.24017048 epoch total loss 1.39473164\n",
      "Trained batch 589 batch loss 1.14602399 epoch total loss 1.39430928\n",
      "Trained batch 590 batch loss 1.30962121 epoch total loss 1.39416575\n",
      "Trained batch 591 batch loss 1.3751061 epoch total loss 1.39413357\n",
      "Trained batch 592 batch loss 1.26591623 epoch total loss 1.39391696\n",
      "Trained batch 593 batch loss 1.3249886 epoch total loss 1.39380074\n",
      "Trained batch 594 batch loss 1.39176536 epoch total loss 1.3937974\n",
      "Trained batch 595 batch loss 1.37370372 epoch total loss 1.39376366\n",
      "Trained batch 596 batch loss 1.32399535 epoch total loss 1.3936466\n",
      "Trained batch 597 batch loss 1.35025275 epoch total loss 1.39357388\n",
      "Trained batch 598 batch loss 1.32323289 epoch total loss 1.39345634\n",
      "Trained batch 599 batch loss 1.39606404 epoch total loss 1.39346063\n",
      "Trained batch 600 batch loss 1.23826051 epoch total loss 1.39320195\n",
      "Trained batch 601 batch loss 1.12335491 epoch total loss 1.39275301\n",
      "Trained batch 602 batch loss 1.07778871 epoch total loss 1.3922298\n",
      "Trained batch 603 batch loss 1.1531992 epoch total loss 1.39183331\n",
      "Trained batch 604 batch loss 1.46290445 epoch total loss 1.39195096\n",
      "Trained batch 605 batch loss 1.53486788 epoch total loss 1.39218724\n",
      "Trained batch 606 batch loss 1.50592852 epoch total loss 1.39237487\n",
      "Trained batch 607 batch loss 1.4769032 epoch total loss 1.39251423\n",
      "Trained batch 608 batch loss 1.45332122 epoch total loss 1.39261413\n",
      "Trained batch 609 batch loss 1.4048543 epoch total loss 1.39263427\n",
      "Trained batch 610 batch loss 1.36866188 epoch total loss 1.39259493\n",
      "Trained batch 611 batch loss 1.27656674 epoch total loss 1.39240503\n",
      "Trained batch 612 batch loss 1.36032856 epoch total loss 1.39235258\n",
      "Trained batch 613 batch loss 1.37463331 epoch total loss 1.39232373\n",
      "Trained batch 614 batch loss 1.37894762 epoch total loss 1.39230192\n",
      "Trained batch 615 batch loss 1.3779211 epoch total loss 1.39227855\n",
      "Trained batch 616 batch loss 1.37769985 epoch total loss 1.39225495\n",
      "Trained batch 617 batch loss 1.37126231 epoch total loss 1.39222097\n",
      "Trained batch 618 batch loss 1.39696336 epoch total loss 1.3922286\n",
      "Trained batch 619 batch loss 1.45531738 epoch total loss 1.39233053\n",
      "Trained batch 620 batch loss 1.43820238 epoch total loss 1.39240456\n",
      "Trained batch 621 batch loss 1.51941156 epoch total loss 1.39260912\n",
      "Trained batch 622 batch loss 1.44156885 epoch total loss 1.3926878\n",
      "Trained batch 623 batch loss 1.31809032 epoch total loss 1.39256811\n",
      "Trained batch 624 batch loss 1.34580064 epoch total loss 1.39249325\n",
      "Trained batch 625 batch loss 1.36346388 epoch total loss 1.39244676\n",
      "Trained batch 626 batch loss 1.27556241 epoch total loss 1.39226007\n",
      "Trained batch 627 batch loss 1.22890496 epoch total loss 1.39199948\n",
      "Trained batch 628 batch loss 1.2567575 epoch total loss 1.39178419\n",
      "Trained batch 629 batch loss 1.2684505 epoch total loss 1.39158809\n",
      "Trained batch 630 batch loss 1.42067242 epoch total loss 1.39163423\n",
      "Trained batch 631 batch loss 1.39361393 epoch total loss 1.39163733\n",
      "Trained batch 632 batch loss 1.41270578 epoch total loss 1.3916707\n",
      "Trained batch 633 batch loss 1.41373706 epoch total loss 1.39170563\n",
      "Trained batch 634 batch loss 1.24651766 epoch total loss 1.39147663\n",
      "Trained batch 635 batch loss 1.12232268 epoch total loss 1.39105272\n",
      "Trained batch 636 batch loss 1.31352818 epoch total loss 1.39093089\n",
      "Trained batch 637 batch loss 1.40196061 epoch total loss 1.39094818\n",
      "Trained batch 638 batch loss 1.40498233 epoch total loss 1.39097011\n",
      "Trained batch 639 batch loss 1.42522931 epoch total loss 1.39102376\n",
      "Trained batch 640 batch loss 1.47735679 epoch total loss 1.3911587\n",
      "Trained batch 641 batch loss 1.55664444 epoch total loss 1.39141679\n",
      "Trained batch 642 batch loss 1.36242223 epoch total loss 1.39137173\n",
      "Trained batch 643 batch loss 1.4085933 epoch total loss 1.39139843\n",
      "Trained batch 644 batch loss 1.45190549 epoch total loss 1.39149237\n",
      "Trained batch 645 batch loss 1.39445364 epoch total loss 1.39149702\n",
      "Trained batch 646 batch loss 1.37559414 epoch total loss 1.39147246\n",
      "Trained batch 647 batch loss 1.45076132 epoch total loss 1.39156401\n",
      "Trained batch 648 batch loss 1.38322425 epoch total loss 1.39155114\n",
      "Trained batch 649 batch loss 1.46737981 epoch total loss 1.39166808\n",
      "Trained batch 650 batch loss 1.40080619 epoch total loss 1.39168215\n",
      "Trained batch 651 batch loss 1.4163841 epoch total loss 1.39172\n",
      "Trained batch 652 batch loss 1.41327977 epoch total loss 1.39175308\n",
      "Trained batch 653 batch loss 1.29561663 epoch total loss 1.39160585\n",
      "Trained batch 654 batch loss 1.31359494 epoch total loss 1.39148653\n",
      "Trained batch 655 batch loss 1.28209734 epoch total loss 1.39131963\n",
      "Trained batch 656 batch loss 1.3167479 epoch total loss 1.39120591\n",
      "Trained batch 657 batch loss 1.29507816 epoch total loss 1.39105964\n",
      "Trained batch 658 batch loss 1.26289117 epoch total loss 1.39086485\n",
      "Trained batch 659 batch loss 1.45096779 epoch total loss 1.39095616\n",
      "Trained batch 660 batch loss 1.30334139 epoch total loss 1.39082336\n",
      "Trained batch 661 batch loss 1.37030876 epoch total loss 1.39079237\n",
      "Trained batch 662 batch loss 1.35954499 epoch total loss 1.39074516\n",
      "Trained batch 663 batch loss 1.40670168 epoch total loss 1.39076912\n",
      "Trained batch 664 batch loss 1.51523161 epoch total loss 1.39095664\n",
      "Trained batch 665 batch loss 1.53929591 epoch total loss 1.39117968\n",
      "Trained batch 666 batch loss 1.60600686 epoch total loss 1.39150226\n",
      "Trained batch 667 batch loss 1.39444506 epoch total loss 1.39150679\n",
      "Trained batch 668 batch loss 1.27613962 epoch total loss 1.39133406\n",
      "Trained batch 669 batch loss 1.30893862 epoch total loss 1.39121091\n",
      "Trained batch 670 batch loss 1.53302085 epoch total loss 1.39142251\n",
      "Trained batch 671 batch loss 1.58798242 epoch total loss 1.39171553\n",
      "Trained batch 672 batch loss 1.54778624 epoch total loss 1.39194775\n",
      "Trained batch 673 batch loss 1.46267772 epoch total loss 1.39205289\n",
      "Trained batch 674 batch loss 1.51514387 epoch total loss 1.39223552\n",
      "Trained batch 675 batch loss 1.47861409 epoch total loss 1.39236355\n",
      "Trained batch 676 batch loss 1.44295931 epoch total loss 1.39243841\n",
      "Trained batch 677 batch loss 1.41103899 epoch total loss 1.39246583\n",
      "Trained batch 678 batch loss 1.34569597 epoch total loss 1.39239681\n",
      "Trained batch 679 batch loss 1.38103354 epoch total loss 1.39238012\n",
      "Trained batch 680 batch loss 1.3820045 epoch total loss 1.39236486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 681 batch loss 1.39048815 epoch total loss 1.39236212\n",
      "Trained batch 682 batch loss 1.51648521 epoch total loss 1.39254415\n",
      "Trained batch 683 batch loss 1.35893989 epoch total loss 1.39249492\n",
      "Trained batch 684 batch loss 1.35201192 epoch total loss 1.39243567\n",
      "Trained batch 685 batch loss 1.43437707 epoch total loss 1.39249694\n",
      "Trained batch 686 batch loss 1.33765948 epoch total loss 1.39241695\n",
      "Trained batch 687 batch loss 1.33641279 epoch total loss 1.39233553\n",
      "Trained batch 688 batch loss 1.33396602 epoch total loss 1.39225066\n",
      "Trained batch 689 batch loss 1.38329673 epoch total loss 1.39223766\n",
      "Trained batch 690 batch loss 1.22862482 epoch total loss 1.39200056\n",
      "Trained batch 691 batch loss 1.31179714 epoch total loss 1.39188445\n",
      "Trained batch 692 batch loss 1.24556279 epoch total loss 1.39167297\n",
      "Trained batch 693 batch loss 1.39979577 epoch total loss 1.39168465\n",
      "Trained batch 694 batch loss 1.56216443 epoch total loss 1.39193034\n",
      "Trained batch 695 batch loss 1.51817644 epoch total loss 1.39211202\n",
      "Trained batch 696 batch loss 1.46470523 epoch total loss 1.39221644\n",
      "Trained batch 697 batch loss 1.37988973 epoch total loss 1.39219868\n",
      "Trained batch 698 batch loss 1.56502378 epoch total loss 1.39244628\n",
      "Trained batch 699 batch loss 1.46564329 epoch total loss 1.39255095\n",
      "Trained batch 700 batch loss 1.44767094 epoch total loss 1.39262974\n",
      "Trained batch 701 batch loss 1.30409765 epoch total loss 1.39250338\n",
      "Trained batch 702 batch loss 1.26933765 epoch total loss 1.39232802\n",
      "Trained batch 703 batch loss 1.34364986 epoch total loss 1.39225876\n",
      "Trained batch 704 batch loss 1.34254956 epoch total loss 1.39218807\n",
      "Trained batch 705 batch loss 1.41270256 epoch total loss 1.39221716\n",
      "Trained batch 706 batch loss 1.46808577 epoch total loss 1.39232469\n",
      "Trained batch 707 batch loss 1.46987891 epoch total loss 1.39243436\n",
      "Trained batch 708 batch loss 1.42182755 epoch total loss 1.39247584\n",
      "Trained batch 709 batch loss 1.48980463 epoch total loss 1.39261305\n",
      "Trained batch 710 batch loss 1.32129383 epoch total loss 1.39251268\n",
      "Trained batch 711 batch loss 1.30103528 epoch total loss 1.39238393\n",
      "Trained batch 712 batch loss 1.32490695 epoch total loss 1.39228916\n",
      "Trained batch 713 batch loss 1.38235927 epoch total loss 1.39227521\n",
      "Trained batch 714 batch loss 1.35381114 epoch total loss 1.39222145\n",
      "Trained batch 715 batch loss 1.28690588 epoch total loss 1.39207411\n",
      "Trained batch 716 batch loss 1.28277683 epoch total loss 1.39192152\n",
      "Trained batch 717 batch loss 1.21903896 epoch total loss 1.39168036\n",
      "Trained batch 718 batch loss 1.28571987 epoch total loss 1.39153278\n",
      "Trained batch 719 batch loss 1.29920805 epoch total loss 1.39140439\n",
      "Trained batch 720 batch loss 1.3104738 epoch total loss 1.39129198\n",
      "Trained batch 721 batch loss 1.4310751 epoch total loss 1.39134717\n",
      "Trained batch 722 batch loss 1.43041754 epoch total loss 1.39140129\n",
      "Trained batch 723 batch loss 1.41860569 epoch total loss 1.39143884\n",
      "Trained batch 724 batch loss 1.40519321 epoch total loss 1.39145792\n",
      "Trained batch 725 batch loss 1.42917287 epoch total loss 1.39151\n",
      "Trained batch 726 batch loss 1.41819251 epoch total loss 1.39154673\n",
      "Trained batch 727 batch loss 1.42192388 epoch total loss 1.39158857\n",
      "Trained batch 728 batch loss 1.38883901 epoch total loss 1.39158475\n",
      "Trained batch 729 batch loss 1.38778269 epoch total loss 1.39157951\n",
      "Trained batch 730 batch loss 1.48099291 epoch total loss 1.39170206\n",
      "Trained batch 731 batch loss 1.37207496 epoch total loss 1.39167523\n",
      "Trained batch 732 batch loss 1.38775957 epoch total loss 1.39166987\n",
      "Trained batch 733 batch loss 1.48258328 epoch total loss 1.39179397\n",
      "Trained batch 734 batch loss 1.53687048 epoch total loss 1.3919915\n",
      "Trained batch 735 batch loss 1.53992367 epoch total loss 1.39219284\n",
      "Trained batch 736 batch loss 1.29709053 epoch total loss 1.39206362\n",
      "Trained batch 737 batch loss 1.37350726 epoch total loss 1.39203846\n",
      "Trained batch 738 batch loss 1.27479243 epoch total loss 1.39187956\n",
      "Trained batch 739 batch loss 1.46111965 epoch total loss 1.39197326\n",
      "Trained batch 740 batch loss 1.38306451 epoch total loss 1.39196122\n",
      "Trained batch 741 batch loss 1.41680658 epoch total loss 1.3919946\n",
      "Trained batch 742 batch loss 1.43915772 epoch total loss 1.39205825\n",
      "Trained batch 743 batch loss 1.44158387 epoch total loss 1.39212489\n",
      "Trained batch 744 batch loss 1.40463364 epoch total loss 1.3921417\n",
      "Trained batch 745 batch loss 1.37690842 epoch total loss 1.39212132\n",
      "Trained batch 746 batch loss 1.27041554 epoch total loss 1.39195812\n",
      "Trained batch 747 batch loss 1.46207762 epoch total loss 1.39205194\n",
      "Trained batch 748 batch loss 1.29442334 epoch total loss 1.3919214\n",
      "Trained batch 749 batch loss 1.32877779 epoch total loss 1.39183712\n",
      "Trained batch 750 batch loss 1.33754671 epoch total loss 1.39176464\n",
      "Trained batch 751 batch loss 1.3647052 epoch total loss 1.39172864\n",
      "Trained batch 752 batch loss 1.26582551 epoch total loss 1.39156127\n",
      "Trained batch 753 batch loss 1.2065177 epoch total loss 1.39131558\n",
      "Trained batch 754 batch loss 1.17894363 epoch total loss 1.39103401\n",
      "Trained batch 755 batch loss 1.38202 epoch total loss 1.39102209\n",
      "Trained batch 756 batch loss 1.28282 epoch total loss 1.39087903\n",
      "Trained batch 757 batch loss 1.53684223 epoch total loss 1.3910718\n",
      "Trained batch 758 batch loss 1.51366746 epoch total loss 1.39123356\n",
      "Trained batch 759 batch loss 1.49946535 epoch total loss 1.39137626\n",
      "Trained batch 760 batch loss 1.33363008 epoch total loss 1.3913002\n",
      "Trained batch 761 batch loss 1.33278894 epoch total loss 1.39122331\n",
      "Trained batch 762 batch loss 1.37547541 epoch total loss 1.39120269\n",
      "Trained batch 763 batch loss 1.40567446 epoch total loss 1.39122164\n",
      "Trained batch 764 batch loss 1.43650758 epoch total loss 1.39128089\n",
      "Trained batch 765 batch loss 1.50254321 epoch total loss 1.39142632\n",
      "Trained batch 766 batch loss 1.50744641 epoch total loss 1.39157784\n",
      "Trained batch 767 batch loss 1.33632767 epoch total loss 1.39150572\n",
      "Trained batch 768 batch loss 1.34625053 epoch total loss 1.39144671\n",
      "Trained batch 769 batch loss 1.4211396 epoch total loss 1.39148533\n",
      "Trained batch 770 batch loss 1.34152317 epoch total loss 1.39142048\n",
      "Trained batch 771 batch loss 1.49181759 epoch total loss 1.39155078\n",
      "Trained batch 772 batch loss 1.51422548 epoch total loss 1.39170969\n",
      "Trained batch 773 batch loss 1.62963378 epoch total loss 1.39201748\n",
      "Trained batch 774 batch loss 1.42168462 epoch total loss 1.39205575\n",
      "Trained batch 775 batch loss 1.51816654 epoch total loss 1.39221847\n",
      "Trained batch 776 batch loss 1.44993353 epoch total loss 1.39229298\n",
      "Trained batch 777 batch loss 1.45344 epoch total loss 1.39237165\n",
      "Trained batch 778 batch loss 1.52586412 epoch total loss 1.39254332\n",
      "Trained batch 779 batch loss 1.42970645 epoch total loss 1.392591\n",
      "Trained batch 780 batch loss 1.29106009 epoch total loss 1.3924607\n",
      "Trained batch 781 batch loss 1.34151483 epoch total loss 1.39239562\n",
      "Trained batch 782 batch loss 1.31389284 epoch total loss 1.39229512\n",
      "Trained batch 783 batch loss 1.41723406 epoch total loss 1.39232695\n",
      "Trained batch 784 batch loss 1.37969637 epoch total loss 1.39231074\n",
      "Trained batch 785 batch loss 1.25251174 epoch total loss 1.39213276\n",
      "Trained batch 786 batch loss 1.30845118 epoch total loss 1.39202631\n",
      "Trained batch 787 batch loss 1.2567966 epoch total loss 1.39185452\n",
      "Trained batch 788 batch loss 1.21753883 epoch total loss 1.39163327\n",
      "Trained batch 789 batch loss 1.37611771 epoch total loss 1.3916136\n",
      "Trained batch 790 batch loss 1.30020618 epoch total loss 1.39149785\n",
      "Trained batch 791 batch loss 1.24904966 epoch total loss 1.39131773\n",
      "Trained batch 792 batch loss 1.15021145 epoch total loss 1.39101338\n",
      "Trained batch 793 batch loss 1.2933805 epoch total loss 1.39089024\n",
      "Trained batch 794 batch loss 1.19124448 epoch total loss 1.39063883\n",
      "Trained batch 795 batch loss 1.43072104 epoch total loss 1.39068913\n",
      "Trained batch 796 batch loss 1.32339525 epoch total loss 1.39060462\n",
      "Trained batch 797 batch loss 1.33169937 epoch total loss 1.39053071\n",
      "Trained batch 798 batch loss 1.34622335 epoch total loss 1.39047503\n",
      "Trained batch 799 batch loss 1.42509556 epoch total loss 1.39051831\n",
      "Trained batch 800 batch loss 1.41860723 epoch total loss 1.39055347\n",
      "Trained batch 801 batch loss 1.44719803 epoch total loss 1.39062405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 802 batch loss 1.39300847 epoch total loss 1.39062715\n",
      "Trained batch 803 batch loss 1.55514097 epoch total loss 1.39083207\n",
      "Trained batch 804 batch loss 1.63786483 epoch total loss 1.39113927\n",
      "Trained batch 805 batch loss 1.41788983 epoch total loss 1.39117241\n",
      "Trained batch 806 batch loss 1.2672267 epoch total loss 1.39101863\n",
      "Trained batch 807 batch loss 1.26524067 epoch total loss 1.39086282\n",
      "Trained batch 808 batch loss 1.33578312 epoch total loss 1.39079463\n",
      "Trained batch 809 batch loss 1.42139494 epoch total loss 1.39083242\n",
      "Trained batch 810 batch loss 1.32731164 epoch total loss 1.39075398\n",
      "Trained batch 811 batch loss 1.37633502 epoch total loss 1.39073622\n",
      "Trained batch 812 batch loss 1.4215982 epoch total loss 1.39077425\n",
      "Trained batch 813 batch loss 1.44129312 epoch total loss 1.39083636\n",
      "Trained batch 814 batch loss 1.49513555 epoch total loss 1.39096451\n",
      "Trained batch 815 batch loss 1.36676669 epoch total loss 1.39093494\n",
      "Trained batch 816 batch loss 1.37712836 epoch total loss 1.3909179\n",
      "Trained batch 817 batch loss 1.33356571 epoch total loss 1.3908478\n",
      "Trained batch 818 batch loss 1.32164371 epoch total loss 1.39076316\n",
      "Trained batch 819 batch loss 1.3873229 epoch total loss 1.39075899\n",
      "Trained batch 820 batch loss 1.3302449 epoch total loss 1.3906852\n",
      "Trained batch 821 batch loss 1.29861033 epoch total loss 1.39057291\n",
      "Trained batch 822 batch loss 1.20681214 epoch total loss 1.39034939\n",
      "Trained batch 823 batch loss 1.29106593 epoch total loss 1.39022863\n",
      "Trained batch 824 batch loss 1.25458729 epoch total loss 1.39006412\n",
      "Trained batch 825 batch loss 1.38928449 epoch total loss 1.39006317\n",
      "Trained batch 826 batch loss 1.34383988 epoch total loss 1.39000726\n",
      "Trained batch 827 batch loss 1.34944773 epoch total loss 1.38995826\n",
      "Trained batch 828 batch loss 1.37534058 epoch total loss 1.38994062\n",
      "Trained batch 829 batch loss 1.45191717 epoch total loss 1.39001536\n",
      "Trained batch 830 batch loss 1.40335381 epoch total loss 1.39003146\n",
      "Trained batch 831 batch loss 1.27566683 epoch total loss 1.38989377\n",
      "Trained batch 832 batch loss 1.38035119 epoch total loss 1.38988233\n",
      "Trained batch 833 batch loss 1.30826879 epoch total loss 1.38978434\n",
      "Trained batch 834 batch loss 1.28649819 epoch total loss 1.38966048\n",
      "Trained batch 835 batch loss 1.21954393 epoch total loss 1.38945675\n",
      "Trained batch 836 batch loss 1.33341086 epoch total loss 1.38938975\n",
      "Trained batch 837 batch loss 1.43011653 epoch total loss 1.38943839\n",
      "Trained batch 838 batch loss 1.51645362 epoch total loss 1.38959\n",
      "Trained batch 839 batch loss 1.60873234 epoch total loss 1.38985121\n",
      "Trained batch 840 batch loss 1.49064493 epoch total loss 1.38997126\n",
      "Trained batch 841 batch loss 1.44208527 epoch total loss 1.39003325\n",
      "Trained batch 842 batch loss 1.29267454 epoch total loss 1.38991761\n",
      "Trained batch 843 batch loss 1.16053712 epoch total loss 1.38964558\n",
      "Trained batch 844 batch loss 1.0792383 epoch total loss 1.3892777\n",
      "Trained batch 845 batch loss 1.09409106 epoch total loss 1.38892841\n",
      "Trained batch 846 batch loss 1.23573804 epoch total loss 1.38874733\n",
      "Trained batch 847 batch loss 1.27852309 epoch total loss 1.38861728\n",
      "Trained batch 848 batch loss 1.29657233 epoch total loss 1.3885088\n",
      "Trained batch 849 batch loss 1.34896028 epoch total loss 1.38846219\n",
      "Trained batch 850 batch loss 1.32005358 epoch total loss 1.38838172\n",
      "Trained batch 851 batch loss 1.24755979 epoch total loss 1.38821626\n",
      "Trained batch 852 batch loss 1.26241028 epoch total loss 1.38806868\n",
      "Trained batch 853 batch loss 1.2211405 epoch total loss 1.38787305\n",
      "Trained batch 854 batch loss 1.28634799 epoch total loss 1.3877542\n",
      "Trained batch 855 batch loss 1.33336473 epoch total loss 1.38769054\n",
      "Trained batch 856 batch loss 1.22653723 epoch total loss 1.38750231\n",
      "Trained batch 857 batch loss 1.31945336 epoch total loss 1.38742292\n",
      "Trained batch 858 batch loss 1.20920861 epoch total loss 1.38721526\n",
      "Trained batch 859 batch loss 1.36181569 epoch total loss 1.38718569\n",
      "Trained batch 860 batch loss 1.54620433 epoch total loss 1.38737071\n",
      "Trained batch 861 batch loss 1.47221041 epoch total loss 1.38746917\n",
      "Trained batch 862 batch loss 1.39216948 epoch total loss 1.38747466\n",
      "Trained batch 863 batch loss 1.5457058 epoch total loss 1.387658\n",
      "Trained batch 864 batch loss 1.5443666 epoch total loss 1.38783932\n",
      "Trained batch 865 batch loss 1.37456357 epoch total loss 1.38782382\n",
      "Trained batch 866 batch loss 1.38486671 epoch total loss 1.38782048\n",
      "Trained batch 867 batch loss 1.36171019 epoch total loss 1.38779032\n",
      "Trained batch 868 batch loss 1.34067369 epoch total loss 1.38773608\n",
      "Trained batch 869 batch loss 1.33962393 epoch total loss 1.38768065\n",
      "Trained batch 870 batch loss 1.37676144 epoch total loss 1.38766813\n",
      "Trained batch 871 batch loss 1.32308245 epoch total loss 1.38759398\n",
      "Trained batch 872 batch loss 1.29319572 epoch total loss 1.38748574\n",
      "Trained batch 873 batch loss 1.22276711 epoch total loss 1.38729703\n",
      "Trained batch 874 batch loss 1.27273822 epoch total loss 1.38716602\n",
      "Trained batch 875 batch loss 1.20397615 epoch total loss 1.38695657\n",
      "Trained batch 876 batch loss 1.2278111 epoch total loss 1.3867749\n",
      "Trained batch 877 batch loss 1.32018673 epoch total loss 1.38669896\n",
      "Trained batch 878 batch loss 1.20268774 epoch total loss 1.38648939\n",
      "Trained batch 879 batch loss 1.29290462 epoch total loss 1.38638282\n",
      "Trained batch 880 batch loss 1.29240453 epoch total loss 1.38627601\n",
      "Trained batch 881 batch loss 1.43840933 epoch total loss 1.38633513\n",
      "Trained batch 882 batch loss 1.41491246 epoch total loss 1.38636744\n",
      "Trained batch 883 batch loss 1.25100183 epoch total loss 1.38621414\n",
      "Trained batch 884 batch loss 1.42845726 epoch total loss 1.38626194\n",
      "Trained batch 885 batch loss 1.34175634 epoch total loss 1.38621175\n",
      "Trained batch 886 batch loss 1.26668453 epoch total loss 1.38607681\n",
      "Trained batch 887 batch loss 1.33232391 epoch total loss 1.38601625\n",
      "Trained batch 888 batch loss 1.42666638 epoch total loss 1.38606191\n",
      "Trained batch 889 batch loss 1.30406499 epoch total loss 1.38596976\n",
      "Trained batch 890 batch loss 1.13089132 epoch total loss 1.38568306\n",
      "Trained batch 891 batch loss 1.12122691 epoch total loss 1.38538623\n",
      "Trained batch 892 batch loss 1.24430108 epoch total loss 1.38522804\n",
      "Trained batch 893 batch loss 1.36491823 epoch total loss 1.38520527\n",
      "Trained batch 894 batch loss 1.60786927 epoch total loss 1.3854543\n",
      "Trained batch 895 batch loss 1.53997755 epoch total loss 1.38562691\n",
      "Trained batch 896 batch loss 1.40777099 epoch total loss 1.38565159\n",
      "Trained batch 897 batch loss 1.25977218 epoch total loss 1.38551128\n",
      "Trained batch 898 batch loss 1.39503467 epoch total loss 1.38552189\n",
      "Trained batch 899 batch loss 1.46116066 epoch total loss 1.38560605\n",
      "Trained batch 900 batch loss 1.36922479 epoch total loss 1.38558781\n",
      "Trained batch 901 batch loss 1.39970171 epoch total loss 1.38560343\n",
      "Trained batch 902 batch loss 1.36803186 epoch total loss 1.385584\n",
      "Trained batch 903 batch loss 1.45267916 epoch total loss 1.38565826\n",
      "Trained batch 904 batch loss 1.36893702 epoch total loss 1.38563967\n",
      "Trained batch 905 batch loss 1.29774475 epoch total loss 1.38554251\n",
      "Trained batch 906 batch loss 1.3132571 epoch total loss 1.38546276\n",
      "Trained batch 907 batch loss 1.32687426 epoch total loss 1.38539815\n",
      "Trained batch 908 batch loss 1.36532509 epoch total loss 1.3853761\n",
      "Trained batch 909 batch loss 1.35280418 epoch total loss 1.38534021\n",
      "Trained batch 910 batch loss 1.21393359 epoch total loss 1.38515198\n",
      "Trained batch 911 batch loss 1.26184738 epoch total loss 1.38501656\n",
      "Trained batch 912 batch loss 1.28899169 epoch total loss 1.3849113\n",
      "Trained batch 913 batch loss 1.38113296 epoch total loss 1.38490713\n",
      "Trained batch 914 batch loss 1.31654453 epoch total loss 1.38483226\n",
      "Trained batch 915 batch loss 1.16535878 epoch total loss 1.38459241\n",
      "Trained batch 916 batch loss 1.24024546 epoch total loss 1.38443482\n",
      "Trained batch 917 batch loss 1.27603054 epoch total loss 1.38431656\n",
      "Trained batch 918 batch loss 1.21653306 epoch total loss 1.38413382\n",
      "Trained batch 919 batch loss 1.1977421 epoch total loss 1.38393104\n",
      "Trained batch 920 batch loss 1.38614905 epoch total loss 1.38393342\n",
      "Trained batch 921 batch loss 1.3811357 epoch total loss 1.38393033\n",
      "Trained batch 922 batch loss 1.220433 epoch total loss 1.38375306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 923 batch loss 1.21939218 epoch total loss 1.38357496\n",
      "Trained batch 924 batch loss 1.3374486 epoch total loss 1.38352501\n",
      "Trained batch 925 batch loss 1.41312921 epoch total loss 1.38355696\n",
      "Trained batch 926 batch loss 1.33759761 epoch total loss 1.38350737\n",
      "Trained batch 927 batch loss 1.51712596 epoch total loss 1.38365149\n",
      "Trained batch 928 batch loss 1.39360619 epoch total loss 1.3836621\n",
      "Trained batch 929 batch loss 1.33596587 epoch total loss 1.38361073\n",
      "Trained batch 930 batch loss 1.38056707 epoch total loss 1.38360751\n",
      "Trained batch 931 batch loss 1.34908259 epoch total loss 1.38357043\n",
      "Trained batch 932 batch loss 1.38322616 epoch total loss 1.38357008\n",
      "Trained batch 933 batch loss 1.4165206 epoch total loss 1.38360536\n",
      "Trained batch 934 batch loss 1.34134197 epoch total loss 1.38356006\n",
      "Trained batch 935 batch loss 1.35551608 epoch total loss 1.38353\n",
      "Trained batch 936 batch loss 1.33500445 epoch total loss 1.38347816\n",
      "Trained batch 937 batch loss 1.26330137 epoch total loss 1.3833499\n",
      "Trained batch 938 batch loss 1.37218904 epoch total loss 1.38333797\n",
      "Trained batch 939 batch loss 1.33740294 epoch total loss 1.3832891\n",
      "Trained batch 940 batch loss 1.22899127 epoch total loss 1.38312495\n",
      "Trained batch 941 batch loss 1.17645121 epoch total loss 1.38290524\n",
      "Trained batch 942 batch loss 1.11605597 epoch total loss 1.382622\n",
      "Trained batch 943 batch loss 1.24500465 epoch total loss 1.38247609\n",
      "Trained batch 944 batch loss 1.27436209 epoch total loss 1.38236153\n",
      "Trained batch 945 batch loss 1.13680267 epoch total loss 1.38210177\n",
      "Trained batch 946 batch loss 1.28313422 epoch total loss 1.38199711\n",
      "Trained batch 947 batch loss 1.30521297 epoch total loss 1.38191593\n",
      "Trained batch 948 batch loss 1.42755938 epoch total loss 1.38196421\n",
      "Trained batch 949 batch loss 1.17024636 epoch total loss 1.38174117\n",
      "Trained batch 950 batch loss 1.24104452 epoch total loss 1.38159311\n",
      "Trained batch 951 batch loss 1.31057775 epoch total loss 1.38151836\n",
      "Trained batch 952 batch loss 1.40128696 epoch total loss 1.38153911\n",
      "Trained batch 953 batch loss 1.37164474 epoch total loss 1.38152874\n",
      "Trained batch 954 batch loss 1.3406142 epoch total loss 1.38148582\n",
      "Trained batch 955 batch loss 1.31162941 epoch total loss 1.38141274\n",
      "Trained batch 956 batch loss 1.29814386 epoch total loss 1.3813256\n",
      "Trained batch 957 batch loss 1.27708232 epoch total loss 1.38121665\n",
      "Trained batch 958 batch loss 1.30187941 epoch total loss 1.38113379\n",
      "Trained batch 959 batch loss 1.2874887 epoch total loss 1.38103616\n",
      "Trained batch 960 batch loss 1.31501245 epoch total loss 1.3809675\n",
      "Trained batch 961 batch loss 1.17805243 epoch total loss 1.38075638\n",
      "Trained batch 962 batch loss 1.34485626 epoch total loss 1.38071907\n",
      "Trained batch 963 batch loss 1.2964716 epoch total loss 1.38063157\n",
      "Trained batch 964 batch loss 1.30386209 epoch total loss 1.38055193\n",
      "Trained batch 965 batch loss 1.35342836 epoch total loss 1.3805238\n",
      "Trained batch 966 batch loss 1.2609868 epoch total loss 1.38040006\n",
      "Trained batch 967 batch loss 1.2905283 epoch total loss 1.38030708\n",
      "Trained batch 968 batch loss 1.30534172 epoch total loss 1.38022959\n",
      "Trained batch 969 batch loss 1.3810302 epoch total loss 1.38023043\n",
      "Trained batch 970 batch loss 1.34825134 epoch total loss 1.38019741\n",
      "Trained batch 971 batch loss 1.4002198 epoch total loss 1.38021815\n",
      "Trained batch 972 batch loss 1.2317183 epoch total loss 1.38006532\n",
      "Trained batch 973 batch loss 1.26691401 epoch total loss 1.37994909\n",
      "Trained batch 974 batch loss 1.24620426 epoch total loss 1.37981176\n",
      "Trained batch 975 batch loss 1.27858448 epoch total loss 1.37970793\n",
      "Trained batch 976 batch loss 1.23364353 epoch total loss 1.37955821\n",
      "Trained batch 977 batch loss 1.33509684 epoch total loss 1.37951279\n",
      "Trained batch 978 batch loss 1.46635532 epoch total loss 1.37960148\n",
      "Trained batch 979 batch loss 1.4525938 epoch total loss 1.3796761\n",
      "Trained batch 980 batch loss 1.41193795 epoch total loss 1.37970901\n",
      "Trained batch 981 batch loss 1.37902141 epoch total loss 1.37970841\n",
      "Trained batch 982 batch loss 1.39930964 epoch total loss 1.37972832\n",
      "Trained batch 983 batch loss 1.43189347 epoch total loss 1.37978137\n",
      "Trained batch 984 batch loss 1.25947809 epoch total loss 1.37965918\n",
      "Trained batch 985 batch loss 1.32510507 epoch total loss 1.37960374\n",
      "Trained batch 986 batch loss 1.4977473 epoch total loss 1.37972355\n",
      "Trained batch 987 batch loss 1.48556304 epoch total loss 1.37983084\n",
      "Trained batch 988 batch loss 1.28958797 epoch total loss 1.37973952\n",
      "Trained batch 989 batch loss 1.44763875 epoch total loss 1.37980819\n",
      "Trained batch 990 batch loss 1.37873542 epoch total loss 1.37980711\n",
      "Trained batch 991 batch loss 1.32996392 epoch total loss 1.37975681\n",
      "Trained batch 992 batch loss 1.40993309 epoch total loss 1.37978721\n",
      "Trained batch 993 batch loss 1.41244066 epoch total loss 1.37982011\n",
      "Trained batch 994 batch loss 1.56524229 epoch total loss 1.38000655\n",
      "Trained batch 995 batch loss 1.38418221 epoch total loss 1.38001072\n",
      "Trained batch 996 batch loss 1.2456491 epoch total loss 1.37987578\n",
      "Trained batch 997 batch loss 1.21425343 epoch total loss 1.37970972\n",
      "Trained batch 998 batch loss 1.23349452 epoch total loss 1.37956321\n",
      "Trained batch 999 batch loss 1.2887845 epoch total loss 1.37947237\n",
      "Trained batch 1000 batch loss 1.39031768 epoch total loss 1.3794831\n",
      "Trained batch 1001 batch loss 1.3569032 epoch total loss 1.37946057\n",
      "Trained batch 1002 batch loss 1.3792944 epoch total loss 1.37946045\n",
      "Trained batch 1003 batch loss 1.3755765 epoch total loss 1.37945664\n",
      "Trained batch 1004 batch loss 1.31921554 epoch total loss 1.37939656\n",
      "Trained batch 1005 batch loss 1.36139679 epoch total loss 1.3793788\n",
      "Trained batch 1006 batch loss 1.26877868 epoch total loss 1.37926877\n",
      "Trained batch 1007 batch loss 1.32467258 epoch total loss 1.37921464\n",
      "Trained batch 1008 batch loss 1.31565559 epoch total loss 1.37915158\n",
      "Trained batch 1009 batch loss 1.42409611 epoch total loss 1.37919617\n",
      "Trained batch 1010 batch loss 1.42453885 epoch total loss 1.37924099\n",
      "Trained batch 1011 batch loss 1.3788631 epoch total loss 1.37924075\n",
      "Trained batch 1012 batch loss 1.40724659 epoch total loss 1.37926841\n",
      "Trained batch 1013 batch loss 1.29363573 epoch total loss 1.37918377\n",
      "Trained batch 1014 batch loss 1.19006908 epoch total loss 1.37899721\n",
      "Trained batch 1015 batch loss 1.1963408 epoch total loss 1.3788172\n",
      "Trained batch 1016 batch loss 1.29545319 epoch total loss 1.37873518\n",
      "Trained batch 1017 batch loss 1.30460167 epoch total loss 1.37866223\n",
      "Trained batch 1018 batch loss 1.46262312 epoch total loss 1.37874472\n",
      "Trained batch 1019 batch loss 1.40102577 epoch total loss 1.37876654\n",
      "Trained batch 1020 batch loss 1.37306952 epoch total loss 1.37876093\n",
      "Trained batch 1021 batch loss 1.45272732 epoch total loss 1.37883341\n",
      "Trained batch 1022 batch loss 1.3577404 epoch total loss 1.37881279\n",
      "Trained batch 1023 batch loss 1.40125442 epoch total loss 1.37883472\n",
      "Trained batch 1024 batch loss 1.43859911 epoch total loss 1.37889314\n",
      "Trained batch 1025 batch loss 1.34119093 epoch total loss 1.3788563\n",
      "Trained batch 1026 batch loss 1.35079885 epoch total loss 1.378829\n",
      "Trained batch 1027 batch loss 1.36660814 epoch total loss 1.37881708\n",
      "Trained batch 1028 batch loss 1.41054153 epoch total loss 1.37884796\n",
      "Trained batch 1029 batch loss 1.35925865 epoch total loss 1.37882888\n",
      "Trained batch 1030 batch loss 1.33145106 epoch total loss 1.37878287\n",
      "Trained batch 1031 batch loss 1.30210328 epoch total loss 1.37870848\n",
      "Trained batch 1032 batch loss 1.32862401 epoch total loss 1.37866\n",
      "Trained batch 1033 batch loss 1.26798296 epoch total loss 1.37855279\n",
      "Trained batch 1034 batch loss 1.3292017 epoch total loss 1.37850511\n",
      "Trained batch 1035 batch loss 1.21871507 epoch total loss 1.37835073\n",
      "Trained batch 1036 batch loss 1.28370118 epoch total loss 1.37825942\n",
      "Trained batch 1037 batch loss 1.36925 epoch total loss 1.37825072\n",
      "Trained batch 1038 batch loss 1.30808127 epoch total loss 1.37818313\n",
      "Trained batch 1039 batch loss 1.34776902 epoch total loss 1.3781538\n",
      "Trained batch 1040 batch loss 1.39427841 epoch total loss 1.37816942\n",
      "Trained batch 1041 batch loss 1.46961844 epoch total loss 1.37825716\n",
      "Trained batch 1042 batch loss 1.39249229 epoch total loss 1.37827086\n",
      "Trained batch 1043 batch loss 1.31168175 epoch total loss 1.37820697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1044 batch loss 1.35784841 epoch total loss 1.37818742\n",
      "Trained batch 1045 batch loss 1.4756397 epoch total loss 1.37828064\n",
      "Trained batch 1046 batch loss 1.36441755 epoch total loss 1.37826729\n",
      "Trained batch 1047 batch loss 1.24379671 epoch total loss 1.3781389\n",
      "Trained batch 1048 batch loss 1.26674342 epoch total loss 1.37803257\n",
      "Trained batch 1049 batch loss 1.27442598 epoch total loss 1.37793374\n",
      "Trained batch 1050 batch loss 1.25933504 epoch total loss 1.37782073\n",
      "Trained batch 1051 batch loss 1.25427103 epoch total loss 1.37770319\n",
      "Trained batch 1052 batch loss 1.30393863 epoch total loss 1.37763309\n",
      "Trained batch 1053 batch loss 1.20001149 epoch total loss 1.37746441\n",
      "Trained batch 1054 batch loss 1.27995622 epoch total loss 1.37737179\n",
      "Trained batch 1055 batch loss 1.25618494 epoch total loss 1.37725699\n",
      "Trained batch 1056 batch loss 1.27440047 epoch total loss 1.3771596\n",
      "Trained batch 1057 batch loss 1.30188096 epoch total loss 1.37708831\n",
      "Trained batch 1058 batch loss 1.28655863 epoch total loss 1.37700272\n",
      "Trained batch 1059 batch loss 1.39626789 epoch total loss 1.37702096\n",
      "Trained batch 1060 batch loss 1.3565551 epoch total loss 1.37700164\n",
      "Trained batch 1061 batch loss 1.37333322 epoch total loss 1.37699807\n",
      "Trained batch 1062 batch loss 1.30521572 epoch total loss 1.37693048\n",
      "Trained batch 1063 batch loss 1.20107055 epoch total loss 1.37676501\n",
      "Trained batch 1064 batch loss 1.20900428 epoch total loss 1.3766073\n",
      "Trained batch 1065 batch loss 1.40115297 epoch total loss 1.37663031\n",
      "Trained batch 1066 batch loss 1.44252074 epoch total loss 1.37669218\n",
      "Trained batch 1067 batch loss 1.48793352 epoch total loss 1.37679636\n",
      "Trained batch 1068 batch loss 1.42175329 epoch total loss 1.37683845\n",
      "Trained batch 1069 batch loss 1.42300272 epoch total loss 1.3768816\n",
      "Trained batch 1070 batch loss 1.31315649 epoch total loss 1.37682199\n",
      "Trained batch 1071 batch loss 1.26845837 epoch total loss 1.37672079\n",
      "Trained batch 1072 batch loss 1.34618545 epoch total loss 1.37669241\n",
      "Trained batch 1073 batch loss 1.33587015 epoch total loss 1.37665427\n",
      "Trained batch 1074 batch loss 1.34161067 epoch total loss 1.3766216\n",
      "Trained batch 1075 batch loss 1.38635659 epoch total loss 1.37663066\n",
      "Trained batch 1076 batch loss 1.38242042 epoch total loss 1.37663603\n",
      "Trained batch 1077 batch loss 1.40276861 epoch total loss 1.37666023\n",
      "Trained batch 1078 batch loss 1.44875574 epoch total loss 1.3767271\n",
      "Trained batch 1079 batch loss 1.38069856 epoch total loss 1.3767308\n",
      "Trained batch 1080 batch loss 1.39632702 epoch total loss 1.37674904\n",
      "Trained batch 1081 batch loss 1.45591009 epoch total loss 1.37682223\n",
      "Trained batch 1082 batch loss 1.46668386 epoch total loss 1.37690532\n",
      "Trained batch 1083 batch loss 1.43396688 epoch total loss 1.37695801\n",
      "Trained batch 1084 batch loss 1.34667504 epoch total loss 1.37693\n",
      "Trained batch 1085 batch loss 1.44518304 epoch total loss 1.37699294\n",
      "Trained batch 1086 batch loss 1.26798677 epoch total loss 1.37689257\n",
      "Trained batch 1087 batch loss 1.3640784 epoch total loss 1.37688076\n",
      "Trained batch 1088 batch loss 1.31026316 epoch total loss 1.37681961\n",
      "Trained batch 1089 batch loss 1.34404433 epoch total loss 1.37678945\n",
      "Trained batch 1090 batch loss 1.28903735 epoch total loss 1.37670898\n",
      "Trained batch 1091 batch loss 1.2512362 epoch total loss 1.37659395\n",
      "Trained batch 1092 batch loss 1.32284379 epoch total loss 1.37654471\n",
      "Trained batch 1093 batch loss 1.33856606 epoch total loss 1.37651\n",
      "Trained batch 1094 batch loss 1.33493924 epoch total loss 1.37647212\n",
      "Trained batch 1095 batch loss 1.43548119 epoch total loss 1.37652588\n",
      "Trained batch 1096 batch loss 1.48802054 epoch total loss 1.37662768\n",
      "Trained batch 1097 batch loss 1.33369756 epoch total loss 1.37658858\n",
      "Trained batch 1098 batch loss 1.44260228 epoch total loss 1.37664878\n",
      "Trained batch 1099 batch loss 1.39617157 epoch total loss 1.37666643\n",
      "Trained batch 1100 batch loss 1.44530487 epoch total loss 1.37672889\n",
      "Trained batch 1101 batch loss 1.36411166 epoch total loss 1.37671745\n",
      "Trained batch 1102 batch loss 1.27668214 epoch total loss 1.37662673\n",
      "Trained batch 1103 batch loss 1.32508421 epoch total loss 1.37658\n",
      "Trained batch 1104 batch loss 1.25352263 epoch total loss 1.37646854\n",
      "Trained batch 1105 batch loss 1.20749497 epoch total loss 1.37631559\n",
      "Trained batch 1106 batch loss 1.31462312 epoch total loss 1.3762598\n",
      "Trained batch 1107 batch loss 1.24402595 epoch total loss 1.37614036\n",
      "Trained batch 1108 batch loss 1.2996279 epoch total loss 1.37607133\n",
      "Trained batch 1109 batch loss 1.2277559 epoch total loss 1.37593758\n",
      "Trained batch 1110 batch loss 1.22581899 epoch total loss 1.3758024\n",
      "Trained batch 1111 batch loss 1.30850136 epoch total loss 1.37574172\n",
      "Trained batch 1112 batch loss 1.31430554 epoch total loss 1.37568653\n",
      "Trained batch 1113 batch loss 1.22758865 epoch total loss 1.37555349\n",
      "Trained batch 1114 batch loss 1.27964234 epoch total loss 1.3754673\n",
      "Trained batch 1115 batch loss 1.1413312 epoch total loss 1.37525737\n",
      "Trained batch 1116 batch loss 1.09096766 epoch total loss 1.37500262\n",
      "Trained batch 1117 batch loss 1.17286801 epoch total loss 1.37482166\n",
      "Trained batch 1118 batch loss 1.39506304 epoch total loss 1.37483966\n",
      "Trained batch 1119 batch loss 1.40908802 epoch total loss 1.3748703\n",
      "Trained batch 1120 batch loss 1.29225266 epoch total loss 1.37479651\n",
      "Trained batch 1121 batch loss 1.35698223 epoch total loss 1.37478054\n",
      "Trained batch 1122 batch loss 1.37620711 epoch total loss 1.37478185\n",
      "Trained batch 1123 batch loss 1.2429111 epoch total loss 1.37466443\n",
      "Trained batch 1124 batch loss 1.25311971 epoch total loss 1.3745563\n",
      "Trained batch 1125 batch loss 1.29819679 epoch total loss 1.37448847\n",
      "Trained batch 1126 batch loss 1.28372526 epoch total loss 1.37440789\n",
      "Trained batch 1127 batch loss 1.33351684 epoch total loss 1.37437153\n",
      "Trained batch 1128 batch loss 1.33509111 epoch total loss 1.37433672\n",
      "Trained batch 1129 batch loss 1.44229805 epoch total loss 1.37439692\n",
      "Trained batch 1130 batch loss 1.4455986 epoch total loss 1.37445986\n",
      "Trained batch 1131 batch loss 1.38314986 epoch total loss 1.37446761\n",
      "Trained batch 1132 batch loss 1.44502163 epoch total loss 1.37453\n",
      "Trained batch 1133 batch loss 1.42442906 epoch total loss 1.37457395\n",
      "Trained batch 1134 batch loss 1.40054262 epoch total loss 1.37459683\n",
      "Trained batch 1135 batch loss 1.28646553 epoch total loss 1.37451923\n",
      "Trained batch 1136 batch loss 1.2897613 epoch total loss 1.37444472\n",
      "Trained batch 1137 batch loss 1.14833617 epoch total loss 1.37424576\n",
      "Trained batch 1138 batch loss 1.18897939 epoch total loss 1.37408292\n",
      "Trained batch 1139 batch loss 1.18350744 epoch total loss 1.37391567\n",
      "Trained batch 1140 batch loss 1.24210644 epoch total loss 1.37379992\n",
      "Trained batch 1141 batch loss 1.1022023 epoch total loss 1.37356186\n",
      "Trained batch 1142 batch loss 1.09291148 epoch total loss 1.37331617\n",
      "Trained batch 1143 batch loss 1.0748316 epoch total loss 1.37305498\n",
      "Trained batch 1144 batch loss 1.04360867 epoch total loss 1.37276697\n",
      "Trained batch 1145 batch loss 1.32148039 epoch total loss 1.37272227\n",
      "Trained batch 1146 batch loss 1.36206222 epoch total loss 1.37271297\n",
      "Trained batch 1147 batch loss 1.32462168 epoch total loss 1.37267101\n",
      "Trained batch 1148 batch loss 1.26903319 epoch total loss 1.37258077\n",
      "Trained batch 1149 batch loss 1.34005034 epoch total loss 1.37255239\n",
      "Trained batch 1150 batch loss 1.21173859 epoch total loss 1.37241268\n",
      "Trained batch 1151 batch loss 1.21621346 epoch total loss 1.3722769\n",
      "Trained batch 1152 batch loss 1.28892827 epoch total loss 1.37220454\n",
      "Trained batch 1153 batch loss 1.44852102 epoch total loss 1.3722707\n",
      "Trained batch 1154 batch loss 1.35690451 epoch total loss 1.37225747\n",
      "Trained batch 1155 batch loss 1.30947626 epoch total loss 1.37220311\n",
      "Trained batch 1156 batch loss 1.37317908 epoch total loss 1.37220395\n",
      "Trained batch 1157 batch loss 1.211797 epoch total loss 1.37206531\n",
      "Trained batch 1158 batch loss 1.33165479 epoch total loss 1.37203038\n",
      "Trained batch 1159 batch loss 1.37033379 epoch total loss 1.37202895\n",
      "Trained batch 1160 batch loss 1.23102522 epoch total loss 1.37190735\n",
      "Trained batch 1161 batch loss 1.32538307 epoch total loss 1.37186742\n",
      "Trained batch 1162 batch loss 1.17218733 epoch total loss 1.37169564\n",
      "Trained batch 1163 batch loss 1.33570218 epoch total loss 1.37166464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1164 batch loss 1.2504847 epoch total loss 1.37156057\n",
      "Trained batch 1165 batch loss 1.40696776 epoch total loss 1.37159097\n",
      "Trained batch 1166 batch loss 1.41511881 epoch total loss 1.37162828\n",
      "Trained batch 1167 batch loss 1.17477798 epoch total loss 1.3714596\n",
      "Trained batch 1168 batch loss 1.22667348 epoch total loss 1.37133574\n",
      "Trained batch 1169 batch loss 1.16405773 epoch total loss 1.37115836\n",
      "Trained batch 1170 batch loss 1.15983033 epoch total loss 1.37097776\n",
      "Trained batch 1171 batch loss 1.20984197 epoch total loss 1.37084007\n",
      "Trained batch 1172 batch loss 1.3087132 epoch total loss 1.37078714\n",
      "Trained batch 1173 batch loss 1.30397177 epoch total loss 1.37073016\n",
      "Trained batch 1174 batch loss 1.24560106 epoch total loss 1.37062359\n",
      "Trained batch 1175 batch loss 1.26914322 epoch total loss 1.37053716\n",
      "Trained batch 1176 batch loss 1.2502588 epoch total loss 1.37043488\n",
      "Trained batch 1177 batch loss 1.32917118 epoch total loss 1.3704\n",
      "Trained batch 1178 batch loss 1.30861843 epoch total loss 1.3703475\n",
      "Trained batch 1179 batch loss 1.49941921 epoch total loss 1.37045693\n",
      "Trained batch 1180 batch loss 1.29898763 epoch total loss 1.37039626\n",
      "Trained batch 1181 batch loss 1.29953742 epoch total loss 1.37033629\n",
      "Trained batch 1182 batch loss 1.20017803 epoch total loss 1.37019241\n",
      "Trained batch 1183 batch loss 1.17483401 epoch total loss 1.37002718\n",
      "Trained batch 1184 batch loss 1.13329613 epoch total loss 1.36982727\n",
      "Trained batch 1185 batch loss 1.14216816 epoch total loss 1.36963522\n",
      "Trained batch 1186 batch loss 1.1813935 epoch total loss 1.36947644\n",
      "Trained batch 1187 batch loss 1.22653437 epoch total loss 1.36935604\n",
      "Trained batch 1188 batch loss 1.31788862 epoch total loss 1.36931276\n",
      "Trained batch 1189 batch loss 1.27799022 epoch total loss 1.36923587\n",
      "Trained batch 1190 batch loss 1.36566854 epoch total loss 1.36923289\n",
      "Trained batch 1191 batch loss 1.38414741 epoch total loss 1.36924553\n",
      "Trained batch 1192 batch loss 1.32553911 epoch total loss 1.36920881\n",
      "Trained batch 1193 batch loss 1.19773412 epoch total loss 1.36906517\n",
      "Trained batch 1194 batch loss 1.11333942 epoch total loss 1.36885095\n",
      "Trained batch 1195 batch loss 1.2864244 epoch total loss 1.36878192\n",
      "Trained batch 1196 batch loss 1.41542327 epoch total loss 1.36882091\n",
      "Trained batch 1197 batch loss 1.50045848 epoch total loss 1.36893082\n",
      "Trained batch 1198 batch loss 1.54553473 epoch total loss 1.36907828\n",
      "Trained batch 1199 batch loss 1.35684443 epoch total loss 1.36906803\n",
      "Trained batch 1200 batch loss 1.47826195 epoch total loss 1.36915898\n",
      "Trained batch 1201 batch loss 1.35294831 epoch total loss 1.36914551\n",
      "Trained batch 1202 batch loss 1.47581351 epoch total loss 1.3692342\n",
      "Trained batch 1203 batch loss 1.46164477 epoch total loss 1.36931109\n",
      "Trained batch 1204 batch loss 1.40777326 epoch total loss 1.36934304\n",
      "Trained batch 1205 batch loss 1.39500308 epoch total loss 1.36936426\n",
      "Trained batch 1206 batch loss 1.31979513 epoch total loss 1.36932325\n",
      "Trained batch 1207 batch loss 1.23134756 epoch total loss 1.36920893\n",
      "Trained batch 1208 batch loss 1.26676834 epoch total loss 1.36912405\n",
      "Trained batch 1209 batch loss 1.23409462 epoch total loss 1.36901236\n",
      "Trained batch 1210 batch loss 1.35632157 epoch total loss 1.36900187\n",
      "Trained batch 1211 batch loss 1.41583729 epoch total loss 1.36904061\n",
      "Trained batch 1212 batch loss 1.41069961 epoch total loss 1.36907494\n",
      "Trained batch 1213 batch loss 1.39501846 epoch total loss 1.3690964\n",
      "Trained batch 1214 batch loss 1.36752069 epoch total loss 1.36909509\n",
      "Trained batch 1215 batch loss 1.41072416 epoch total loss 1.36912942\n",
      "Trained batch 1216 batch loss 1.38242149 epoch total loss 1.36914027\n",
      "Trained batch 1217 batch loss 1.28344071 epoch total loss 1.36906993\n",
      "Trained batch 1218 batch loss 1.45024681 epoch total loss 1.36913657\n",
      "Trained batch 1219 batch loss 1.36600041 epoch total loss 1.36913395\n",
      "Trained batch 1220 batch loss 1.25525093 epoch total loss 1.36904061\n",
      "Trained batch 1221 batch loss 1.27346683 epoch total loss 1.36896229\n",
      "Trained batch 1222 batch loss 1.32147932 epoch total loss 1.36892343\n",
      "Trained batch 1223 batch loss 1.26672816 epoch total loss 1.36883986\n",
      "Trained batch 1224 batch loss 1.29293966 epoch total loss 1.36877787\n",
      "Trained batch 1225 batch loss 1.30718637 epoch total loss 1.36872756\n",
      "Trained batch 1226 batch loss 1.4115032 epoch total loss 1.36876249\n",
      "Trained batch 1227 batch loss 1.41965771 epoch total loss 1.36880398\n",
      "Trained batch 1228 batch loss 1.37748563 epoch total loss 1.36881101\n",
      "Trained batch 1229 batch loss 1.39853191 epoch total loss 1.36883521\n",
      "Trained batch 1230 batch loss 1.37882352 epoch total loss 1.36884332\n",
      "Trained batch 1231 batch loss 1.32895589 epoch total loss 1.36881089\n",
      "Trained batch 1232 batch loss 1.33901453 epoch total loss 1.36878669\n",
      "Trained batch 1233 batch loss 1.25065684 epoch total loss 1.36869085\n",
      "Trained batch 1234 batch loss 1.39399219 epoch total loss 1.36871135\n",
      "Trained batch 1235 batch loss 1.24596798 epoch total loss 1.36861205\n",
      "Trained batch 1236 batch loss 1.43160534 epoch total loss 1.36866295\n",
      "Trained batch 1237 batch loss 1.228652 epoch total loss 1.36854982\n",
      "Trained batch 1238 batch loss 1.31934261 epoch total loss 1.36851\n",
      "Trained batch 1239 batch loss 1.41873932 epoch total loss 1.36855054\n",
      "Trained batch 1240 batch loss 1.33819723 epoch total loss 1.3685261\n",
      "Trained batch 1241 batch loss 1.27596796 epoch total loss 1.3684516\n",
      "Trained batch 1242 batch loss 1.35330021 epoch total loss 1.36843932\n",
      "Trained batch 1243 batch loss 1.28461027 epoch total loss 1.36837196\n",
      "Trained batch 1244 batch loss 1.34662986 epoch total loss 1.36835456\n",
      "Trained batch 1245 batch loss 1.33318305 epoch total loss 1.36832619\n",
      "Trained batch 1246 batch loss 1.32972884 epoch total loss 1.36829519\n",
      "Trained batch 1247 batch loss 1.36192966 epoch total loss 1.36829019\n",
      "Trained batch 1248 batch loss 1.2723279 epoch total loss 1.3682133\n",
      "Trained batch 1249 batch loss 1.35729516 epoch total loss 1.36820447\n",
      "Trained batch 1250 batch loss 1.33185303 epoch total loss 1.36817551\n",
      "Trained batch 1251 batch loss 1.3517983 epoch total loss 1.36816239\n",
      "Trained batch 1252 batch loss 1.32218874 epoch total loss 1.36812568\n",
      "Trained batch 1253 batch loss 1.49539328 epoch total loss 1.36822724\n",
      "Trained batch 1254 batch loss 1.26451826 epoch total loss 1.36814451\n",
      "Trained batch 1255 batch loss 1.40092468 epoch total loss 1.36817062\n",
      "Trained batch 1256 batch loss 1.28356504 epoch total loss 1.36810327\n",
      "Trained batch 1257 batch loss 1.33089542 epoch total loss 1.3680737\n",
      "Trained batch 1258 batch loss 1.41611099 epoch total loss 1.36811185\n",
      "Trained batch 1259 batch loss 1.37427568 epoch total loss 1.36811674\n",
      "Trained batch 1260 batch loss 1.34520817 epoch total loss 1.36809862\n",
      "Trained batch 1261 batch loss 1.27218902 epoch total loss 1.36802256\n",
      "Trained batch 1262 batch loss 1.40690517 epoch total loss 1.36805332\n",
      "Trained batch 1263 batch loss 1.25679278 epoch total loss 1.36796522\n",
      "Trained batch 1264 batch loss 1.27057862 epoch total loss 1.36788821\n",
      "Trained batch 1265 batch loss 1.2836051 epoch total loss 1.36782157\n",
      "Trained batch 1266 batch loss 1.39453256 epoch total loss 1.36784267\n",
      "Trained batch 1267 batch loss 1.23301756 epoch total loss 1.36773634\n",
      "Trained batch 1268 batch loss 1.31782198 epoch total loss 1.367697\n",
      "Trained batch 1269 batch loss 1.357903 epoch total loss 1.36768925\n",
      "Trained batch 1270 batch loss 1.28458643 epoch total loss 1.36762381\n",
      "Trained batch 1271 batch loss 1.2584641 epoch total loss 1.36753786\n",
      "Trained batch 1272 batch loss 1.30749261 epoch total loss 1.36749065\n",
      "Trained batch 1273 batch loss 1.38277435 epoch total loss 1.36750269\n",
      "Trained batch 1274 batch loss 1.29872429 epoch total loss 1.36744869\n",
      "Trained batch 1275 batch loss 1.36376941 epoch total loss 1.36744583\n",
      "Trained batch 1276 batch loss 1.32212985 epoch total loss 1.3674103\n",
      "Trained batch 1277 batch loss 1.19522 epoch total loss 1.36727548\n",
      "Trained batch 1278 batch loss 1.30655706 epoch total loss 1.36722791\n",
      "Trained batch 1279 batch loss 1.40683317 epoch total loss 1.36725891\n",
      "Trained batch 1280 batch loss 1.36945057 epoch total loss 1.36726069\n",
      "Trained batch 1281 batch loss 1.34633613 epoch total loss 1.36724424\n",
      "Trained batch 1282 batch loss 1.329036 epoch total loss 1.36721444\n",
      "Trained batch 1283 batch loss 1.3695488 epoch total loss 1.36721623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1284 batch loss 1.30924129 epoch total loss 1.36717105\n",
      "Trained batch 1285 batch loss 1.35538936 epoch total loss 1.36716187\n",
      "Trained batch 1286 batch loss 1.28292406 epoch total loss 1.36709642\n",
      "Trained batch 1287 batch loss 1.37270248 epoch total loss 1.36710072\n",
      "Trained batch 1288 batch loss 1.35097587 epoch total loss 1.3670882\n",
      "Trained batch 1289 batch loss 1.49486387 epoch total loss 1.36718726\n",
      "Trained batch 1290 batch loss 1.38640928 epoch total loss 1.36720216\n",
      "Trained batch 1291 batch loss 1.41876531 epoch total loss 1.3672421\n",
      "Trained batch 1292 batch loss 1.39003801 epoch total loss 1.36725974\n",
      "Trained batch 1293 batch loss 1.25241435 epoch total loss 1.36717093\n",
      "Trained batch 1294 batch loss 1.39592063 epoch total loss 1.3671931\n",
      "Trained batch 1295 batch loss 1.20746601 epoch total loss 1.36706984\n",
      "Trained batch 1296 batch loss 1.3351202 epoch total loss 1.36704516\n",
      "Trained batch 1297 batch loss 1.29056382 epoch total loss 1.36698616\n",
      "Trained batch 1298 batch loss 1.35864687 epoch total loss 1.36697972\n",
      "Trained batch 1299 batch loss 1.28998399 epoch total loss 1.36692047\n",
      "Trained batch 1300 batch loss 1.32781649 epoch total loss 1.36689043\n",
      "Trained batch 1301 batch loss 1.38224244 epoch total loss 1.36690211\n",
      "Trained batch 1302 batch loss 1.26840734 epoch total loss 1.36682653\n",
      "Trained batch 1303 batch loss 1.36978889 epoch total loss 1.3668288\n",
      "Trained batch 1304 batch loss 1.32695389 epoch total loss 1.36679816\n",
      "Trained batch 1305 batch loss 1.24108016 epoch total loss 1.36670184\n",
      "Trained batch 1306 batch loss 1.20352769 epoch total loss 1.36657691\n",
      "Trained batch 1307 batch loss 1.18402123 epoch total loss 1.3664372\n",
      "Trained batch 1308 batch loss 1.36205482 epoch total loss 1.36643386\n",
      "Trained batch 1309 batch loss 1.30927658 epoch total loss 1.36639023\n",
      "Trained batch 1310 batch loss 1.52321422 epoch total loss 1.36650991\n",
      "Trained batch 1311 batch loss 1.54584479 epoch total loss 1.36664677\n",
      "Trained batch 1312 batch loss 1.47474301 epoch total loss 1.36672914\n",
      "Trained batch 1313 batch loss 1.32383084 epoch total loss 1.36669648\n",
      "Trained batch 1314 batch loss 1.33025038 epoch total loss 1.3666687\n",
      "Trained batch 1315 batch loss 1.2620858 epoch total loss 1.36658919\n",
      "Trained batch 1316 batch loss 1.29395223 epoch total loss 1.36653399\n",
      "Trained batch 1317 batch loss 1.25065327 epoch total loss 1.36644602\n",
      "Trained batch 1318 batch loss 1.33298433 epoch total loss 1.36642063\n",
      "Trained batch 1319 batch loss 1.33985734 epoch total loss 1.36640048\n",
      "Trained batch 1320 batch loss 1.38056886 epoch total loss 1.36641121\n",
      "Trained batch 1321 batch loss 1.35220122 epoch total loss 1.36640048\n",
      "Trained batch 1322 batch loss 1.30340862 epoch total loss 1.36635292\n",
      "Trained batch 1323 batch loss 1.3487041 epoch total loss 1.36633956\n",
      "Trained batch 1324 batch loss 1.41061473 epoch total loss 1.36637306\n",
      "Trained batch 1325 batch loss 1.21648586 epoch total loss 1.36625981\n",
      "Trained batch 1326 batch loss 1.36993873 epoch total loss 1.36626267\n",
      "Trained batch 1327 batch loss 1.21413875 epoch total loss 1.36614799\n",
      "Trained batch 1328 batch loss 1.40382934 epoch total loss 1.36617637\n",
      "Trained batch 1329 batch loss 1.35072851 epoch total loss 1.36616468\n",
      "Trained batch 1330 batch loss 1.44254446 epoch total loss 1.36622214\n",
      "Trained batch 1331 batch loss 1.27592874 epoch total loss 1.36615431\n",
      "Trained batch 1332 batch loss 1.25318193 epoch total loss 1.36606944\n",
      "Trained batch 1333 batch loss 1.24483979 epoch total loss 1.36597848\n",
      "Trained batch 1334 batch loss 1.2917943 epoch total loss 1.36592293\n",
      "Trained batch 1335 batch loss 1.35471368 epoch total loss 1.36591446\n",
      "Trained batch 1336 batch loss 1.27143335 epoch total loss 1.36584377\n",
      "Trained batch 1337 batch loss 1.27820516 epoch total loss 1.36577821\n",
      "Trained batch 1338 batch loss 1.36641884 epoch total loss 1.3657788\n",
      "Trained batch 1339 batch loss 1.33520722 epoch total loss 1.36575592\n",
      "Trained batch 1340 batch loss 1.42571414 epoch total loss 1.36580062\n",
      "Trained batch 1341 batch loss 1.33391738 epoch total loss 1.36577678\n",
      "Trained batch 1342 batch loss 1.39989924 epoch total loss 1.36580229\n",
      "Trained batch 1343 batch loss 1.35322499 epoch total loss 1.36579287\n",
      "Trained batch 1344 batch loss 1.30851865 epoch total loss 1.36575031\n",
      "Trained batch 1345 batch loss 1.26134515 epoch total loss 1.36567271\n",
      "Trained batch 1346 batch loss 1.3870858 epoch total loss 1.36568856\n",
      "Trained batch 1347 batch loss 1.37604833 epoch total loss 1.36569631\n",
      "Trained batch 1348 batch loss 1.40024126 epoch total loss 1.36572194\n",
      "Trained batch 1349 batch loss 1.29235375 epoch total loss 1.36566758\n",
      "Trained batch 1350 batch loss 1.25740504 epoch total loss 1.36558735\n",
      "Trained batch 1351 batch loss 1.26836252 epoch total loss 1.36551535\n",
      "Trained batch 1352 batch loss 1.25510108 epoch total loss 1.36543369\n",
      "Trained batch 1353 batch loss 1.45023584 epoch total loss 1.3654964\n",
      "Trained batch 1354 batch loss 1.33651912 epoch total loss 1.36547506\n",
      "Trained batch 1355 batch loss 1.32905364 epoch total loss 1.36544812\n",
      "Trained batch 1356 batch loss 1.29812407 epoch total loss 1.36539853\n",
      "Trained batch 1357 batch loss 1.316136 epoch total loss 1.36536217\n",
      "Trained batch 1358 batch loss 1.2537818 epoch total loss 1.36528\n",
      "Trained batch 1359 batch loss 1.36308694 epoch total loss 1.36527836\n",
      "Trained batch 1360 batch loss 1.28696299 epoch total loss 1.36522079\n",
      "Trained batch 1361 batch loss 1.48015499 epoch total loss 1.36530519\n",
      "Trained batch 1362 batch loss 1.38088691 epoch total loss 1.36531663\n",
      "Trained batch 1363 batch loss 1.32272053 epoch total loss 1.3652854\n",
      "Trained batch 1364 batch loss 1.27001429 epoch total loss 1.36521554\n",
      "Trained batch 1365 batch loss 1.20809066 epoch total loss 1.3651005\n",
      "Trained batch 1366 batch loss 1.30759585 epoch total loss 1.36505842\n",
      "Trained batch 1367 batch loss 1.32275188 epoch total loss 1.36502743\n",
      "Trained batch 1368 batch loss 1.39675748 epoch total loss 1.36505067\n",
      "Trained batch 1369 batch loss 1.50322151 epoch total loss 1.36515152\n",
      "Trained batch 1370 batch loss 1.31085324 epoch total loss 1.36511195\n",
      "Trained batch 1371 batch loss 1.36679697 epoch total loss 1.36511314\n",
      "Trained batch 1372 batch loss 1.33161879 epoch total loss 1.36508882\n",
      "Trained batch 1373 batch loss 1.38821352 epoch total loss 1.36510563\n",
      "Trained batch 1374 batch loss 1.41228032 epoch total loss 1.36514\n",
      "Trained batch 1375 batch loss 1.45995903 epoch total loss 1.36520886\n",
      "Trained batch 1376 batch loss 1.38085032 epoch total loss 1.36522031\n",
      "Trained batch 1377 batch loss 1.23071015 epoch total loss 1.36512256\n",
      "Trained batch 1378 batch loss 1.40973854 epoch total loss 1.36515498\n",
      "Trained batch 1379 batch loss 1.42365432 epoch total loss 1.36519742\n",
      "Trained batch 1380 batch loss 1.26316249 epoch total loss 1.36512351\n",
      "Trained batch 1381 batch loss 1.37133467 epoch total loss 1.36512804\n",
      "Trained batch 1382 batch loss 1.30900908 epoch total loss 1.36508739\n",
      "Trained batch 1383 batch loss 1.3523401 epoch total loss 1.36507809\n",
      "Trained batch 1384 batch loss 1.39159465 epoch total loss 1.36509728\n",
      "Trained batch 1385 batch loss 1.27153945 epoch total loss 1.36502969\n",
      "Trained batch 1386 batch loss 1.41369271 epoch total loss 1.36506486\n",
      "Trained batch 1387 batch loss 1.30850708 epoch total loss 1.36502409\n",
      "Trained batch 1388 batch loss 1.28790462 epoch total loss 1.36496854\n",
      "Epoch 2 train loss 1.3649685382843018\n",
      "Validated batch 1 batch loss 1.30992568\n",
      "Validated batch 2 batch loss 1.28679681\n",
      "Validated batch 3 batch loss 1.24824381\n",
      "Validated batch 4 batch loss 1.36876392\n",
      "Validated batch 5 batch loss 1.27531981\n",
      "Validated batch 6 batch loss 1.33790946\n",
      "Validated batch 7 batch loss 1.42241955\n",
      "Validated batch 8 batch loss 1.35683954\n",
      "Validated batch 9 batch loss 1.38771605\n",
      "Validated batch 10 batch loss 1.30199873\n",
      "Validated batch 11 batch loss 1.38715458\n",
      "Validated batch 12 batch loss 1.2852546\n",
      "Validated batch 13 batch loss 1.30911934\n",
      "Validated batch 14 batch loss 1.45631981\n",
      "Validated batch 15 batch loss 1.37121272\n",
      "Validated batch 16 batch loss 1.30207372\n",
      "Validated batch 17 batch loss 1.44098461\n",
      "Validated batch 18 batch loss 1.1599673\n",
      "Validated batch 19 batch loss 1.34482491\n",
      "Validated batch 20 batch loss 1.15779662\n",
      "Validated batch 21 batch loss 1.36319506\n",
      "Validated batch 22 batch loss 1.38730824\n",
      "Validated batch 23 batch loss 1.23969889\n",
      "Validated batch 24 batch loss 1.29954958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 25 batch loss 1.19515431\n",
      "Validated batch 26 batch loss 1.31442654\n",
      "Validated batch 27 batch loss 1.23869753\n",
      "Validated batch 28 batch loss 1.29403949\n",
      "Validated batch 29 batch loss 1.35357833\n",
      "Validated batch 30 batch loss 1.30319297\n",
      "Validated batch 31 batch loss 1.44745111\n",
      "Validated batch 32 batch loss 1.38436723\n",
      "Validated batch 33 batch loss 1.32149732\n",
      "Validated batch 34 batch loss 1.30889535\n",
      "Validated batch 35 batch loss 1.4050132\n",
      "Validated batch 36 batch loss 1.40803766\n",
      "Validated batch 37 batch loss 1.38507462\n",
      "Validated batch 38 batch loss 1.35288572\n",
      "Validated batch 39 batch loss 1.38072681\n",
      "Validated batch 40 batch loss 1.36917067\n",
      "Validated batch 41 batch loss 1.19945598\n",
      "Validated batch 42 batch loss 1.29317129\n",
      "Validated batch 43 batch loss 1.34352469\n",
      "Validated batch 44 batch loss 1.33897579\n",
      "Validated batch 45 batch loss 1.33200538\n",
      "Validated batch 46 batch loss 1.29866862\n",
      "Validated batch 47 batch loss 1.29113412\n",
      "Validated batch 48 batch loss 1.29667377\n",
      "Validated batch 49 batch loss 1.2799449\n",
      "Validated batch 50 batch loss 1.18933415\n",
      "Validated batch 51 batch loss 1.21775436\n",
      "Validated batch 52 batch loss 1.3676281\n",
      "Validated batch 53 batch loss 1.26533937\n",
      "Validated batch 54 batch loss 1.19431841\n",
      "Validated batch 55 batch loss 1.26928663\n",
      "Validated batch 56 batch loss 1.26670063\n",
      "Validated batch 57 batch loss 1.22254038\n",
      "Validated batch 58 batch loss 1.28802228\n",
      "Validated batch 59 batch loss 1.32715452\n",
      "Validated batch 60 batch loss 1.28431141\n",
      "Validated batch 61 batch loss 1.33564222\n",
      "Validated batch 62 batch loss 1.42301166\n",
      "Validated batch 63 batch loss 1.26600718\n",
      "Validated batch 64 batch loss 1.40168548\n",
      "Validated batch 65 batch loss 1.1409471\n",
      "Validated batch 66 batch loss 1.26477528\n",
      "Validated batch 67 batch loss 1.2740593\n",
      "Validated batch 68 batch loss 1.32334542\n",
      "Validated batch 69 batch loss 1.46913981\n",
      "Validated batch 70 batch loss 1.2854929\n",
      "Validated batch 71 batch loss 1.22259915\n",
      "Validated batch 72 batch loss 1.29921722\n",
      "Validated batch 73 batch loss 1.24435651\n",
      "Validated batch 74 batch loss 1.25569832\n",
      "Validated batch 75 batch loss 1.30427718\n",
      "Validated batch 76 batch loss 1.35700595\n",
      "Validated batch 77 batch loss 1.26049542\n",
      "Validated batch 78 batch loss 1.33781564\n",
      "Validated batch 79 batch loss 1.30765247\n",
      "Validated batch 80 batch loss 1.36897\n",
      "Validated batch 81 batch loss 1.33561575\n",
      "Validated batch 82 batch loss 1.26847756\n",
      "Validated batch 83 batch loss 1.24413633\n",
      "Validated batch 84 batch loss 1.3560828\n",
      "Validated batch 85 batch loss 1.26860607\n",
      "Validated batch 86 batch loss 1.46358252\n",
      "Validated batch 87 batch loss 1.30224216\n",
      "Validated batch 88 batch loss 1.26192725\n",
      "Validated batch 89 batch loss 1.3591727\n",
      "Validated batch 90 batch loss 1.30469358\n",
      "Validated batch 91 batch loss 1.24822903\n",
      "Validated batch 92 batch loss 1.3252188\n",
      "Validated batch 93 batch loss 1.34739041\n",
      "Validated batch 94 batch loss 1.30577755\n",
      "Validated batch 95 batch loss 1.27551854\n",
      "Validated batch 96 batch loss 1.26238692\n",
      "Validated batch 97 batch loss 1.32023931\n",
      "Validated batch 98 batch loss 1.44949293\n",
      "Validated batch 99 batch loss 1.22968221\n",
      "Validated batch 100 batch loss 1.34246397\n",
      "Validated batch 101 batch loss 1.31490564\n",
      "Validated batch 102 batch loss 1.35805023\n",
      "Validated batch 103 batch loss 1.30202675\n",
      "Validated batch 104 batch loss 1.21028948\n",
      "Validated batch 105 batch loss 1.38388908\n",
      "Validated batch 106 batch loss 1.34400845\n",
      "Validated batch 107 batch loss 1.34425223\n",
      "Validated batch 108 batch loss 1.31560087\n",
      "Validated batch 109 batch loss 1.34132099\n",
      "Validated batch 110 batch loss 1.21790159\n",
      "Validated batch 111 batch loss 1.26601839\n",
      "Validated batch 112 batch loss 1.3094126\n",
      "Validated batch 113 batch loss 1.22185433\n",
      "Validated batch 114 batch loss 1.33652472\n",
      "Validated batch 115 batch loss 1.29561985\n",
      "Validated batch 116 batch loss 1.47459042\n",
      "Validated batch 117 batch loss 1.29256821\n",
      "Validated batch 118 batch loss 1.28672552\n",
      "Validated batch 119 batch loss 1.29541636\n",
      "Validated batch 120 batch loss 1.23367238\n",
      "Validated batch 121 batch loss 1.34408581\n",
      "Validated batch 122 batch loss 1.30050159\n",
      "Validated batch 123 batch loss 1.2406919\n",
      "Validated batch 124 batch loss 1.2558136\n",
      "Validated batch 125 batch loss 1.30933905\n",
      "Validated batch 126 batch loss 1.32930493\n",
      "Validated batch 127 batch loss 1.35783339\n",
      "Validated batch 128 batch loss 1.3305558\n",
      "Validated batch 129 batch loss 1.21982014\n",
      "Validated batch 130 batch loss 1.26990902\n",
      "Validated batch 131 batch loss 1.31447101\n",
      "Validated batch 132 batch loss 1.31170392\n",
      "Validated batch 133 batch loss 1.35331559\n",
      "Validated batch 134 batch loss 1.3956399\n",
      "Validated batch 135 batch loss 1.50840127\n",
      "Validated batch 136 batch loss 1.44397318\n",
      "Validated batch 137 batch loss 1.30808449\n",
      "Validated batch 138 batch loss 1.23944175\n",
      "Validated batch 139 batch loss 1.15928793\n",
      "Validated batch 140 batch loss 1.31100798\n",
      "Validated batch 141 batch loss 1.37590933\n",
      "Validated batch 142 batch loss 1.2893405\n",
      "Validated batch 143 batch loss 1.35100901\n",
      "Validated batch 144 batch loss 1.45828164\n",
      "Validated batch 145 batch loss 1.19341564\n",
      "Validated batch 146 batch loss 1.322644\n",
      "Validated batch 147 batch loss 1.26727509\n",
      "Validated batch 148 batch loss 1.33217132\n",
      "Validated batch 149 batch loss 1.35913277\n",
      "Validated batch 150 batch loss 1.25353777\n",
      "Validated batch 151 batch loss 1.07124734\n",
      "Validated batch 152 batch loss 1.34867465\n",
      "Validated batch 153 batch loss 1.28222728\n",
      "Validated batch 154 batch loss 1.29719889\n",
      "Validated batch 155 batch loss 1.35674691\n",
      "Validated batch 156 batch loss 1.23448753\n",
      "Validated batch 157 batch loss 1.33993471\n",
      "Validated batch 158 batch loss 1.37932467\n",
      "Validated batch 159 batch loss 1.33594036\n",
      "Validated batch 160 batch loss 1.32144797\n",
      "Validated batch 161 batch loss 1.21771574\n",
      "Validated batch 162 batch loss 1.2891984\n",
      "Validated batch 163 batch loss 1.36868238\n",
      "Validated batch 164 batch loss 1.25558972\n",
      "Validated batch 165 batch loss 1.27952087\n",
      "Validated batch 166 batch loss 1.35272133\n",
      "Validated batch 167 batch loss 1.2959621\n",
      "Validated batch 168 batch loss 1.28548789\n",
      "Validated batch 169 batch loss 1.23336768\n",
      "Validated batch 170 batch loss 1.21964538\n",
      "Validated batch 171 batch loss 1.42355728\n",
      "Validated batch 172 batch loss 1.27253819\n",
      "Validated batch 173 batch loss 1.18950045\n",
      "Validated batch 174 batch loss 1.26010311\n",
      "Validated batch 175 batch loss 1.40317428\n",
      "Validated batch 176 batch loss 1.38458788\n",
      "Validated batch 177 batch loss 1.40559459\n",
      "Validated batch 178 batch loss 1.28515279\n",
      "Validated batch 179 batch loss 1.45251012\n",
      "Validated batch 180 batch loss 1.31812441\n",
      "Validated batch 181 batch loss 1.34865355\n",
      "Validated batch 182 batch loss 1.35426629\n",
      "Validated batch 183 batch loss 1.12895036\n",
      "Validated batch 184 batch loss 1.2282182\n",
      "Validated batch 185 batch loss 1.4188782\n",
      "Epoch 2 val loss 1.3109793663024902\n",
      "Model /aiffel/aiffel/mpii/models1/stacked_hourglass-epoch-2-loss-1.3110.h5 saved.\n",
      "Start epoch 3 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 1.36612618 epoch total loss 1.36612618\n",
      "Trained batch 2 batch loss 1.25102854 epoch total loss 1.3085773\n",
      "Trained batch 3 batch loss 1.42639613 epoch total loss 1.3478502\n",
      "Trained batch 4 batch loss 1.24715877 epoch total loss 1.32267737\n",
      "Trained batch 5 batch loss 1.2999233 epoch total loss 1.31812656\n",
      "Trained batch 6 batch loss 1.24694848 epoch total loss 1.30626357\n",
      "Trained batch 7 batch loss 1.25021744 epoch total loss 1.29825699\n",
      "Trained batch 8 batch loss 1.26002908 epoch total loss 1.29347849\n",
      "Trained batch 9 batch loss 1.37630081 epoch total loss 1.30268097\n",
      "Trained batch 10 batch loss 1.31119585 epoch total loss 1.30353236\n",
      "Trained batch 11 batch loss 1.40804231 epoch total loss 1.31303322\n",
      "Trained batch 12 batch loss 1.4689635 epoch total loss 1.32602751\n",
      "Trained batch 13 batch loss 1.33535814 epoch total loss 1.32674527\n",
      "Trained batch 14 batch loss 1.34655118 epoch total loss 1.32816\n",
      "Trained batch 15 batch loss 1.34559488 epoch total loss 1.32932234\n",
      "Trained batch 16 batch loss 1.35270417 epoch total loss 1.33078372\n",
      "Trained batch 17 batch loss 1.38129807 epoch total loss 1.33375514\n",
      "Trained batch 18 batch loss 1.22212446 epoch total loss 1.32755339\n",
      "Trained batch 19 batch loss 1.279351 epoch total loss 1.32501638\n",
      "Trained batch 20 batch loss 1.20853496 epoch total loss 1.31919229\n",
      "Trained batch 21 batch loss 1.20521951 epoch total loss 1.31376505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 22 batch loss 1.25738406 epoch total loss 1.31120217\n",
      "Trained batch 23 batch loss 1.22474718 epoch total loss 1.30744326\n",
      "Trained batch 24 batch loss 1.1529367 epoch total loss 1.30100548\n",
      "Trained batch 25 batch loss 1.16026521 epoch total loss 1.29537594\n",
      "Trained batch 26 batch loss 1.37142777 epoch total loss 1.2983011\n",
      "Trained batch 27 batch loss 1.37928772 epoch total loss 1.30130064\n",
      "Trained batch 28 batch loss 1.32088161 epoch total loss 1.30199993\n",
      "Trained batch 29 batch loss 1.29089785 epoch total loss 1.30161703\n",
      "Trained batch 30 batch loss 1.35418844 epoch total loss 1.3033694\n",
      "Trained batch 31 batch loss 1.37468338 epoch total loss 1.3056699\n",
      "Trained batch 32 batch loss 1.42329311 epoch total loss 1.3093456\n",
      "Trained batch 33 batch loss 1.30289972 epoch total loss 1.30915022\n",
      "Trained batch 34 batch loss 1.32310486 epoch total loss 1.30956066\n",
      "Trained batch 35 batch loss 1.2577579 epoch total loss 1.30808067\n",
      "Trained batch 36 batch loss 1.28653383 epoch total loss 1.30748212\n",
      "Trained batch 37 batch loss 1.15812278 epoch total loss 1.30344534\n",
      "Trained batch 38 batch loss 1.2441237 epoch total loss 1.30188429\n",
      "Trained batch 39 batch loss 1.32257056 epoch total loss 1.30241477\n",
      "Trained batch 40 batch loss 1.29015565 epoch total loss 1.30210829\n",
      "Trained batch 41 batch loss 1.23496366 epoch total loss 1.30047059\n",
      "Trained batch 42 batch loss 1.21691918 epoch total loss 1.29848123\n",
      "Trained batch 43 batch loss 1.25229239 epoch total loss 1.29740715\n",
      "Trained batch 44 batch loss 1.34258747 epoch total loss 1.2984339\n",
      "Trained batch 45 batch loss 1.22028077 epoch total loss 1.29669714\n",
      "Trained batch 46 batch loss 1.29726219 epoch total loss 1.29670942\n",
      "Trained batch 47 batch loss 1.1411742 epoch total loss 1.29340017\n",
      "Trained batch 48 batch loss 1.09671032 epoch total loss 1.28930247\n",
      "Trained batch 49 batch loss 1.22415745 epoch total loss 1.28797305\n",
      "Trained batch 50 batch loss 1.56506753 epoch total loss 1.29351497\n",
      "Trained batch 51 batch loss 1.47962093 epoch total loss 1.2971642\n",
      "Trained batch 52 batch loss 1.31687689 epoch total loss 1.29754329\n",
      "Trained batch 53 batch loss 1.26423037 epoch total loss 1.2969147\n",
      "Trained batch 54 batch loss 1.4019407 epoch total loss 1.2988596\n",
      "Trained batch 55 batch loss 1.19112027 epoch total loss 1.29690075\n",
      "Trained batch 56 batch loss 1.21707368 epoch total loss 1.29547524\n",
      "Trained batch 57 batch loss 1.2402 epoch total loss 1.2945056\n",
      "Trained batch 58 batch loss 1.30282903 epoch total loss 1.294649\n",
      "Trained batch 59 batch loss 1.35313964 epoch total loss 1.29564047\n",
      "Trained batch 60 batch loss 1.26128221 epoch total loss 1.29506791\n",
      "Trained batch 61 batch loss 1.35873365 epoch total loss 1.29611158\n",
      "Trained batch 62 batch loss 1.22907448 epoch total loss 1.29503024\n",
      "Trained batch 63 batch loss 1.22785711 epoch total loss 1.29396403\n",
      "Trained batch 64 batch loss 1.25187409 epoch total loss 1.29330647\n",
      "Trained batch 65 batch loss 1.28367698 epoch total loss 1.29315829\n",
      "Trained batch 66 batch loss 1.3360678 epoch total loss 1.29380846\n",
      "Trained batch 67 batch loss 1.26348829 epoch total loss 1.29335594\n",
      "Trained batch 68 batch loss 1.22786832 epoch total loss 1.29239285\n",
      "Trained batch 69 batch loss 1.24380517 epoch total loss 1.29168868\n",
      "Trained batch 70 batch loss 1.26741982 epoch total loss 1.2913419\n",
      "Trained batch 71 batch loss 1.40019476 epoch total loss 1.29287505\n",
      "Trained batch 72 batch loss 1.35288322 epoch total loss 1.29370844\n",
      "Trained batch 73 batch loss 1.26531577 epoch total loss 1.29331946\n",
      "Trained batch 74 batch loss 1.35356975 epoch total loss 1.29413366\n",
      "Trained batch 75 batch loss 1.17327857 epoch total loss 1.29252231\n",
      "Trained batch 76 batch loss 1.24076807 epoch total loss 1.29184127\n",
      "Trained batch 77 batch loss 1.32187104 epoch total loss 1.29223132\n",
      "Trained batch 78 batch loss 1.23080158 epoch total loss 1.29144371\n",
      "Trained batch 79 batch loss 1.21782207 epoch total loss 1.29051185\n",
      "Trained batch 80 batch loss 1.40635216 epoch total loss 1.29195976\n",
      "Trained batch 81 batch loss 1.31213367 epoch total loss 1.29220879\n",
      "Trained batch 82 batch loss 1.28968143 epoch total loss 1.29217803\n",
      "Trained batch 83 batch loss 1.37578201 epoch total loss 1.29318535\n",
      "Trained batch 84 batch loss 1.37723386 epoch total loss 1.29418588\n",
      "Trained batch 85 batch loss 1.30714703 epoch total loss 1.29433835\n",
      "Trained batch 86 batch loss 1.26364374 epoch total loss 1.29398143\n",
      "Trained batch 87 batch loss 1.2508949 epoch total loss 1.29348612\n",
      "Trained batch 88 batch loss 1.22704983 epoch total loss 1.29273117\n",
      "Trained batch 89 batch loss 1.29898024 epoch total loss 1.29280138\n",
      "Trained batch 90 batch loss 1.28471494 epoch total loss 1.2927115\n",
      "Trained batch 91 batch loss 1.16997409 epoch total loss 1.29136276\n",
      "Trained batch 92 batch loss 1.27346432 epoch total loss 1.29116833\n",
      "Trained batch 93 batch loss 1.27353287 epoch total loss 1.29097867\n",
      "Trained batch 94 batch loss 1.26076746 epoch total loss 1.29065728\n",
      "Trained batch 95 batch loss 1.18680179 epoch total loss 1.28956401\n",
      "Trained batch 96 batch loss 1.23517919 epoch total loss 1.28899753\n",
      "Trained batch 97 batch loss 1.32175469 epoch total loss 1.28933525\n",
      "Trained batch 98 batch loss 1.24357355 epoch total loss 1.28886831\n",
      "Trained batch 99 batch loss 1.28324068 epoch total loss 1.28881145\n",
      "Trained batch 100 batch loss 1.38803673 epoch total loss 1.28980362\n",
      "Trained batch 101 batch loss 1.29496837 epoch total loss 1.28985476\n",
      "Trained batch 102 batch loss 1.24113882 epoch total loss 1.28937709\n",
      "Trained batch 103 batch loss 1.40211058 epoch total loss 1.29047167\n",
      "Trained batch 104 batch loss 1.25592911 epoch total loss 1.29013956\n",
      "Trained batch 105 batch loss 1.36257279 epoch total loss 1.29082942\n",
      "Trained batch 106 batch loss 1.25204122 epoch total loss 1.29046357\n",
      "Trained batch 107 batch loss 1.22642159 epoch total loss 1.28986514\n",
      "Trained batch 108 batch loss 1.30386305 epoch total loss 1.28999472\n",
      "Trained batch 109 batch loss 1.0507195 epoch total loss 1.28779948\n",
      "Trained batch 110 batch loss 1.23883128 epoch total loss 1.28735435\n",
      "Trained batch 111 batch loss 1.35376549 epoch total loss 1.28795254\n",
      "Trained batch 112 batch loss 1.24686658 epoch total loss 1.28758585\n",
      "Trained batch 113 batch loss 1.33928418 epoch total loss 1.28804326\n",
      "Trained batch 114 batch loss 1.38546598 epoch total loss 1.28889787\n",
      "Trained batch 115 batch loss 1.31487608 epoch total loss 1.28912377\n",
      "Trained batch 116 batch loss 1.26621652 epoch total loss 1.28892636\n",
      "Trained batch 117 batch loss 1.20373797 epoch total loss 1.28819823\n",
      "Trained batch 118 batch loss 1.27918231 epoch total loss 1.2881217\n",
      "Trained batch 119 batch loss 1.26511645 epoch total loss 1.28792846\n",
      "Trained batch 120 batch loss 1.25191951 epoch total loss 1.28762841\n",
      "Trained batch 121 batch loss 1.34488273 epoch total loss 1.28810155\n",
      "Trained batch 122 batch loss 1.43008149 epoch total loss 1.28926539\n",
      "Trained batch 123 batch loss 1.35341668 epoch total loss 1.28978693\n",
      "Trained batch 124 batch loss 1.43313193 epoch total loss 1.29094303\n",
      "Trained batch 125 batch loss 1.2906369 epoch total loss 1.29094052\n",
      "Trained batch 126 batch loss 1.43188727 epoch total loss 1.29205918\n",
      "Trained batch 127 batch loss 1.37636662 epoch total loss 1.29272306\n",
      "Trained batch 128 batch loss 1.41421974 epoch total loss 1.2936722\n",
      "Trained batch 129 batch loss 1.34016502 epoch total loss 1.29403257\n",
      "Trained batch 130 batch loss 1.24312496 epoch total loss 1.29364097\n",
      "Trained batch 131 batch loss 1.1155771 epoch total loss 1.29228163\n",
      "Trained batch 132 batch loss 1.07828486 epoch total loss 1.29066038\n",
      "Trained batch 133 batch loss 1.14474285 epoch total loss 1.2895633\n",
      "Trained batch 134 batch loss 1.43638253 epoch total loss 1.29065895\n",
      "Trained batch 135 batch loss 1.6125977 epoch total loss 1.29304373\n",
      "Trained batch 136 batch loss 1.44265366 epoch total loss 1.2941438\n",
      "Trained batch 137 batch loss 1.4383173 epoch total loss 1.29519618\n",
      "Trained batch 138 batch loss 1.18424332 epoch total loss 1.29439223\n",
      "Trained batch 139 batch loss 1.381675 epoch total loss 1.2950201\n",
      "Trained batch 140 batch loss 1.35592413 epoch total loss 1.29545522\n",
      "Trained batch 141 batch loss 1.36344242 epoch total loss 1.29593742\n",
      "Trained batch 142 batch loss 1.33480179 epoch total loss 1.29621112\n",
      "Trained batch 143 batch loss 1.3931464 epoch total loss 1.29688895\n",
      "Trained batch 144 batch loss 1.35637188 epoch total loss 1.29730201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 145 batch loss 1.29411101 epoch total loss 1.29728007\n",
      "Trained batch 146 batch loss 1.31023371 epoch total loss 1.29736876\n",
      "Trained batch 147 batch loss 1.17674327 epoch total loss 1.29654813\n",
      "Trained batch 148 batch loss 1.30740094 epoch total loss 1.29662144\n",
      "Trained batch 149 batch loss 1.27170444 epoch total loss 1.29645419\n",
      "Trained batch 150 batch loss 1.25497675 epoch total loss 1.29617763\n",
      "Trained batch 151 batch loss 1.23673463 epoch total loss 1.295784\n",
      "Trained batch 152 batch loss 1.17828691 epoch total loss 1.29501104\n",
      "Trained batch 153 batch loss 1.34456515 epoch total loss 1.29533482\n",
      "Trained batch 154 batch loss 1.21729589 epoch total loss 1.29482818\n",
      "Trained batch 155 batch loss 1.24457836 epoch total loss 1.29450393\n",
      "Trained batch 156 batch loss 1.3063 epoch total loss 1.29457963\n",
      "Trained batch 157 batch loss 1.24486613 epoch total loss 1.29426301\n",
      "Trained batch 158 batch loss 1.14564466 epoch total loss 1.29332244\n",
      "Trained batch 159 batch loss 1.41066611 epoch total loss 1.29406035\n",
      "Trained batch 160 batch loss 1.4065212 epoch total loss 1.29476333\n",
      "Trained batch 161 batch loss 1.25489438 epoch total loss 1.29451561\n",
      "Trained batch 162 batch loss 1.1509316 epoch total loss 1.29362929\n",
      "Trained batch 163 batch loss 1.11244738 epoch total loss 1.29251778\n",
      "Trained batch 164 batch loss 1.16509736 epoch total loss 1.29174078\n",
      "Trained batch 165 batch loss 1.0785532 epoch total loss 1.29044878\n",
      "Trained batch 166 batch loss 1.20353818 epoch total loss 1.28992522\n",
      "Trained batch 167 batch loss 1.15905511 epoch total loss 1.28914154\n",
      "Trained batch 168 batch loss 1.21317637 epoch total loss 1.28868937\n",
      "Trained batch 169 batch loss 1.14764524 epoch total loss 1.28785479\n",
      "Trained batch 170 batch loss 1.23133886 epoch total loss 1.28752232\n",
      "Trained batch 171 batch loss 1.37715554 epoch total loss 1.28804648\n",
      "Trained batch 172 batch loss 1.33084869 epoch total loss 1.28829527\n",
      "Trained batch 173 batch loss 1.23043883 epoch total loss 1.28796089\n",
      "Trained batch 174 batch loss 1.31623459 epoch total loss 1.28812337\n",
      "Trained batch 175 batch loss 1.32939947 epoch total loss 1.28835928\n",
      "Trained batch 176 batch loss 1.3628161 epoch total loss 1.28878236\n",
      "Trained batch 177 batch loss 1.34194171 epoch total loss 1.28908265\n",
      "Trained batch 178 batch loss 1.41426063 epoch total loss 1.28978586\n",
      "Trained batch 179 batch loss 1.46198952 epoch total loss 1.290748\n",
      "Trained batch 180 batch loss 1.319525 epoch total loss 1.29090774\n",
      "Trained batch 181 batch loss 1.46505368 epoch total loss 1.29187\n",
      "Trained batch 182 batch loss 1.31785619 epoch total loss 1.29201269\n",
      "Trained batch 183 batch loss 1.38399291 epoch total loss 1.29251528\n",
      "Trained batch 184 batch loss 1.33276629 epoch total loss 1.29273403\n",
      "Trained batch 185 batch loss 1.29505646 epoch total loss 1.29274666\n",
      "Trained batch 186 batch loss 1.2330035 epoch total loss 1.29242539\n",
      "Trained batch 187 batch loss 1.21850085 epoch total loss 1.2920301\n",
      "Trained batch 188 batch loss 1.32252 epoch total loss 1.29219234\n",
      "Trained batch 189 batch loss 1.36956751 epoch total loss 1.2926017\n",
      "Trained batch 190 batch loss 1.41376138 epoch total loss 1.29323936\n",
      "Trained batch 191 batch loss 1.21580935 epoch total loss 1.29283392\n",
      "Trained batch 192 batch loss 1.23553324 epoch total loss 1.29253554\n",
      "Trained batch 193 batch loss 1.31675863 epoch total loss 1.29266107\n",
      "Trained batch 194 batch loss 1.22391057 epoch total loss 1.29230666\n",
      "Trained batch 195 batch loss 1.28142774 epoch total loss 1.29225087\n",
      "Trained batch 196 batch loss 1.18130946 epoch total loss 1.29168487\n",
      "Trained batch 197 batch loss 1.25880492 epoch total loss 1.29151797\n",
      "Trained batch 198 batch loss 1.28986466 epoch total loss 1.29150963\n",
      "Trained batch 199 batch loss 1.21732891 epoch total loss 1.29113674\n",
      "Trained batch 200 batch loss 1.34451687 epoch total loss 1.29140365\n",
      "Trained batch 201 batch loss 1.33493876 epoch total loss 1.29162025\n",
      "Trained batch 202 batch loss 1.30607784 epoch total loss 1.2916919\n",
      "Trained batch 203 batch loss 1.3291986 epoch total loss 1.29187655\n",
      "Trained batch 204 batch loss 1.39147508 epoch total loss 1.29236484\n",
      "Trained batch 205 batch loss 1.25299466 epoch total loss 1.29217279\n",
      "Trained batch 206 batch loss 1.36090577 epoch total loss 1.29250634\n",
      "Trained batch 207 batch loss 1.33277011 epoch total loss 1.29270089\n",
      "Trained batch 208 batch loss 1.22420728 epoch total loss 1.29237163\n",
      "Trained batch 209 batch loss 1.18174875 epoch total loss 1.29184234\n",
      "Trained batch 210 batch loss 1.24771392 epoch total loss 1.29163218\n",
      "Trained batch 211 batch loss 1.32376194 epoch total loss 1.29178452\n",
      "Trained batch 212 batch loss 1.50093424 epoch total loss 1.2927711\n",
      "Trained batch 213 batch loss 1.33584797 epoch total loss 1.29297328\n",
      "Trained batch 214 batch loss 1.3668896 epoch total loss 1.29331875\n",
      "Trained batch 215 batch loss 1.17158031 epoch total loss 1.29275239\n",
      "Trained batch 216 batch loss 1.36979461 epoch total loss 1.29310906\n",
      "Trained batch 217 batch loss 1.36377919 epoch total loss 1.29343462\n",
      "Trained batch 218 batch loss 1.4434 epoch total loss 1.29412258\n",
      "Trained batch 219 batch loss 1.40592682 epoch total loss 1.29463303\n",
      "Trained batch 220 batch loss 1.41259742 epoch total loss 1.29516923\n",
      "Trained batch 221 batch loss 1.296193 epoch total loss 1.29517388\n",
      "Trained batch 222 batch loss 1.23098457 epoch total loss 1.2948848\n",
      "Trained batch 223 batch loss 1.33878696 epoch total loss 1.29508162\n",
      "Trained batch 224 batch loss 1.27830446 epoch total loss 1.29500663\n",
      "Trained batch 225 batch loss 1.22822487 epoch total loss 1.2947098\n",
      "Trained batch 226 batch loss 1.27645648 epoch total loss 1.29462898\n",
      "Trained batch 227 batch loss 1.38971376 epoch total loss 1.29504788\n",
      "Trained batch 228 batch loss 1.32311475 epoch total loss 1.29517102\n",
      "Trained batch 229 batch loss 1.28013301 epoch total loss 1.29510522\n",
      "Trained batch 230 batch loss 1.33175135 epoch total loss 1.2952646\n",
      "Trained batch 231 batch loss 1.25259233 epoch total loss 1.29507983\n",
      "Trained batch 232 batch loss 1.22130013 epoch total loss 1.2947619\n",
      "Trained batch 233 batch loss 1.26413941 epoch total loss 1.29463041\n",
      "Trained batch 234 batch loss 1.28711748 epoch total loss 1.29459834\n",
      "Trained batch 235 batch loss 1.20865178 epoch total loss 1.29423261\n",
      "Trained batch 236 batch loss 1.17303371 epoch total loss 1.29371905\n",
      "Trained batch 237 batch loss 1.22703838 epoch total loss 1.29343772\n",
      "Trained batch 238 batch loss 1.30752015 epoch total loss 1.29349697\n",
      "Trained batch 239 batch loss 1.25674009 epoch total loss 1.29334319\n",
      "Trained batch 240 batch loss 1.3769238 epoch total loss 1.2936914\n",
      "Trained batch 241 batch loss 1.42434335 epoch total loss 1.29423356\n",
      "Trained batch 242 batch loss 1.37355185 epoch total loss 1.29456139\n",
      "Trained batch 243 batch loss 1.36988342 epoch total loss 1.29487121\n",
      "Trained batch 244 batch loss 1.54166031 epoch total loss 1.2958827\n",
      "Trained batch 245 batch loss 1.51540887 epoch total loss 1.29677868\n",
      "Trained batch 246 batch loss 1.2384572 epoch total loss 1.29654169\n",
      "Trained batch 247 batch loss 1.21736205 epoch total loss 1.29622114\n",
      "Trained batch 248 batch loss 1.13231623 epoch total loss 1.29556024\n",
      "Trained batch 249 batch loss 1.1051079 epoch total loss 1.29479539\n",
      "Trained batch 250 batch loss 1.23093545 epoch total loss 1.29453993\n",
      "Trained batch 251 batch loss 1.14825797 epoch total loss 1.29395711\n",
      "Trained batch 252 batch loss 1.06083381 epoch total loss 1.29303193\n",
      "Trained batch 253 batch loss 1.02251124 epoch total loss 1.29196274\n",
      "Trained batch 254 batch loss 1.1463213 epoch total loss 1.29138935\n",
      "Trained batch 255 batch loss 1.16633487 epoch total loss 1.29089892\n",
      "Trained batch 256 batch loss 1.24295163 epoch total loss 1.29071164\n",
      "Trained batch 257 batch loss 1.36716592 epoch total loss 1.29100907\n",
      "Trained batch 258 batch loss 1.27851069 epoch total loss 1.29096067\n",
      "Trained batch 259 batch loss 1.41195381 epoch total loss 1.29142773\n",
      "Trained batch 260 batch loss 1.37114716 epoch total loss 1.29173446\n",
      "Trained batch 261 batch loss 1.38830042 epoch total loss 1.29210448\n",
      "Trained batch 262 batch loss 1.22600877 epoch total loss 1.29185224\n",
      "Trained batch 263 batch loss 1.20249832 epoch total loss 1.29151237\n",
      "Trained batch 264 batch loss 1.0703429 epoch total loss 1.29067457\n",
      "Trained batch 265 batch loss 1.17466009 epoch total loss 1.29023683\n",
      "Trained batch 266 batch loss 1.22269499 epoch total loss 1.2899828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 267 batch loss 1.20121896 epoch total loss 1.28965044\n",
      "Trained batch 268 batch loss 1.28955019 epoch total loss 1.28965008\n",
      "Trained batch 269 batch loss 1.31913805 epoch total loss 1.28975976\n",
      "Trained batch 270 batch loss 1.25436282 epoch total loss 1.28962862\n",
      "Trained batch 271 batch loss 1.38369596 epoch total loss 1.28997576\n",
      "Trained batch 272 batch loss 1.29131508 epoch total loss 1.28998077\n",
      "Trained batch 273 batch loss 1.42609656 epoch total loss 1.2904793\n",
      "Trained batch 274 batch loss 1.23749423 epoch total loss 1.29028583\n",
      "Trained batch 275 batch loss 1.20483661 epoch total loss 1.28997517\n",
      "Trained batch 276 batch loss 1.22849 epoch total loss 1.28975236\n",
      "Trained batch 277 batch loss 1.34565055 epoch total loss 1.28995407\n",
      "Trained batch 278 batch loss 1.36408329 epoch total loss 1.29022074\n",
      "Trained batch 279 batch loss 1.46084499 epoch total loss 1.29083228\n",
      "Trained batch 280 batch loss 1.3178817 epoch total loss 1.29092884\n",
      "Trained batch 281 batch loss 1.23370361 epoch total loss 1.29072523\n",
      "Trained batch 282 batch loss 1.22131479 epoch total loss 1.29047906\n",
      "Trained batch 283 batch loss 1.35486126 epoch total loss 1.29070652\n",
      "Trained batch 284 batch loss 1.27706373 epoch total loss 1.29065859\n",
      "Trained batch 285 batch loss 1.31660581 epoch total loss 1.29074967\n",
      "Trained batch 286 batch loss 1.31068838 epoch total loss 1.29081941\n",
      "Trained batch 287 batch loss 1.32141423 epoch total loss 1.29092598\n",
      "Trained batch 288 batch loss 1.21320808 epoch total loss 1.29065609\n",
      "Trained batch 289 batch loss 1.33541989 epoch total loss 1.29081094\n",
      "Trained batch 290 batch loss 1.26677966 epoch total loss 1.29072809\n",
      "Trained batch 291 batch loss 1.17415643 epoch total loss 1.29032755\n",
      "Trained batch 292 batch loss 1.25668931 epoch total loss 1.29021239\n",
      "Trained batch 293 batch loss 1.3634007 epoch total loss 1.29046214\n",
      "Trained batch 294 batch loss 1.37312627 epoch total loss 1.29074335\n",
      "Trained batch 295 batch loss 1.36129892 epoch total loss 1.29098248\n",
      "Trained batch 296 batch loss 1.30507815 epoch total loss 1.29103017\n",
      "Trained batch 297 batch loss 1.32263315 epoch total loss 1.29113662\n",
      "Trained batch 298 batch loss 1.38923442 epoch total loss 1.29146576\n",
      "Trained batch 299 batch loss 1.30726278 epoch total loss 1.29151845\n",
      "Trained batch 300 batch loss 1.22530568 epoch total loss 1.29129779\n",
      "Trained batch 301 batch loss 1.21961224 epoch total loss 1.29105961\n",
      "Trained batch 302 batch loss 1.22068858 epoch total loss 1.29082668\n",
      "Trained batch 303 batch loss 1.3428427 epoch total loss 1.29099834\n",
      "Trained batch 304 batch loss 1.32030523 epoch total loss 1.29109478\n",
      "Trained batch 305 batch loss 1.25383639 epoch total loss 1.29097259\n",
      "Trained batch 306 batch loss 1.29743242 epoch total loss 1.29099369\n",
      "Trained batch 307 batch loss 1.20151448 epoch total loss 1.29070222\n",
      "Trained batch 308 batch loss 1.24337089 epoch total loss 1.29054856\n",
      "Trained batch 309 batch loss 1.27084339 epoch total loss 1.29048479\n",
      "Trained batch 310 batch loss 1.27778625 epoch total loss 1.2904439\n",
      "Trained batch 311 batch loss 1.36469579 epoch total loss 1.29068255\n",
      "Trained batch 312 batch loss 1.26649523 epoch total loss 1.29060507\n",
      "Trained batch 313 batch loss 1.22970653 epoch total loss 1.29041052\n",
      "Trained batch 314 batch loss 1.22941363 epoch total loss 1.29021621\n",
      "Trained batch 315 batch loss 1.32291865 epoch total loss 1.29032\n",
      "Trained batch 316 batch loss 1.33072758 epoch total loss 1.29044783\n",
      "Trained batch 317 batch loss 1.349213 epoch total loss 1.2906332\n",
      "Trained batch 318 batch loss 1.32423091 epoch total loss 1.29073882\n",
      "Trained batch 319 batch loss 1.27144325 epoch total loss 1.29067838\n",
      "Trained batch 320 batch loss 1.25829732 epoch total loss 1.29057717\n",
      "Trained batch 321 batch loss 1.15175867 epoch total loss 1.2901448\n",
      "Trained batch 322 batch loss 1.28980434 epoch total loss 1.29014373\n",
      "Trained batch 323 batch loss 1.26096356 epoch total loss 1.29005337\n",
      "Trained batch 324 batch loss 1.28597271 epoch total loss 1.29004073\n",
      "Trained batch 325 batch loss 1.23685682 epoch total loss 1.28987706\n",
      "Trained batch 326 batch loss 1.25101912 epoch total loss 1.28975785\n",
      "Trained batch 327 batch loss 1.22922075 epoch total loss 1.28957272\n",
      "Trained batch 328 batch loss 1.28308368 epoch total loss 1.28955293\n",
      "Trained batch 329 batch loss 1.22285485 epoch total loss 1.28935027\n",
      "Trained batch 330 batch loss 1.25752962 epoch total loss 1.28925383\n",
      "Trained batch 331 batch loss 1.12659442 epoch total loss 1.28876245\n",
      "Trained batch 332 batch loss 1.1428225 epoch total loss 1.28832281\n",
      "Trained batch 333 batch loss 1.2264924 epoch total loss 1.2881372\n",
      "Trained batch 334 batch loss 1.15383196 epoch total loss 1.2877351\n",
      "Trained batch 335 batch loss 1.22560871 epoch total loss 1.28754961\n",
      "Trained batch 336 batch loss 1.12358677 epoch total loss 1.28706169\n",
      "Trained batch 337 batch loss 1.16711426 epoch total loss 1.28670573\n",
      "Trained batch 338 batch loss 1.18081009 epoch total loss 1.28639245\n",
      "Trained batch 339 batch loss 1.44904733 epoch total loss 1.28687227\n",
      "Trained batch 340 batch loss 1.38299966 epoch total loss 1.28715491\n",
      "Trained batch 341 batch loss 1.45875502 epoch total loss 1.2876581\n",
      "Trained batch 342 batch loss 1.30882645 epoch total loss 1.28772008\n",
      "Trained batch 343 batch loss 1.66025352 epoch total loss 1.2888062\n",
      "Trained batch 344 batch loss 1.18517804 epoch total loss 1.28850496\n",
      "Trained batch 345 batch loss 1.39855778 epoch total loss 1.28882396\n",
      "Trained batch 346 batch loss 1.21117854 epoch total loss 1.28859949\n",
      "Trained batch 347 batch loss 1.26933193 epoch total loss 1.28854394\n",
      "Trained batch 348 batch loss 1.20728886 epoch total loss 1.28831041\n",
      "Trained batch 349 batch loss 1.18393576 epoch total loss 1.28801131\n",
      "Trained batch 350 batch loss 1.26216114 epoch total loss 1.2879374\n",
      "Trained batch 351 batch loss 1.27022147 epoch total loss 1.28788698\n",
      "Trained batch 352 batch loss 1.24623239 epoch total loss 1.28776872\n",
      "Trained batch 353 batch loss 1.40328109 epoch total loss 1.28809595\n",
      "Trained batch 354 batch loss 1.32112491 epoch total loss 1.28818929\n",
      "Trained batch 355 batch loss 1.35249424 epoch total loss 1.28837049\n",
      "Trained batch 356 batch loss 1.3476814 epoch total loss 1.28853714\n",
      "Trained batch 357 batch loss 1.33933604 epoch total loss 1.28867936\n",
      "Trained batch 358 batch loss 1.37513709 epoch total loss 1.28892088\n",
      "Trained batch 359 batch loss 1.181633 epoch total loss 1.28862202\n",
      "Trained batch 360 batch loss 1.17498624 epoch total loss 1.28830636\n",
      "Trained batch 361 batch loss 1.24139285 epoch total loss 1.28817642\n",
      "Trained batch 362 batch loss 1.21734381 epoch total loss 1.28798068\n",
      "Trained batch 363 batch loss 1.48061657 epoch total loss 1.2885114\n",
      "Trained batch 364 batch loss 1.37150681 epoch total loss 1.28873944\n",
      "Trained batch 365 batch loss 1.27833104 epoch total loss 1.28871095\n",
      "Trained batch 366 batch loss 1.20715547 epoch total loss 1.28848803\n",
      "Trained batch 367 batch loss 1.35664678 epoch total loss 1.28867388\n",
      "Trained batch 368 batch loss 1.10855842 epoch total loss 1.2881844\n",
      "Trained batch 369 batch loss 1.27621341 epoch total loss 1.28815198\n",
      "Trained batch 370 batch loss 1.2733947 epoch total loss 1.28811204\n",
      "Trained batch 371 batch loss 1.26196992 epoch total loss 1.28804159\n",
      "Trained batch 372 batch loss 1.40062141 epoch total loss 1.28834426\n",
      "Trained batch 381 batch loss 1.29354179 epoch total loss 1.28806388\n",
      "Trained batch 382 batch loss 1.22234535 epoch total loss 1.28789186\n",
      "Trained batch 383 batch loss 1.29844141 epoch total loss 1.28791928\n",
      "Trained batch 384 batch loss 1.41435754 epoch total loss 1.28824866\n",
      "Trained batch 385 batch loss 1.20726025 epoch total loss 1.28803825\n",
      "Trained batch 386 batch loss 1.33454633 epoch total loss 1.28815877\n",
      "Trained batch 387 batch loss 1.23000789 epoch total loss 1.28800845\n",
      "Trained batch 388 batch loss 1.18764746 epoch total loss 1.28774989\n",
      "Trained batch 389 batch loss 1.30779505 epoch total loss 1.28780138\n",
      "Trained batch 390 batch loss 1.27326751 epoch total loss 1.28776407\n",
      "Trained batch 391 batch loss 1.24552965 epoch total loss 1.28765607\n",
      "Trained batch 392 batch loss 1.29795218 epoch total loss 1.28768241\n",
      "Trained batch 393 batch loss 1.37666726 epoch total loss 1.28790879\n",
      "Trained batch 394 batch loss 1.2680366 epoch total loss 1.28785837\n",
      "Trained batch 395 batch loss 1.39133668 epoch total loss 1.28812027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 396 batch loss 1.30220675 epoch total loss 1.28815591\n",
      "Trained batch 397 batch loss 1.30068409 epoch total loss 1.2881875\n",
      "Trained batch 398 batch loss 1.34241235 epoch total loss 1.28832376\n",
      "Trained batch 399 batch loss 1.3983686 epoch total loss 1.28859961\n",
      "Trained batch 400 batch loss 1.39190531 epoch total loss 1.28885794\n",
      "Trained batch 401 batch loss 1.23528194 epoch total loss 1.2887243\n",
      "Trained batch 402 batch loss 1.26964486 epoch total loss 1.28867686\n",
      "Trained batch 403 batch loss 1.34073031 epoch total loss 1.28880608\n",
      "Trained batch 404 batch loss 1.29948664 epoch total loss 1.28883255\n",
      "Trained batch 405 batch loss 1.25128388 epoch total loss 1.2887398\n",
      "Trained batch 406 batch loss 1.3279835 epoch total loss 1.2888366\n",
      "Trained batch 407 batch loss 1.26330543 epoch total loss 1.28877378\n",
      "Trained batch 408 batch loss 1.30446696 epoch total loss 1.28881228\n",
      "Trained batch 409 batch loss 1.28748369 epoch total loss 1.28880894\n",
      "Trained batch 410 batch loss 1.35716128 epoch total loss 1.28897572\n",
      "Trained batch 411 batch loss 1.24044275 epoch total loss 1.28885758\n",
      "Trained batch 412 batch loss 1.29532015 epoch total loss 1.28887331\n",
      "Trained batch 413 batch loss 1.31014371 epoch total loss 1.28892481\n",
      "Trained batch 414 batch loss 1.31307757 epoch total loss 1.28898299\n",
      "Trained batch 415 batch loss 1.26741993 epoch total loss 1.28893101\n",
      "Trained batch 416 batch loss 1.25078833 epoch total loss 1.28883934\n",
      "Trained batch 417 batch loss 1.18464065 epoch total loss 1.28858948\n",
      "Trained batch 418 batch loss 1.32686722 epoch total loss 1.28868091\n",
      "Trained batch 419 batch loss 1.2863307 epoch total loss 1.28867531\n",
      "Trained batch 420 batch loss 1.31335092 epoch total loss 1.28873408\n",
      "Trained batch 421 batch loss 1.35651183 epoch total loss 1.28889501\n",
      "Trained batch 422 batch loss 1.35778463 epoch total loss 1.28905833\n",
      "Trained batch 423 batch loss 1.39487529 epoch total loss 1.28930855\n",
      "Trained batch 424 batch loss 1.36421204 epoch total loss 1.2894851\n",
      "Trained batch 425 batch loss 1.40909958 epoch total loss 1.28976667\n",
      "Trained batch 426 batch loss 1.47149754 epoch total loss 1.2901932\n",
      "Trained batch 427 batch loss 1.31115544 epoch total loss 1.29024231\n",
      "Trained batch 428 batch loss 1.22146261 epoch total loss 1.2900815\n",
      "Trained batch 429 batch loss 1.20007145 epoch total loss 1.28987169\n",
      "Trained batch 430 batch loss 1.36213052 epoch total loss 1.29003978\n",
      "Trained batch 431 batch loss 1.08920252 epoch total loss 1.28957367\n",
      "Trained batch 432 batch loss 1.21258867 epoch total loss 1.28939545\n",
      "Trained batch 433 batch loss 1.26252222 epoch total loss 1.28933346\n",
      "Trained batch 434 batch loss 1.27929 epoch total loss 1.28931034\n",
      "Trained batch 435 batch loss 1.3374536 epoch total loss 1.28942096\n",
      "Trained batch 436 batch loss 1.39870214 epoch total loss 1.28967154\n",
      "Trained batch 437 batch loss 1.48896 epoch total loss 1.29012764\n",
      "Trained batch 438 batch loss 1.47900748 epoch total loss 1.29055882\n",
      "Trained batch 439 batch loss 1.43117404 epoch total loss 1.29087913\n",
      "Trained batch 440 batch loss 1.29473579 epoch total loss 1.29088783\n",
      "Trained batch 441 batch loss 1.24523687 epoch total loss 1.29078436\n",
      "Trained batch 442 batch loss 1.18725705 epoch total loss 1.29055011\n",
      "Trained batch 443 batch loss 1.39592552 epoch total loss 1.29078805\n",
      "Trained batch 444 batch loss 1.32350206 epoch total loss 1.29086161\n",
      "Trained batch 445 batch loss 1.218153 epoch total loss 1.29069829\n",
      "Trained batch 446 batch loss 1.12779379 epoch total loss 1.29033303\n",
      "Trained batch 447 batch loss 1.10756707 epoch total loss 1.28992414\n",
      "Trained batch 448 batch loss 1.16175234 epoch total loss 1.28963792\n",
      "Trained batch 449 batch loss 1.22347319 epoch total loss 1.28949058\n",
      "Trained batch 450 batch loss 1.47967029 epoch total loss 1.28991318\n",
      "Trained batch 451 batch loss 1.5398283 epoch total loss 1.29046738\n",
      "Trained batch 452 batch loss 1.4863466 epoch total loss 1.29090071\n",
      "Trained batch 453 batch loss 1.43303633 epoch total loss 1.29121447\n",
      "Trained batch 454 batch loss 1.49594009 epoch total loss 1.29166532\n",
      "Trained batch 455 batch loss 1.49417579 epoch total loss 1.29211044\n",
      "Trained batch 456 batch loss 1.49108064 epoch total loss 1.29254687\n",
      "Trained batch 457 batch loss 1.55124664 epoch total loss 1.29311299\n",
      "Trained batch 458 batch loss 1.33119559 epoch total loss 1.29319608\n",
      "Trained batch 459 batch loss 1.32864523 epoch total loss 1.29327345\n",
      "Trained batch 460 batch loss 1.26759 epoch total loss 1.29321754\n",
      "Trained batch 461 batch loss 1.22045434 epoch total loss 1.29305971\n",
      "Trained batch 462 batch loss 1.34776115 epoch total loss 1.2931782\n",
      "Trained batch 463 batch loss 1.26020169 epoch total loss 1.29310691\n",
      "Trained batch 464 batch loss 1.3375572 epoch total loss 1.29320276\n",
      "Trained batch 465 batch loss 1.34386933 epoch total loss 1.29331172\n",
      "Trained batch 466 batch loss 1.38093925 epoch total loss 1.29349971\n",
      "Trained batch 467 batch loss 1.46097 epoch total loss 1.29385841\n",
      "Trained batch 468 batch loss 1.38325644 epoch total loss 1.29404938\n",
      "Trained batch 469 batch loss 1.35547471 epoch total loss 1.29418039\n",
      "Trained batch 470 batch loss 1.29534888 epoch total loss 1.29418278\n",
      "Trained batch 471 batch loss 1.25480819 epoch total loss 1.29409921\n",
      "Trained batch 472 batch loss 1.29288471 epoch total loss 1.29409671\n",
      "Trained batch 473 batch loss 1.30320835 epoch total loss 1.29411602\n",
      "Trained batch 474 batch loss 1.18911576 epoch total loss 1.29389441\n",
      "Trained batch 475 batch loss 1.22416961 epoch total loss 1.29374766\n",
      "Trained batch 476 batch loss 1.22183132 epoch total loss 1.29359651\n",
      "Trained batch 477 batch loss 1.29777765 epoch total loss 1.29360533\n",
      "Trained batch 478 batch loss 1.20992208 epoch total loss 1.29343021\n",
      "Trained batch 479 batch loss 1.31085801 epoch total loss 1.29346657\n",
      "Trained batch 480 batch loss 1.33961046 epoch total loss 1.29356265\n",
      "Trained batch 481 batch loss 1.39682353 epoch total loss 1.29377747\n",
      "Trained batch 482 batch loss 1.47071075 epoch total loss 1.29414451\n",
      "Trained batch 483 batch loss 1.40210462 epoch total loss 1.29436803\n",
      "Trained batch 484 batch loss 1.36892581 epoch total loss 1.29452205\n",
      "Trained batch 485 batch loss 1.27169597 epoch total loss 1.29447484\n",
      "Trained batch 486 batch loss 1.25198174 epoch total loss 1.29438734\n",
      "Trained batch 487 batch loss 1.32056034 epoch total loss 1.2944411\n",
      "Trained batch 488 batch loss 1.32099724 epoch total loss 1.29449546\n",
      "Trained batch 489 batch loss 1.35187554 epoch total loss 1.29461288\n",
      "Trained batch 490 batch loss 1.38014913 epoch total loss 1.29478741\n",
      "Trained batch 491 batch loss 1.37574244 epoch total loss 1.29495215\n",
      "Trained batch 492 batch loss 1.48229575 epoch total loss 1.29533303\n",
      "Trained batch 493 batch loss 1.48923337 epoch total loss 1.2957263\n",
      "Trained batch 494 batch loss 1.46025717 epoch total loss 1.29605937\n",
      "Trained batch 495 batch loss 1.43465424 epoch total loss 1.29633939\n",
      "Trained batch 496 batch loss 1.41658175 epoch total loss 1.29658175\n",
      "Trained batch 497 batch loss 1.42931283 epoch total loss 1.29684889\n",
      "Trained batch 498 batch loss 1.35610807 epoch total loss 1.29696774\n",
      "Trained batch 499 batch loss 1.43370867 epoch total loss 1.29724181\n",
      "Trained batch 500 batch loss 1.36403894 epoch total loss 1.29737532\n",
      "Trained batch 501 batch loss 1.38891292 epoch total loss 1.29755807\n",
      "Trained batch 502 batch loss 1.3670845 epoch total loss 1.29769659\n",
      "Trained batch 503 batch loss 1.37676787 epoch total loss 1.29785371\n",
      "Trained batch 504 batch loss 1.33053386 epoch total loss 1.29791856\n",
      "Trained batch 505 batch loss 1.44964743 epoch total loss 1.29821897\n",
      "Trained batch 506 batch loss 1.31461608 epoch total loss 1.29825139\n",
      "Trained batch 507 batch loss 1.32909775 epoch total loss 1.29831231\n",
      "Trained batch 508 batch loss 1.36525893 epoch total loss 1.29844403\n",
      "Trained batch 509 batch loss 1.28052354 epoch total loss 1.29840875\n",
      "Trained batch 510 batch loss 1.25441837 epoch total loss 1.29832244\n",
      "Trained batch 511 batch loss 1.26277971 epoch total loss 1.29825294\n",
      "Trained batch 512 batch loss 1.27001548 epoch total loss 1.29819775\n",
      "Trained batch 513 batch loss 1.21067679 epoch total loss 1.29802716\n",
      "Trained batch 514 batch loss 1.19715762 epoch total loss 1.29783094\n",
      "Trained batch 515 batch loss 1.17705762 epoch total loss 1.29759645\n",
      "Trained batch 516 batch loss 1.26032615 epoch total loss 1.29752409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 517 batch loss 1.24046707 epoch total loss 1.29741383\n",
      "Trained batch 518 batch loss 1.25301337 epoch total loss 1.297328\n",
      "Trained batch 519 batch loss 1.40440166 epoch total loss 1.29753435\n",
      "Trained batch 520 batch loss 1.24698639 epoch total loss 1.29743719\n",
      "Trained batch 521 batch loss 1.18871689 epoch total loss 1.29722857\n",
      "Trained batch 522 batch loss 1.0736 epoch total loss 1.29680014\n",
      "Trained batch 523 batch loss 1.26162958 epoch total loss 1.29673302\n",
      "Trained batch 524 batch loss 1.42436481 epoch total loss 1.29697657\n",
      "Trained batch 525 batch loss 1.447155 epoch total loss 1.29726255\n",
      "Trained batch 526 batch loss 1.41851223 epoch total loss 1.2974931\n",
      "Trained batch 527 batch loss 1.45629 epoch total loss 1.29779446\n",
      "Trained batch 528 batch loss 1.3302809 epoch total loss 1.29785597\n",
      "Trained batch 529 batch loss 1.34348989 epoch total loss 1.29794228\n",
      "Trained batch 530 batch loss 1.44720852 epoch total loss 1.29822385\n",
      "Trained batch 531 batch loss 1.32965899 epoch total loss 1.2982831\n",
      "Trained batch 532 batch loss 1.39901125 epoch total loss 1.2984724\n",
      "Trained batch 533 batch loss 1.28629112 epoch total loss 1.29844952\n",
      "Trained batch 534 batch loss 1.19349015 epoch total loss 1.29825294\n",
      "Trained batch 535 batch loss 1.17896366 epoch total loss 1.29803\n",
      "Trained batch 536 batch loss 1.16439104 epoch total loss 1.29778063\n",
      "Trained batch 537 batch loss 1.20524585 epoch total loss 1.29760838\n",
      "Trained batch 538 batch loss 1.2879976 epoch total loss 1.29759049\n",
      "Trained batch 539 batch loss 1.34742558 epoch total loss 1.297683\n",
      "Trained batch 540 batch loss 1.39917445 epoch total loss 1.29787087\n",
      "Trained batch 541 batch loss 1.30301952 epoch total loss 1.29788041\n",
      "Trained batch 542 batch loss 1.3519578 epoch total loss 1.29798019\n",
      "Trained batch 543 batch loss 1.35089612 epoch total loss 1.29807758\n",
      "Trained batch 544 batch loss 1.21818602 epoch total loss 1.29793072\n",
      "Trained batch 545 batch loss 1.23985887 epoch total loss 1.29782426\n",
      "Trained batch 546 batch loss 1.32776356 epoch total loss 1.2978791\n",
      "Trained batch 547 batch loss 1.34222186 epoch total loss 1.29796016\n",
      "Trained batch 548 batch loss 1.35395455 epoch total loss 1.29806232\n",
      "Trained batch 549 batch loss 1.11811471 epoch total loss 1.2977345\n",
      "Trained batch 550 batch loss 1.28022492 epoch total loss 1.29770267\n",
      "Trained batch 551 batch loss 1.19208705 epoch total loss 1.29751098\n",
      "Trained batch 552 batch loss 1.15324736 epoch total loss 1.29724956\n",
      "Trained batch 553 batch loss 1.11390781 epoch total loss 1.29691803\n",
      "Trained batch 554 batch loss 1.23598027 epoch total loss 1.296808\n",
      "Trained batch 555 batch loss 1.26493335 epoch total loss 1.29675066\n",
      "Trained batch 556 batch loss 1.1603446 epoch total loss 1.29650533\n",
      "Trained batch 557 batch loss 1.16270757 epoch total loss 1.29626513\n",
      "Trained batch 558 batch loss 1.20782936 epoch total loss 1.29610658\n",
      "Trained batch 559 batch loss 1.21772838 epoch total loss 1.29596639\n",
      "Trained batch 560 batch loss 1.19558895 epoch total loss 1.29578722\n",
      "Trained batch 561 batch loss 1.32419133 epoch total loss 1.29583788\n",
      "Trained batch 562 batch loss 1.33789563 epoch total loss 1.29591262\n",
      "Trained batch 563 batch loss 1.25129092 epoch total loss 1.29583335\n",
      "Trained batch 564 batch loss 1.33524799 epoch total loss 1.29590333\n",
      "Trained batch 565 batch loss 1.27049065 epoch total loss 1.29585838\n",
      "Trained batch 566 batch loss 1.23230219 epoch total loss 1.29574609\n",
      "Trained batch 567 batch loss 1.42723584 epoch total loss 1.29597795\n",
      "Trained batch 568 batch loss 1.26570415 epoch total loss 1.29592466\n",
      "Trained batch 569 batch loss 1.33063376 epoch total loss 1.2959857\n",
      "Trained batch 570 batch loss 1.32293618 epoch total loss 1.29603291\n",
      "Trained batch 571 batch loss 1.32376266 epoch total loss 1.29608154\n",
      "Trained batch 572 batch loss 1.25406623 epoch total loss 1.29600811\n",
      "Trained batch 573 batch loss 1.23735952 epoch total loss 1.29590583\n",
      "Trained batch 574 batch loss 1.29155159 epoch total loss 1.2958982\n",
      "Trained batch 575 batch loss 1.29742038 epoch total loss 1.29590082\n",
      "Trained batch 576 batch loss 1.4254123 epoch total loss 1.29612577\n",
      "Trained batch 577 batch loss 1.33946347 epoch total loss 1.29620087\n",
      "Trained batch 578 batch loss 1.26352906 epoch total loss 1.29614437\n",
      "Trained batch 579 batch loss 1.26729512 epoch total loss 1.29609454\n",
      "Trained batch 580 batch loss 1.16674018 epoch total loss 1.2958715\n",
      "Trained batch 581 batch loss 1.12728298 epoch total loss 1.29558134\n",
      "Trained batch 582 batch loss 1.25981 epoch total loss 1.29551983\n",
      "Trained batch 583 batch loss 1.16301286 epoch total loss 1.29529262\n",
      "Trained batch 584 batch loss 1.41360307 epoch total loss 1.29549515\n",
      "Trained batch 585 batch loss 1.29361975 epoch total loss 1.29549193\n",
      "Trained batch 586 batch loss 1.22123444 epoch total loss 1.29536521\n",
      "Trained batch 587 batch loss 1.24163902 epoch total loss 1.29527378\n",
      "Trained batch 588 batch loss 1.57227182 epoch total loss 1.29574478\n",
      "Trained batch 589 batch loss 1.26405144 epoch total loss 1.29569101\n",
      "Trained batch 590 batch loss 1.25593483 epoch total loss 1.29562354\n",
      "Trained batch 591 batch loss 1.19733 epoch total loss 1.29545724\n",
      "Trained batch 592 batch loss 1.12254071 epoch total loss 1.29516518\n",
      "Trained batch 593 batch loss 1.21032465 epoch total loss 1.29502213\n",
      "Trained batch 594 batch loss 1.41447306 epoch total loss 1.29522324\n",
      "Trained batch 595 batch loss 1.26351917 epoch total loss 1.29517\n",
      "Trained batch 596 batch loss 1.3504734 epoch total loss 1.29526269\n",
      "Trained batch 597 batch loss 1.2894305 epoch total loss 1.29525292\n",
      "Trained batch 598 batch loss 1.22995949 epoch total loss 1.29514372\n",
      "Trained batch 599 batch loss 1.22863054 epoch total loss 1.29503274\n",
      "Trained batch 600 batch loss 1.28233266 epoch total loss 1.29501164\n",
      "Trained batch 601 batch loss 1.30446911 epoch total loss 1.29502726\n",
      "Trained batch 602 batch loss 1.41287112 epoch total loss 1.295223\n",
      "Trained batch 603 batch loss 1.34308267 epoch total loss 1.29530239\n",
      "Trained batch 604 batch loss 1.22240591 epoch total loss 1.29518163\n",
      "Trained batch 605 batch loss 1.1925813 epoch total loss 1.29501212\n",
      "Trained batch 606 batch loss 1.21058488 epoch total loss 1.29487276\n",
      "Trained batch 607 batch loss 1.37105274 epoch total loss 1.29499817\n",
      "Trained batch 608 batch loss 1.28904223 epoch total loss 1.29498839\n",
      "Trained batch 609 batch loss 1.33123684 epoch total loss 1.295048\n",
      "Trained batch 610 batch loss 1.33947492 epoch total loss 1.29512084\n",
      "Trained batch 611 batch loss 1.2830354 epoch total loss 1.29510093\n",
      "Trained batch 612 batch loss 1.42127228 epoch total loss 1.29530716\n",
      "Trained batch 613 batch loss 1.49462104 epoch total loss 1.29563224\n",
      "Trained batch 614 batch loss 1.60558152 epoch total loss 1.29613709\n",
      "Trained batch 615 batch loss 1.25854504 epoch total loss 1.29607594\n",
      "Trained batch 616 batch loss 1.24654984 epoch total loss 1.29599559\n",
      "Trained batch 617 batch loss 1.19906354 epoch total loss 1.29583836\n",
      "Trained batch 618 batch loss 1.24571919 epoch total loss 1.29575729\n",
      "Trained batch 619 batch loss 1.2297591 epoch total loss 1.2956506\n",
      "Trained batch 620 batch loss 1.19583631 epoch total loss 1.29548967\n",
      "Trained batch 621 batch loss 1.16323757 epoch total loss 1.29527664\n",
      "Trained batch 622 batch loss 1.22638762 epoch total loss 1.2951659\n",
      "Trained batch 623 batch loss 1.12906861 epoch total loss 1.29489934\n",
      "Trained batch 624 batch loss 1.13378 epoch total loss 1.29464114\n",
      "Trained batch 625 batch loss 1.22406363 epoch total loss 1.29452825\n",
      "Trained batch 626 batch loss 1.22064412 epoch total loss 1.29441023\n",
      "Trained batch 627 batch loss 1.11711442 epoch total loss 1.29412746\n",
      "Trained batch 628 batch loss 1.17184043 epoch total loss 1.29393268\n",
      "Trained batch 629 batch loss 1.17979193 epoch total loss 1.29375124\n",
      "Trained batch 630 batch loss 1.2210865 epoch total loss 1.29363585\n",
      "Trained batch 631 batch loss 1.17823136 epoch total loss 1.29345298\n",
      "Trained batch 632 batch loss 1.22124088 epoch total loss 1.29333878\n",
      "Trained batch 633 batch loss 1.2714361 epoch total loss 1.29330409\n",
      "Trained batch 634 batch loss 1.19620085 epoch total loss 1.29315102\n",
      "Trained batch 635 batch loss 1.20441222 epoch total loss 1.29301119\n",
      "Trained batch 636 batch loss 1.21372581 epoch total loss 1.29288661\n",
      "Trained batch 637 batch loss 1.24849176 epoch total loss 1.29281688\n",
      "Trained batch 638 batch loss 1.11453009 epoch total loss 1.29253733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 639 batch loss 1.01749909 epoch total loss 1.29210699\n",
      "Trained batch 640 batch loss 1.17190015 epoch total loss 1.29191911\n",
      "Trained batch 641 batch loss 1.32897353 epoch total loss 1.29197693\n",
      "Trained batch 642 batch loss 1.36176896 epoch total loss 1.29208565\n",
      "Trained batch 643 batch loss 1.2848165 epoch total loss 1.29207432\n",
      "Trained batch 644 batch loss 1.338902 epoch total loss 1.29214704\n",
      "Trained batch 645 batch loss 1.23226893 epoch total loss 1.29205418\n",
      "Trained batch 646 batch loss 1.18375266 epoch total loss 1.29188657\n",
      "Trained batch 647 batch loss 1.22068143 epoch total loss 1.29177654\n",
      "Trained batch 648 batch loss 1.24989986 epoch total loss 1.29171193\n",
      "Trained batch 649 batch loss 1.1683352 epoch total loss 1.29152179\n",
      "Trained batch 650 batch loss 1.25457275 epoch total loss 1.29146492\n",
      "Trained batch 651 batch loss 1.38106465 epoch total loss 1.29160249\n",
      "Trained batch 652 batch loss 1.26360714 epoch total loss 1.29155958\n",
      "Trained batch 653 batch loss 1.41730416 epoch total loss 1.2917521\n",
      "Trained batch 654 batch loss 1.36578345 epoch total loss 1.29186535\n",
      "Trained batch 655 batch loss 1.16824234 epoch total loss 1.29167652\n",
      "Trained batch 656 batch loss 1.22740209 epoch total loss 1.29157865\n",
      "Trained batch 657 batch loss 1.23370862 epoch total loss 1.29149055\n",
      "Trained batch 658 batch loss 1.39263284 epoch total loss 1.29164422\n",
      "Trained batch 659 batch loss 1.40640306 epoch total loss 1.29181838\n",
      "Trained batch 660 batch loss 1.13032722 epoch total loss 1.29157376\n",
      "Trained batch 661 batch loss 1.11534584 epoch total loss 1.29130709\n",
      "Trained batch 662 batch loss 1.19284272 epoch total loss 1.29115844\n",
      "Trained batch 663 batch loss 1.14255977 epoch total loss 1.29093432\n",
      "Trained batch 664 batch loss 1.17122257 epoch total loss 1.29075396\n",
      "Trained batch 665 batch loss 1.2628814 epoch total loss 1.29071212\n",
      "Trained batch 666 batch loss 1.28901649 epoch total loss 1.2907095\n",
      "Trained batch 667 batch loss 1.33644271 epoch total loss 1.29077804\n",
      "Trained batch 668 batch loss 1.42451429 epoch total loss 1.29097831\n",
      "Trained batch 669 batch loss 1.29699445 epoch total loss 1.29098725\n",
      "Trained batch 670 batch loss 1.2792933 epoch total loss 1.29096985\n",
      "Trained batch 671 batch loss 1.59274 epoch total loss 1.29141951\n",
      "Trained batch 672 batch loss 1.43196332 epoch total loss 1.2916286\n",
      "Trained batch 673 batch loss 1.45534658 epoch total loss 1.29187179\n",
      "Trained batch 674 batch loss 1.30500388 epoch total loss 1.29189134\n",
      "Trained batch 675 batch loss 1.31881404 epoch total loss 1.29193115\n",
      "Trained batch 676 batch loss 1.31208169 epoch total loss 1.29196095\n",
      "Trained batch 677 batch loss 1.23406315 epoch total loss 1.29187548\n",
      "Trained batch 678 batch loss 1.26037502 epoch total loss 1.29182899\n",
      "Trained batch 679 batch loss 1.18447018 epoch total loss 1.2916708\n",
      "Trained batch 680 batch loss 1.19200778 epoch total loss 1.29152429\n",
      "Trained batch 681 batch loss 1.27190447 epoch total loss 1.29149544\n",
      "Trained batch 682 batch loss 1.29740834 epoch total loss 1.29150414\n",
      "Trained batch 683 batch loss 1.24298406 epoch total loss 1.2914331\n",
      "Trained batch 684 batch loss 1.25737238 epoch total loss 1.29138339\n",
      "Trained batch 685 batch loss 1.16008008 epoch total loss 1.2911917\n",
      "Trained batch 686 batch loss 1.25810277 epoch total loss 1.29114354\n",
      "Trained batch 687 batch loss 1.2721343 epoch total loss 1.29111588\n",
      "Trained batch 688 batch loss 1.22669768 epoch total loss 1.29102218\n",
      "Trained batch 689 batch loss 1.15937924 epoch total loss 1.29083109\n",
      "Trained batch 690 batch loss 1.24217558 epoch total loss 1.29076064\n",
      "Trained batch 691 batch loss 1.15961432 epoch total loss 1.29057086\n",
      "Trained batch 692 batch loss 1.29285789 epoch total loss 1.29057407\n",
      "Trained batch 693 batch loss 1.31023872 epoch total loss 1.29060245\n",
      "Trained batch 694 batch loss 1.35587621 epoch total loss 1.2906965\n",
      "Trained batch 695 batch loss 1.33925295 epoch total loss 1.29076636\n",
      "Trained batch 696 batch loss 1.25531387 epoch total loss 1.29071546\n",
      "Trained batch 697 batch loss 1.28835595 epoch total loss 1.290712\n",
      "Trained batch 698 batch loss 1.28124404 epoch total loss 1.29069853\n",
      "Trained batch 699 batch loss 1.25321555 epoch total loss 1.29064488\n",
      "Trained batch 700 batch loss 1.30384266 epoch total loss 1.29066372\n",
      "Trained batch 701 batch loss 1.30788922 epoch total loss 1.29068828\n",
      "Trained batch 702 batch loss 1.29986954 epoch total loss 1.29070127\n",
      "Trained batch 703 batch loss 1.33747137 epoch total loss 1.29076779\n",
      "Trained batch 704 batch loss 1.42525876 epoch total loss 1.29095888\n",
      "Trained batch 705 batch loss 1.37051785 epoch total loss 1.29107177\n",
      "Trained batch 706 batch loss 1.34027529 epoch total loss 1.29114139\n",
      "Trained batch 707 batch loss 1.30828047 epoch total loss 1.29116571\n",
      "Trained batch 708 batch loss 1.22738814 epoch total loss 1.29107559\n",
      "Trained batch 709 batch loss 1.20592928 epoch total loss 1.29095554\n",
      "Trained batch 710 batch loss 1.24410486 epoch total loss 1.2908895\n",
      "Trained batch 711 batch loss 1.32609916 epoch total loss 1.29093909\n",
      "Trained batch 712 batch loss 1.30604744 epoch total loss 1.29096019\n",
      "Trained batch 713 batch loss 1.24118328 epoch total loss 1.29089046\n",
      "Trained batch 714 batch loss 1.34399223 epoch total loss 1.29096484\n",
      "Trained batch 715 batch loss 1.2905004 epoch total loss 1.29096425\n",
      "Trained batch 716 batch loss 1.23727763 epoch total loss 1.29088926\n",
      "Trained batch 717 batch loss 1.33487129 epoch total loss 1.29095066\n",
      "Trained batch 718 batch loss 1.41386974 epoch total loss 1.29112184\n",
      "Trained batch 719 batch loss 1.28333807 epoch total loss 1.29111099\n",
      "Trained batch 720 batch loss 1.43312502 epoch total loss 1.29130828\n",
      "Trained batch 721 batch loss 1.40485072 epoch total loss 1.29146576\n",
      "Trained batch 722 batch loss 1.32477188 epoch total loss 1.29151189\n",
      "Trained batch 723 batch loss 1.2334938 epoch total loss 1.29143167\n",
      "Trained batch 724 batch loss 1.33072352 epoch total loss 1.29148591\n",
      "Trained batch 725 batch loss 1.33627748 epoch total loss 1.29154778\n",
      "Trained batch 726 batch loss 1.27588117 epoch total loss 1.2915262\n",
      "Trained batch 727 batch loss 1.32525492 epoch total loss 1.29157257\n",
      "Trained batch 728 batch loss 1.26831698 epoch total loss 1.29154062\n",
      "Trained batch 729 batch loss 1.25961971 epoch total loss 1.29149687\n",
      "Trained batch 730 batch loss 1.14425969 epoch total loss 1.29129517\n",
      "Trained batch 731 batch loss 1.2093159 epoch total loss 1.29118299\n",
      "Trained batch 732 batch loss 1.13860285 epoch total loss 1.29097462\n",
      "Trained batch 733 batch loss 1.11917651 epoch total loss 1.29074025\n",
      "Trained batch 734 batch loss 1.33893394 epoch total loss 1.29080594\n",
      "Trained batch 735 batch loss 1.31528342 epoch total loss 1.2908392\n",
      "Trained batch 736 batch loss 1.44208288 epoch total loss 1.29104471\n",
      "Trained batch 737 batch loss 1.43958497 epoch total loss 1.29124629\n",
      "Trained batch 738 batch loss 1.41208708 epoch total loss 1.29141009\n",
      "Trained batch 739 batch loss 1.3006115 epoch total loss 1.29142249\n",
      "Trained batch 740 batch loss 1.24898386 epoch total loss 1.29136515\n",
      "Trained batch 741 batch loss 1.25946712 epoch total loss 1.29132199\n",
      "Trained batch 742 batch loss 1.23564768 epoch total loss 1.29124701\n",
      "Trained batch 743 batch loss 1.22071087 epoch total loss 1.29115212\n",
      "Trained batch 744 batch loss 1.19626319 epoch total loss 1.29102457\n",
      "Trained batch 745 batch loss 1.19058788 epoch total loss 1.29088974\n",
      "Trained batch 746 batch loss 1.16614676 epoch total loss 1.29072261\n",
      "Trained batch 747 batch loss 1.20110738 epoch total loss 1.29060256\n",
      "Trained batch 748 batch loss 1.15388453 epoch total loss 1.29041982\n",
      "Trained batch 749 batch loss 1.08076024 epoch total loss 1.29013991\n",
      "Trained batch 750 batch loss 1.2374053 epoch total loss 1.29006958\n",
      "Trained batch 751 batch loss 1.4308126 epoch total loss 1.29025698\n",
      "Trained batch 752 batch loss 1.23848367 epoch total loss 1.29018807\n",
      "Trained batch 753 batch loss 1.24838448 epoch total loss 1.29013264\n",
      "Trained batch 754 batch loss 1.24610209 epoch total loss 1.29007423\n",
      "Trained batch 755 batch loss 1.36705041 epoch total loss 1.29017615\n",
      "Trained batch 756 batch loss 1.24055672 epoch total loss 1.29011047\n",
      "Trained batch 757 batch loss 1.22756028 epoch total loss 1.29002786\n",
      "Trained batch 758 batch loss 1.34823394 epoch total loss 1.29010463\n",
      "Trained batch 759 batch loss 1.28290009 epoch total loss 1.29009509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 760 batch loss 1.1953485 epoch total loss 1.28997052\n",
      "Trained batch 761 batch loss 1.36332035 epoch total loss 1.29006684\n",
      "Trained batch 762 batch loss 1.424577 epoch total loss 1.29024339\n",
      "Trained batch 763 batch loss 1.51766062 epoch total loss 1.29054141\n",
      "Trained batch 764 batch loss 1.52825594 epoch total loss 1.29085255\n",
      "Trained batch 765 batch loss 1.40924251 epoch total loss 1.29100728\n",
      "Trained batch 766 batch loss 1.3042779 epoch total loss 1.29102468\n",
      "Trained batch 767 batch loss 1.30369461 epoch total loss 1.29104114\n",
      "Trained batch 768 batch loss 1.22022152 epoch total loss 1.29094899\n",
      "Trained batch 769 batch loss 1.20354021 epoch total loss 1.29083526\n",
      "Trained batch 770 batch loss 1.25500941 epoch total loss 1.29078877\n",
      "Trained batch 771 batch loss 1.3257724 epoch total loss 1.29083407\n",
      "Trained batch 772 batch loss 1.30829155 epoch total loss 1.29085672\n",
      "Trained batch 773 batch loss 1.30563951 epoch total loss 1.29087591\n",
      "Trained batch 774 batch loss 1.18955123 epoch total loss 1.29074502\n",
      "Trained batch 775 batch loss 1.19352341 epoch total loss 1.29061961\n",
      "Trained batch 776 batch loss 1.1062839 epoch total loss 1.29038203\n",
      "Trained batch 777 batch loss 1.1626972 epoch total loss 1.29021764\n",
      "Trained batch 778 batch loss 1.19502306 epoch total loss 1.29009533\n",
      "Trained batch 779 batch loss 1.22599292 epoch total loss 1.29001307\n",
      "Trained batch 780 batch loss 1.23482752 epoch total loss 1.28994226\n",
      "Trained batch 781 batch loss 1.43828642 epoch total loss 1.29013216\n",
      "Trained batch 782 batch loss 1.42975104 epoch total loss 1.29031074\n",
      "Trained batch 783 batch loss 1.32882822 epoch total loss 1.29036\n",
      "Trained batch 784 batch loss 1.41485202 epoch total loss 1.29051876\n",
      "Trained batch 785 batch loss 1.42506945 epoch total loss 1.29069018\n",
      "Trained batch 786 batch loss 1.37213111 epoch total loss 1.29079378\n",
      "Trained batch 787 batch loss 1.34020817 epoch total loss 1.2908566\n",
      "Trained batch 788 batch loss 1.17999864 epoch total loss 1.29071581\n",
      "Trained batch 789 batch loss 1.19806647 epoch total loss 1.29059839\n",
      "Trained batch 790 batch loss 1.30709624 epoch total loss 1.29061925\n",
      "Trained batch 791 batch loss 1.31921935 epoch total loss 1.29065537\n",
      "Trained batch 792 batch loss 1.34196687 epoch total loss 1.29072022\n",
      "Trained batch 793 batch loss 1.36942124 epoch total loss 1.29081953\n",
      "Trained batch 794 batch loss 1.33678579 epoch total loss 1.29087746\n",
      "Trained batch 795 batch loss 1.30471897 epoch total loss 1.29089475\n",
      "Trained batch 796 batch loss 1.3767941 epoch total loss 1.29100275\n",
      "Trained batch 797 batch loss 1.27003288 epoch total loss 1.29097641\n",
      "Trained batch 798 batch loss 1.22206652 epoch total loss 1.29089\n",
      "Trained batch 799 batch loss 1.2388382 epoch total loss 1.29082501\n",
      "Trained batch 800 batch loss 1.18972826 epoch total loss 1.29069853\n",
      "Trained batch 801 batch loss 1.33902431 epoch total loss 1.29075885\n",
      "Trained batch 802 batch loss 1.30845284 epoch total loss 1.2907809\n",
      "Trained batch 803 batch loss 1.27722204 epoch total loss 1.29076409\n",
      "Trained batch 804 batch loss 1.26467705 epoch total loss 1.29073155\n",
      "Trained batch 805 batch loss 1.28349853 epoch total loss 1.29072249\n",
      "Trained batch 806 batch loss 1.35240245 epoch total loss 1.29079902\n",
      "Trained batch 807 batch loss 1.19935119 epoch total loss 1.29068577\n",
      "Trained batch 808 batch loss 1.25833142 epoch total loss 1.2906456\n",
      "Trained batch 809 batch loss 1.22015691 epoch total loss 1.29055858\n",
      "Trained batch 810 batch loss 1.22820187 epoch total loss 1.29048157\n",
      "Trained batch 811 batch loss 1.28382349 epoch total loss 1.29047334\n",
      "Trained batch 812 batch loss 1.07000113 epoch total loss 1.29020166\n",
      "Trained batch 813 batch loss 1.10620248 epoch total loss 1.2899754\n",
      "Trained batch 814 batch loss 1.24291766 epoch total loss 1.28991759\n",
      "Trained batch 815 batch loss 1.15009236 epoch total loss 1.28974605\n",
      "Trained batch 816 batch loss 1.11993 epoch total loss 1.28953791\n",
      "Trained batch 817 batch loss 1.28662026 epoch total loss 1.28953433\n",
      "Trained batch 818 batch loss 1.18406916 epoch total loss 1.28940547\n",
      "Trained batch 819 batch loss 1.28356922 epoch total loss 1.28939831\n",
      "Trained batch 820 batch loss 1.34252453 epoch total loss 1.28946304\n",
      "Trained batch 821 batch loss 1.39364481 epoch total loss 1.28959\n",
      "Trained batch 822 batch loss 1.29128432 epoch total loss 1.28959203\n",
      "Trained batch 823 batch loss 1.28815484 epoch total loss 1.28959036\n",
      "Trained batch 824 batch loss 1.45844042 epoch total loss 1.2897954\n",
      "Trained batch 825 batch loss 1.46009064 epoch total loss 1.29000175\n",
      "Trained batch 826 batch loss 1.25317252 epoch total loss 1.28995717\n",
      "Trained batch 827 batch loss 1.23713636 epoch total loss 1.28989339\n",
      "Trained batch 828 batch loss 1.1720649 epoch total loss 1.28975117\n",
      "Trained batch 829 batch loss 1.22552657 epoch total loss 1.28967369\n",
      "Trained batch 830 batch loss 1.29718411 epoch total loss 1.28968287\n",
      "Trained batch 831 batch loss 1.41459143 epoch total loss 1.28983307\n",
      "Trained batch 832 batch loss 1.31305015 epoch total loss 1.28986108\n",
      "Trained batch 833 batch loss 1.33778143 epoch total loss 1.28991866\n",
      "Trained batch 834 batch loss 1.34559226 epoch total loss 1.2899853\n",
      "Trained batch 835 batch loss 1.22067046 epoch total loss 1.28990233\n",
      "Trained batch 836 batch loss 1.23959577 epoch total loss 1.28984225\n",
      "Trained batch 837 batch loss 1.30812871 epoch total loss 1.28986406\n",
      "Trained batch 838 batch loss 1.29425859 epoch total loss 1.28986931\n",
      "Trained batch 839 batch loss 1.24318933 epoch total loss 1.28981364\n",
      "Trained batch 840 batch loss 1.26809263 epoch total loss 1.28978777\n",
      "Trained batch 841 batch loss 1.25174296 epoch total loss 1.28974247\n",
      "Trained batch 842 batch loss 1.3276999 epoch total loss 1.28978765\n",
      "Trained batch 843 batch loss 1.30057573 epoch total loss 1.28980041\n",
      "Trained batch 844 batch loss 1.31136179 epoch total loss 1.28982604\n",
      "Trained batch 845 batch loss 1.32073462 epoch total loss 1.28986251\n",
      "Trained batch 846 batch loss 1.37953055 epoch total loss 1.28996849\n",
      "Trained batch 847 batch loss 1.2691195 epoch total loss 1.28994393\n",
      "Trained batch 848 batch loss 1.31691051 epoch total loss 1.28997576\n",
      "Trained batch 849 batch loss 1.30273104 epoch total loss 1.28999078\n",
      "Trained batch 850 batch loss 1.30671477 epoch total loss 1.29001045\n",
      "Trained batch 851 batch loss 1.25401616 epoch total loss 1.28996825\n",
      "Trained batch 852 batch loss 1.09554088 epoch total loss 1.28974009\n",
      "Trained batch 853 batch loss 1.12898207 epoch total loss 1.28955162\n",
      "Trained batch 854 batch loss 1.30224323 epoch total loss 1.28956652\n",
      "Trained batch 855 batch loss 1.32969046 epoch total loss 1.28961349\n",
      "Trained batch 856 batch loss 1.36419511 epoch total loss 1.28970051\n",
      "Trained batch 857 batch loss 1.39304066 epoch total loss 1.28982115\n",
      "Trained batch 858 batch loss 1.4037075 epoch total loss 1.28995383\n",
      "Trained batch 859 batch loss 1.27187383 epoch total loss 1.28993273\n",
      "Trained batch 860 batch loss 1.40953374 epoch total loss 1.29007185\n",
      "Trained batch 861 batch loss 1.33389008 epoch total loss 1.29012275\n",
      "Trained batch 862 batch loss 1.33387327 epoch total loss 1.29017341\n",
      "Trained batch 863 batch loss 1.2504108 epoch total loss 1.29012728\n",
      "Trained batch 864 batch loss 1.53255594 epoch total loss 1.29040802\n",
      "Trained batch 865 batch loss 1.32980955 epoch total loss 1.29045355\n",
      "Trained batch 866 batch loss 1.28662491 epoch total loss 1.29044914\n",
      "Trained batch 867 batch loss 1.20782256 epoch total loss 1.29035378\n",
      "Trained batch 868 batch loss 1.25479805 epoch total loss 1.29031277\n",
      "Trained batch 869 batch loss 1.20222449 epoch total loss 1.29021144\n",
      "Trained batch 870 batch loss 1.23187733 epoch total loss 1.29014444\n",
      "Trained batch 871 batch loss 1.1820004 epoch total loss 1.29002023\n",
      "Trained batch 872 batch loss 1.22782826 epoch total loss 1.28994894\n",
      "Trained batch 873 batch loss 1.23792529 epoch total loss 1.28988934\n",
      "Trained batch 874 batch loss 1.31846499 epoch total loss 1.289922\n",
      "Trained batch 875 batch loss 1.01065898 epoch total loss 1.28960288\n",
      "Trained batch 876 batch loss 1.29505014 epoch total loss 1.28960907\n",
      "Trained batch 877 batch loss 1.18307734 epoch total loss 1.2894876\n",
      "Trained batch 878 batch loss 1.13096452 epoch total loss 1.289307\n",
      "Trained batch 879 batch loss 1.17903364 epoch total loss 1.28918171\n",
      "Trained batch 880 batch loss 1.12476301 epoch total loss 1.28899479\n",
      "Trained batch 881 batch loss 1.17330146 epoch total loss 1.28886354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 882 batch loss 1.22514522 epoch total loss 1.28879118\n",
      "Trained batch 883 batch loss 1.15512216 epoch total loss 1.2886399\n",
      "Trained batch 884 batch loss 1.2777431 epoch total loss 1.28862751\n",
      "Trained batch 885 batch loss 1.34655249 epoch total loss 1.28869295\n",
      "Trained batch 886 batch loss 1.29889178 epoch total loss 1.28870451\n",
      "Trained batch 887 batch loss 1.37084234 epoch total loss 1.28879714\n",
      "Trained batch 888 batch loss 1.27824163 epoch total loss 1.28878522\n",
      "Trained batch 889 batch loss 1.35222852 epoch total loss 1.28885651\n",
      "Trained batch 890 batch loss 1.2116003 epoch total loss 1.28876972\n",
      "Trained batch 891 batch loss 1.26345015 epoch total loss 1.28874123\n",
      "Trained batch 892 batch loss 1.1443398 epoch total loss 1.28857923\n",
      "Trained batch 893 batch loss 1.03549027 epoch total loss 1.28829587\n",
      "Trained batch 894 batch loss 1.11117363 epoch total loss 1.28809786\n",
      "Trained batch 895 batch loss 1.21175456 epoch total loss 1.2880125\n",
      "Trained batch 896 batch loss 1.41512978 epoch total loss 1.28815448\n",
      "Trained batch 897 batch loss 1.45173514 epoch total loss 1.28833687\n",
      "Trained batch 898 batch loss 1.30957651 epoch total loss 1.28836048\n",
      "Trained batch 899 batch loss 1.21263087 epoch total loss 1.28827631\n",
      "Trained batch 900 batch loss 1.13277161 epoch total loss 1.28810358\n",
      "Trained batch 901 batch loss 1.38908792 epoch total loss 1.28821564\n",
      "Trained batch 902 batch loss 1.36048102 epoch total loss 1.28829575\n",
      "Trained batch 903 batch loss 1.30309415 epoch total loss 1.28831208\n",
      "Trained batch 904 batch loss 1.32325923 epoch total loss 1.2883507\n",
      "Trained batch 905 batch loss 1.29092216 epoch total loss 1.28835356\n",
      "Trained batch 906 batch loss 1.52447009 epoch total loss 1.28861415\n",
      "Trained batch 907 batch loss 1.33411908 epoch total loss 1.28866422\n",
      "Trained batch 908 batch loss 1.28942895 epoch total loss 1.28866506\n",
      "Trained batch 909 batch loss 1.26887465 epoch total loss 1.28864336\n",
      "Trained batch 910 batch loss 1.09556115 epoch total loss 1.28843117\n",
      "Trained batch 911 batch loss 1.27840221 epoch total loss 1.2884202\n",
      "Trained batch 912 batch loss 1.30443096 epoch total loss 1.28843784\n",
      "Trained batch 913 batch loss 1.25691414 epoch total loss 1.28840339\n",
      "Trained batch 914 batch loss 1.19502938 epoch total loss 1.28830123\n",
      "Trained batch 915 batch loss 1.36047781 epoch total loss 1.28838015\n",
      "Trained batch 916 batch loss 1.33418202 epoch total loss 1.28843021\n",
      "Trained batch 917 batch loss 1.23432374 epoch total loss 1.28837121\n",
      "Trained batch 918 batch loss 1.26560068 epoch total loss 1.28834641\n",
      "Trained batch 919 batch loss 1.18000329 epoch total loss 1.28822863\n",
      "Trained batch 920 batch loss 1.28100193 epoch total loss 1.28822076\n",
      "Trained batch 921 batch loss 1.196859 epoch total loss 1.28812158\n",
      "Trained batch 922 batch loss 1.15544009 epoch total loss 1.2879777\n",
      "Trained batch 923 batch loss 1.23772204 epoch total loss 1.2879231\n",
      "Trained batch 924 batch loss 1.36916244 epoch total loss 1.28801107\n",
      "Trained batch 925 batch loss 1.56549668 epoch total loss 1.28831112\n",
      "Trained batch 926 batch loss 1.48429191 epoch total loss 1.28852272\n",
      "Trained batch 927 batch loss 1.3345511 epoch total loss 1.28857243\n",
      "Trained batch 928 batch loss 1.36331391 epoch total loss 1.2886529\n",
      "Trained batch 929 batch loss 1.15777206 epoch total loss 1.28851199\n",
      "Trained batch 930 batch loss 1.10606718 epoch total loss 1.28831577\n",
      "Trained batch 931 batch loss 1.02764738 epoch total loss 1.28803575\n",
      "Trained batch 932 batch loss 1.01897502 epoch total loss 1.28774703\n",
      "Trained batch 933 batch loss 1.10707557 epoch total loss 1.28755331\n",
      "Trained batch 934 batch loss 1.14626145 epoch total loss 1.28740203\n",
      "Trained batch 935 batch loss 1.23440862 epoch total loss 1.28734529\n",
      "Trained batch 936 batch loss 1.34397817 epoch total loss 1.28740585\n",
      "Trained batch 937 batch loss 1.1962992 epoch total loss 1.28730857\n",
      "Trained batch 938 batch loss 1.24687743 epoch total loss 1.28726542\n",
      "Trained batch 939 batch loss 1.30666542 epoch total loss 1.28728604\n",
      "Trained batch 940 batch loss 1.22827804 epoch total loss 1.28722322\n",
      "Trained batch 941 batch loss 1.27509713 epoch total loss 1.28721046\n",
      "Trained batch 942 batch loss 1.26708603 epoch total loss 1.28718913\n",
      "Trained batch 943 batch loss 1.22751808 epoch total loss 1.28712583\n",
      "Trained batch 944 batch loss 1.12605882 epoch total loss 1.28695524\n",
      "Trained batch 945 batch loss 1.17350364 epoch total loss 1.28683519\n",
      "Trained batch 946 batch loss 1.2119875 epoch total loss 1.28675604\n",
      "Trained batch 947 batch loss 1.32520282 epoch total loss 1.28679669\n",
      "Trained batch 948 batch loss 1.34329712 epoch total loss 1.28685617\n",
      "Trained batch 949 batch loss 1.25255847 epoch total loss 1.28682\n",
      "Trained batch 950 batch loss 1.19903123 epoch total loss 1.28672767\n",
      "Trained batch 951 batch loss 1.04919112 epoch total loss 1.2864778\n",
      "Trained batch 952 batch loss 1.0581212 epoch total loss 1.28623796\n",
      "Trained batch 953 batch loss 1.09813535 epoch total loss 1.28604054\n",
      "Trained batch 954 batch loss 1.1059742 epoch total loss 1.28585184\n",
      "Trained batch 955 batch loss 1.17384624 epoch total loss 1.28573453\n",
      "Trained batch 956 batch loss 1.13822317 epoch total loss 1.28558016\n",
      "Trained batch 957 batch loss 1.27641261 epoch total loss 1.2855705\n",
      "Trained batch 958 batch loss 1.2669239 epoch total loss 1.28555119\n",
      "Trained batch 959 batch loss 1.15458465 epoch total loss 1.28541458\n",
      "Trained batch 960 batch loss 1.3849535 epoch total loss 1.28551829\n",
      "Trained batch 961 batch loss 1.3908515 epoch total loss 1.28562784\n",
      "Trained batch 962 batch loss 1.35931921 epoch total loss 1.28570449\n",
      "Trained batch 963 batch loss 1.42548323 epoch total loss 1.28584981\n",
      "Trained batch 964 batch loss 1.33465099 epoch total loss 1.28590035\n",
      "Trained batch 965 batch loss 1.32618034 epoch total loss 1.28594208\n",
      "Trained batch 966 batch loss 1.23510396 epoch total loss 1.28588939\n",
      "Trained batch 967 batch loss 1.30047011 epoch total loss 1.28590441\n",
      "Trained batch 968 batch loss 1.34098566 epoch total loss 1.28596127\n",
      "Trained batch 969 batch loss 1.34799504 epoch total loss 1.2860254\n",
      "Trained batch 970 batch loss 1.18351197 epoch total loss 1.28591967\n",
      "Trained batch 971 batch loss 1.19110942 epoch total loss 1.28582203\n",
      "Trained batch 972 batch loss 1.19706213 epoch total loss 1.28573072\n",
      "Trained batch 973 batch loss 1.17167044 epoch total loss 1.28561342\n",
      "Trained batch 974 batch loss 1.15578246 epoch total loss 1.28548014\n",
      "Trained batch 975 batch loss 1.29110312 epoch total loss 1.28548586\n",
      "Trained batch 976 batch loss 1.33119714 epoch total loss 1.28553271\n",
      "Trained batch 977 batch loss 1.14991927 epoch total loss 1.28539383\n",
      "Trained batch 978 batch loss 1.26396751 epoch total loss 1.2853719\n",
      "Trained batch 979 batch loss 1.4064641 epoch total loss 1.28549564\n",
      "Trained batch 980 batch loss 1.37084985 epoch total loss 1.28558278\n",
      "Trained batch 981 batch loss 1.401636 epoch total loss 1.28570104\n",
      "Trained batch 982 batch loss 1.23421454 epoch total loss 1.28564858\n",
      "Trained batch 983 batch loss 1.31529093 epoch total loss 1.28567886\n",
      "Trained batch 984 batch loss 1.39329755 epoch total loss 1.28578818\n",
      "Trained batch 985 batch loss 1.27706432 epoch total loss 1.28577936\n",
      "Trained batch 986 batch loss 1.41271377 epoch total loss 1.2859081\n",
      "Trained batch 987 batch loss 1.34738588 epoch total loss 1.28597045\n",
      "Trained batch 988 batch loss 1.30790198 epoch total loss 1.28599262\n",
      "Trained batch 989 batch loss 1.32929444 epoch total loss 1.28603637\n",
      "Trained batch 990 batch loss 1.33627272 epoch total loss 1.28608716\n",
      "Trained batch 991 batch loss 1.31681585 epoch total loss 1.28611815\n",
      "Trained batch 992 batch loss 1.30719352 epoch total loss 1.28613949\n",
      "Trained batch 993 batch loss 1.27337599 epoch total loss 1.28612649\n",
      "Trained batch 994 batch loss 1.32695162 epoch total loss 1.28616762\n",
      "Trained batch 995 batch loss 1.25349784 epoch total loss 1.28613472\n",
      "Trained batch 996 batch loss 1.25978327 epoch total loss 1.28610826\n",
      "Trained batch 997 batch loss 1.13181305 epoch total loss 1.28595352\n",
      "Trained batch 998 batch loss 1.24219275 epoch total loss 1.28590965\n",
      "Trained batch 999 batch loss 1.15135622 epoch total loss 1.28577507\n",
      "Trained batch 1000 batch loss 1.16985536 epoch total loss 1.28565907\n",
      "Trained batch 1001 batch loss 1.28223121 epoch total loss 1.28565562\n",
      "Trained batch 1002 batch loss 1.22504604 epoch total loss 1.28559518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1003 batch loss 1.20105684 epoch total loss 1.2855109\n",
      "Trained batch 1004 batch loss 1.20709276 epoch total loss 1.28543282\n",
      "Trained batch 1005 batch loss 1.19485211 epoch total loss 1.28534269\n",
      "Trained batch 1006 batch loss 1.1807971 epoch total loss 1.28523874\n",
      "Trained batch 1007 batch loss 1.2715199 epoch total loss 1.28522515\n",
      "Trained batch 1008 batch loss 1.23453069 epoch total loss 1.28517473\n",
      "Trained batch 1009 batch loss 1.20833373 epoch total loss 1.28509867\n",
      "Trained batch 1010 batch loss 1.14039397 epoch total loss 1.28495538\n",
      "Trained batch 1011 batch loss 1.22561324 epoch total loss 1.28489661\n",
      "Trained batch 1012 batch loss 1.27384639 epoch total loss 1.28488564\n",
      "Trained batch 1013 batch loss 1.30138445 epoch total loss 1.28490198\n",
      "Trained batch 1014 batch loss 1.2518605 epoch total loss 1.28486931\n",
      "Trained batch 1015 batch loss 1.2443769 epoch total loss 1.2848295\n",
      "Trained batch 1016 batch loss 1.09354556 epoch total loss 1.28464115\n",
      "Trained batch 1017 batch loss 1.19261646 epoch total loss 1.28455067\n",
      "Trained batch 1018 batch loss 1.20536494 epoch total loss 1.28447282\n",
      "Trained batch 1019 batch loss 1.17726028 epoch total loss 1.28436768\n",
      "Trained batch 1020 batch loss 1.33976126 epoch total loss 1.28442192\n",
      "Trained batch 1021 batch loss 1.36992955 epoch total loss 1.28450561\n",
      "Trained batch 1022 batch loss 1.35843158 epoch total loss 1.28457797\n",
      "Trained batch 1023 batch loss 1.30884743 epoch total loss 1.28460157\n",
      "Trained batch 1024 batch loss 1.39365637 epoch total loss 1.28470814\n",
      "Trained batch 1025 batch loss 1.42963338 epoch total loss 1.28484964\n",
      "Trained batch 1026 batch loss 1.23003531 epoch total loss 1.28479612\n",
      "Trained batch 1027 batch loss 1.19467878 epoch total loss 1.28470838\n",
      "Trained batch 1028 batch loss 1.07612896 epoch total loss 1.28450549\n",
      "Trained batch 1029 batch loss 1.15149784 epoch total loss 1.28437626\n",
      "Trained batch 1030 batch loss 1.07849503 epoch total loss 1.28417635\n",
      "Trained batch 1031 batch loss 1.14137185 epoch total loss 1.28403783\n",
      "Trained batch 1032 batch loss 1.08648014 epoch total loss 1.28384638\n",
      "Trained batch 1033 batch loss 0.979285717 epoch total loss 1.28355145\n",
      "Trained batch 1034 batch loss 1.01090419 epoch total loss 1.28328776\n",
      "Trained batch 1035 batch loss 0.967423677 epoch total loss 1.28298259\n",
      "Trained batch 1036 batch loss 1.23790872 epoch total loss 1.28293908\n",
      "Trained batch 1037 batch loss 1.20266199 epoch total loss 1.28286159\n",
      "Trained batch 1038 batch loss 1.22110319 epoch total loss 1.2828021\n",
      "Trained batch 1039 batch loss 1.27526426 epoch total loss 1.28279483\n",
      "Trained batch 1040 batch loss 1.2094847 epoch total loss 1.28272438\n",
      "Trained batch 1041 batch loss 1.35691237 epoch total loss 1.28279567\n",
      "Trained batch 1042 batch loss 1.40361285 epoch total loss 1.28291154\n",
      "Trained batch 1043 batch loss 1.40588188 epoch total loss 1.28302944\n",
      "Trained batch 1044 batch loss 1.27861917 epoch total loss 1.28302515\n",
      "Trained batch 1045 batch loss 1.16191411 epoch total loss 1.28290927\n",
      "Trained batch 1046 batch loss 1.31478274 epoch total loss 1.28293967\n",
      "Trained batch 1047 batch loss 1.22757208 epoch total loss 1.28288686\n",
      "Trained batch 1048 batch loss 1.26727116 epoch total loss 1.28287184\n",
      "Trained batch 1049 batch loss 1.09371591 epoch total loss 1.2826916\n",
      "Trained batch 1050 batch loss 1.05691099 epoch total loss 1.28247654\n",
      "Trained batch 1051 batch loss 1.08719695 epoch total loss 1.2822907\n",
      "Trained batch 1052 batch loss 1.21410704 epoch total loss 1.28222585\n",
      "Trained batch 1053 batch loss 1.12827063 epoch total loss 1.2820797\n",
      "Trained batch 1054 batch loss 1.16187072 epoch total loss 1.28196561\n",
      "Trained batch 1055 batch loss 1.25617063 epoch total loss 1.28194118\n",
      "Trained batch 1056 batch loss 1.23315334 epoch total loss 1.28189504\n",
      "Trained batch 1057 batch loss 1.25463033 epoch total loss 1.28186929\n",
      "Trained batch 1058 batch loss 1.14356709 epoch total loss 1.28173852\n",
      "Trained batch 1059 batch loss 1.12918651 epoch total loss 1.2815944\n",
      "Trained batch 1060 batch loss 1.35360885 epoch total loss 1.28166234\n",
      "Trained batch 1061 batch loss 1.29775822 epoch total loss 1.28167748\n",
      "Trained batch 1062 batch loss 1.325037 epoch total loss 1.28171837\n",
      "Trained batch 1063 batch loss 1.28343654 epoch total loss 1.28172\n",
      "Trained batch 1064 batch loss 1.31001604 epoch total loss 1.28174663\n",
      "Trained batch 1065 batch loss 1.44947577 epoch total loss 1.2819041\n",
      "Trained batch 1066 batch loss 1.41813147 epoch total loss 1.28203189\n",
      "Trained batch 1067 batch loss 1.347821 epoch total loss 1.28209352\n",
      "Trained batch 1068 batch loss 1.43347239 epoch total loss 1.28223526\n",
      "Trained batch 1069 batch loss 1.30933928 epoch total loss 1.28226054\n",
      "Trained batch 1070 batch loss 1.21922541 epoch total loss 1.28220165\n",
      "Trained batch 1071 batch loss 1.22738934 epoch total loss 1.28215051\n",
      "Trained batch 1072 batch loss 1.38375795 epoch total loss 1.2822454\n",
      "Trained batch 1073 batch loss 1.46858144 epoch total loss 1.28241909\n",
      "Trained batch 1074 batch loss 1.28088832 epoch total loss 1.28241765\n",
      "Trained batch 1075 batch loss 1.2269702 epoch total loss 1.28236604\n",
      "Trained batch 1076 batch loss 1.35581601 epoch total loss 1.28243434\n",
      "Trained batch 1077 batch loss 1.22822142 epoch total loss 1.28238404\n",
      "Trained batch 1078 batch loss 1.28690982 epoch total loss 1.28238821\n",
      "Trained batch 1079 batch loss 1.33708465 epoch total loss 1.28243876\n",
      "Trained batch 1080 batch loss 1.35956526 epoch total loss 1.28251028\n",
      "Trained batch 1081 batch loss 1.43455338 epoch total loss 1.28265095\n",
      "Trained batch 1082 batch loss 1.26575685 epoch total loss 1.28263533\n",
      "Trained batch 1083 batch loss 1.25804782 epoch total loss 1.28261256\n",
      "Trained batch 1084 batch loss 1.23803711 epoch total loss 1.28257143\n",
      "Trained batch 1085 batch loss 1.22040772 epoch total loss 1.28251421\n",
      "Trained batch 1086 batch loss 1.3038609 epoch total loss 1.28253388\n",
      "Trained batch 1087 batch loss 1.27293563 epoch total loss 1.28252506\n",
      "Trained batch 1088 batch loss 1.39615273 epoch total loss 1.28262949\n",
      "Trained batch 1089 batch loss 1.31714475 epoch total loss 1.2826612\n",
      "Trained batch 1090 batch loss 1.30303311 epoch total loss 1.2826798\n",
      "Trained batch 1091 batch loss 1.33870745 epoch total loss 1.28273118\n",
      "Trained batch 1092 batch loss 1.31126463 epoch total loss 1.28275728\n",
      "Trained batch 1093 batch loss 1.34485435 epoch total loss 1.28281415\n",
      "Trained batch 1094 batch loss 1.23390865 epoch total loss 1.28276944\n",
      "Trained batch 1095 batch loss 1.3014307 epoch total loss 1.28278637\n",
      "Trained batch 1096 batch loss 1.21393108 epoch total loss 1.28272367\n",
      "Trained batch 1097 batch loss 1.34598088 epoch total loss 1.28278124\n",
      "Trained batch 1098 batch loss 1.2842716 epoch total loss 1.28278267\n",
      "Trained batch 1099 batch loss 1.19924235 epoch total loss 1.28270662\n",
      "Trained batch 1100 batch loss 1.10850716 epoch total loss 1.28254831\n",
      "Trained batch 1101 batch loss 1.12613869 epoch total loss 1.28240621\n",
      "Trained batch 1102 batch loss 1.12797201 epoch total loss 1.28226602\n",
      "Trained batch 1103 batch loss 1.20127249 epoch total loss 1.28219259\n",
      "Trained batch 1104 batch loss 1.25157142 epoch total loss 1.28216481\n",
      "Trained batch 1105 batch loss 1.07745612 epoch total loss 1.28197968\n",
      "Trained batch 1106 batch loss 1.11628592 epoch total loss 1.28182983\n",
      "Trained batch 1107 batch loss 1.07804024 epoch total loss 1.28164577\n",
      "Trained batch 1108 batch loss 1.07721472 epoch total loss 1.28146136\n",
      "Trained batch 1109 batch loss 1.10475326 epoch total loss 1.28130198\n",
      "Trained batch 1110 batch loss 1.16623282 epoch total loss 1.28119826\n",
      "Trained batch 1111 batch loss 1.21882772 epoch total loss 1.28114223\n",
      "Trained batch 1112 batch loss 1.18567705 epoch total loss 1.2810564\n",
      "Trained batch 1113 batch loss 1.19358277 epoch total loss 1.28097773\n",
      "Trained batch 1114 batch loss 1.19578838 epoch total loss 1.28090131\n",
      "Trained batch 1115 batch loss 1.1854713 epoch total loss 1.28081572\n",
      "Trained batch 1116 batch loss 1.3243897 epoch total loss 1.2808547\n",
      "Trained batch 1117 batch loss 1.25702322 epoch total loss 1.28083336\n",
      "Trained batch 1118 batch loss 1.08688 epoch total loss 1.28065991\n",
      "Trained batch 1119 batch loss 1.12850225 epoch total loss 1.28052402\n",
      "Trained batch 1120 batch loss 1.18058801 epoch total loss 1.28043473\n",
      "Trained batch 1121 batch loss 1.25621819 epoch total loss 1.28041315\n",
      "Trained batch 1122 batch loss 1.32747006 epoch total loss 1.28045511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1123 batch loss 1.53603947 epoch total loss 1.28068268\n",
      "Trained batch 1124 batch loss 1.50661922 epoch total loss 1.28088367\n",
      "Trained batch 1125 batch loss 1.26824737 epoch total loss 1.28087234\n",
      "Trained batch 1126 batch loss 1.20579374 epoch total loss 1.28080571\n",
      "Trained batch 1127 batch loss 1.18041205 epoch total loss 1.28071666\n",
      "Trained batch 1128 batch loss 1.24594951 epoch total loss 1.2806859\n",
      "Trained batch 1129 batch loss 1.31285715 epoch total loss 1.28071439\n",
      "Trained batch 1130 batch loss 1.25980628 epoch total loss 1.2806958\n",
      "Trained batch 1131 batch loss 1.25891757 epoch total loss 1.2806766\n",
      "Trained batch 1132 batch loss 1.32748032 epoch total loss 1.28071797\n",
      "Trained batch 1133 batch loss 1.42581558 epoch total loss 1.280846\n",
      "Trained batch 1134 batch loss 1.44727802 epoch total loss 1.28099275\n",
      "Trained batch 1135 batch loss 1.28206837 epoch total loss 1.2809937\n",
      "Trained batch 1136 batch loss 1.27292752 epoch total loss 1.28098667\n",
      "Trained batch 1137 batch loss 1.24762797 epoch total loss 1.28095734\n",
      "Trained batch 1138 batch loss 1.24521983 epoch total loss 1.28092599\n",
      "Trained batch 1139 batch loss 1.34950447 epoch total loss 1.28098619\n",
      "Trained batch 1140 batch loss 1.31200957 epoch total loss 1.28101337\n",
      "Trained batch 1141 batch loss 1.55275977 epoch total loss 1.28125155\n",
      "Trained batch 1142 batch loss 1.45443082 epoch total loss 1.28140318\n",
      "Trained batch 1143 batch loss 1.31444299 epoch total loss 1.28143203\n",
      "Trained batch 1144 batch loss 1.40166259 epoch total loss 1.28153718\n",
      "Trained batch 1145 batch loss 1.35101295 epoch total loss 1.28159773\n",
      "Trained batch 1146 batch loss 1.37242818 epoch total loss 1.28167701\n",
      "Trained batch 1147 batch loss 1.32789636 epoch total loss 1.2817173\n",
      "Trained batch 1148 batch loss 1.26783228 epoch total loss 1.28170526\n",
      "Trained batch 1149 batch loss 1.18752813 epoch total loss 1.28162324\n",
      "Trained batch 1150 batch loss 1.27640414 epoch total loss 1.2816186\n",
      "Trained batch 1151 batch loss 1.24523342 epoch total loss 1.281587\n",
      "Trained batch 1152 batch loss 1.27361655 epoch total loss 1.28158009\n",
      "Trained batch 1153 batch loss 1.34867167 epoch total loss 1.28163826\n",
      "Trained batch 1154 batch loss 1.25232506 epoch total loss 1.28161287\n",
      "Trained batch 1155 batch loss 1.35486579 epoch total loss 1.28167629\n",
      "Trained batch 1156 batch loss 1.28934395 epoch total loss 1.28168285\n",
      "Trained batch 1157 batch loss 1.27349162 epoch total loss 1.2816757\n",
      "Trained batch 1158 batch loss 1.1622808 epoch total loss 1.28157258\n",
      "Trained batch 1159 batch loss 1.31542945 epoch total loss 1.28160179\n",
      "Trained batch 1160 batch loss 1.19255614 epoch total loss 1.28152502\n",
      "Trained batch 1161 batch loss 1.40205634 epoch total loss 1.28162885\n",
      "Trained batch 1162 batch loss 1.32782865 epoch total loss 1.28166866\n",
      "Trained batch 1163 batch loss 1.24236548 epoch total loss 1.28163481\n",
      "Trained batch 1164 batch loss 1.31260395 epoch total loss 1.28166139\n",
      "Trained batch 1165 batch loss 1.32787049 epoch total loss 1.28170109\n",
      "Trained batch 1166 batch loss 1.25499761 epoch total loss 1.2816782\n",
      "Trained batch 1167 batch loss 1.11897182 epoch total loss 1.28153884\n",
      "Trained batch 1168 batch loss 1.25024045 epoch total loss 1.28151202\n",
      "Trained batch 1169 batch loss 1.36011565 epoch total loss 1.28157926\n",
      "Trained batch 1170 batch loss 1.28314281 epoch total loss 1.28158069\n",
      "Trained batch 1171 batch loss 1.30941916 epoch total loss 1.28160441\n",
      "Trained batch 1172 batch loss 1.25054622 epoch total loss 1.28157783\n",
      "Trained batch 1173 batch loss 1.21504796 epoch total loss 1.2815212\n",
      "Trained batch 1174 batch loss 1.35058904 epoch total loss 1.28158\n",
      "Trained batch 1175 batch loss 1.32185125 epoch total loss 1.2816143\n",
      "Trained batch 1176 batch loss 1.25073791 epoch total loss 1.28158808\n",
      "Trained batch 1177 batch loss 1.18195236 epoch total loss 1.28150344\n",
      "Trained batch 1178 batch loss 1.2084589 epoch total loss 1.28144145\n",
      "Trained batch 1179 batch loss 1.09567714 epoch total loss 1.28128397\n",
      "Trained batch 1180 batch loss 1.16086793 epoch total loss 1.28118193\n",
      "Trained batch 1181 batch loss 1.25733495 epoch total loss 1.28116179\n",
      "Trained batch 1182 batch loss 1.31241345 epoch total loss 1.28118813\n",
      "Trained batch 1183 batch loss 1.21902013 epoch total loss 1.28113556\n",
      "Trained batch 1184 batch loss 1.10841107 epoch total loss 1.28098965\n",
      "Trained batch 1185 batch loss 1.15514195 epoch total loss 1.28088343\n",
      "Trained batch 1186 batch loss 1.34668839 epoch total loss 1.28093898\n",
      "Trained batch 1187 batch loss 1.44958842 epoch total loss 1.28108108\n",
      "Trained batch 1188 batch loss 1.20932353 epoch total loss 1.28102064\n",
      "Trained batch 1189 batch loss 1.21731961 epoch total loss 1.280967\n",
      "Trained batch 1190 batch loss 1.05295992 epoch total loss 1.28077543\n",
      "Trained batch 1191 batch loss 1.04919839 epoch total loss 1.280581\n",
      "Trained batch 1192 batch loss 1.00530028 epoch total loss 1.28035009\n",
      "Trained batch 1193 batch loss 1.08309186 epoch total loss 1.28018475\n",
      "Trained batch 1194 batch loss 1.06845164 epoch total loss 1.28000736\n",
      "Trained batch 1195 batch loss 1.11587691 epoch total loss 1.27987\n",
      "Trained batch 1196 batch loss 1.14787149 epoch total loss 1.27975965\n",
      "Trained batch 1197 batch loss 1.20957923 epoch total loss 1.27970099\n",
      "Trained batch 1198 batch loss 1.29682839 epoch total loss 1.2797153\n",
      "Trained batch 1199 batch loss 1.33071363 epoch total loss 1.27975786\n",
      "Trained batch 1200 batch loss 1.34248841 epoch total loss 1.27981019\n",
      "Trained batch 1201 batch loss 1.33606577 epoch total loss 1.27985704\n",
      "Trained batch 1202 batch loss 1.27200723 epoch total loss 1.27985048\n",
      "Trained batch 1203 batch loss 1.3216269 epoch total loss 1.27988517\n",
      "Trained batch 1204 batch loss 1.22980392 epoch total loss 1.27984369\n",
      "Trained batch 1205 batch loss 1.30568171 epoch total loss 1.27986503\n",
      "Trained batch 1206 batch loss 1.2551403 epoch total loss 1.27984452\n",
      "Trained batch 1207 batch loss 1.3964901 epoch total loss 1.2799412\n",
      "Trained batch 1208 batch loss 1.38018978 epoch total loss 1.28002429\n",
      "Trained batch 1209 batch loss 1.2999835 epoch total loss 1.28004074\n",
      "Trained batch 1210 batch loss 1.29024982 epoch total loss 1.2800492\n",
      "Trained batch 1211 batch loss 1.35599589 epoch total loss 1.28011191\n",
      "Trained batch 1212 batch loss 1.38141441 epoch total loss 1.28019547\n",
      "Trained batch 1213 batch loss 1.27462232 epoch total loss 1.28019094\n",
      "Trained batch 1214 batch loss 1.28720784 epoch total loss 1.28019667\n",
      "Trained batch 1215 batch loss 1.17261434 epoch total loss 1.28010821\n",
      "Trained batch 1216 batch loss 1.20771909 epoch total loss 1.28004873\n",
      "Trained batch 1217 batch loss 1.18269551 epoch total loss 1.27996874\n",
      "Trained batch 1218 batch loss 1.23474765 epoch total loss 1.27993155\n",
      "Trained batch 1219 batch loss 1.23215222 epoch total loss 1.27989244\n",
      "Trained batch 1220 batch loss 1.29760265 epoch total loss 1.27990687\n",
      "Trained batch 1221 batch loss 1.32380104 epoch total loss 1.27994287\n",
      "Trained batch 1222 batch loss 1.21705186 epoch total loss 1.27989149\n",
      "Trained batch 1223 batch loss 1.15366125 epoch total loss 1.27978826\n",
      "Trained batch 1224 batch loss 1.15566993 epoch total loss 1.27968681\n",
      "Trained batch 1225 batch loss 1.21103573 epoch total loss 1.27963078\n",
      "Trained batch 1226 batch loss 1.18174326 epoch total loss 1.27955103\n",
      "Trained batch 1227 batch loss 1.31194985 epoch total loss 1.27957737\n",
      "Trained batch 1228 batch loss 1.30244303 epoch total loss 1.27959597\n",
      "Trained batch 1229 batch loss 1.28929639 epoch total loss 1.27960384\n",
      "Trained batch 1230 batch loss 1.24329853 epoch total loss 1.27957439\n",
      "Trained batch 1231 batch loss 1.24673247 epoch total loss 1.27954769\n",
      "Trained batch 1232 batch loss 1.28088307 epoch total loss 1.27954876\n",
      "Trained batch 1233 batch loss 1.24439168 epoch total loss 1.27952027\n",
      "Trained batch 1234 batch loss 1.31407332 epoch total loss 1.27954829\n",
      "Trained batch 1235 batch loss 1.32217717 epoch total loss 1.27958274\n",
      "Trained batch 1236 batch loss 1.3619014 epoch total loss 1.27964938\n",
      "Trained batch 1237 batch loss 1.3994447 epoch total loss 1.27974617\n",
      "Trained batch 1238 batch loss 1.43284452 epoch total loss 1.27986991\n",
      "Trained batch 1239 batch loss 1.09577823 epoch total loss 1.27972126\n",
      "Trained batch 1240 batch loss 1.11869836 epoch total loss 1.27959144\n",
      "Trained batch 1241 batch loss 1.18291163 epoch total loss 1.27951348\n",
      "Trained batch 1242 batch loss 1.15934825 epoch total loss 1.27941668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1243 batch loss 1.2928021 epoch total loss 1.27942753\n",
      "Trained batch 1244 batch loss 1.20107 epoch total loss 1.27936447\n",
      "Trained batch 1245 batch loss 1.3389405 epoch total loss 1.27941239\n",
      "Trained batch 1246 batch loss 1.17781973 epoch total loss 1.27933085\n",
      "Trained batch 1247 batch loss 1.32260978 epoch total loss 1.27936554\n",
      "Trained batch 1248 batch loss 1.28037524 epoch total loss 1.27936637\n",
      "Trained batch 1249 batch loss 1.39815235 epoch total loss 1.2794615\n",
      "Trained batch 1250 batch loss 1.46916509 epoch total loss 1.27961326\n",
      "Trained batch 1251 batch loss 1.49295425 epoch total loss 1.27978384\n",
      "Trained batch 1252 batch loss 1.4321413 epoch total loss 1.27990544\n",
      "Trained batch 1253 batch loss 1.24526787 epoch total loss 1.27987778\n",
      "Trained batch 1254 batch loss 1.1681776 epoch total loss 1.27978873\n",
      "Trained batch 1255 batch loss 1.40249872 epoch total loss 1.27988648\n",
      "Trained batch 1256 batch loss 1.45970893 epoch total loss 1.28002965\n",
      "Trained batch 1257 batch loss 1.34927726 epoch total loss 1.28008473\n",
      "Trained batch 1258 batch loss 1.38880503 epoch total loss 1.28017116\n",
      "Trained batch 1259 batch loss 1.34498954 epoch total loss 1.28022265\n",
      "Trained batch 1260 batch loss 1.28316045 epoch total loss 1.28022504\n",
      "Trained batch 1261 batch loss 1.24450684 epoch total loss 1.28019667\n",
      "Trained batch 1262 batch loss 1.13791013 epoch total loss 1.28008389\n",
      "Trained batch 1263 batch loss 1.1144222 epoch total loss 1.27995276\n",
      "Trained batch 1264 batch loss 1.18016291 epoch total loss 1.27987385\n",
      "Trained batch 1265 batch loss 1.34097052 epoch total loss 1.27992213\n",
      "Trained batch 1266 batch loss 1.30699944 epoch total loss 1.27994347\n",
      "Trained batch 1267 batch loss 1.44841146 epoch total loss 1.28007638\n",
      "Trained batch 1268 batch loss 1.46988451 epoch total loss 1.28022611\n",
      "Trained batch 1269 batch loss 1.37402463 epoch total loss 1.2803\n",
      "Trained batch 1270 batch loss 1.3143369 epoch total loss 1.28032672\n",
      "Trained batch 1271 batch loss 1.2832638 epoch total loss 1.28032899\n",
      "Trained batch 1272 batch loss 1.09990561 epoch total loss 1.28018713\n",
      "Trained batch 1273 batch loss 1.1724385 epoch total loss 1.28010261\n",
      "Trained batch 1274 batch loss 1.23152018 epoch total loss 1.28006446\n",
      "Trained batch 1275 batch loss 1.2602129 epoch total loss 1.28004897\n",
      "Trained batch 1276 batch loss 1.28869092 epoch total loss 1.28005564\n",
      "Trained batch 1277 batch loss 1.35008943 epoch total loss 1.2801106\n",
      "Trained batch 1278 batch loss 1.25614762 epoch total loss 1.28009176\n",
      "Trained batch 1279 batch loss 1.21503687 epoch total loss 1.28004098\n",
      "Trained batch 1280 batch loss 1.23191655 epoch total loss 1.28000331\n",
      "Trained batch 1281 batch loss 1.22334719 epoch total loss 1.2799592\n",
      "Trained batch 1282 batch loss 1.27223158 epoch total loss 1.27995312\n",
      "Trained batch 1283 batch loss 1.29501784 epoch total loss 1.27996492\n",
      "Trained batch 1284 batch loss 1.22241628 epoch total loss 1.2799201\n",
      "Trained batch 1285 batch loss 1.19344032 epoch total loss 1.27985275\n",
      "Trained batch 1286 batch loss 1.15761185 epoch total loss 1.27975774\n",
      "Trained batch 1287 batch loss 1.25364888 epoch total loss 1.27973747\n",
      "Trained batch 1288 batch loss 1.2734462 epoch total loss 1.27973258\n",
      "Trained batch 1289 batch loss 1.35634124 epoch total loss 1.27979195\n",
      "Trained batch 1290 batch loss 1.25180566 epoch total loss 1.27977026\n",
      "Trained batch 1291 batch loss 1.22593772 epoch total loss 1.27972865\n",
      "Trained batch 1292 batch loss 1.20428562 epoch total loss 1.27967024\n",
      "Trained batch 1293 batch loss 1.18714142 epoch total loss 1.27959871\n",
      "Trained batch 1294 batch loss 1.24625635 epoch total loss 1.27957284\n",
      "Trained batch 1295 batch loss 1.34407592 epoch total loss 1.27962279\n",
      "Trained batch 1296 batch loss 1.35125279 epoch total loss 1.27967799\n",
      "Trained batch 1297 batch loss 1.41088641 epoch total loss 1.27977908\n",
      "Trained batch 1298 batch loss 1.38620853 epoch total loss 1.27986109\n",
      "Trained batch 1299 batch loss 1.31744885 epoch total loss 1.27989018\n",
      "Trained batch 1300 batch loss 1.22509968 epoch total loss 1.27984798\n",
      "Trained batch 1301 batch loss 1.16512227 epoch total loss 1.27975976\n",
      "Trained batch 1302 batch loss 1.18189335 epoch total loss 1.27968466\n",
      "Trained batch 1303 batch loss 1.22248805 epoch total loss 1.27964079\n",
      "Trained batch 1304 batch loss 1.19076145 epoch total loss 1.27957261\n",
      "Trained batch 1305 batch loss 1.14361644 epoch total loss 1.27946854\n",
      "Trained batch 1306 batch loss 1.30940294 epoch total loss 1.27949142\n",
      "Trained batch 1307 batch loss 1.35506272 epoch total loss 1.27954936\n",
      "Trained batch 1308 batch loss 1.53170323 epoch total loss 1.27974212\n",
      "Trained batch 1309 batch loss 1.43609393 epoch total loss 1.27986157\n",
      "Trained batch 1310 batch loss 1.36873 epoch total loss 1.2799294\n",
      "Trained batch 1311 batch loss 1.29497266 epoch total loss 1.27994084\n",
      "Trained batch 1312 batch loss 1.44029808 epoch total loss 1.28006303\n",
      "Trained batch 1313 batch loss 1.32543504 epoch total loss 1.2800976\n",
      "Trained batch 1314 batch loss 1.29146528 epoch total loss 1.28010631\n",
      "Trained batch 1315 batch loss 1.25563049 epoch total loss 1.28008771\n",
      "Trained batch 1316 batch loss 1.17406559 epoch total loss 1.28000712\n",
      "Trained batch 1317 batch loss 1.27768898 epoch total loss 1.28000534\n",
      "Trained batch 1318 batch loss 1.30864811 epoch total loss 1.28002703\n",
      "Trained batch 1319 batch loss 1.30797148 epoch total loss 1.28004825\n",
      "Trained batch 1320 batch loss 1.23961449 epoch total loss 1.28001761\n",
      "Trained batch 1321 batch loss 1.25829411 epoch total loss 1.28000116\n",
      "Trained batch 1322 batch loss 1.22305477 epoch total loss 1.27995813\n",
      "Trained batch 1323 batch loss 1.22873211 epoch total loss 1.27991939\n",
      "Trained batch 1324 batch loss 1.16249812 epoch total loss 1.27983069\n",
      "Trained batch 1325 batch loss 1.15912223 epoch total loss 1.27973962\n",
      "Trained batch 1326 batch loss 1.10573483 epoch total loss 1.27960837\n",
      "Trained batch 1327 batch loss 1.06996083 epoch total loss 1.27945042\n",
      "Trained batch 1328 batch loss 1.17806315 epoch total loss 1.27937412\n",
      "Trained batch 1329 batch loss 1.32707095 epoch total loss 1.27940989\n",
      "Trained batch 1330 batch loss 1.22361028 epoch total loss 1.27936804\n",
      "Trained batch 1331 batch loss 1.2945416 epoch total loss 1.27937937\n",
      "Trained batch 1332 batch loss 1.377352 epoch total loss 1.27945292\n",
      "Trained batch 1333 batch loss 1.20205092 epoch total loss 1.27939487\n",
      "Trained batch 1334 batch loss 1.25609779 epoch total loss 1.27937746\n",
      "Trained batch 1335 batch loss 1.21313214 epoch total loss 1.27932775\n",
      "Trained batch 1336 batch loss 1.27593875 epoch total loss 1.27932525\n",
      "Trained batch 1337 batch loss 1.2915926 epoch total loss 1.27933443\n",
      "Trained batch 1338 batch loss 0.998169065 epoch total loss 1.27912426\n",
      "Trained batch 1339 batch loss 0.968638957 epoch total loss 1.2788924\n",
      "Trained batch 1340 batch loss 1.08510423 epoch total loss 1.2787478\n",
      "Trained batch 1341 batch loss 1.20977962 epoch total loss 1.2786963\n",
      "Trained batch 1342 batch loss 1.42420125 epoch total loss 1.27880478\n",
      "Trained batch 1343 batch loss 1.49306619 epoch total loss 1.27896428\n",
      "Trained batch 1344 batch loss 1.38724625 epoch total loss 1.27904487\n",
      "Trained batch 1345 batch loss 1.32422638 epoch total loss 1.27907836\n",
      "Trained batch 1346 batch loss 1.40578222 epoch total loss 1.27917254\n",
      "Trained batch 1347 batch loss 1.40167189 epoch total loss 1.27926338\n",
      "Trained batch 1348 batch loss 1.34540391 epoch total loss 1.27931249\n",
      "Trained batch 1349 batch loss 1.17703581 epoch total loss 1.27923667\n",
      "Trained batch 1350 batch loss 1.21067309 epoch total loss 1.27918589\n",
      "Trained batch 1351 batch loss 1.13493216 epoch total loss 1.27907908\n",
      "Trained batch 1352 batch loss 1.35252 epoch total loss 1.27913344\n",
      "Trained batch 1353 batch loss 1.32135427 epoch total loss 1.27916467\n",
      "Trained batch 1354 batch loss 1.24212098 epoch total loss 1.27913725\n",
      "Trained batch 1355 batch loss 1.23603606 epoch total loss 1.27910554\n",
      "Trained batch 1356 batch loss 1.24725235 epoch total loss 1.27908194\n",
      "Trained batch 1357 batch loss 1.25415218 epoch total loss 1.27906358\n",
      "Trained batch 1358 batch loss 1.18679 epoch total loss 1.27899563\n",
      "Trained batch 1359 batch loss 1.22921968 epoch total loss 1.27895904\n",
      "Trained batch 1360 batch loss 1.19699144 epoch total loss 1.27889884\n",
      "Trained batch 1361 batch loss 1.21842563 epoch total loss 1.27885437\n",
      "Trained batch 1362 batch loss 1.3045454 epoch total loss 1.27887321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1363 batch loss 1.30851579 epoch total loss 1.2788949\n",
      "Trained batch 1364 batch loss 1.19512606 epoch total loss 1.27883351\n",
      "Trained batch 1365 batch loss 1.15955043 epoch total loss 1.27874613\n",
      "Trained batch 1366 batch loss 1.15610766 epoch total loss 1.27865636\n",
      "Trained batch 1367 batch loss 1.2510289 epoch total loss 1.2786361\n",
      "Trained batch 1368 batch loss 1.30471516 epoch total loss 1.27865517\n",
      "Trained batch 1369 batch loss 1.11134684 epoch total loss 1.27853286\n",
      "Trained batch 1370 batch loss 1.1040864 epoch total loss 1.27840555\n",
      "Trained batch 1371 batch loss 1.17979848 epoch total loss 1.27833366\n",
      "Trained batch 1372 batch loss 1.12223339 epoch total loss 1.27821982\n",
      "Trained batch 1373 batch loss 1.19448078 epoch total loss 1.2781589\n",
      "Trained batch 1374 batch loss 1.15329742 epoch total loss 1.27806795\n",
      "Trained batch 1375 batch loss 1.11801672 epoch total loss 1.2779516\n",
      "Trained batch 1376 batch loss 1.19034421 epoch total loss 1.27788794\n",
      "Trained batch 1377 batch loss 1.16972101 epoch total loss 1.27780938\n",
      "Trained batch 1378 batch loss 1.11425507 epoch total loss 1.27769065\n",
      "Trained batch 1379 batch loss 1.26103556 epoch total loss 1.27767849\n",
      "Trained batch 1380 batch loss 1.21175909 epoch total loss 1.27763081\n",
      "Trained batch 1381 batch loss 1.26878619 epoch total loss 1.27762437\n",
      "Trained batch 1382 batch loss 1.3642652 epoch total loss 1.27768707\n",
      "Trained batch 1383 batch loss 1.37445939 epoch total loss 1.27775705\n",
      "Trained batch 1384 batch loss 1.12259221 epoch total loss 1.27764499\n",
      "Trained batch 1385 batch loss 1.31209755 epoch total loss 1.27766991\n",
      "Trained batch 1386 batch loss 1.3152585 epoch total loss 1.27769697\n",
      "Trained batch 1387 batch loss 1.17564023 epoch total loss 1.27762341\n",
      "Trained batch 1388 batch loss 1.17000782 epoch total loss 1.27754593\n",
      "Epoch 3 train loss 1.2775459289550781\n",
      "Validated batch 1 batch loss 1.2583766\n",
      "Validated batch 2 batch loss 1.22959626\n",
      "Validated batch 3 batch loss 1.19137383\n",
      "Validated batch 4 batch loss 1.27750337\n",
      "Validated batch 5 batch loss 1.22688615\n",
      "Validated batch 6 batch loss 1.28550839\n",
      "Validated batch 7 batch loss 1.36867404\n",
      "Validated batch 8 batch loss 1.29053974\n",
      "Validated batch 9 batch loss 1.239591\n",
      "Validated batch 10 batch loss 1.20563173\n",
      "Validated batch 11 batch loss 1.31984508\n",
      "Validated batch 12 batch loss 1.22353435\n",
      "Validated batch 13 batch loss 1.26493406\n",
      "Validated batch 14 batch loss 1.35410249\n",
      "Validated batch 15 batch loss 1.30925441\n",
      "Validated batch 16 batch loss 1.24571133\n",
      "Validated batch 17 batch loss 1.41139579\n",
      "Validated batch 18 batch loss 1.13114893\n",
      "Validated batch 19 batch loss 1.31706619\n",
      "Validated batch 20 batch loss 1.03139532\n",
      "Validated batch 21 batch loss 1.24734533\n",
      "Validated batch 22 batch loss 1.31792879\n",
      "Validated batch 23 batch loss 1.14536166\n",
      "Validated batch 24 batch loss 1.26006746\n",
      "Validated batch 25 batch loss 1.17626262\n",
      "Validated batch 26 batch loss 1.24166656\n",
      "Validated batch 27 batch loss 1.12951171\n",
      "Validated batch 28 batch loss 1.20938635\n",
      "Validated batch 29 batch loss 1.2920562\n",
      "Validated batch 30 batch loss 1.2638036\n",
      "Validated batch 31 batch loss 1.37340593\n",
      "Validated batch 32 batch loss 1.30447054\n",
      "Validated batch 33 batch loss 1.23645031\n",
      "Validated batch 34 batch loss 1.27623475\n",
      "Validated batch 35 batch loss 1.35238314\n",
      "Validated batch 36 batch loss 1.33641934\n",
      "Validated batch 37 batch loss 1.3400172\n",
      "Validated batch 38 batch loss 1.32398784\n",
      "Validated batch 39 batch loss 1.3440057\n",
      "Validated batch 40 batch loss 1.32156527\n",
      "Validated batch 41 batch loss 1.16479468\n",
      "Validated batch 42 batch loss 1.23061228\n",
      "Validated batch 43 batch loss 1.32225859\n",
      "Validated batch 44 batch loss 1.26791465\n",
      "Validated batch 45 batch loss 1.25281262\n",
      "Validated batch 46 batch loss 1.23108029\n",
      "Validated batch 47 batch loss 1.21556485\n",
      "Validated batch 48 batch loss 1.22649932\n",
      "Validated batch 49 batch loss 1.21871173\n",
      "Validated batch 50 batch loss 1.15540242\n",
      "Validated batch 51 batch loss 1.18724537\n",
      "Validated batch 52 batch loss 1.3060267\n",
      "Validated batch 53 batch loss 1.19688249\n",
      "Validated batch 54 batch loss 1.0418551\n",
      "Validated batch 55 batch loss 1.16056979\n",
      "Validated batch 56 batch loss 1.15841067\n",
      "Validated batch 57 batch loss 1.11114383\n",
      "Validated batch 58 batch loss 1.21226954\n",
      "Validated batch 59 batch loss 1.21747732\n",
      "Validated batch 60 batch loss 1.20156622\n",
      "Validated batch 61 batch loss 1.31216347\n",
      "Validated batch 62 batch loss 1.31349945\n",
      "Validated batch 63 batch loss 1.18998313\n",
      "Validated batch 64 batch loss 1.33859944\n",
      "Validated batch 65 batch loss 0.99271524\n",
      "Validated batch 66 batch loss 1.18801057\n",
      "Validated batch 67 batch loss 1.13942099\n",
      "Validated batch 68 batch loss 1.21821213\n",
      "Validated batch 69 batch loss 1.39853525\n",
      "Validated batch 70 batch loss 1.1080687\n",
      "Validated batch 71 batch loss 1.26372302\n",
      "Validated batch 72 batch loss 1.35001755\n",
      "Validated batch 73 batch loss 1.18447685\n",
      "Validated batch 74 batch loss 1.29199541\n",
      "Validated batch 75 batch loss 1.41720557\n",
      "Validated batch 76 batch loss 1.14578021\n",
      "Validated batch 77 batch loss 1.25349069\n",
      "Validated batch 78 batch loss 1.27015328\n",
      "Validated batch 79 batch loss 1.32157254\n",
      "Validated batch 80 batch loss 1.29835975\n",
      "Validated batch 81 batch loss 1.16532397\n",
      "Validated batch 82 batch loss 1.08052254\n",
      "Validated batch 83 batch loss 1.22294438\n",
      "Validated batch 84 batch loss 1.20692801\n",
      "Validated batch 85 batch loss 1.19896233\n",
      "Validated batch 86 batch loss 1.2490778\n",
      "Validated batch 87 batch loss 1.16834033\n",
      "Validated batch 88 batch loss 1.25706124\n",
      "Validated batch 89 batch loss 1.32550263\n",
      "Validated batch 90 batch loss 1.30414474\n",
      "Validated batch 91 batch loss 1.24118662\n",
      "Validated batch 92 batch loss 1.13617134\n",
      "Validated batch 93 batch loss 1.25157917\n",
      "Validated batch 94 batch loss 1.0909971\n",
      "Validated batch 95 batch loss 1.21639383\n",
      "Validated batch 96 batch loss 1.17551219\n",
      "Validated batch 97 batch loss 1.20020187\n",
      "Validated batch 98 batch loss 1.22849226\n",
      "Validated batch 99 batch loss 1.25834787\n",
      "Validated batch 100 batch loss 1.23606396\n",
      "Validated batch 101 batch loss 1.2717334\n",
      "Validated batch 102 batch loss 1.17752838\n",
      "Validated batch 103 batch loss 1.27572823\n",
      "Validated batch 104 batch loss 1.24062932\n",
      "Validated batch 105 batch loss 1.13747501\n",
      "Validated batch 106 batch loss 1.18733418\n",
      "Validated batch 107 batch loss 1.27300346\n",
      "Validated batch 108 batch loss 1.1903491\n",
      "Validated batch 109 batch loss 1.37183762\n",
      "Validated batch 110 batch loss 1.28114915\n",
      "Validated batch 111 batch loss 1.20805991\n",
      "Validated batch 112 batch loss 1.29283822\n",
      "Validated batch 113 batch loss 1.20526278\n",
      "Validated batch 114 batch loss 1.14741528\n",
      "Validated batch 115 batch loss 1.19763553\n",
      "Validated batch 116 batch loss 1.37018538\n",
      "Validated batch 117 batch loss 1.24674046\n",
      "Validated batch 118 batch loss 1.20668948\n",
      "Validated batch 119 batch loss 1.26291728\n",
      "Validated batch 120 batch loss 1.18066037\n",
      "Validated batch 121 batch loss 1.27637386\n",
      "Validated batch 122 batch loss 1.27797067\n",
      "Validated batch 123 batch loss 1.23076308\n",
      "Validated batch 124 batch loss 1.19265819\n",
      "Validated batch 125 batch loss 1.27306604\n",
      "Validated batch 126 batch loss 1.28953207\n",
      "Validated batch 127 batch loss 1.33608246\n",
      "Validated batch 128 batch loss 1.28012204\n",
      "Validated batch 129 batch loss 1.15086019\n",
      "Validated batch 130 batch loss 1.20192\n",
      "Validated batch 131 batch loss 1.26587176\n",
      "Validated batch 132 batch loss 1.22236228\n",
      "Validated batch 133 batch loss 1.28590214\n",
      "Validated batch 134 batch loss 1.30116618\n",
      "Validated batch 135 batch loss 1.46739757\n",
      "Validated batch 136 batch loss 1.38319397\n",
      "Validated batch 137 batch loss 1.26294124\n",
      "Validated batch 138 batch loss 1.17928219\n",
      "Validated batch 139 batch loss 1.20631695\n",
      "Validated batch 140 batch loss 1.24792302\n",
      "Validated batch 141 batch loss 1.16015768\n",
      "Validated batch 142 batch loss 1.20094323\n",
      "Validated batch 143 batch loss 1.22457385\n",
      "Validated batch 144 batch loss 1.26080275\n",
      "Validated batch 145 batch loss 1.26571083\n",
      "Validated batch 146 batch loss 1.24867725\n",
      "Validated batch 147 batch loss 1.17713356\n",
      "Validated batch 148 batch loss 1.35253966\n",
      "Validated batch 149 batch loss 1.16256046\n",
      "Validated batch 150 batch loss 1.10076594\n",
      "Validated batch 151 batch loss 1.21640229\n",
      "Validated batch 152 batch loss 1.37437034\n",
      "Validated batch 153 batch loss 1.32431245\n",
      "Validated batch 154 batch loss 1.39331412\n",
      "Validated batch 155 batch loss 1.21129537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 156 batch loss 1.39420342\n",
      "Validated batch 157 batch loss 1.23803806\n",
      "Validated batch 158 batch loss 1.32662606\n",
      "Validated batch 159 batch loss 1.26378095\n",
      "Validated batch 160 batch loss 1.04160726\n",
      "Validated batch 161 batch loss 1.2010659\n",
      "Validated batch 162 batch loss 1.30095673\n",
      "Validated batch 163 batch loss 1.25090492\n",
      "Validated batch 164 batch loss 1.27229238\n",
      "Validated batch 165 batch loss 1.20953178\n",
      "Validated batch 166 batch loss 1.29980946\n",
      "Validated batch 167 batch loss 1.47855616\n",
      "Validated batch 168 batch loss 1.23018479\n",
      "Validated batch 169 batch loss 1.29145169\n",
      "Validated batch 170 batch loss 1.19948328\n",
      "Validated batch 171 batch loss 1.32495379\n",
      "Validated batch 172 batch loss 1.26902199\n",
      "Validated batch 173 batch loss 1.2500608\n",
      "Validated batch 174 batch loss 1.29431915\n",
      "Validated batch 175 batch loss 1.32022309\n",
      "Validated batch 176 batch loss 1.29748821\n",
      "Validated batch 177 batch loss 1.31874704\n",
      "Validated batch 178 batch loss 1.30197346\n",
      "Validated batch 179 batch loss 1.26175559\n",
      "Validated batch 180 batch loss 1.19702113\n",
      "Validated batch 181 batch loss 1.29099631\n",
      "Validated batch 182 batch loss 1.20110679\n",
      "Validated batch 183 batch loss 1.2377671\n",
      "Validated batch 184 batch loss 1.28712988\n",
      "Validated batch 185 batch loss 1.35094905\n",
      "Epoch 3 val loss 1.2480847835540771\n",
      "Model /aiffel/aiffel/mpii/models1/stacked_hourglass-epoch-3-loss-1.2481.h5 saved.\n",
      "Start epoch 4 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 1.50163007 epoch total loss 1.50163007\n",
      "Trained batch 2 batch loss 1.38761544 epoch total loss 1.44462276\n",
      "Trained batch 3 batch loss 1.38169098 epoch total loss 1.4236455\n",
      "Trained batch 4 batch loss 1.41930163 epoch total loss 1.4225595\n",
      "Trained batch 5 batch loss 1.32055247 epoch total loss 1.40215802\n",
      "Trained batch 6 batch loss 1.26725006 epoch total loss 1.37967336\n",
      "Trained batch 7 batch loss 1.20919275 epoch total loss 1.3553189\n",
      "Trained batch 8 batch loss 1.26503205 epoch total loss 1.344033\n",
      "Trained batch 9 batch loss 1.13779736 epoch total loss 1.32111788\n",
      "Trained batch 10 batch loss 1.27934945 epoch total loss 1.31694102\n",
      "Trained batch 11 batch loss 1.29615188 epoch total loss 1.3150512\n",
      "Trained batch 12 batch loss 1.29567015 epoch total loss 1.31343615\n",
      "Trained batch 13 batch loss 1.33269715 epoch total loss 1.3149178\n",
      "Trained batch 14 batch loss 1.25522077 epoch total loss 1.31065369\n",
      "Trained batch 15 batch loss 1.37503052 epoch total loss 1.31494546\n",
      "Trained batch 16 batch loss 1.2701925 epoch total loss 1.31214845\n",
      "Trained batch 17 batch loss 1.15750134 epoch total loss 1.30305159\n",
      "Trained batch 18 batch loss 1.06733143 epoch total loss 1.28995597\n",
      "Trained batch 19 batch loss 1.2413609 epoch total loss 1.28739834\n",
      "Trained batch 20 batch loss 1.33292615 epoch total loss 1.28967476\n",
      "Trained batch 21 batch loss 1.16185617 epoch total loss 1.28358817\n",
      "Trained batch 22 batch loss 1.26650119 epoch total loss 1.2828114\n",
      "Trained batch 23 batch loss 1.20512486 epoch total loss 1.27943373\n",
      "Trained batch 24 batch loss 1.17242694 epoch total loss 1.27497506\n",
      "Trained batch 25 batch loss 1.2479558 epoch total loss 1.27389431\n",
      "Trained batch 26 batch loss 1.28702474 epoch total loss 1.27439928\n",
      "Trained batch 27 batch loss 1.19177938 epoch total loss 1.2713393\n",
      "Trained batch 28 batch loss 1.19257236 epoch total loss 1.2685262\n",
      "Trained batch 29 batch loss 1.22736967 epoch total loss 1.26710713\n",
      "Trained batch 30 batch loss 1.21195602 epoch total loss 1.26526868\n",
      "Trained batch 31 batch loss 1.12184858 epoch total loss 1.26064229\n",
      "Trained batch 32 batch loss 1.18178034 epoch total loss 1.25817788\n",
      "Trained batch 33 batch loss 1.2749511 epoch total loss 1.25868618\n",
      "Trained batch 34 batch loss 1.37439692 epoch total loss 1.26208949\n",
      "Trained batch 35 batch loss 1.25971317 epoch total loss 1.26202154\n",
      "Trained batch 36 batch loss 1.20016313 epoch total loss 1.26030326\n",
      "Trained batch 37 batch loss 1.27186894 epoch total loss 1.26061594\n",
      "Trained batch 38 batch loss 1.31865549 epoch total loss 1.26214325\n",
      "Trained batch 39 batch loss 1.21169198 epoch total loss 1.26084971\n",
      "Trained batch 40 batch loss 1.23664618 epoch total loss 1.26024461\n",
      "Trained batch 41 batch loss 1.27703941 epoch total loss 1.26065421\n",
      "Trained batch 42 batch loss 1.17431843 epoch total loss 1.25859857\n",
      "Trained batch 43 batch loss 1.15369391 epoch total loss 1.25615895\n",
      "Trained batch 44 batch loss 1.11155272 epoch total loss 1.25287247\n",
      "Trained batch 45 batch loss 1.31058216 epoch total loss 1.25415492\n",
      "Trained batch 46 batch loss 1.36425495 epoch total loss 1.25654829\n",
      "Trained batch 47 batch loss 1.42435563 epoch total loss 1.26011872\n",
      "Trained batch 48 batch loss 1.43243563 epoch total loss 1.26370859\n",
      "Trained batch 49 batch loss 1.36647308 epoch total loss 1.26580584\n",
      "Trained batch 50 batch loss 1.20564532 epoch total loss 1.26460266\n",
      "Trained batch 51 batch loss 1.32700825 epoch total loss 1.26582634\n",
      "Trained batch 52 batch loss 1.22946727 epoch total loss 1.26512718\n",
      "Trained batch 53 batch loss 1.20373571 epoch total loss 1.26396883\n",
      "Trained batch 54 batch loss 1.15669751 epoch total loss 1.26198244\n",
      "Trained batch 55 batch loss 1.31202745 epoch total loss 1.26289225\n",
      "Trained batch 56 batch loss 1.35220969 epoch total loss 1.26448727\n",
      "Trained batch 57 batch loss 1.30329561 epoch total loss 1.26516819\n",
      "Trained batch 58 batch loss 1.17863846 epoch total loss 1.2636764\n",
      "Trained batch 59 batch loss 1.07216096 epoch total loss 1.26043034\n",
      "Trained batch 60 batch loss 1.11183369 epoch total loss 1.25795364\n",
      "Trained batch 61 batch loss 1.12270117 epoch total loss 1.25573647\n",
      "Trained batch 62 batch loss 1.1653198 epoch total loss 1.25427806\n",
      "Trained batch 63 batch loss 1.10056102 epoch total loss 1.25183821\n",
      "Trained batch 64 batch loss 1.17033112 epoch total loss 1.25056469\n",
      "Trained batch 65 batch loss 1.21446967 epoch total loss 1.25000942\n",
      "Trained batch 66 batch loss 1.15188563 epoch total loss 1.24852264\n",
      "Trained batch 67 batch loss 1.12884355 epoch total loss 1.24673641\n",
      "Trained batch 68 batch loss 1.16125417 epoch total loss 1.24547935\n",
      "Trained batch 69 batch loss 1.27550578 epoch total loss 1.24591446\n",
      "Trained batch 70 batch loss 1.33312118 epoch total loss 1.24716032\n",
      "Trained batch 71 batch loss 1.33831048 epoch total loss 1.2484442\n",
      "Trained batch 72 batch loss 1.33796072 epoch total loss 1.24968743\n",
      "Trained batch 73 batch loss 1.25571704 epoch total loss 1.24976993\n",
      "Trained batch 74 batch loss 1.2973485 epoch total loss 1.25041294\n",
      "Trained batch 75 batch loss 1.31799948 epoch total loss 1.25131404\n",
      "Trained batch 76 batch loss 1.25410843 epoch total loss 1.25135076\n",
      "Trained batch 77 batch loss 1.18990684 epoch total loss 1.25055277\n",
      "Trained batch 78 batch loss 1.1902 epoch total loss 1.24977899\n",
      "Trained batch 79 batch loss 1.200315 epoch total loss 1.2491529\n",
      "Trained batch 80 batch loss 1.21897495 epoch total loss 1.24877572\n",
      "Trained batch 81 batch loss 1.1075685 epoch total loss 1.2470324\n",
      "Trained batch 82 batch loss 1.3288765 epoch total loss 1.24803054\n",
      "Trained batch 83 batch loss 1.19810474 epoch total loss 1.24742901\n",
      "Trained batch 84 batch loss 1.19745588 epoch total loss 1.24683404\n",
      "Trained batch 85 batch loss 1.12883878 epoch total loss 1.24544585\n",
      "Trained batch 86 batch loss 1.19539809 epoch total loss 1.24486387\n",
      "Trained batch 87 batch loss 1.31217122 epoch total loss 1.24563754\n",
      "Trained batch 88 batch loss 1.35885906 epoch total loss 1.24692416\n",
      "Trained batch 89 batch loss 1.24129224 epoch total loss 1.24686086\n",
      "Trained batch 90 batch loss 1.22190809 epoch total loss 1.2465837\n",
      "Trained batch 91 batch loss 1.26659846 epoch total loss 1.24680364\n",
      "Trained batch 92 batch loss 1.25058353 epoch total loss 1.24684465\n",
      "Trained batch 93 batch loss 1.27880228 epoch total loss 1.24718833\n",
      "Trained batch 94 batch loss 1.19070029 epoch total loss 1.24658728\n",
      "Trained batch 95 batch loss 1.34930193 epoch total loss 1.2476685\n",
      "Trained batch 96 batch loss 1.30614686 epoch total loss 1.24827766\n",
      "Trained batch 97 batch loss 1.37522113 epoch total loss 1.24958634\n",
      "Trained batch 98 batch loss 1.34315598 epoch total loss 1.25054109\n",
      "Trained batch 99 batch loss 1.34791636 epoch total loss 1.25152469\n",
      "Trained batch 100 batch loss 1.24249816 epoch total loss 1.25143445\n",
      "Trained batch 101 batch loss 1.16660321 epoch total loss 1.25059462\n",
      "Trained batch 102 batch loss 1.23634267 epoch total loss 1.2504549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 103 batch loss 1.27022302 epoch total loss 1.25064683\n",
      "Trained batch 104 batch loss 1.21717441 epoch total loss 1.25032496\n",
      "Trained batch 105 batch loss 1.22018993 epoch total loss 1.25003791\n",
      "Trained batch 106 batch loss 1.22118711 epoch total loss 1.24976575\n",
      "Trained batch 107 batch loss 1.25937223 epoch total loss 1.24985552\n",
      "Trained batch 108 batch loss 1.26405501 epoch total loss 1.24998701\n",
      "Trained batch 109 batch loss 1.27217257 epoch total loss 1.2501905\n",
      "Trained batch 110 batch loss 1.32031155 epoch total loss 1.25082803\n",
      "Trained batch 111 batch loss 1.3018316 epoch total loss 1.25128746\n",
      "Trained batch 112 batch loss 1.3307302 epoch total loss 1.25199687\n",
      "Trained batch 113 batch loss 1.42886 epoch total loss 1.25356209\n",
      "Trained batch 114 batch loss 1.42707491 epoch total loss 1.25508416\n",
      "Trained batch 115 batch loss 1.39067137 epoch total loss 1.25626314\n",
      "Trained batch 116 batch loss 1.24514484 epoch total loss 1.25616729\n",
      "Trained batch 117 batch loss 1.17905962 epoch total loss 1.2555083\n",
      "Trained batch 118 batch loss 0.951458871 epoch total loss 1.25293159\n",
      "Trained batch 119 batch loss 1.15644526 epoch total loss 1.25212085\n",
      "Trained batch 120 batch loss 1.1713 epoch total loss 1.25144732\n",
      "Trained batch 121 batch loss 0.993407607 epoch total loss 1.24931479\n",
      "Trained batch 122 batch loss 0.994561732 epoch total loss 1.2472266\n",
      "Trained batch 123 batch loss 1.01060581 epoch total loss 1.24530292\n",
      "Trained batch 124 batch loss 1.09559882 epoch total loss 1.24409556\n",
      "Trained batch 125 batch loss 1.11058235 epoch total loss 1.24302745\n",
      "Trained batch 126 batch loss 1.26119721 epoch total loss 1.24317169\n",
      "Trained batch 127 batch loss 1.28185582 epoch total loss 1.24347627\n",
      "Trained batch 128 batch loss 1.26276827 epoch total loss 1.24362707\n",
      "Trained batch 129 batch loss 1.29598641 epoch total loss 1.24403298\n",
      "Trained batch 130 batch loss 1.2896297 epoch total loss 1.24438369\n",
      "Trained batch 131 batch loss 1.24410272 epoch total loss 1.24438167\n",
      "Trained batch 132 batch loss 1.15332317 epoch total loss 1.2436918\n",
      "Trained batch 133 batch loss 1.20468676 epoch total loss 1.24339843\n",
      "Trained batch 134 batch loss 1.22047043 epoch total loss 1.24322736\n",
      "Trained batch 135 batch loss 1.18579459 epoch total loss 1.2428019\n",
      "Trained batch 136 batch loss 1.16132343 epoch total loss 1.24220276\n",
      "Trained batch 137 batch loss 1.07997501 epoch total loss 1.24101853\n",
      "Trained batch 138 batch loss 1.26133 epoch total loss 1.24116588\n",
      "Trained batch 139 batch loss 1.13186097 epoch total loss 1.24037945\n",
      "Trained batch 140 batch loss 1.31320596 epoch total loss 1.24089968\n",
      "Trained batch 141 batch loss 1.19541788 epoch total loss 1.2405771\n",
      "Trained batch 142 batch loss 1.1044054 epoch total loss 1.23961806\n",
      "Trained batch 143 batch loss 1.14454269 epoch total loss 1.23895323\n",
      "Trained batch 144 batch loss 1.18149066 epoch total loss 1.23855424\n",
      "Trained batch 145 batch loss 1.23881376 epoch total loss 1.23855603\n",
      "Trained batch 146 batch loss 1.21842206 epoch total loss 1.2384181\n",
      "Trained batch 147 batch loss 1.2459445 epoch total loss 1.23846936\n",
      "Trained batch 148 batch loss 1.19236314 epoch total loss 1.23815787\n",
      "Trained batch 149 batch loss 1.13662755 epoch total loss 1.23747647\n",
      "Trained batch 150 batch loss 1.18531644 epoch total loss 1.23712873\n",
      "Trained batch 151 batch loss 1.17213023 epoch total loss 1.23669827\n",
      "Trained batch 152 batch loss 1.07800794 epoch total loss 1.23565423\n",
      "Trained batch 153 batch loss 1.2124697 epoch total loss 1.2355026\n",
      "Trained batch 154 batch loss 1.18750095 epoch total loss 1.23519099\n",
      "Trained batch 155 batch loss 1.29620862 epoch total loss 1.23558462\n",
      "Trained batch 156 batch loss 1.06272471 epoch total loss 1.23447657\n",
      "Trained batch 157 batch loss 1.18149781 epoch total loss 1.23413908\n",
      "Trained batch 158 batch loss 1.17978942 epoch total loss 1.23379517\n",
      "Trained batch 159 batch loss 1.24354768 epoch total loss 1.23385644\n",
      "Trained batch 160 batch loss 1.15152097 epoch total loss 1.23334193\n",
      "Trained batch 161 batch loss 1.1474092 epoch total loss 1.23280823\n",
      "Trained batch 162 batch loss 1.23614144 epoch total loss 1.23282874\n",
      "Trained batch 163 batch loss 1.31373978 epoch total loss 1.23332512\n",
      "Trained batch 164 batch loss 1.25055647 epoch total loss 1.23343015\n",
      "Trained batch 165 batch loss 1.2218293 epoch total loss 1.23335993\n",
      "Trained batch 166 batch loss 1.27095962 epoch total loss 1.23358643\n",
      "Trained batch 167 batch loss 1.32249331 epoch total loss 1.23411882\n",
      "Trained batch 168 batch loss 1.16830385 epoch total loss 1.2337271\n",
      "Trained batch 169 batch loss 1.24182904 epoch total loss 1.23377502\n",
      "Trained batch 170 batch loss 1.31560457 epoch total loss 1.23425639\n",
      "Trained batch 171 batch loss 1.24994588 epoch total loss 1.23434806\n",
      "Trained batch 172 batch loss 1.10447681 epoch total loss 1.23359299\n",
      "Trained batch 173 batch loss 1.28364718 epoch total loss 1.23388231\n",
      "Trained batch 174 batch loss 1.29742682 epoch total loss 1.23424745\n",
      "Trained batch 175 batch loss 1.26870024 epoch total loss 1.23444438\n",
      "Trained batch 176 batch loss 1.23489165 epoch total loss 1.234447\n",
      "Trained batch 177 batch loss 1.23285329 epoch total loss 1.23443794\n",
      "Trained batch 178 batch loss 1.16855359 epoch total loss 1.2340678\n",
      "Trained batch 179 batch loss 1.25787044 epoch total loss 1.23420072\n",
      "Trained batch 180 batch loss 1.21392739 epoch total loss 1.23408818\n",
      "Trained batch 181 batch loss 1.13603759 epoch total loss 1.23354638\n",
      "Trained batch 182 batch loss 1.30236721 epoch total loss 1.23392451\n",
      "Trained batch 183 batch loss 1.37109566 epoch total loss 1.2346741\n",
      "Trained batch 184 batch loss 1.29147303 epoch total loss 1.23498273\n",
      "Trained batch 185 batch loss 1.30566 epoch total loss 1.23536479\n",
      "Trained batch 186 batch loss 1.35005069 epoch total loss 1.23598146\n",
      "Trained batch 187 batch loss 1.28981292 epoch total loss 1.23626924\n",
      "Trained batch 188 batch loss 1.28844213 epoch total loss 1.23654675\n",
      "Trained batch 189 batch loss 1.25667334 epoch total loss 1.23665321\n",
      "Trained batch 190 batch loss 1.29135942 epoch total loss 1.23694122\n",
      "Trained batch 191 batch loss 1.1827625 epoch total loss 1.23665762\n",
      "Trained batch 192 batch loss 1.1761837 epoch total loss 1.23634255\n",
      "Trained batch 193 batch loss 1.20346582 epoch total loss 1.2361722\n",
      "Trained batch 194 batch loss 1.11907589 epoch total loss 1.23556864\n",
      "Trained batch 195 batch loss 1.1813153 epoch total loss 1.23529041\n",
      "Trained batch 196 batch loss 1.17143393 epoch total loss 1.23496461\n",
      "Trained batch 197 batch loss 1.2379365 epoch total loss 1.23497975\n",
      "Trained batch 198 batch loss 1.22388947 epoch total loss 1.23492372\n",
      "Trained batch 199 batch loss 1.19240654 epoch total loss 1.2347101\n",
      "Trained batch 200 batch loss 1.26021409 epoch total loss 1.23483753\n",
      "Trained batch 201 batch loss 1.31536293 epoch total loss 1.23523819\n",
      "Trained batch 202 batch loss 1.3402673 epoch total loss 1.23575819\n",
      "Trained batch 203 batch loss 1.2368871 epoch total loss 1.23576379\n",
      "Trained batch 204 batch loss 1.2158066 epoch total loss 1.23566592\n",
      "Trained batch 205 batch loss 1.16447401 epoch total loss 1.23531866\n",
      "Trained batch 206 batch loss 1.33753669 epoch total loss 1.23581493\n",
      "Trained batch 207 batch loss 1.2062757 epoch total loss 1.23567212\n",
      "Trained batch 208 batch loss 1.23093462 epoch total loss 1.23564935\n",
      "Trained batch 209 batch loss 1.18758917 epoch total loss 1.23541951\n",
      "Trained batch 210 batch loss 1.30557895 epoch total loss 1.23575354\n",
      "Trained batch 211 batch loss 1.30264831 epoch total loss 1.23607051\n",
      "Trained batch 212 batch loss 1.36808038 epoch total loss 1.23669314\n",
      "Trained batch 213 batch loss 1.20514512 epoch total loss 1.23654509\n",
      "Trained batch 214 batch loss 1.32451618 epoch total loss 1.23695612\n",
      "Trained batch 215 batch loss 1.34746933 epoch total loss 1.23747015\n",
      "Trained batch 216 batch loss 1.25985885 epoch total loss 1.23757386\n",
      "Trained batch 217 batch loss 1.23938656 epoch total loss 1.23758221\n",
      "Trained batch 218 batch loss 1.25682926 epoch total loss 1.23767042\n",
      "Trained batch 219 batch loss 1.28235364 epoch total loss 1.23787451\n",
      "Trained batch 220 batch loss 1.23079371 epoch total loss 1.23784232\n",
      "Trained batch 221 batch loss 1.18181813 epoch total loss 1.23758888\n",
      "Trained batch 222 batch loss 1.10782027 epoch total loss 1.23700428\n",
      "Trained batch 223 batch loss 1.14473212 epoch total loss 1.23659062\n",
      "Trained batch 224 batch loss 1.22098422 epoch total loss 1.23652089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 225 batch loss 1.07870984 epoch total loss 1.23581946\n",
      "Trained batch 226 batch loss 1.2012068 epoch total loss 1.23566628\n",
      "Trained batch 227 batch loss 1.11415827 epoch total loss 1.23513103\n",
      "Trained batch 228 batch loss 1.15167332 epoch total loss 1.23476505\n",
      "Trained batch 229 batch loss 1.06343818 epoch total loss 1.2340169\n",
      "Trained batch 230 batch loss 1.22709155 epoch total loss 1.23398674\n",
      "Trained batch 231 batch loss 1.3355248 epoch total loss 1.23442626\n",
      "Trained batch 232 batch loss 1.1473608 epoch total loss 1.23405099\n",
      "Trained batch 233 batch loss 1.23510695 epoch total loss 1.23405552\n",
      "Trained batch 234 batch loss 1.22880578 epoch total loss 1.23403323\n",
      "Trained batch 235 batch loss 1.22633123 epoch total loss 1.23400033\n",
      "Trained batch 236 batch loss 1.15742445 epoch total loss 1.23367584\n",
      "Trained batch 237 batch loss 1.12046373 epoch total loss 1.23319805\n",
      "Trained batch 238 batch loss 1.32158232 epoch total loss 1.2335695\n",
      "Trained batch 239 batch loss 1.18391848 epoch total loss 1.23336184\n",
      "Trained batch 240 batch loss 1.2198149 epoch total loss 1.23330534\n",
      "Trained batch 241 batch loss 1.38861263 epoch total loss 1.23394978\n",
      "Trained batch 242 batch loss 1.27115059 epoch total loss 1.23410344\n",
      "Trained batch 243 batch loss 1.13596749 epoch total loss 1.23369956\n",
      "Trained batch 244 batch loss 1.00372267 epoch total loss 1.23275709\n",
      "Trained batch 245 batch loss 1.19648993 epoch total loss 1.23260903\n",
      "Trained batch 246 batch loss 1.13258862 epoch total loss 1.23220253\n",
      "Trained batch 247 batch loss 1.33660436 epoch total loss 1.23262525\n",
      "Trained batch 248 batch loss 1.2630446 epoch total loss 1.23274779\n",
      "Trained batch 249 batch loss 1.21165633 epoch total loss 1.23266315\n",
      "Trained batch 250 batch loss 1.25304461 epoch total loss 1.23274469\n",
      "Trained batch 251 batch loss 1.17193854 epoch total loss 1.23250246\n",
      "Trained batch 252 batch loss 1.21775031 epoch total loss 1.23244393\n",
      "Trained batch 253 batch loss 1.2373178 epoch total loss 1.23246312\n",
      "Trained batch 254 batch loss 1.32089388 epoch total loss 1.23281133\n",
      "Trained batch 255 batch loss 1.32501233 epoch total loss 1.23317289\n",
      "Trained batch 256 batch loss 1.26580226 epoch total loss 1.23330033\n",
      "Trained batch 257 batch loss 1.17680943 epoch total loss 1.23308051\n",
      "Trained batch 258 batch loss 1.04093254 epoch total loss 1.23233581\n",
      "Trained batch 259 batch loss 1.18621039 epoch total loss 1.23215771\n",
      "Trained batch 260 batch loss 1.27527285 epoch total loss 1.23232353\n",
      "Trained batch 261 batch loss 1.30320859 epoch total loss 1.23259521\n",
      "Trained batch 262 batch loss 1.36094642 epoch total loss 1.23308504\n",
      "Trained batch 263 batch loss 1.39158773 epoch total loss 1.23368776\n",
      "Trained batch 264 batch loss 1.36544323 epoch total loss 1.23418677\n",
      "Trained batch 265 batch loss 1.43622208 epoch total loss 1.23494923\n",
      "Trained batch 266 batch loss 1.34861898 epoch total loss 1.2353766\n",
      "Trained batch 267 batch loss 1.28594398 epoch total loss 1.23556602\n",
      "Trained batch 268 batch loss 1.22864175 epoch total loss 1.23554015\n",
      "Trained batch 269 batch loss 1.28877378 epoch total loss 1.23573804\n",
      "Trained batch 270 batch loss 1.25195754 epoch total loss 1.23579812\n",
      "Trained batch 271 batch loss 1.27290583 epoch total loss 1.23593509\n",
      "Trained batch 272 batch loss 1.27614641 epoch total loss 1.23608303\n",
      "Trained batch 273 batch loss 1.21792829 epoch total loss 1.23601651\n",
      "Trained batch 274 batch loss 1.23809445 epoch total loss 1.23602402\n",
      "Trained batch 275 batch loss 1.19712567 epoch total loss 1.23588252\n",
      "Trained batch 276 batch loss 1.01659989 epoch total loss 1.23508811\n",
      "Trained batch 277 batch loss 1.01977789 epoch total loss 1.23431075\n",
      "Trained batch 278 batch loss 1.22130859 epoch total loss 1.23426402\n",
      "Trained batch 279 batch loss 1.3319273 epoch total loss 1.23461413\n",
      "Trained batch 280 batch loss 1.28674066 epoch total loss 1.23480034\n",
      "Trained batch 281 batch loss 1.39016354 epoch total loss 1.23535323\n",
      "Trained batch 282 batch loss 1.33100808 epoch total loss 1.23569238\n",
      "Trained batch 283 batch loss 1.25116169 epoch total loss 1.23574698\n",
      "Trained batch 284 batch loss 1.2431972 epoch total loss 1.23577321\n",
      "Trained batch 285 batch loss 1.2695657 epoch total loss 1.23589182\n",
      "Trained batch 286 batch loss 1.31770742 epoch total loss 1.23617792\n",
      "Trained batch 287 batch loss 1.26836514 epoch total loss 1.2362901\n",
      "Trained batch 288 batch loss 1.34114027 epoch total loss 1.23665404\n",
      "Trained batch 289 batch loss 1.33733046 epoch total loss 1.23700249\n",
      "Trained batch 290 batch loss 1.24682379 epoch total loss 1.23703635\n",
      "Trained batch 291 batch loss 1.20837641 epoch total loss 1.23693788\n",
      "Trained batch 292 batch loss 1.23840904 epoch total loss 1.23694289\n",
      "Trained batch 293 batch loss 1.3650707 epoch total loss 1.23738015\n",
      "Trained batch 294 batch loss 1.31923437 epoch total loss 1.23765862\n",
      "Trained batch 295 batch loss 1.42321765 epoch total loss 1.23828769\n",
      "Trained batch 296 batch loss 1.39617515 epoch total loss 1.23882103\n",
      "Trained batch 297 batch loss 1.40272331 epoch total loss 1.23937285\n",
      "Trained batch 298 batch loss 1.24295282 epoch total loss 1.23938489\n",
      "Trained batch 299 batch loss 1.28622389 epoch total loss 1.23954153\n",
      "Trained batch 300 batch loss 1.29889131 epoch total loss 1.23973942\n",
      "Trained batch 301 batch loss 1.28927398 epoch total loss 1.23990393\n",
      "Trained batch 302 batch loss 1.30581546 epoch total loss 1.2401222\n",
      "Trained batch 303 batch loss 1.11109447 epoch total loss 1.23969638\n",
      "Trained batch 304 batch loss 1.21689546 epoch total loss 1.23962128\n",
      "Trained batch 305 batch loss 1.1965487 epoch total loss 1.23948014\n",
      "Trained batch 306 batch loss 1.33306623 epoch total loss 1.23978603\n",
      "Trained batch 307 batch loss 1.27441573 epoch total loss 1.2398988\n",
      "Trained batch 308 batch loss 1.32997775 epoch total loss 1.24019122\n",
      "Trained batch 309 batch loss 1.4363122 epoch total loss 1.24082601\n",
      "Trained batch 310 batch loss 1.4591918 epoch total loss 1.24153042\n",
      "Trained batch 311 batch loss 1.25199866 epoch total loss 1.24156404\n",
      "Trained batch 312 batch loss 1.29196656 epoch total loss 1.24172556\n",
      "Trained batch 313 batch loss 1.24369717 epoch total loss 1.24173176\n",
      "Trained batch 314 batch loss 1.26587582 epoch total loss 1.24180865\n",
      "Trained batch 315 batch loss 1.31957746 epoch total loss 1.24205554\n",
      "Trained batch 316 batch loss 1.39502811 epoch total loss 1.24253964\n",
      "Trained batch 317 batch loss 1.38508654 epoch total loss 1.2429893\n",
      "Trained batch 318 batch loss 1.3509779 epoch total loss 1.24332893\n",
      "Trained batch 319 batch loss 1.43812454 epoch total loss 1.24393952\n",
      "Trained batch 320 batch loss 1.3725152 epoch total loss 1.24434137\n",
      "Trained batch 321 batch loss 1.43868291 epoch total loss 1.24494684\n",
      "Trained batch 322 batch loss 1.38476682 epoch total loss 1.245381\n",
      "Trained batch 323 batch loss 1.36236 epoch total loss 1.24574327\n",
      "Trained batch 324 batch loss 1.37936258 epoch total loss 1.24615562\n",
      "Trained batch 325 batch loss 1.31094432 epoch total loss 1.24635494\n",
      "Trained batch 326 batch loss 1.1464889 epoch total loss 1.24604857\n",
      "Trained batch 327 batch loss 1.1060189 epoch total loss 1.24562037\n",
      "Trained batch 328 batch loss 1.23514104 epoch total loss 1.24558842\n",
      "Trained batch 329 batch loss 1.24154902 epoch total loss 1.24557614\n",
      "Trained batch 330 batch loss 1.31697857 epoch total loss 1.24579251\n",
      "Trained batch 331 batch loss 1.28401732 epoch total loss 1.24590802\n",
      "Trained batch 332 batch loss 1.37328196 epoch total loss 1.24629176\n",
      "Trained batch 333 batch loss 1.24464047 epoch total loss 1.24628675\n",
      "Trained batch 334 batch loss 1.25653839 epoch total loss 1.24631739\n",
      "Trained batch 335 batch loss 1.23286331 epoch total loss 1.24627721\n",
      "Trained batch 336 batch loss 1.29102921 epoch total loss 1.24641037\n",
      "Trained batch 337 batch loss 1.21372283 epoch total loss 1.24631333\n",
      "Trained batch 338 batch loss 1.21448362 epoch total loss 1.24621916\n",
      "Trained batch 339 batch loss 1.33964741 epoch total loss 1.24649477\n",
      "Trained batch 340 batch loss 1.33241498 epoch total loss 1.24674749\n",
      "Trained batch 341 batch loss 1.22743642 epoch total loss 1.24669099\n",
      "Trained batch 342 batch loss 1.31346774 epoch total loss 1.24688625\n",
      "Trained batch 343 batch loss 1.30641937 epoch total loss 1.24705982\n",
      "Trained batch 344 batch loss 1.37199163 epoch total loss 1.24742293\n",
      "Trained batch 345 batch loss 1.30523872 epoch total loss 1.24759054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 346 batch loss 1.30313 epoch total loss 1.247751\n",
      "Trained batch 347 batch loss 1.23270023 epoch total loss 1.24770761\n",
      "Trained batch 348 batch loss 1.11940455 epoch total loss 1.24733901\n",
      "Trained batch 349 batch loss 1.19509625 epoch total loss 1.24718928\n",
      "Trained batch 350 batch loss 1.09551716 epoch total loss 1.24675596\n",
      "Trained batch 351 batch loss 1.05550206 epoch total loss 1.24621117\n",
      "Trained batch 352 batch loss 1.15402341 epoch total loss 1.24594927\n",
      "Trained batch 353 batch loss 1.19237494 epoch total loss 1.24579751\n",
      "Trained batch 354 batch loss 1.27968955 epoch total loss 1.24589324\n",
      "Trained batch 355 batch loss 1.27489018 epoch total loss 1.2459749\n",
      "Trained batch 356 batch loss 1.22730494 epoch total loss 1.24592245\n",
      "Trained batch 357 batch loss 1.19165349 epoch total loss 1.24577045\n",
      "Trained batch 358 batch loss 1.17138267 epoch total loss 1.24556267\n",
      "Trained batch 359 batch loss 1.221277 epoch total loss 1.24549508\n",
      "Trained batch 360 batch loss 1.20492697 epoch total loss 1.24538231\n",
      "Trained batch 361 batch loss 1.150388 epoch total loss 1.24511921\n",
      "Trained batch 362 batch loss 1.04653263 epoch total loss 1.24457061\n",
      "Trained batch 363 batch loss 1.02965641 epoch total loss 1.24397862\n",
      "Trained batch 364 batch loss 0.99724853 epoch total loss 1.2433008\n",
      "Trained batch 365 batch loss 1.17014074 epoch total loss 1.2431004\n",
      "Trained batch 366 batch loss 1.35250258 epoch total loss 1.24339926\n",
      "Trained batch 367 batch loss 1.35289168 epoch total loss 1.24369764\n",
      "Trained batch 368 batch loss 1.443753 epoch total loss 1.24424136\n",
      "Trained batch 369 batch loss 1.07932937 epoch total loss 1.24379432\n",
      "Trained batch 370 batch loss 0.997842491 epoch total loss 1.24312961\n",
      "Trained batch 371 batch loss 1.06646812 epoch total loss 1.24265337\n",
      "Trained batch 372 batch loss 1.2085377 epoch total loss 1.2425617\n",
      "Trained batch 373 batch loss 1.31668365 epoch total loss 1.24276042\n",
      "Trained batch 374 batch loss 1.5765419 epoch total loss 1.24365282\n",
      "Trained batch 375 batch loss 1.372648 epoch total loss 1.24399686\n",
      "Trained batch 376 batch loss 1.09597826 epoch total loss 1.24360311\n",
      "Trained batch 377 batch loss 1.26163495 epoch total loss 1.24365091\n",
      "Trained batch 378 batch loss 1.3664813 epoch total loss 1.24397588\n",
      "Trained batch 379 batch loss 1.32080674 epoch total loss 1.24417865\n",
      "Trained batch 380 batch loss 1.26753962 epoch total loss 1.24424016\n",
      "Trained batch 381 batch loss 1.18423772 epoch total loss 1.24408269\n",
      "Trained batch 382 batch loss 1.37819862 epoch total loss 1.24443376\n",
      "Trained batch 383 batch loss 1.26423025 epoch total loss 1.24448538\n",
      "Trained batch 384 batch loss 1.25615025 epoch total loss 1.24451578\n",
      "Trained batch 385 batch loss 1.19880557 epoch total loss 1.24439704\n",
      "Trained batch 386 batch loss 1.14348257 epoch total loss 1.24413562\n",
      "Trained batch 387 batch loss 1.18193674 epoch total loss 1.24397492\n",
      "Trained batch 388 batch loss 1.24483216 epoch total loss 1.24397719\n",
      "Trained batch 389 batch loss 1.13028896 epoch total loss 1.24368489\n",
      "Trained batch 390 batch loss 1.13220739 epoch total loss 1.24339902\n",
      "Trained batch 391 batch loss 1.1962831 epoch total loss 1.2432785\n",
      "Trained batch 392 batch loss 1.30160546 epoch total loss 1.2434274\n",
      "Trained batch 393 batch loss 1.244488 epoch total loss 1.24343\n",
      "Trained batch 394 batch loss 1.3102026 epoch total loss 1.24359953\n",
      "Trained batch 395 batch loss 1.30982161 epoch total loss 1.24376714\n",
      "Trained batch 396 batch loss 1.26311064 epoch total loss 1.24381602\n",
      "Trained batch 397 batch loss 1.28208506 epoch total loss 1.24391234\n",
      "Trained batch 398 batch loss 1.26020908 epoch total loss 1.24395335\n",
      "Trained batch 399 batch loss 1.25012255 epoch total loss 1.24396884\n",
      "Trained batch 400 batch loss 1.17634428 epoch total loss 1.24379969\n",
      "Trained batch 401 batch loss 1.17064357 epoch total loss 1.2436173\n",
      "Trained batch 402 batch loss 1.23669744 epoch total loss 1.24360013\n",
      "Trained batch 403 batch loss 1.18289542 epoch total loss 1.24344945\n",
      "Trained batch 404 batch loss 1.107337 epoch total loss 1.24311256\n",
      "Trained batch 405 batch loss 1.20482969 epoch total loss 1.24301803\n",
      "Trained batch 406 batch loss 1.05231738 epoch total loss 1.24254835\n",
      "Trained batch 407 batch loss 1.15569234 epoch total loss 1.24233496\n",
      "Trained batch 408 batch loss 1.16402912 epoch total loss 1.24214303\n",
      "Trained batch 409 batch loss 1.20908666 epoch total loss 1.24206209\n",
      "Trained batch 410 batch loss 1.28966737 epoch total loss 1.24217832\n",
      "Trained batch 411 batch loss 1.25341594 epoch total loss 1.24220562\n",
      "Trained batch 412 batch loss 1.28243589 epoch total loss 1.24230325\n",
      "Trained batch 413 batch loss 1.3696301 epoch total loss 1.24261165\n",
      "Trained batch 414 batch loss 1.25416827 epoch total loss 1.24263954\n",
      "Trained batch 415 batch loss 1.32716012 epoch total loss 1.24284315\n",
      "Trained batch 416 batch loss 1.147089 epoch total loss 1.24261296\n",
      "Trained batch 417 batch loss 1.21359825 epoch total loss 1.24254346\n",
      "Trained batch 418 batch loss 1.22602177 epoch total loss 1.24250388\n",
      "Trained batch 419 batch loss 1.1422224 epoch total loss 1.24226451\n",
      "Trained batch 420 batch loss 1.31448221 epoch total loss 1.24243641\n",
      "Trained batch 421 batch loss 1.16527927 epoch total loss 1.24225318\n",
      "Trained batch 422 batch loss 1.23910093 epoch total loss 1.24224567\n",
      "Trained batch 423 batch loss 1.23707306 epoch total loss 1.2422334\n",
      "Trained batch 424 batch loss 1.12272739 epoch total loss 1.24195158\n",
      "Trained batch 425 batch loss 1.13701653 epoch total loss 1.2417047\n",
      "Trained batch 426 batch loss 1.23460484 epoch total loss 1.24168801\n",
      "Trained batch 427 batch loss 1.09319615 epoch total loss 1.24134028\n",
      "Trained batch 428 batch loss 1.26749802 epoch total loss 1.24140143\n",
      "Trained batch 429 batch loss 1.15165424 epoch total loss 1.24119234\n",
      "Trained batch 430 batch loss 1.26331592 epoch total loss 1.24124372\n",
      "Trained batch 431 batch loss 1.15968704 epoch total loss 1.24105442\n",
      "Trained batch 432 batch loss 1.21321344 epoch total loss 1.24098992\n",
      "Trained batch 433 batch loss 1.15073109 epoch total loss 1.24078155\n",
      "Trained batch 434 batch loss 1.21955073 epoch total loss 1.24073267\n",
      "Trained batch 435 batch loss 1.21154904 epoch total loss 1.24066556\n",
      "Trained batch 436 batch loss 1.35404754 epoch total loss 1.24092567\n",
      "Trained batch 437 batch loss 1.39342737 epoch total loss 1.2412746\n",
      "Trained batch 438 batch loss 1.28005815 epoch total loss 1.24136305\n",
      "Trained batch 439 batch loss 1.38851988 epoch total loss 1.24169838\n",
      "Trained batch 440 batch loss 1.29338157 epoch total loss 1.24181592\n",
      "Trained batch 441 batch loss 1.23014975 epoch total loss 1.24178946\n",
      "Trained batch 442 batch loss 1.1329304 epoch total loss 1.24154317\n",
      "Trained batch 443 batch loss 1.29828358 epoch total loss 1.2416712\n",
      "Trained batch 444 batch loss 1.40874267 epoch total loss 1.24204755\n",
      "Trained batch 445 batch loss 1.33472562 epoch total loss 1.24225581\n",
      "Trained batch 446 batch loss 1.26316345 epoch total loss 1.24230278\n",
      "Trained batch 447 batch loss 1.13948941 epoch total loss 1.2420727\n",
      "Trained batch 448 batch loss 1.28786421 epoch total loss 1.24217486\n",
      "Trained batch 449 batch loss 1.23424637 epoch total loss 1.24215722\n",
      "Trained batch 450 batch loss 1.27079225 epoch total loss 1.24222088\n",
      "Trained batch 451 batch loss 1.36820579 epoch total loss 1.24250031\n",
      "Trained batch 452 batch loss 1.38198638 epoch total loss 1.24280882\n",
      "Trained batch 453 batch loss 1.30824685 epoch total loss 1.24295318\n",
      "Trained batch 454 batch loss 1.11903596 epoch total loss 1.24268019\n",
      "Trained batch 455 batch loss 1.10189056 epoch total loss 1.24237072\n",
      "Trained batch 456 batch loss 1.11761928 epoch total loss 1.24209714\n",
      "Trained batch 457 batch loss 1.15506577 epoch total loss 1.24190676\n",
      "Trained batch 458 batch loss 1.12301326 epoch total loss 1.24164712\n",
      "Trained batch 459 batch loss 1.18989146 epoch total loss 1.24153435\n",
      "Trained batch 460 batch loss 1.2519021 epoch total loss 1.24155688\n",
      "Trained batch 461 batch loss 1.30602884 epoch total loss 1.24169672\n",
      "Trained batch 462 batch loss 1.3160845 epoch total loss 1.24185777\n",
      "Trained batch 463 batch loss 1.25435603 epoch total loss 1.24188471\n",
      "Trained batch 464 batch loss 1.0647018 epoch total loss 1.24150288\n",
      "Trained batch 465 batch loss 1.18961179 epoch total loss 1.2413913\n",
      "Trained batch 466 batch loss 1.13072121 epoch total loss 1.24115384\n",
      "Trained batch 467 batch loss 1.184 epoch total loss 1.24103153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 468 batch loss 1.32877731 epoch total loss 1.24121904\n",
      "Trained batch 469 batch loss 1.20426702 epoch total loss 1.24114025\n",
      "Trained batch 470 batch loss 1.22036612 epoch total loss 1.24109602\n",
      "Trained batch 471 batch loss 1.19723248 epoch total loss 1.2410028\n",
      "Trained batch 472 batch loss 1.20604467 epoch total loss 1.24092877\n",
      "Trained batch 473 batch loss 1.18046677 epoch total loss 1.24080098\n",
      "Trained batch 474 batch loss 1.24189758 epoch total loss 1.24080324\n",
      "Trained batch 475 batch loss 1.19412613 epoch total loss 1.24070501\n",
      "Trained batch 476 batch loss 1.23815727 epoch total loss 1.24069965\n",
      "Trained batch 477 batch loss 1.32438231 epoch total loss 1.24087512\n",
      "Trained batch 478 batch loss 1.18749595 epoch total loss 1.24076355\n",
      "Trained batch 479 batch loss 1.17401516 epoch total loss 1.24062419\n",
      "Trained batch 480 batch loss 1.13843226 epoch total loss 1.24041128\n",
      "Trained batch 481 batch loss 1.19632 epoch total loss 1.24031961\n",
      "Trained batch 482 batch loss 1.1527729 epoch total loss 1.24013805\n",
      "Trained batch 483 batch loss 1.21606922 epoch total loss 1.24008822\n",
      "Trained batch 484 batch loss 1.2077527 epoch total loss 1.24002135\n",
      "Trained batch 485 batch loss 1.06227088 epoch total loss 1.2396549\n",
      "Trained batch 486 batch loss 1.08292377 epoch total loss 1.23933244\n",
      "Trained batch 487 batch loss 1.04273438 epoch total loss 1.23892868\n",
      "Trained batch 488 batch loss 1.14111626 epoch total loss 1.23872828\n",
      "Trained batch 489 batch loss 1.28482628 epoch total loss 1.23882258\n",
      "Trained batch 490 batch loss 1.16137743 epoch total loss 1.23866451\n",
      "Trained batch 491 batch loss 1.12664592 epoch total loss 1.23843634\n",
      "Trained batch 492 batch loss 1.26499283 epoch total loss 1.23849046\n",
      "Trained batch 493 batch loss 1.15783477 epoch total loss 1.23832679\n",
      "Trained batch 494 batch loss 1.13810718 epoch total loss 1.23812401\n",
      "Trained batch 495 batch loss 1.02479601 epoch total loss 1.23769295\n",
      "Trained batch 496 batch loss 1.22582853 epoch total loss 1.23766911\n",
      "Trained batch 497 batch loss 1.28288424 epoch total loss 1.23776007\n",
      "Trained batch 498 batch loss 1.158095 epoch total loss 1.23760009\n",
      "Trained batch 499 batch loss 1.46077669 epoch total loss 1.23804724\n",
      "Trained batch 500 batch loss 1.27703452 epoch total loss 1.23812521\n",
      "Trained batch 501 batch loss 1.22749579 epoch total loss 1.23810399\n",
      "Trained batch 502 batch loss 1.23911512 epoch total loss 1.23810601\n",
      "Trained batch 503 batch loss 1.31887126 epoch total loss 1.23826659\n",
      "Trained batch 504 batch loss 1.31610227 epoch total loss 1.23842096\n",
      "Trained batch 505 batch loss 1.26522183 epoch total loss 1.23847401\n",
      "Trained batch 506 batch loss 1.19720531 epoch total loss 1.23839247\n",
      "Trained batch 507 batch loss 1.30468953 epoch total loss 1.23852324\n",
      "Trained batch 508 batch loss 1.24245739 epoch total loss 1.23853087\n",
      "Trained batch 509 batch loss 1.26382983 epoch total loss 1.2385807\n",
      "Trained batch 510 batch loss 1.23546112 epoch total loss 1.23857462\n",
      "Trained batch 511 batch loss 1.24129701 epoch total loss 1.23857987\n",
      "Trained batch 512 batch loss 1.24069667 epoch total loss 1.23858404\n",
      "Trained batch 513 batch loss 1.18970251 epoch total loss 1.23848879\n",
      "Trained batch 514 batch loss 1.12498212 epoch total loss 1.2382679\n",
      "Trained batch 515 batch loss 1.05416393 epoch total loss 1.23791039\n",
      "Trained batch 516 batch loss 1.17013502 epoch total loss 1.23777902\n",
      "Trained batch 517 batch loss 1.10698533 epoch total loss 1.23752606\n",
      "Trained batch 518 batch loss 1.19588888 epoch total loss 1.23744559\n",
      "Trained batch 519 batch loss 0.989213347 epoch total loss 1.23696733\n",
      "Trained batch 520 batch loss 1.25013435 epoch total loss 1.2369926\n",
      "Trained batch 521 batch loss 1.22416627 epoch total loss 1.23696804\n",
      "Trained batch 522 batch loss 1.26178241 epoch total loss 1.23701549\n",
      "Trained batch 523 batch loss 1.31965661 epoch total loss 1.23717356\n",
      "Trained batch 524 batch loss 1.24831629 epoch total loss 1.23719478\n",
      "Trained batch 525 batch loss 1.28966534 epoch total loss 1.23729467\n",
      "Trained batch 526 batch loss 1.37567461 epoch total loss 1.23755777\n",
      "Trained batch 527 batch loss 1.11809433 epoch total loss 1.23733115\n",
      "Trained batch 528 batch loss 1.1577934 epoch total loss 1.23718047\n",
      "Trained batch 529 batch loss 1.12643242 epoch total loss 1.23697102\n",
      "Trained batch 530 batch loss 1.05007672 epoch total loss 1.23661828\n",
      "Trained batch 531 batch loss 0.978657603 epoch total loss 1.2361325\n",
      "Trained batch 532 batch loss 1.12371254 epoch total loss 1.23592114\n",
      "Trained batch 533 batch loss 1.13014412 epoch total loss 1.23572266\n",
      "Trained batch 534 batch loss 0.938264787 epoch total loss 1.23516572\n",
      "Trained batch 535 batch loss 0.965209961 epoch total loss 1.2346611\n",
      "Trained batch 536 batch loss 0.903318167 epoch total loss 1.234043\n",
      "Trained batch 537 batch loss 1.07028937 epoch total loss 1.23373806\n",
      "Trained batch 538 batch loss 1.09626281 epoch total loss 1.23348248\n",
      "Trained batch 539 batch loss 1.20981932 epoch total loss 1.23343861\n",
      "Trained batch 540 batch loss 1.14484131 epoch total loss 1.23327458\n",
      "Trained batch 541 batch loss 1.17676604 epoch total loss 1.23317\n",
      "Trained batch 542 batch loss 1.34023333 epoch total loss 1.23336756\n",
      "Trained batch 543 batch loss 1.42428398 epoch total loss 1.23371911\n",
      "Trained batch 544 batch loss 1.3872577 epoch total loss 1.2340014\n",
      "Trained batch 545 batch loss 1.3307147 epoch total loss 1.23417878\n",
      "Trained batch 546 batch loss 1.27512538 epoch total loss 1.23425388\n",
      "Trained batch 547 batch loss 1.17000949 epoch total loss 1.23413634\n",
      "Trained batch 548 batch loss 1.26530218 epoch total loss 1.23419321\n",
      "Trained batch 549 batch loss 1.25449884 epoch total loss 1.23423028\n",
      "Trained batch 550 batch loss 1.19036865 epoch total loss 1.23415053\n",
      "Trained batch 551 batch loss 1.25640702 epoch total loss 1.23419094\n",
      "Trained batch 552 batch loss 1.24592686 epoch total loss 1.23421216\n",
      "Trained batch 553 batch loss 1.19301188 epoch total loss 1.23413754\n",
      "Trained batch 554 batch loss 1.25468707 epoch total loss 1.23417473\n",
      "Trained batch 555 batch loss 1.30063713 epoch total loss 1.23429453\n",
      "Trained batch 556 batch loss 1.16227806 epoch total loss 1.23416495\n",
      "Trained batch 557 batch loss 1.15441716 epoch total loss 1.23402178\n",
      "Trained batch 558 batch loss 1.13933921 epoch total loss 1.23385215\n",
      "Trained batch 559 batch loss 1.26192701 epoch total loss 1.23390234\n",
      "Trained batch 560 batch loss 1.12838459 epoch total loss 1.23371387\n",
      "Trained batch 561 batch loss 1.12691164 epoch total loss 1.23352349\n",
      "Trained batch 562 batch loss 1.14547539 epoch total loss 1.23336673\n",
      "Trained batch 563 batch loss 1.27368045 epoch total loss 1.23343837\n",
      "Trained batch 564 batch loss 1.256464 epoch total loss 1.23347914\n",
      "Trained batch 565 batch loss 1.23850274 epoch total loss 1.23348808\n",
      "Trained batch 566 batch loss 1.27237034 epoch total loss 1.23355687\n",
      "Trained batch 567 batch loss 1.17041504 epoch total loss 1.23344553\n",
      "Trained batch 568 batch loss 1.12202191 epoch total loss 1.23324931\n",
      "Trained batch 569 batch loss 1.03243101 epoch total loss 1.23289633\n",
      "Trained batch 570 batch loss 1.13716531 epoch total loss 1.23272836\n",
      "Trained batch 571 batch loss 1.10434437 epoch total loss 1.23250353\n",
      "Trained batch 572 batch loss 1.0474962 epoch total loss 1.23218012\n",
      "Trained batch 573 batch loss 1.05616343 epoch total loss 1.23187292\n",
      "Trained batch 574 batch loss 1.21022904 epoch total loss 1.23183513\n",
      "Trained batch 575 batch loss 1.10482919 epoch total loss 1.23161435\n",
      "Trained batch 576 batch loss 1.16872776 epoch total loss 1.23150504\n",
      "Trained batch 577 batch loss 1.20750785 epoch total loss 1.23146355\n",
      "Trained batch 578 batch loss 1.22945166 epoch total loss 1.23146\n",
      "Trained batch 579 batch loss 1.30329835 epoch total loss 1.23158407\n",
      "Trained batch 580 batch loss 1.35029924 epoch total loss 1.23178864\n",
      "Trained batch 581 batch loss 1.20394576 epoch total loss 1.23174071\n",
      "Trained batch 582 batch loss 1.17171216 epoch total loss 1.2316376\n",
      "Trained batch 583 batch loss 1.21112955 epoch total loss 1.23160231\n",
      "Trained batch 584 batch loss 1.23705626 epoch total loss 1.23161173\n",
      "Trained batch 585 batch loss 1.12298131 epoch total loss 1.231426\n",
      "Trained batch 586 batch loss 1.03196418 epoch total loss 1.23108566\n",
      "Trained batch 587 batch loss 0.977084816 epoch total loss 1.23065305\n",
      "Trained batch 588 batch loss 1.12662292 epoch total loss 1.23047614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 589 batch loss 1.04844248 epoch total loss 1.23016715\n",
      "Trained batch 590 batch loss 1.12781763 epoch total loss 1.22999358\n",
      "Trained batch 591 batch loss 1.17323649 epoch total loss 1.2298975\n",
      "Trained batch 592 batch loss 1.03236854 epoch total loss 1.22956383\n",
      "Trained batch 593 batch loss 1.14827025 epoch total loss 1.22942674\n",
      "Trained batch 594 batch loss 1.21859479 epoch total loss 1.2294085\n",
      "Trained batch 595 batch loss 1.12689853 epoch total loss 1.22923613\n",
      "Trained batch 596 batch loss 1.18240762 epoch total loss 1.22915757\n",
      "Trained batch 597 batch loss 1.11572134 epoch total loss 1.22896767\n",
      "Trained batch 598 batch loss 1.11719394 epoch total loss 1.22878075\n",
      "Trained batch 599 batch loss 1.13926649 epoch total loss 1.22863126\n",
      "Trained batch 600 batch loss 1.17841661 epoch total loss 1.22854757\n",
      "Trained batch 601 batch loss 1.22777832 epoch total loss 1.22854626\n",
      "Trained batch 602 batch loss 1.36709309 epoch total loss 1.22877634\n",
      "Trained batch 603 batch loss 1.4835484 epoch total loss 1.22919881\n",
      "Trained batch 604 batch loss 1.34684157 epoch total loss 1.22939372\n",
      "Trained batch 605 batch loss 1.10504162 epoch total loss 1.22918808\n",
      "Trained batch 606 batch loss 1.14922321 epoch total loss 1.22905612\n",
      "Trained batch 607 batch loss 1.24022973 epoch total loss 1.2290746\n",
      "Trained batch 608 batch loss 1.41996408 epoch total loss 1.22938859\n",
      "Trained batch 609 batch loss 1.27364409 epoch total loss 1.22946119\n",
      "Trained batch 610 batch loss 1.28493261 epoch total loss 1.22955215\n",
      "Trained batch 611 batch loss 1.05374992 epoch total loss 1.22926438\n",
      "Trained batch 612 batch loss 1.16826868 epoch total loss 1.22916472\n",
      "Trained batch 613 batch loss 1.15397477 epoch total loss 1.22904217\n",
      "Trained batch 614 batch loss 1.19746578 epoch total loss 1.22899067\n",
      "Trained batch 615 batch loss 1.15248537 epoch total loss 1.22886622\n",
      "Trained batch 616 batch loss 1.32632363 epoch total loss 1.22902441\n",
      "Trained batch 617 batch loss 1.17045641 epoch total loss 1.22892952\n",
      "Trained batch 618 batch loss 1.27268744 epoch total loss 1.22900033\n",
      "Trained batch 619 batch loss 1.23058319 epoch total loss 1.22900295\n",
      "Trained batch 620 batch loss 1.35998869 epoch total loss 1.22921419\n",
      "Trained batch 621 batch loss 1.47000921 epoch total loss 1.22960198\n",
      "Trained batch 622 batch loss 1.41260135 epoch total loss 1.22989619\n",
      "Trained batch 623 batch loss 1.44868529 epoch total loss 1.23024738\n",
      "Trained batch 624 batch loss 1.26099205 epoch total loss 1.23029661\n",
      "Trained batch 625 batch loss 1.14039135 epoch total loss 1.23015273\n",
      "Trained batch 626 batch loss 1.26500821 epoch total loss 1.2302084\n",
      "Trained batch 627 batch loss 1.36138928 epoch total loss 1.23041761\n",
      "Trained batch 628 batch loss 1.35928679 epoch total loss 1.23062289\n",
      "Trained batch 629 batch loss 1.38580024 epoch total loss 1.23086965\n",
      "Trained batch 630 batch loss 1.20430195 epoch total loss 1.23082745\n",
      "Trained batch 631 batch loss 1.26181364 epoch total loss 1.23087656\n",
      "Trained batch 632 batch loss 1.30526865 epoch total loss 1.23099434\n",
      "Trained batch 633 batch loss 1.22209549 epoch total loss 1.23098028\n",
      "Trained batch 634 batch loss 1.29864645 epoch total loss 1.23108697\n",
      "Trained batch 635 batch loss 1.24658823 epoch total loss 1.23111141\n",
      "Trained batch 636 batch loss 1.23813176 epoch total loss 1.23112249\n",
      "Trained batch 637 batch loss 1.20180929 epoch total loss 1.23107636\n",
      "Trained batch 638 batch loss 1.35397696 epoch total loss 1.23126912\n",
      "Trained batch 639 batch loss 1.00227439 epoch total loss 1.23091066\n",
      "Trained batch 640 batch loss 0.992067695 epoch total loss 1.23053753\n",
      "Trained batch 641 batch loss 1.16184771 epoch total loss 1.23043036\n",
      "Trained batch 642 batch loss 1.25924778 epoch total loss 1.23047531\n",
      "Trained batch 643 batch loss 1.20567763 epoch total loss 1.2304368\n",
      "Trained batch 644 batch loss 1.24044561 epoch total loss 1.2304523\n",
      "Trained batch 645 batch loss 1.28964829 epoch total loss 1.23054409\n",
      "Trained batch 646 batch loss 1.21493936 epoch total loss 1.23052\n",
      "Trained batch 647 batch loss 1.27075493 epoch total loss 1.23058212\n",
      "Trained batch 648 batch loss 1.33218646 epoch total loss 1.230739\n",
      "Trained batch 649 batch loss 1.41006958 epoch total loss 1.23101532\n",
      "Trained batch 650 batch loss 1.48129404 epoch total loss 1.23140037\n",
      "Trained batch 651 batch loss 1.32829201 epoch total loss 1.23154926\n",
      "Trained batch 652 batch loss 1.10268331 epoch total loss 1.23135161\n",
      "Trained batch 653 batch loss 1.18641961 epoch total loss 1.23128271\n",
      "Trained batch 654 batch loss 1.0943774 epoch total loss 1.23107338\n",
      "Trained batch 655 batch loss 1.24682748 epoch total loss 1.23109746\n",
      "Trained batch 656 batch loss 1.29524148 epoch total loss 1.23119521\n",
      "Trained batch 657 batch loss 1.24002409 epoch total loss 1.23120868\n",
      "Trained batch 658 batch loss 1.1958878 epoch total loss 1.23115492\n",
      "Trained batch 659 batch loss 1.32969975 epoch total loss 1.23130453\n",
      "Trained batch 660 batch loss 1.28743076 epoch total loss 1.23138952\n",
      "Trained batch 661 batch loss 1.26073837 epoch total loss 1.23143399\n",
      "Trained batch 662 batch loss 1.30512011 epoch total loss 1.23154521\n",
      "Trained batch 663 batch loss 1.20201385 epoch total loss 1.23150074\n",
      "Trained batch 664 batch loss 1.13216531 epoch total loss 1.23135114\n",
      "Trained batch 665 batch loss 1.14920688 epoch total loss 1.23122764\n",
      "Trained batch 666 batch loss 1.29807615 epoch total loss 1.23132801\n",
      "Trained batch 667 batch loss 1.39009356 epoch total loss 1.23156595\n",
      "Trained batch 668 batch loss 1.31789303 epoch total loss 1.23169518\n",
      "Trained batch 669 batch loss 1.3603723 epoch total loss 1.23188758\n",
      "Trained batch 670 batch loss 1.17817807 epoch total loss 1.23180735\n",
      "Trained batch 671 batch loss 1.04876637 epoch total loss 1.2315346\n",
      "Trained batch 672 batch loss 1.26866388 epoch total loss 1.23158979\n",
      "Trained batch 673 batch loss 1.19511163 epoch total loss 1.23153567\n",
      "Trained batch 674 batch loss 1.20657015 epoch total loss 1.2314986\n",
      "Trained batch 675 batch loss 1.15582538 epoch total loss 1.23138642\n",
      "Trained batch 676 batch loss 1.15799594 epoch total loss 1.23127794\n",
      "Trained batch 677 batch loss 1.13263059 epoch total loss 1.23113215\n",
      "Trained batch 678 batch loss 1.2264055 epoch total loss 1.23112524\n",
      "Trained batch 679 batch loss 1.33955836 epoch total loss 1.23128486\n",
      "Trained batch 680 batch loss 1.35835326 epoch total loss 1.23147166\n",
      "Trained batch 681 batch loss 1.30609202 epoch total loss 1.23158133\n",
      "Trained batch 682 batch loss 1.28174651 epoch total loss 1.23165476\n",
      "Trained batch 683 batch loss 1.21154535 epoch total loss 1.23162544\n",
      "Trained batch 684 batch loss 1.12969136 epoch total loss 1.23147631\n",
      "Trained batch 685 batch loss 1.0355618 epoch total loss 1.23119044\n",
      "Trained batch 686 batch loss 1.14672124 epoch total loss 1.2310673\n",
      "Trained batch 687 batch loss 1.2791605 epoch total loss 1.23113728\n",
      "Trained batch 688 batch loss 1.28366196 epoch total loss 1.23121369\n",
      "Trained batch 689 batch loss 1.34543359 epoch total loss 1.23137951\n",
      "Trained batch 690 batch loss 1.13592362 epoch total loss 1.23124111\n",
      "Trained batch 691 batch loss 1.19977808 epoch total loss 1.23119557\n",
      "Trained batch 692 batch loss 1.24563932 epoch total loss 1.23121655\n",
      "Trained batch 693 batch loss 1.08382452 epoch total loss 1.23100376\n",
      "Trained batch 694 batch loss 1.10587299 epoch total loss 1.23082352\n",
      "Trained batch 695 batch loss 1.24708772 epoch total loss 1.23084688\n",
      "Trained batch 696 batch loss 1.24746978 epoch total loss 1.23087084\n",
      "Trained batch 697 batch loss 1.24107885 epoch total loss 1.23088551\n",
      "Trained batch 698 batch loss 1.2637341 epoch total loss 1.23093259\n",
      "Trained batch 699 batch loss 1.26677132 epoch total loss 1.23098385\n",
      "Trained batch 700 batch loss 1.26682055 epoch total loss 1.23103511\n",
      "Trained batch 701 batch loss 1.22487557 epoch total loss 1.23102629\n",
      "Trained batch 702 batch loss 1.15952349 epoch total loss 1.23092437\n",
      "Trained batch 703 batch loss 1.26245117 epoch total loss 1.23096931\n",
      "Trained batch 704 batch loss 1.09420466 epoch total loss 1.230775\n",
      "Trained batch 705 batch loss 1.16054189 epoch total loss 1.23067534\n",
      "Trained batch 706 batch loss 1.13264143 epoch total loss 1.23053646\n",
      "Trained batch 707 batch loss 1.32342529 epoch total loss 1.23066783\n",
      "Trained batch 708 batch loss 1.45984316 epoch total loss 1.23099148\n",
      "Trained batch 709 batch loss 1.44872487 epoch total loss 1.23129857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 710 batch loss 1.36914659 epoch total loss 1.23149276\n",
      "Trained batch 711 batch loss 1.22550499 epoch total loss 1.23148441\n",
      "Trained batch 712 batch loss 1.17476249 epoch total loss 1.23140466\n",
      "Trained batch 713 batch loss 1.01994467 epoch total loss 1.23110807\n",
      "Trained batch 714 batch loss 1.04077744 epoch total loss 1.23084152\n",
      "Trained batch 715 batch loss 0.98078835 epoch total loss 1.23049176\n",
      "Trained batch 716 batch loss 1.08201921 epoch total loss 1.23028445\n",
      "Trained batch 717 batch loss 1.14273596 epoch total loss 1.23016238\n",
      "Trained batch 718 batch loss 1.33258 epoch total loss 1.23030508\n",
      "Trained batch 719 batch loss 1.22467566 epoch total loss 1.23029721\n",
      "Trained batch 720 batch loss 1.24683082 epoch total loss 1.2303201\n",
      "Trained batch 721 batch loss 1.31865478 epoch total loss 1.23044264\n",
      "Trained batch 722 batch loss 1.2315532 epoch total loss 1.23044419\n",
      "Trained batch 723 batch loss 1.2578975 epoch total loss 1.23048222\n",
      "Trained batch 724 batch loss 1.31183243 epoch total loss 1.23059452\n",
      "Trained batch 725 batch loss 1.4342761 epoch total loss 1.23087549\n",
      "Trained batch 726 batch loss 1.20634151 epoch total loss 1.23084164\n",
      "Trained batch 727 batch loss 1.25105238 epoch total loss 1.23086941\n",
      "Trained batch 728 batch loss 1.20425928 epoch total loss 1.23083293\n",
      "Trained batch 729 batch loss 1.25371504 epoch total loss 1.23086441\n",
      "Trained batch 730 batch loss 1.23597288 epoch total loss 1.23087132\n",
      "Trained batch 731 batch loss 1.30721927 epoch total loss 1.23097575\n",
      "Trained batch 732 batch loss 1.24106383 epoch total loss 1.23098958\n",
      "Trained batch 733 batch loss 1.2277962 epoch total loss 1.23098516\n",
      "Trained batch 734 batch loss 1.22597623 epoch total loss 1.23097837\n",
      "Trained batch 735 batch loss 1.22056592 epoch total loss 1.23096418\n",
      "Trained batch 736 batch loss 1.26340818 epoch total loss 1.23100829\n",
      "Trained batch 737 batch loss 1.16776681 epoch total loss 1.23092246\n",
      "Trained batch 738 batch loss 1.23894238 epoch total loss 1.23093343\n",
      "Trained batch 739 batch loss 1.28407931 epoch total loss 1.23100531\n",
      "Trained batch 740 batch loss 1.20926881 epoch total loss 1.23097587\n",
      "Trained batch 741 batch loss 1.31714225 epoch total loss 1.23109221\n",
      "Trained batch 742 batch loss 1.17891526 epoch total loss 1.23102188\n",
      "Trained batch 743 batch loss 1.26863503 epoch total loss 1.23107243\n",
      "Trained batch 744 batch loss 1.30034316 epoch total loss 1.23116553\n",
      "Trained batch 745 batch loss 1.2056253 epoch total loss 1.23113132\n",
      "Trained batch 746 batch loss 1.1098597 epoch total loss 1.23096871\n",
      "Trained batch 747 batch loss 1.15854049 epoch total loss 1.2308718\n",
      "Trained batch 748 batch loss 1.26056302 epoch total loss 1.23091149\n",
      "Trained batch 749 batch loss 1.30661774 epoch total loss 1.23101258\n",
      "Trained batch 750 batch loss 1.26986241 epoch total loss 1.23106432\n",
      "Trained batch 751 batch loss 1.28451061 epoch total loss 1.23113549\n",
      "Trained batch 752 batch loss 1.17783475 epoch total loss 1.23106468\n",
      "Trained batch 753 batch loss 1.20767784 epoch total loss 1.23103368\n",
      "Trained batch 754 batch loss 1.19793701 epoch total loss 1.23098969\n",
      "Trained batch 755 batch loss 1.05898166 epoch total loss 1.23076189\n",
      "Trained batch 756 batch loss 1.26335573 epoch total loss 1.23080504\n",
      "Trained batch 757 batch loss 1.25666845 epoch total loss 1.23083913\n",
      "Trained batch 758 batch loss 1.31079662 epoch total loss 1.23094463\n",
      "Trained batch 759 batch loss 1.2169764 epoch total loss 1.23092628\n",
      "Trained batch 760 batch loss 1.1874702 epoch total loss 1.23086905\n",
      "Trained batch 761 batch loss 1.15672171 epoch total loss 1.23077166\n",
      "Trained batch 762 batch loss 1.28232455 epoch total loss 1.23083937\n",
      "Trained batch 763 batch loss 1.29645383 epoch total loss 1.23092532\n",
      "Trained batch 764 batch loss 1.30066931 epoch total loss 1.23101664\n",
      "Trained batch 765 batch loss 1.20324326 epoch total loss 1.23098028\n",
      "Trained batch 766 batch loss 1.24556887 epoch total loss 1.23099935\n",
      "Trained batch 767 batch loss 1.31057358 epoch total loss 1.23110306\n",
      "Trained batch 768 batch loss 1.19132471 epoch total loss 1.23105133\n",
      "Trained batch 769 batch loss 1.35183 epoch total loss 1.23120832\n",
      "Trained batch 770 batch loss 1.33488607 epoch total loss 1.23134303\n",
      "Trained batch 771 batch loss 1.18745112 epoch total loss 1.23128605\n",
      "Trained batch 772 batch loss 1.40561271 epoch total loss 1.23151183\n",
      "Trained batch 773 batch loss 1.28931451 epoch total loss 1.23158669\n",
      "Trained batch 774 batch loss 1.18715405 epoch total loss 1.23152924\n",
      "Trained batch 775 batch loss 1.23288023 epoch total loss 1.23153102\n",
      "Trained batch 776 batch loss 1.3034153 epoch total loss 1.23162365\n",
      "Trained batch 777 batch loss 1.20819819 epoch total loss 1.23159349\n",
      "Trained batch 778 batch loss 1.20509613 epoch total loss 1.2315594\n",
      "Trained batch 779 batch loss 1.23787141 epoch total loss 1.2315675\n",
      "Trained batch 780 batch loss 1.10847807 epoch total loss 1.23140967\n",
      "Trained batch 781 batch loss 1.11601412 epoch total loss 1.23126185\n",
      "Trained batch 782 batch loss 1.2435708 epoch total loss 1.2312777\n",
      "Trained batch 783 batch loss 1.04619312 epoch total loss 1.23104131\n",
      "Trained batch 784 batch loss 1.06223536 epoch total loss 1.23082602\n",
      "Trained batch 785 batch loss 0.956582665 epoch total loss 1.23047674\n",
      "Trained batch 786 batch loss 1.0773046 epoch total loss 1.23028183\n",
      "Trained batch 787 batch loss 1.18783152 epoch total loss 1.23022783\n",
      "Trained batch 788 batch loss 1.40332866 epoch total loss 1.23044753\n",
      "Trained batch 789 batch loss 1.34825552 epoch total loss 1.2305969\n",
      "Trained batch 790 batch loss 1.21798956 epoch total loss 1.23058093\n",
      "Trained batch 791 batch loss 1.18435645 epoch total loss 1.23052251\n",
      "Trained batch 792 batch loss 1.06883514 epoch total loss 1.23031831\n",
      "Trained batch 793 batch loss 1.20700598 epoch total loss 1.23028898\n",
      "Trained batch 794 batch loss 1.18082929 epoch total loss 1.23022664\n",
      "Trained batch 795 batch loss 1.30276608 epoch total loss 1.23031795\n",
      "Trained batch 796 batch loss 1.26080382 epoch total loss 1.23035622\n",
      "Trained batch 797 batch loss 1.35657072 epoch total loss 1.23051465\n",
      "Trained batch 798 batch loss 1.33792365 epoch total loss 1.23064923\n",
      "Trained batch 799 batch loss 1.31648 epoch total loss 1.23075664\n",
      "Trained batch 800 batch loss 1.18816817 epoch total loss 1.23070347\n",
      "Trained batch 801 batch loss 1.19066334 epoch total loss 1.23065341\n",
      "Trained batch 802 batch loss 1.08303404 epoch total loss 1.23046935\n",
      "Trained batch 803 batch loss 1.16209173 epoch total loss 1.23038423\n",
      "Trained batch 804 batch loss 1.1202929 epoch total loss 1.23024726\n",
      "Trained batch 805 batch loss 1.21045256 epoch total loss 1.2302227\n",
      "Trained batch 806 batch loss 1.25614738 epoch total loss 1.23025489\n",
      "Trained batch 807 batch loss 1.2113173 epoch total loss 1.2302314\n",
      "Trained batch 808 batch loss 1.15966046 epoch total loss 1.23014414\n",
      "Trained batch 809 batch loss 1.18396139 epoch total loss 1.23008704\n",
      "Trained batch 810 batch loss 1.18446898 epoch total loss 1.23003066\n",
      "Trained batch 811 batch loss 1.21147203 epoch total loss 1.23000777\n",
      "Trained batch 812 batch loss 1.23985875 epoch total loss 1.23001993\n",
      "Trained batch 813 batch loss 1.29271495 epoch total loss 1.23009706\n",
      "Trained batch 814 batch loss 1.20725834 epoch total loss 1.23006904\n",
      "Trained batch 815 batch loss 1.12441635 epoch total loss 1.22993934\n",
      "Trained batch 816 batch loss 1.18887711 epoch total loss 1.22988904\n",
      "Trained batch 817 batch loss 1.23754716 epoch total loss 1.22989845\n",
      "Trained batch 818 batch loss 1.18989086 epoch total loss 1.22984958\n",
      "Trained batch 819 batch loss 1.33592963 epoch total loss 1.22997904\n",
      "Trained batch 820 batch loss 1.34150839 epoch total loss 1.23011506\n",
      "Trained batch 821 batch loss 1.36740863 epoch total loss 1.23028231\n",
      "Trained batch 822 batch loss 1.28137529 epoch total loss 1.23034441\n",
      "Trained batch 823 batch loss 1.20859814 epoch total loss 1.23031807\n",
      "Trained batch 824 batch loss 1.13412452 epoch total loss 1.23020124\n",
      "Trained batch 825 batch loss 1.29463887 epoch total loss 1.23027933\n",
      "Trained batch 826 batch loss 1.1503917 epoch total loss 1.23018265\n",
      "Trained batch 827 batch loss 1.10388434 epoch total loss 1.23003\n",
      "Trained batch 828 batch loss 1.27984381 epoch total loss 1.23009\n",
      "Trained batch 829 batch loss 1.1876111 epoch total loss 1.23003888\n",
      "Trained batch 830 batch loss 1.11060917 epoch total loss 1.229895\n",
      "Trained batch 831 batch loss 1.36951137 epoch total loss 1.23006296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 832 batch loss 1.26750219 epoch total loss 1.23010802\n",
      "Trained batch 833 batch loss 1.28470945 epoch total loss 1.23017347\n",
      "Trained batch 834 batch loss 1.1198864 epoch total loss 1.23004127\n",
      "Trained batch 835 batch loss 1.02416492 epoch total loss 1.22979462\n",
      "Trained batch 836 batch loss 1.11107492 epoch total loss 1.22965264\n",
      "Trained batch 837 batch loss 1.06669307 epoch total loss 1.22945786\n",
      "Trained batch 838 batch loss 1.08017552 epoch total loss 1.22927976\n",
      "Trained batch 839 batch loss 1.00901341 epoch total loss 1.22901726\n",
      "Trained batch 840 batch loss 1.07407153 epoch total loss 1.22883284\n",
      "Trained batch 841 batch loss 1.14086533 epoch total loss 1.22872829\n",
      "Trained batch 842 batch loss 1.22480774 epoch total loss 1.22872365\n",
      "Trained batch 843 batch loss 1.19415438 epoch total loss 1.22868276\n",
      "Trained batch 844 batch loss 1.231933 epoch total loss 1.22868657\n",
      "Trained batch 845 batch loss 1.24267685 epoch total loss 1.22870314\n",
      "Trained batch 846 batch loss 1.15844381 epoch total loss 1.22862\n",
      "Trained batch 847 batch loss 1.29757977 epoch total loss 1.22870159\n",
      "Trained batch 848 batch loss 1.21556759 epoch total loss 1.22868609\n",
      "Trained batch 849 batch loss 1.0176363 epoch total loss 1.22843742\n",
      "Trained batch 850 batch loss 0.957036853 epoch total loss 1.22811806\n",
      "Trained batch 851 batch loss 1.04404688 epoch total loss 1.22790182\n",
      "Trained batch 852 batch loss 1.17507267 epoch total loss 1.22783983\n",
      "Trained batch 853 batch loss 1.17211294 epoch total loss 1.2277745\n",
      "Trained batch 854 batch loss 1.1676302 epoch total loss 1.22770405\n",
      "Trained batch 855 batch loss 1.17826307 epoch total loss 1.22764611\n",
      "Trained batch 856 batch loss 1.26669979 epoch total loss 1.22769177\n",
      "Trained batch 857 batch loss 1.25069642 epoch total loss 1.22771871\n",
      "Trained batch 858 batch loss 1.32606196 epoch total loss 1.22783327\n",
      "Trained batch 859 batch loss 1.21915662 epoch total loss 1.22782314\n",
      "Trained batch 860 batch loss 1.19606614 epoch total loss 1.22778618\n",
      "Trained batch 861 batch loss 1.14694977 epoch total loss 1.22769237\n",
      "Trained batch 862 batch loss 1.25340807 epoch total loss 1.22772217\n",
      "Trained batch 863 batch loss 1.32682574 epoch total loss 1.22783697\n",
      "Trained batch 864 batch loss 1.42056859 epoch total loss 1.22806\n",
      "Trained batch 865 batch loss 1.18864834 epoch total loss 1.22801435\n",
      "Trained batch 866 batch loss 1.2508533 epoch total loss 1.2280407\n",
      "Trained batch 867 batch loss 1.17059219 epoch total loss 1.22797441\n",
      "Trained batch 868 batch loss 1.24236798 epoch total loss 1.22799087\n",
      "Trained batch 869 batch loss 1.16337967 epoch total loss 1.22791648\n",
      "Trained batch 870 batch loss 1.26216376 epoch total loss 1.22795594\n",
      "Trained batch 871 batch loss 1.28434837 epoch total loss 1.22802067\n",
      "Trained batch 872 batch loss 1.22269034 epoch total loss 1.22801447\n",
      "Trained batch 873 batch loss 1.16704047 epoch total loss 1.22794461\n",
      "Trained batch 874 batch loss 1.13141418 epoch total loss 1.22783422\n",
      "Trained batch 875 batch loss 0.99717617 epoch total loss 1.22757053\n",
      "Trained batch 876 batch loss 1.17737186 epoch total loss 1.22751331\n",
      "Trained batch 877 batch loss 1.25328314 epoch total loss 1.22754264\n",
      "Trained batch 878 batch loss 1.22968316 epoch total loss 1.22754514\n",
      "Trained batch 879 batch loss 1.24003482 epoch total loss 1.22755933\n",
      "Trained batch 880 batch loss 1.12673879 epoch total loss 1.22744477\n",
      "Trained batch 881 batch loss 1.08657575 epoch total loss 1.22728479\n",
      "Trained batch 882 batch loss 1.24230349 epoch total loss 1.22730184\n",
      "Trained batch 883 batch loss 1.33256245 epoch total loss 1.22742105\n",
      "Trained batch 884 batch loss 1.29811478 epoch total loss 1.22750092\n",
      "Trained batch 885 batch loss 1.21899855 epoch total loss 1.22749138\n",
      "Trained batch 886 batch loss 1.10999978 epoch total loss 1.2273587\n",
      "Trained batch 887 batch loss 0.909498 epoch total loss 1.22700036\n",
      "Trained batch 888 batch loss 0.984018087 epoch total loss 1.22672677\n",
      "Trained batch 889 batch loss 0.914554119 epoch total loss 1.22637558\n",
      "Trained batch 890 batch loss 0.968877435 epoch total loss 1.22608626\n",
      "Trained batch 891 batch loss 1.09182084 epoch total loss 1.22593558\n",
      "Trained batch 892 batch loss 1.28054094 epoch total loss 1.22599673\n",
      "Trained batch 893 batch loss 1.27858484 epoch total loss 1.22605562\n",
      "Trained batch 894 batch loss 1.40262568 epoch total loss 1.22625303\n",
      "Trained batch 895 batch loss 1.32963324 epoch total loss 1.22636855\n",
      "Trained batch 896 batch loss 1.21217597 epoch total loss 1.22635269\n",
      "Trained batch 897 batch loss 1.12547934 epoch total loss 1.22624028\n",
      "Trained batch 898 batch loss 1.13851786 epoch total loss 1.22614264\n",
      "Trained batch 899 batch loss 1.1547308 epoch total loss 1.22606325\n",
      "Trained batch 900 batch loss 1.193802 epoch total loss 1.22602737\n",
      "Trained batch 901 batch loss 1.26988363 epoch total loss 1.22607613\n",
      "Trained batch 902 batch loss 1.29066682 epoch total loss 1.22614765\n",
      "Trained batch 903 batch loss 1.29429007 epoch total loss 1.22622323\n",
      "Trained batch 904 batch loss 1.29794 epoch total loss 1.2263025\n",
      "Trained batch 905 batch loss 1.24397707 epoch total loss 1.22632217\n",
      "Trained batch 906 batch loss 1.34150815 epoch total loss 1.22644937\n",
      "Trained batch 907 batch loss 1.44259477 epoch total loss 1.22668767\n",
      "Trained batch 908 batch loss 1.26857924 epoch total loss 1.2267338\n",
      "Trained batch 909 batch loss 1.43449938 epoch total loss 1.22696233\n",
      "Trained batch 910 batch loss 1.28110218 epoch total loss 1.22702181\n",
      "Trained batch 911 batch loss 1.1941402 epoch total loss 1.22698569\n",
      "Trained batch 912 batch loss 1.20504081 epoch total loss 1.22696161\n",
      "Trained batch 913 batch loss 1.20621681 epoch total loss 1.22693884\n",
      "Trained batch 914 batch loss 1.10393798 epoch total loss 1.22680426\n",
      "Trained batch 915 batch loss 1.05910552 epoch total loss 1.22662091\n",
      "Trained batch 916 batch loss 1.03309059 epoch total loss 1.22640967\n",
      "Trained batch 917 batch loss 1.04524386 epoch total loss 1.22621214\n",
      "Trained batch 918 batch loss 1.24774218 epoch total loss 1.22623563\n",
      "Trained batch 919 batch loss 1.2926389 epoch total loss 1.22630787\n",
      "Trained batch 920 batch loss 1.48032236 epoch total loss 1.22658396\n",
      "Trained batch 921 batch loss 1.43892717 epoch total loss 1.22681463\n",
      "Trained batch 922 batch loss 1.24881923 epoch total loss 1.22683847\n",
      "Trained batch 923 batch loss 1.34092498 epoch total loss 1.22696209\n",
      "Trained batch 924 batch loss 1.20514858 epoch total loss 1.22693849\n",
      "Trained batch 925 batch loss 1.08680451 epoch total loss 1.22678697\n",
      "Trained batch 926 batch loss 1.20533252 epoch total loss 1.22676384\n",
      "Trained batch 927 batch loss 1.25104189 epoch total loss 1.22679007\n",
      "Trained batch 928 batch loss 1.15556896 epoch total loss 1.2267133\n",
      "Trained batch 929 batch loss 1.19039154 epoch total loss 1.2266742\n",
      "Trained batch 930 batch loss 1.29475522 epoch total loss 1.22674739\n",
      "Trained batch 931 batch loss 1.25364709 epoch total loss 1.22677636\n",
      "Trained batch 932 batch loss 1.21550882 epoch total loss 1.2267642\n",
      "Trained batch 933 batch loss 1.22324979 epoch total loss 1.22676051\n",
      "Trained batch 934 batch loss 1.14739084 epoch total loss 1.22667539\n",
      "Trained batch 935 batch loss 1.1241765 epoch total loss 1.22656572\n",
      "Trained batch 936 batch loss 1.15393949 epoch total loss 1.22648811\n",
      "Trained batch 937 batch loss 1.19045424 epoch total loss 1.22644973\n",
      "Trained batch 938 batch loss 1.30063212 epoch total loss 1.22652876\n",
      "Trained batch 939 batch loss 1.31266606 epoch total loss 1.22662044\n",
      "Trained batch 940 batch loss 1.2962209 epoch total loss 1.22669458\n",
      "Trained batch 941 batch loss 1.35593832 epoch total loss 1.22683191\n",
      "Trained batch 942 batch loss 1.34209371 epoch total loss 1.22695422\n",
      "Trained batch 943 batch loss 1.3488791 epoch total loss 1.22708356\n",
      "Trained batch 944 batch loss 1.1892283 epoch total loss 1.22704339\n",
      "Trained batch 945 batch loss 1.21755934 epoch total loss 1.22703338\n",
      "Trained batch 946 batch loss 1.2499 epoch total loss 1.22705746\n",
      "Trained batch 947 batch loss 1.30838883 epoch total loss 1.22714329\n",
      "Trained batch 948 batch loss 1.22316134 epoch total loss 1.22713912\n",
      "Trained batch 949 batch loss 1.12313342 epoch total loss 1.22702956\n",
      "Trained batch 950 batch loss 1.09533477 epoch total loss 1.22689092\n",
      "Trained batch 951 batch loss 1.11260962 epoch total loss 1.22677076\n",
      "Trained batch 952 batch loss 1.20300269 epoch total loss 1.22674572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 953 batch loss 1.20644855 epoch total loss 1.22672439\n",
      "Trained batch 954 batch loss 1.13626647 epoch total loss 1.2266295\n",
      "Trained batch 955 batch loss 1.19000268 epoch total loss 1.22659123\n",
      "Trained batch 956 batch loss 1.34379327 epoch total loss 1.22671378\n",
      "Trained batch 957 batch loss 1.50772703 epoch total loss 1.22700739\n",
      "Trained batch 958 batch loss 1.40785766 epoch total loss 1.22719622\n",
      "Trained batch 959 batch loss 1.33614051 epoch total loss 1.22730982\n",
      "Trained batch 960 batch loss 1.31464386 epoch total loss 1.2274009\n",
      "Trained batch 961 batch loss 1.23398745 epoch total loss 1.22740769\n",
      "Trained batch 962 batch loss 1.14946151 epoch total loss 1.22732663\n",
      "Trained batch 963 batch loss 1.17133665 epoch total loss 1.22726858\n",
      "Trained batch 964 batch loss 1.31019258 epoch total loss 1.22735453\n",
      "Trained batch 965 batch loss 1.17985308 epoch total loss 1.22730529\n",
      "Trained batch 966 batch loss 1.10235834 epoch total loss 1.22717607\n",
      "Trained batch 967 batch loss 1.03010321 epoch total loss 1.22697222\n",
      "Trained batch 968 batch loss 1.11088705 epoch total loss 1.2268523\n",
      "Trained batch 969 batch loss 1.04141033 epoch total loss 1.22666085\n",
      "Trained batch 970 batch loss 1.29204321 epoch total loss 1.2267282\n",
      "Trained batch 971 batch loss 1.5013088 epoch total loss 1.22701108\n",
      "Trained batch 972 batch loss 1.57006085 epoch total loss 1.22736394\n",
      "Trained batch 973 batch loss 1.44925737 epoch total loss 1.22759199\n",
      "Trained batch 974 batch loss 1.33035386 epoch total loss 1.22769749\n",
      "Trained batch 975 batch loss 1.39545286 epoch total loss 1.22786963\n",
      "Trained batch 976 batch loss 1.35231757 epoch total loss 1.22799706\n",
      "Trained batch 977 batch loss 1.18688309 epoch total loss 1.22795498\n",
      "Trained batch 978 batch loss 1.30922055 epoch total loss 1.22803807\n",
      "Trained batch 979 batch loss 1.29932511 epoch total loss 1.22811091\n",
      "Trained batch 980 batch loss 1.3438468 epoch total loss 1.22822905\n",
      "Trained batch 981 batch loss 1.49906909 epoch total loss 1.22850502\n",
      "Trained batch 982 batch loss 1.41681075 epoch total loss 1.22869682\n",
      "Trained batch 983 batch loss 1.47097635 epoch total loss 1.22894335\n",
      "Trained batch 984 batch loss 1.19917 epoch total loss 1.22891307\n",
      "Trained batch 985 batch loss 1.17854714 epoch total loss 1.22886205\n",
      "Trained batch 986 batch loss 1.18115568 epoch total loss 1.22881365\n",
      "Trained batch 987 batch loss 1.18877625 epoch total loss 1.228773\n",
      "Trained batch 988 batch loss 1.15376902 epoch total loss 1.22869718\n",
      "Trained batch 989 batch loss 1.10689116 epoch total loss 1.22857404\n",
      "Trained batch 990 batch loss 1.12285352 epoch total loss 1.22846723\n",
      "Trained batch 991 batch loss 1.13312757 epoch total loss 1.22837102\n",
      "Trained batch 992 batch loss 1.02641022 epoch total loss 1.22816741\n",
      "Trained batch 993 batch loss 1.04775 epoch total loss 1.22798562\n",
      "Trained batch 994 batch loss 1.1890949 epoch total loss 1.22794652\n",
      "Trained batch 995 batch loss 1.15443766 epoch total loss 1.22787261\n",
      "Trained batch 996 batch loss 1.09581661 epoch total loss 1.22774\n",
      "Trained batch 997 batch loss 1.13021362 epoch total loss 1.2276423\n",
      "Trained batch 998 batch loss 1.16200054 epoch total loss 1.22757649\n",
      "Trained batch 999 batch loss 1.23443341 epoch total loss 1.22758329\n",
      "Trained batch 1000 batch loss 1.19182992 epoch total loss 1.22754753\n",
      "Trained batch 1001 batch loss 1.28907561 epoch total loss 1.22760892\n",
      "Trained batch 1002 batch loss 1.25892782 epoch total loss 1.22764015\n",
      "Trained batch 1003 batch loss 1.09676337 epoch total loss 1.22750974\n",
      "Trained batch 1004 batch loss 0.978313148 epoch total loss 1.22726154\n",
      "Trained batch 1005 batch loss 1.22726011 epoch total loss 1.22726154\n",
      "Trained batch 1006 batch loss 1.32862949 epoch total loss 1.22736228\n",
      "Trained batch 1007 batch loss 1.34818745 epoch total loss 1.2274822\n",
      "Trained batch 1008 batch loss 1.28348279 epoch total loss 1.22753775\n",
      "Trained batch 1009 batch loss 1.38066173 epoch total loss 1.22768939\n",
      "Trained batch 1010 batch loss 1.27979434 epoch total loss 1.227741\n",
      "Trained batch 1011 batch loss 1.20183468 epoch total loss 1.22771537\n",
      "Trained batch 1012 batch loss 1.40036058 epoch total loss 1.22788596\n",
      "Trained batch 1013 batch loss 1.24200916 epoch total loss 1.2279\n",
      "Trained batch 1014 batch loss 1.2114563 epoch total loss 1.2278837\n",
      "Trained batch 1015 batch loss 1.29747438 epoch total loss 1.22795224\n",
      "Trained batch 1016 batch loss 1.31636465 epoch total loss 1.22803938\n",
      "Trained batch 1017 batch loss 1.27105403 epoch total loss 1.22808158\n",
      "Trained batch 1018 batch loss 1.36696076 epoch total loss 1.22821796\n",
      "Trained batch 1019 batch loss 1.39531088 epoch total loss 1.22838199\n",
      "Trained batch 1020 batch loss 1.37410665 epoch total loss 1.2285248\n",
      "Trained batch 1021 batch loss 1.51725268 epoch total loss 1.22880757\n",
      "Trained batch 1022 batch loss 1.3100512 epoch total loss 1.22888708\n",
      "Trained batch 1023 batch loss 1.11534297 epoch total loss 1.2287761\n",
      "Trained batch 1024 batch loss 1.17889309 epoch total loss 1.22872734\n",
      "Trained batch 1025 batch loss 1.09928286 epoch total loss 1.22860098\n",
      "Trained batch 1026 batch loss 1.31530631 epoch total loss 1.2286855\n",
      "Trained batch 1027 batch loss 1.26137853 epoch total loss 1.22871733\n",
      "Trained batch 1028 batch loss 1.28693783 epoch total loss 1.22877407\n",
      "Trained batch 1029 batch loss 1.27724934 epoch total loss 1.22882104\n",
      "Trained batch 1030 batch loss 1.39730835 epoch total loss 1.22898471\n",
      "Trained batch 1031 batch loss 1.3141371 epoch total loss 1.22906721\n",
      "Trained batch 1032 batch loss 1.34130132 epoch total loss 1.22917604\n",
      "Trained batch 1033 batch loss 1.27262282 epoch total loss 1.22921801\n",
      "Trained batch 1034 batch loss 1.17982948 epoch total loss 1.2291702\n",
      "Trained batch 1035 batch loss 1.26325178 epoch total loss 1.22920322\n",
      "Trained batch 1036 batch loss 1.22648335 epoch total loss 1.2292006\n",
      "Trained batch 1037 batch loss 1.17221892 epoch total loss 1.22914565\n",
      "Trained batch 1038 batch loss 1.156919 epoch total loss 1.22907603\n",
      "Trained batch 1039 batch loss 1.21292543 epoch total loss 1.22906041\n",
      "Trained batch 1040 batch loss 1.23658061 epoch total loss 1.22906768\n",
      "Trained batch 1041 batch loss 1.12703323 epoch total loss 1.22896969\n",
      "Trained batch 1042 batch loss 1.15386248 epoch total loss 1.22889757\n",
      "Trained batch 1043 batch loss 1.15118027 epoch total loss 1.22882295\n",
      "Trained batch 1044 batch loss 1.05600977 epoch total loss 1.22865748\n",
      "Trained batch 1045 batch loss 1.14023328 epoch total loss 1.22857285\n",
      "Trained batch 1046 batch loss 1.11589253 epoch total loss 1.22846508\n",
      "Trained batch 1047 batch loss 1.04819751 epoch total loss 1.22829294\n",
      "Trained batch 1048 batch loss 1.06833553 epoch total loss 1.22814035\n",
      "Trained batch 1049 batch loss 1.07539606 epoch total loss 1.2279948\n",
      "Trained batch 1050 batch loss 1.13360429 epoch total loss 1.2279048\n",
      "Trained batch 1051 batch loss 1.14329946 epoch total loss 1.22782433\n",
      "Trained batch 1052 batch loss 1.12165868 epoch total loss 1.22772348\n",
      "Trained batch 1053 batch loss 1.07953835 epoch total loss 1.22758281\n",
      "Trained batch 1054 batch loss 1.12949228 epoch total loss 1.22748971\n",
      "Trained batch 1055 batch loss 1.4689939 epoch total loss 1.22771859\n",
      "Trained batch 1056 batch loss 1.27110422 epoch total loss 1.22775972\n",
      "Trained batch 1057 batch loss 1.16717386 epoch total loss 1.22770238\n",
      "Trained batch 1058 batch loss 1.45230293 epoch total loss 1.22791457\n",
      "Trained batch 1059 batch loss 1.3920517 epoch total loss 1.22806966\n",
      "Trained batch 1060 batch loss 1.32589614 epoch total loss 1.22816193\n",
      "Trained batch 1061 batch loss 1.172755 epoch total loss 1.22810972\n",
      "Trained batch 1062 batch loss 1.17723763 epoch total loss 1.2280618\n",
      "Trained batch 1063 batch loss 1.05437112 epoch total loss 1.22789836\n",
      "Trained batch 1064 batch loss 1.00372207 epoch total loss 1.2276876\n",
      "Trained batch 1065 batch loss 1.18157434 epoch total loss 1.22764432\n",
      "Trained batch 1066 batch loss 1.29117918 epoch total loss 1.22770381\n",
      "Trained batch 1067 batch loss 1.26494181 epoch total loss 1.22773874\n",
      "Trained batch 1068 batch loss 1.29561877 epoch total loss 1.22780228\n",
      "Trained batch 1069 batch loss 1.31859374 epoch total loss 1.22788727\n",
      "Trained batch 1070 batch loss 1.33133245 epoch total loss 1.22798383\n",
      "Trained batch 1071 batch loss 1.2782433 epoch total loss 1.2280308\n",
      "Trained batch 1072 batch loss 1.28978372 epoch total loss 1.22808838\n",
      "Trained batch 1073 batch loss 1.32210898 epoch total loss 1.228176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1074 batch loss 1.25162125 epoch total loss 1.22819781\n",
      "Trained batch 1075 batch loss 1.21708608 epoch total loss 1.22818744\n",
      "Trained batch 1076 batch loss 1.1806227 epoch total loss 1.22814333\n",
      "Trained batch 1077 batch loss 1.05508959 epoch total loss 1.22798252\n",
      "Trained batch 1078 batch loss 1.04226327 epoch total loss 1.22781026\n",
      "Trained batch 1079 batch loss 1.19096947 epoch total loss 1.22777605\n",
      "Trained batch 1080 batch loss 1.23380935 epoch total loss 1.22778165\n",
      "Trained batch 1081 batch loss 1.20209789 epoch total loss 1.22775793\n",
      "Trained batch 1082 batch loss 1.22545242 epoch total loss 1.22775578\n",
      "Trained batch 1083 batch loss 1.35169935 epoch total loss 1.22787023\n",
      "Trained batch 1084 batch loss 1.19944263 epoch total loss 1.227844\n",
      "Trained batch 1085 batch loss 1.25805187 epoch total loss 1.22787189\n",
      "Trained batch 1086 batch loss 1.25211716 epoch total loss 1.22789419\n",
      "Trained batch 1087 batch loss 1.23345804 epoch total loss 1.22789919\n",
      "Trained batch 1088 batch loss 1.14615965 epoch total loss 1.22782409\n",
      "Trained batch 1089 batch loss 1.08775842 epoch total loss 1.22769547\n",
      "Trained batch 1090 batch loss 1.24950039 epoch total loss 1.22771549\n",
      "Trained batch 1091 batch loss 1.21460962 epoch total loss 1.22770345\n",
      "Trained batch 1092 batch loss 1.27565777 epoch total loss 1.22774732\n",
      "Trained batch 1093 batch loss 1.27254605 epoch total loss 1.22778833\n",
      "Trained batch 1094 batch loss 1.25557446 epoch total loss 1.22781372\n",
      "Trained batch 1095 batch loss 1.2999562 epoch total loss 1.22787964\n",
      "Trained batch 1096 batch loss 1.24439704 epoch total loss 1.22789466\n",
      "Trained batch 1097 batch loss 1.36562419 epoch total loss 1.22802019\n",
      "Trained batch 1098 batch loss 1.30178857 epoch total loss 1.22808743\n",
      "Trained batch 1099 batch loss 1.24307728 epoch total loss 1.22810102\n",
      "Trained batch 1100 batch loss 1.19126117 epoch total loss 1.22806752\n",
      "Trained batch 1101 batch loss 1.2129786 epoch total loss 1.22805381\n",
      "Trained batch 1102 batch loss 1.14783764 epoch total loss 1.22798109\n",
      "Trained batch 1103 batch loss 1.09068227 epoch total loss 1.22785664\n",
      "Trained batch 1104 batch loss 1.16389179 epoch total loss 1.2277987\n",
      "Trained batch 1105 batch loss 1.23046446 epoch total loss 1.22780108\n",
      "Trained batch 1106 batch loss 1.1983 epoch total loss 1.22777438\n",
      "Trained batch 1107 batch loss 1.13743544 epoch total loss 1.22769272\n",
      "Trained batch 1108 batch loss 1.24375319 epoch total loss 1.22770727\n",
      "Trained batch 1109 batch loss 1.10916448 epoch total loss 1.22760034\n",
      "Trained batch 1110 batch loss 1.09763348 epoch total loss 1.22748327\n",
      "Trained batch 1111 batch loss 1.15953469 epoch total loss 1.22742212\n",
      "Trained batch 1112 batch loss 1.18756557 epoch total loss 1.22738636\n",
      "Trained batch 1113 batch loss 1.13813901 epoch total loss 1.22730625\n",
      "Trained batch 1114 batch loss 1.05744326 epoch total loss 1.22715378\n",
      "Trained batch 1115 batch loss 1.17107654 epoch total loss 1.22710347\n",
      "Trained batch 1116 batch loss 1.14481342 epoch total loss 1.22702968\n",
      "Trained batch 1117 batch loss 1.10989726 epoch total loss 1.22692478\n",
      "Trained batch 1118 batch loss 1.02313137 epoch total loss 1.22674239\n",
      "Trained batch 1119 batch loss 1.1642189 epoch total loss 1.22668648\n",
      "Trained batch 1120 batch loss 1.09832478 epoch total loss 1.22657192\n",
      "Trained batch 1121 batch loss 1.24143422 epoch total loss 1.22658515\n",
      "Trained batch 1122 batch loss 1.17126155 epoch total loss 1.2265358\n",
      "Trained batch 1123 batch loss 1.22943318 epoch total loss 1.22653842\n",
      "Trained batch 1124 batch loss 1.30032015 epoch total loss 1.2266041\n",
      "Trained batch 1125 batch loss 1.28576565 epoch total loss 1.22665668\n",
      "Trained batch 1126 batch loss 1.22194874 epoch total loss 1.2266525\n",
      "Trained batch 1127 batch loss 1.28132772 epoch total loss 1.22670102\n",
      "Trained batch 1128 batch loss 1.15378881 epoch total loss 1.22663641\n",
      "Trained batch 1129 batch loss 1.23450792 epoch total loss 1.22664332\n",
      "Trained batch 1130 batch loss 1.26412034 epoch total loss 1.22667658\n",
      "Trained batch 1131 batch loss 1.19672012 epoch total loss 1.22665012\n",
      "Trained batch 1132 batch loss 1.17309487 epoch total loss 1.22660279\n",
      "Trained batch 1133 batch loss 1.13805163 epoch total loss 1.22652471\n",
      "Trained batch 1134 batch loss 1.14673018 epoch total loss 1.22645426\n",
      "Trained batch 1135 batch loss 1.10492659 epoch total loss 1.22634733\n",
      "Trained batch 1136 batch loss 1.197541 epoch total loss 1.22632194\n",
      "Trained batch 1137 batch loss 1.21344852 epoch total loss 1.22631061\n",
      "Trained batch 1138 batch loss 1.18648946 epoch total loss 1.22627568\n",
      "Trained batch 1139 batch loss 1.21693802 epoch total loss 1.22626746\n",
      "Trained batch 1140 batch loss 1.18850231 epoch total loss 1.22623432\n",
      "Trained batch 1141 batch loss 1.13649976 epoch total loss 1.22615564\n",
      "Trained batch 1142 batch loss 1.16952384 epoch total loss 1.22610605\n",
      "Trained batch 1143 batch loss 1.1307354 epoch total loss 1.2260226\n",
      "Trained batch 1144 batch loss 1.09785497 epoch total loss 1.22591066\n",
      "Trained batch 1145 batch loss 1.17474449 epoch total loss 1.22586596\n",
      "Trained batch 1146 batch loss 1.20919394 epoch total loss 1.22585154\n",
      "Trained batch 1147 batch loss 1.18077135 epoch total loss 1.2258122\n",
      "Trained batch 1148 batch loss 1.21871758 epoch total loss 1.225806\n",
      "Trained batch 1149 batch loss 1.28331387 epoch total loss 1.22585607\n",
      "Trained batch 1150 batch loss 1.23031843 epoch total loss 1.22586\n",
      "Trained batch 1151 batch loss 1.25696313 epoch total loss 1.22588706\n",
      "Trained batch 1152 batch loss 1.30296767 epoch total loss 1.22595394\n",
      "Trained batch 1153 batch loss 1.1971885 epoch total loss 1.22592902\n",
      "Trained batch 1154 batch loss 1.33250785 epoch total loss 1.22602129\n",
      "Trained batch 1155 batch loss 1.36004293 epoch total loss 1.22613728\n",
      "Trained batch 1156 batch loss 1.28526914 epoch total loss 1.22618842\n",
      "Trained batch 1157 batch loss 1.26844478 epoch total loss 1.22622502\n",
      "Trained batch 1158 batch loss 1.40036392 epoch total loss 1.22637534\n",
      "Trained batch 1159 batch loss 1.35063219 epoch total loss 1.22648251\n",
      "Trained batch 1160 batch loss 1.25734067 epoch total loss 1.22650909\n",
      "Trained batch 1161 batch loss 1.2929194 epoch total loss 1.22656643\n",
      "Trained batch 1162 batch loss 1.11583686 epoch total loss 1.22647107\n",
      "Trained batch 1163 batch loss 1.16468668 epoch total loss 1.22641802\n",
      "Trained batch 1164 batch loss 1.22642374 epoch total loss 1.22641802\n",
      "Trained batch 1165 batch loss 1.23434579 epoch total loss 1.22642481\n",
      "Trained batch 1166 batch loss 1.22216332 epoch total loss 1.22642112\n",
      "Trained batch 1167 batch loss 1.2827909 epoch total loss 1.22646952\n",
      "Trained batch 1168 batch loss 1.15225649 epoch total loss 1.22640598\n",
      "Trained batch 1169 batch loss 1.11984921 epoch total loss 1.22631478\n",
      "Trained batch 1170 batch loss 1.18886566 epoch total loss 1.22628284\n",
      "Trained batch 1171 batch loss 1.17399311 epoch total loss 1.22623813\n",
      "Trained batch 1172 batch loss 1.29872441 epoch total loss 1.22629988\n",
      "Trained batch 1173 batch loss 1.23090303 epoch total loss 1.22630394\n",
      "Trained batch 1174 batch loss 1.22407603 epoch total loss 1.22630203\n",
      "Trained batch 1175 batch loss 1.26293111 epoch total loss 1.22633326\n",
      "Trained batch 1176 batch loss 1.30133891 epoch total loss 1.22639704\n",
      "Trained batch 1177 batch loss 1.24784577 epoch total loss 1.22641528\n",
      "Trained batch 1178 batch loss 1.01004767 epoch total loss 1.22623158\n",
      "Trained batch 1179 batch loss 1.22591686 epoch total loss 1.22623134\n",
      "Trained batch 1180 batch loss 1.09640908 epoch total loss 1.22612131\n",
      "Trained batch 1181 batch loss 1.11445606 epoch total loss 1.22602677\n",
      "Trained batch 1182 batch loss 1.08667397 epoch total loss 1.22590888\n",
      "Trained batch 1183 batch loss 1.16946208 epoch total loss 1.22586119\n",
      "Trained batch 1184 batch loss 1.13511586 epoch total loss 1.22578454\n",
      "Trained batch 1185 batch loss 1.14687598 epoch total loss 1.2257179\n",
      "Trained batch 1186 batch loss 1.10902047 epoch total loss 1.22561944\n",
      "Trained batch 1187 batch loss 1.15493214 epoch total loss 1.22556\n",
      "Trained batch 1188 batch loss 1.09133542 epoch total loss 1.22544694\n",
      "Trained batch 1189 batch loss 1.15446377 epoch total loss 1.22538722\n",
      "Trained batch 1190 batch loss 1.28391612 epoch total loss 1.22543633\n",
      "Trained batch 1191 batch loss 1.31095886 epoch total loss 1.22550809\n",
      "Trained batch 1192 batch loss 1.20804679 epoch total loss 1.22549343\n",
      "Trained batch 1193 batch loss 1.37820041 epoch total loss 1.22562146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1194 batch loss 1.26297975 epoch total loss 1.22565269\n",
      "Trained batch 1195 batch loss 1.32407832 epoch total loss 1.22573507\n",
      "Trained batch 1196 batch loss 1.14082468 epoch total loss 1.22566414\n",
      "Trained batch 1197 batch loss 1.1836623 epoch total loss 1.22562909\n",
      "Trained batch 1198 batch loss 1.23015726 epoch total loss 1.22563279\n",
      "Trained batch 1199 batch loss 1.24510038 epoch total loss 1.22564912\n",
      "Trained batch 1200 batch loss 1.17726421 epoch total loss 1.22560871\n",
      "Trained batch 1201 batch loss 1.05512989 epoch total loss 1.22546685\n",
      "Trained batch 1202 batch loss 1.09448898 epoch total loss 1.22535789\n",
      "Trained batch 1203 batch loss 1.15373731 epoch total loss 1.22529829\n",
      "Trained batch 1204 batch loss 1.06234872 epoch total loss 1.22516298\n",
      "Trained batch 1205 batch loss 1.0604136 epoch total loss 1.22502625\n",
      "Trained batch 1206 batch loss 1.17029417 epoch total loss 1.22498083\n",
      "Trained batch 1207 batch loss 1.21578753 epoch total loss 1.2249732\n",
      "Trained batch 1208 batch loss 1.20445037 epoch total loss 1.22495627\n",
      "Trained batch 1209 batch loss 1.13325322 epoch total loss 1.22488046\n",
      "Trained batch 1210 batch loss 1.11823618 epoch total loss 1.22479236\n",
      "Trained batch 1211 batch loss 1.11836958 epoch total loss 1.2247045\n",
      "Trained batch 1212 batch loss 1.38273978 epoch total loss 1.22483492\n",
      "Trained batch 1213 batch loss 1.24397552 epoch total loss 1.22485065\n",
      "Trained batch 1214 batch loss 1.2274946 epoch total loss 1.22485292\n",
      "Trained batch 1215 batch loss 1.28319144 epoch total loss 1.22490096\n",
      "Trained batch 1216 batch loss 1.21484292 epoch total loss 1.22489262\n",
      "Trained batch 1217 batch loss 1.17793536 epoch total loss 1.22485411\n",
      "Trained batch 1218 batch loss 1.29201555 epoch total loss 1.22490919\n",
      "Trained batch 1219 batch loss 1.15447366 epoch total loss 1.22485137\n",
      "Trained batch 1220 batch loss 1.17351425 epoch total loss 1.22480929\n",
      "Trained batch 1221 batch loss 1.18244147 epoch total loss 1.2247746\n",
      "Trained batch 1222 batch loss 1.15933275 epoch total loss 1.22472107\n",
      "Trained batch 1223 batch loss 1.17364609 epoch total loss 1.22467935\n",
      "Trained batch 1224 batch loss 1.04367614 epoch total loss 1.22453153\n",
      "Trained batch 1225 batch loss 0.966236234 epoch total loss 1.22432065\n",
      "Trained batch 1226 batch loss 1.12542844 epoch total loss 1.22424\n",
      "Trained batch 1227 batch loss 1.12815475 epoch total loss 1.22416162\n",
      "Trained batch 1228 batch loss 1.13268888 epoch total loss 1.22408724\n",
      "Trained batch 1229 batch loss 1.0919652 epoch total loss 1.22397971\n",
      "Trained batch 1230 batch loss 1.21444 epoch total loss 1.22397196\n",
      "Trained batch 1231 batch loss 1.02450311 epoch total loss 1.22381\n",
      "Trained batch 1232 batch loss 1.36456192 epoch total loss 1.22392416\n",
      "Trained batch 1233 batch loss 1.23646629 epoch total loss 1.22393429\n",
      "Trained batch 1234 batch loss 1.27965188 epoch total loss 1.22397947\n",
      "Trained batch 1235 batch loss 1.28345513 epoch total loss 1.22402763\n",
      "Trained batch 1236 batch loss 1.2212199 epoch total loss 1.22402525\n",
      "Trained batch 1237 batch loss 1.2084074 epoch total loss 1.22401261\n",
      "Trained batch 1238 batch loss 1.25533175 epoch total loss 1.224038\n",
      "Trained batch 1239 batch loss 1.31402719 epoch total loss 1.2241106\n",
      "Trained batch 1240 batch loss 1.31484985 epoch total loss 1.2241838\n",
      "Trained batch 1241 batch loss 1.27415586 epoch total loss 1.22422409\n",
      "Trained batch 1242 batch loss 1.30073667 epoch total loss 1.22428572\n",
      "Trained batch 1243 batch loss 1.25495601 epoch total loss 1.2243104\n",
      "Trained batch 1244 batch loss 1.29908 epoch total loss 1.22437048\n",
      "Trained batch 1245 batch loss 1.28806841 epoch total loss 1.22442174\n",
      "Trained batch 1246 batch loss 1.18994296 epoch total loss 1.22439408\n",
      "Trained batch 1247 batch loss 1.21738029 epoch total loss 1.22438848\n",
      "Trained batch 1248 batch loss 1.36318147 epoch total loss 1.22449958\n",
      "Trained batch 1249 batch loss 1.37246096 epoch total loss 1.22461808\n",
      "Trained batch 1250 batch loss 1.26409173 epoch total loss 1.22464967\n",
      "Trained batch 1251 batch loss 1.28434372 epoch total loss 1.22469735\n",
      "Trained batch 1252 batch loss 1.12547421 epoch total loss 1.22461808\n",
      "Trained batch 1253 batch loss 1.04151845 epoch total loss 1.22447193\n",
      "Trained batch 1254 batch loss 1.17969859 epoch total loss 1.22443616\n",
      "Trained batch 1255 batch loss 1.17769146 epoch total loss 1.22439897\n",
      "Trained batch 1256 batch loss 1.29728782 epoch total loss 1.22445703\n",
      "Trained batch 1257 batch loss 1.26204777 epoch total loss 1.22448695\n",
      "Trained batch 1258 batch loss 1.35197783 epoch total loss 1.22458827\n",
      "Trained batch 1259 batch loss 1.31314731 epoch total loss 1.22465849\n",
      "Trained batch 1260 batch loss 1.22184324 epoch total loss 1.22465622\n",
      "Trained batch 1261 batch loss 1.06979871 epoch total loss 1.22453344\n",
      "Trained batch 1262 batch loss 1.15989673 epoch total loss 1.2244823\n",
      "Trained batch 1263 batch loss 1.30619061 epoch total loss 1.22454691\n",
      "Trained batch 1264 batch loss 1.24785936 epoch total loss 1.22456539\n",
      "Trained batch 1265 batch loss 1.35871506 epoch total loss 1.22467136\n",
      "Trained batch 1266 batch loss 1.26239133 epoch total loss 1.22470129\n",
      "Trained batch 1267 batch loss 1.30197239 epoch total loss 1.22476232\n",
      "Trained batch 1268 batch loss 1.19331288 epoch total loss 1.22473752\n",
      "Trained batch 1269 batch loss 1.14499485 epoch total loss 1.2246747\n",
      "Trained batch 1270 batch loss 1.34555316 epoch total loss 1.22477\n",
      "Trained batch 1271 batch loss 1.20051014 epoch total loss 1.22475088\n",
      "Trained batch 1272 batch loss 1.25360203 epoch total loss 1.22477353\n",
      "Trained batch 1273 batch loss 1.17938018 epoch total loss 1.22473788\n",
      "Trained batch 1274 batch loss 1.27184427 epoch total loss 1.22477484\n",
      "Trained batch 1275 batch loss 1.2005918 epoch total loss 1.22475588\n",
      "Trained batch 1276 batch loss 1.27343225 epoch total loss 1.22479403\n",
      "Trained batch 1277 batch loss 1.24449015 epoch total loss 1.22480941\n",
      "Trained batch 1278 batch loss 1.29922009 epoch total loss 1.2248677\n",
      "Trained batch 1279 batch loss 1.26666045 epoch total loss 1.22490025\n",
      "Trained batch 1280 batch loss 1.36325669 epoch total loss 1.22500837\n",
      "Trained batch 1281 batch loss 1.3188386 epoch total loss 1.22508168\n",
      "Trained batch 1282 batch loss 1.30481553 epoch total loss 1.22514379\n",
      "Trained batch 1283 batch loss 1.31727147 epoch total loss 1.22521567\n",
      "Trained batch 1284 batch loss 1.1936425 epoch total loss 1.225191\n",
      "Trained batch 1285 batch loss 1.14213514 epoch total loss 1.22512639\n",
      "Trained batch 1286 batch loss 1.14945066 epoch total loss 1.2250675\n",
      "Trained batch 1287 batch loss 1.23360777 epoch total loss 1.22507417\n",
      "Trained batch 1288 batch loss 1.2812289 epoch total loss 1.2251178\n",
      "Trained batch 1289 batch loss 1.22898543 epoch total loss 1.22512078\n",
      "Trained batch 1290 batch loss 1.19349158 epoch total loss 1.22509623\n",
      "Trained batch 1291 batch loss 1.21616101 epoch total loss 1.22508931\n",
      "Trained batch 1292 batch loss 1.18276334 epoch total loss 1.22505653\n",
      "Trained batch 1293 batch loss 1.15868711 epoch total loss 1.22500527\n",
      "Trained batch 1294 batch loss 1.28905559 epoch total loss 1.22505474\n",
      "Trained batch 1295 batch loss 1.30856073 epoch total loss 1.22511923\n",
      "Trained batch 1296 batch loss 1.2414794 epoch total loss 1.22513187\n",
      "Trained batch 1297 batch loss 1.21737885 epoch total loss 1.22512591\n",
      "Trained batch 1298 batch loss 1.12896633 epoch total loss 1.22505176\n",
      "Trained batch 1299 batch loss 1.11107635 epoch total loss 1.22496402\n",
      "Trained batch 1300 batch loss 1.27917719 epoch total loss 1.22500575\n",
      "Trained batch 1301 batch loss 1.20896137 epoch total loss 1.22499347\n",
      "Trained batch 1302 batch loss 1.14694834 epoch total loss 1.22493351\n",
      "Trained batch 1303 batch loss 1.11700404 epoch total loss 1.22485065\n",
      "Trained batch 1304 batch loss 1.19811416 epoch total loss 1.22483015\n",
      "Trained batch 1305 batch loss 1.20218801 epoch total loss 1.22481275\n",
      "Trained batch 1306 batch loss 1.21459246 epoch total loss 1.22480488\n",
      "Trained batch 1307 batch loss 1.2974869 epoch total loss 1.22486055\n",
      "Trained batch 1308 batch loss 1.11942387 epoch total loss 1.22477984\n",
      "Trained batch 1309 batch loss 1.19571185 epoch total loss 1.22475767\n",
      "Trained batch 1310 batch loss 1.23860419 epoch total loss 1.22476828\n",
      "Trained batch 1311 batch loss 1.21518111 epoch total loss 1.22476101\n",
      "Trained batch 1312 batch loss 1.11193466 epoch total loss 1.22467494\n",
      "Trained batch 1313 batch loss 1.03519261 epoch total loss 1.22453058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1314 batch loss 1.16814947 epoch total loss 1.22448766\n",
      "Trained batch 1315 batch loss 1.18465364 epoch total loss 1.22445738\n",
      "Trained batch 1316 batch loss 1.20084763 epoch total loss 1.22443938\n",
      "Trained batch 1317 batch loss 1.26709127 epoch total loss 1.22447181\n",
      "Trained batch 1318 batch loss 1.13251579 epoch total loss 1.22440207\n",
      "Trained batch 1319 batch loss 0.964564621 epoch total loss 1.22420514\n",
      "Trained batch 1320 batch loss 1.04272795 epoch total loss 1.22406769\n",
      "Trained batch 1321 batch loss 0.994506955 epoch total loss 1.22389388\n",
      "Trained batch 1322 batch loss 1.08828115 epoch total loss 1.22379124\n",
      "Trained batch 1323 batch loss 1.07367158 epoch total loss 1.22367787\n",
      "Trained batch 1324 batch loss 1.14361382 epoch total loss 1.22361732\n",
      "Trained batch 1325 batch loss 1.12982047 epoch total loss 1.2235465\n",
      "Trained batch 1326 batch loss 1.11970615 epoch total loss 1.22346818\n",
      "Trained batch 1327 batch loss 1.07437766 epoch total loss 1.22335589\n",
      "Trained batch 1328 batch loss 1.29763699 epoch total loss 1.2234118\n",
      "Trained batch 1329 batch loss 1.46364725 epoch total loss 1.22359252\n",
      "Trained batch 1330 batch loss 1.34106898 epoch total loss 1.22368085\n",
      "Trained batch 1331 batch loss 1.38002598 epoch total loss 1.22379827\n",
      "Trained batch 1332 batch loss 1.27755928 epoch total loss 1.22383869\n",
      "Trained batch 1333 batch loss 1.2993741 epoch total loss 1.22389531\n",
      "Trained batch 1334 batch loss 1.2909615 epoch total loss 1.22394562\n",
      "Trained batch 1335 batch loss 1.2699604 epoch total loss 1.22398007\n",
      "Trained batch 1336 batch loss 1.28668141 epoch total loss 1.22402704\n",
      "Trained batch 1337 batch loss 1.21342623 epoch total loss 1.22401905\n",
      "Trained batch 1338 batch loss 1.19032836 epoch total loss 1.22399378\n",
      "Trained batch 1339 batch loss 1.16646838 epoch total loss 1.22395086\n",
      "Trained batch 1340 batch loss 1.29774129 epoch total loss 1.22400594\n",
      "Trained batch 1341 batch loss 1.2077055 epoch total loss 1.22399378\n",
      "Trained batch 1342 batch loss 1.15481222 epoch total loss 1.22394228\n",
      "Trained batch 1343 batch loss 1.17395461 epoch total loss 1.22390509\n",
      "Trained batch 1344 batch loss 1.16870248 epoch total loss 1.22386396\n",
      "Trained batch 1345 batch loss 1.10476506 epoch total loss 1.22377539\n",
      "Trained batch 1346 batch loss 1.2152462 epoch total loss 1.22376907\n",
      "Trained batch 1347 batch loss 1.21161044 epoch total loss 1.22376\n",
      "Trained batch 1348 batch loss 1.10956 epoch total loss 1.22367537\n",
      "Trained batch 1349 batch loss 0.994047284 epoch total loss 1.22350514\n",
      "Trained batch 1350 batch loss 1.20013642 epoch total loss 1.22348785\n",
      "Trained batch 1351 batch loss 1.19486976 epoch total loss 1.22346663\n",
      "Trained batch 1352 batch loss 1.27383673 epoch total loss 1.22350383\n",
      "Trained batch 1353 batch loss 1.17614627 epoch total loss 1.2234689\n",
      "Trained batch 1354 batch loss 1.20257187 epoch total loss 1.2234534\n",
      "Trained batch 1355 batch loss 1.13949311 epoch total loss 1.22339141\n",
      "Trained batch 1356 batch loss 1.33114874 epoch total loss 1.22347093\n",
      "Trained batch 1357 batch loss 1.21270752 epoch total loss 1.22346294\n",
      "Trained batch 1358 batch loss 1.28256464 epoch total loss 1.22350657\n",
      "Trained batch 1359 batch loss 1.26669955 epoch total loss 1.22353828\n",
      "Trained batch 1360 batch loss 1.21757436 epoch total loss 1.22353387\n",
      "Trained batch 1361 batch loss 1.14884257 epoch total loss 1.22347903\n",
      "Trained batch 1362 batch loss 1.15420961 epoch total loss 1.22342813\n",
      "Trained batch 1363 batch loss 1.16339087 epoch total loss 1.22338402\n",
      "Trained batch 1364 batch loss 1.19201458 epoch total loss 1.22336102\n",
      "Trained batch 1365 batch loss 1.23584783 epoch total loss 1.22337019\n",
      "Trained batch 1366 batch loss 1.19481182 epoch total loss 1.22334921\n",
      "Trained batch 1367 batch loss 1.26714194 epoch total loss 1.22338128\n",
      "Trained batch 1368 batch loss 1.24639 epoch total loss 1.22339809\n",
      "Trained batch 1369 batch loss 1.13277626 epoch total loss 1.22333193\n",
      "Trained batch 1370 batch loss 1.00565076 epoch total loss 1.2231729\n",
      "Trained batch 1371 batch loss 1.04701316 epoch total loss 1.2230444\n",
      "Trained batch 1372 batch loss 1.06107831 epoch total loss 1.22292638\n",
      "Trained batch 1373 batch loss 1.43855333 epoch total loss 1.2230835\n",
      "Trained batch 1374 batch loss 1.30430532 epoch total loss 1.22314262\n",
      "Trained batch 1375 batch loss 1.207111 epoch total loss 1.22313094\n",
      "Trained batch 1376 batch loss 1.19329643 epoch total loss 1.22310925\n",
      "Trained batch 1377 batch loss 1.17918646 epoch total loss 1.2230773\n",
      "Trained batch 1378 batch loss 1.13688874 epoch total loss 1.22301471\n",
      "Trained batch 1379 batch loss 1.13396406 epoch total loss 1.2229501\n",
      "Trained batch 1380 batch loss 1.10833454 epoch total loss 1.22286701\n",
      "Trained batch 1381 batch loss 1.20624399 epoch total loss 1.22285509\n",
      "Trained batch 1382 batch loss 1.21364021 epoch total loss 1.22284842\n",
      "Trained batch 1383 batch loss 1.17849398 epoch total loss 1.22281623\n",
      "Trained batch 1384 batch loss 1.27214801 epoch total loss 1.22285187\n",
      "Trained batch 1385 batch loss 1.11189258 epoch total loss 1.22277176\n",
      "Trained batch 1386 batch loss 1.21265829 epoch total loss 1.22276449\n",
      "Trained batch 1387 batch loss 1.0885824 epoch total loss 1.22266781\n",
      "Trained batch 1388 batch loss 1.15433443 epoch total loss 1.22261858\n",
      "Epoch 4 train loss 1.222618579864502\n",
      "Validated batch 1 batch loss 1.1496805\n",
      "Validated batch 2 batch loss 1.1942687\n",
      "Validated batch 3 batch loss 1.25162756\n",
      "Validated batch 4 batch loss 1.17539072\n",
      "Validated batch 5 batch loss 1.31711197\n",
      "Validated batch 6 batch loss 1.35874224\n",
      "Validated batch 7 batch loss 1.06185889\n",
      "Validated batch 8 batch loss 1.19489312\n",
      "Validated batch 9 batch loss 1.21941543\n",
      "Validated batch 10 batch loss 1.31603765\n",
      "Validated batch 11 batch loss 1.21549749\n",
      "Validated batch 12 batch loss 1.07261908\n",
      "Validated batch 13 batch loss 1.11314762\n",
      "Validated batch 14 batch loss 1.16109276\n",
      "Validated batch 15 batch loss 1.13802195\n",
      "Validated batch 16 batch loss 1.21082473\n",
      "Validated batch 17 batch loss 1.19119847\n",
      "Validated batch 18 batch loss 1.121889\n",
      "Validated batch 19 batch loss 1.2394532\n",
      "Validated batch 20 batch loss 1.26101875\n",
      "Validated batch 21 batch loss 1.26764965\n",
      "Validated batch 22 batch loss 1.19959807\n",
      "Validated batch 23 batch loss 1.09680831\n",
      "Validated batch 24 batch loss 1.27405035\n",
      "Validated batch 25 batch loss 1.23054743\n",
      "Validated batch 26 batch loss 1.19426179\n",
      "Validated batch 27 batch loss 1.16327095\n",
      "Validated batch 28 batch loss 1.15051425\n",
      "Validated batch 29 batch loss 1.27352083\n",
      "Validated batch 30 batch loss 1.2142365\n",
      "Validated batch 31 batch loss 1.17136765\n",
      "Validated batch 32 batch loss 1.27508402\n",
      "Validated batch 33 batch loss 1.22964549\n",
      "Validated batch 34 batch loss 1.11772168\n",
      "Validated batch 35 batch loss 1.10227883\n",
      "Validated batch 36 batch loss 1.25091529\n",
      "Validated batch 37 batch loss 1.22493875\n",
      "Validated batch 38 batch loss 1.36782515\n",
      "Validated batch 39 batch loss 1.33273137\n",
      "Validated batch 40 batch loss 1.19672453\n",
      "Validated batch 41 batch loss 1.37080312\n",
      "Validated batch 42 batch loss 1.20469737\n",
      "Validated batch 43 batch loss 1.25791907\n",
      "Validated batch 44 batch loss 1.26369166\n",
      "Validated batch 45 batch loss 1.0092181\n",
      "Validated batch 46 batch loss 1.22416711\n",
      "Validated batch 47 batch loss 1.1989038\n",
      "Validated batch 48 batch loss 1.23391747\n",
      "Validated batch 49 batch loss 1.12411046\n",
      "Validated batch 50 batch loss 1.20615268\n",
      "Validated batch 51 batch loss 1.17977428\n",
      "Validated batch 52 batch loss 1.22236967\n",
      "Validated batch 53 batch loss 1.29738832\n",
      "Validated batch 54 batch loss 1.2702899\n",
      "Validated batch 55 batch loss 1.24466681\n",
      "Validated batch 56 batch loss 1.18118834\n",
      "Validated batch 57 batch loss 1.26310039\n",
      "Validated batch 58 batch loss 1.21659303\n",
      "Validated batch 59 batch loss 1.23554325\n",
      "Validated batch 60 batch loss 1.3246727\n",
      "Validated batch 61 batch loss 1.28467667\n",
      "Validated batch 62 batch loss 1.21182215\n",
      "Validated batch 63 batch loss 1.4055475\n",
      "Validated batch 64 batch loss 1.07990324\n",
      "Validated batch 65 batch loss 1.31827378\n",
      "Validated batch 66 batch loss 1.01865578\n",
      "Validated batch 67 batch loss 1.22397625\n",
      "Validated batch 68 batch loss 1.29766297\n",
      "Validated batch 69 batch loss 1.16868305\n",
      "Validated batch 70 batch loss 1.31422865\n",
      "Validated batch 71 batch loss 1.22071242\n",
      "Validated batch 72 batch loss 1.13591325\n",
      "Validated batch 73 batch loss 1.16514933\n",
      "Validated batch 74 batch loss 1.11331236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 75 batch loss 1.21872497\n",
      "Validated batch 76 batch loss 1.21702814\n",
      "Validated batch 77 batch loss 1.14091039\n",
      "Validated batch 78 batch loss 1.16841757\n",
      "Validated batch 79 batch loss 1.19957542\n",
      "Validated batch 80 batch loss 1.26251721\n",
      "Validated batch 81 batch loss 1.2811867\n",
      "Validated batch 82 batch loss 1.21699798\n",
      "Validated batch 83 batch loss 1.13723791\n",
      "Validated batch 84 batch loss 1.16407704\n",
      "Validated batch 85 batch loss 1.25045645\n",
      "Validated batch 86 batch loss 1.19922709\n",
      "Validated batch 87 batch loss 1.242571\n",
      "Validated batch 88 batch loss 1.25604713\n",
      "Validated batch 89 batch loss 1.45729053\n",
      "Validated batch 90 batch loss 1.29703093\n",
      "Validated batch 91 batch loss 1.23181534\n",
      "Validated batch 92 batch loss 1.15119672\n",
      "Validated batch 93 batch loss 1.14072073\n",
      "Validated batch 94 batch loss 1.21826\n",
      "Validated batch 95 batch loss 1.19139421\n",
      "Validated batch 96 batch loss 1.18539393\n",
      "Validated batch 97 batch loss 1.26408923\n",
      "Validated batch 98 batch loss 1.35817909\n",
      "Validated batch 99 batch loss 1.15143168\n",
      "Validated batch 100 batch loss 1.25576496\n",
      "Validated batch 101 batch loss 1.19565105\n",
      "Validated batch 102 batch loss 1.25704908\n",
      "Validated batch 103 batch loss 1.24301326\n",
      "Validated batch 104 batch loss 1.16204715\n",
      "Validated batch 105 batch loss 1.34322047\n",
      "Validated batch 106 batch loss 1.24458766\n",
      "Validated batch 107 batch loss 1.26688111\n",
      "Validated batch 108 batch loss 1.2073195\n",
      "Validated batch 109 batch loss 1.28185725\n",
      "Validated batch 110 batch loss 1.13696527\n",
      "Validated batch 111 batch loss 1.20289433\n",
      "Validated batch 112 batch loss 1.21155858\n",
      "Validated batch 113 batch loss 1.13333356\n",
      "Validated batch 114 batch loss 1.25128627\n",
      "Validated batch 115 batch loss 1.1803031\n",
      "Validated batch 116 batch loss 1.22422528\n",
      "Validated batch 117 batch loss 1.2600472\n",
      "Validated batch 118 batch loss 1.20071\n",
      "Validated batch 119 batch loss 1.12948179\n",
      "Validated batch 120 batch loss 1.12024355\n",
      "Validated batch 121 batch loss 1.30556726\n",
      "Validated batch 122 batch loss 1.11033058\n",
      "Validated batch 123 batch loss 1.07246304\n",
      "Validated batch 124 batch loss 1.19566941\n",
      "Validated batch 125 batch loss 1.17023802\n",
      "Validated batch 126 batch loss 1.09089708\n",
      "Validated batch 127 batch loss 1.19675612\n",
      "Validated batch 128 batch loss 1.15147269\n",
      "Validated batch 129 batch loss 1.12425065\n",
      "Validated batch 130 batch loss 1.24362659\n",
      "Validated batch 131 batch loss 1.30537\n",
      "Validated batch 132 batch loss 1.08953285\n",
      "Validated batch 133 batch loss 1.33603764\n",
      "Validated batch 134 batch loss 1.01944971\n",
      "Validated batch 135 batch loss 1.12\n",
      "Validated batch 136 batch loss 1.13918\n",
      "Validated batch 137 batch loss 1.21682918\n",
      "Validated batch 138 batch loss 1.33002424\n",
      "Validated batch 139 batch loss 1.23183537\n",
      "Validated batch 140 batch loss 1.06903768\n",
      "Validated batch 141 batch loss 1.20023787\n",
      "Validated batch 142 batch loss 1.16381335\n",
      "Validated batch 143 batch loss 1.15196085\n",
      "Validated batch 144 batch loss 1.21983683\n",
      "Validated batch 145 batch loss 1.19071734\n",
      "Validated batch 146 batch loss 1.24734139\n",
      "Validated batch 147 batch loss 1.31293273\n",
      "Validated batch 148 batch loss 1.03344965\n",
      "Validated batch 149 batch loss 1.29142344\n",
      "Validated batch 150 batch loss 1.21241927\n",
      "Validated batch 151 batch loss 1.0992837\n",
      "Validated batch 152 batch loss 1.24358582\n",
      "Validated batch 153 batch loss 1.21838915\n",
      "Validated batch 154 batch loss 1.11912525\n",
      "Validated batch 155 batch loss 1.34699392\n",
      "Validated batch 156 batch loss 1.2302\n",
      "Validated batch 157 batch loss 1.25936604\n",
      "Validated batch 158 batch loss 1.17976093\n",
      "Validated batch 159 batch loss 1.2031132\n",
      "Validated batch 160 batch loss 1.19508636\n",
      "Validated batch 161 batch loss 1.1206398\n",
      "Validated batch 162 batch loss 1.19196177\n",
      "Validated batch 163 batch loss 1.12095964\n",
      "Validated batch 164 batch loss 1.17013788\n",
      "Validated batch 165 batch loss 1.16160035\n",
      "Validated batch 166 batch loss 1.15589118\n",
      "Validated batch 167 batch loss 1.23329568\n",
      "Validated batch 168 batch loss 1.2055341\n",
      "Validated batch 169 batch loss 1.25905061\n",
      "Validated batch 170 batch loss 1.28688431\n",
      "Validated batch 171 batch loss 1.25479794\n",
      "Validated batch 172 batch loss 1.1827302\n",
      "Validated batch 173 batch loss 1.35807753\n",
      "Validated batch 174 batch loss 1.25179124\n",
      "Validated batch 175 batch loss 1.29202735\n",
      "Validated batch 176 batch loss 1.27493656\n",
      "Validated batch 177 batch loss 1.36765397\n",
      "Validated batch 178 batch loss 1.30367625\n",
      "Validated batch 179 batch loss 1.17845345\n",
      "Validated batch 180 batch loss 1.17557561\n",
      "Validated batch 181 batch loss 1.30014694\n",
      "Validated batch 182 batch loss 1.32509518\n",
      "Validated batch 183 batch loss 1.16000628\n",
      "Validated batch 184 batch loss 1.22810912\n",
      "Validated batch 185 batch loss 1.16208124\n",
      "Epoch 4 val loss 1.2121840715408325\n",
      "Model /aiffel/aiffel/mpii/models1/stacked_hourglass-epoch-4-loss-1.2122.h5 saved.\n",
      "Start epoch 5 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 1.14282107 epoch total loss 1.14282107\n",
      "Trained batch 2 batch loss 1.21225619 epoch total loss 1.17753863\n",
      "Trained batch 3 batch loss 1.25335336 epoch total loss 1.20281017\n",
      "Trained batch 4 batch loss 1.30562878 epoch total loss 1.22851491\n",
      "Trained batch 5 batch loss 1.32475615 epoch total loss 1.24776316\n",
      "Trained batch 6 batch loss 1.39720583 epoch total loss 1.27267027\n",
      "Trained batch 7 batch loss 1.44393373 epoch total loss 1.29713643\n",
      "Trained batch 8 batch loss 1.23023951 epoch total loss 1.28877437\n",
      "Trained batch 9 batch loss 1.02683473 epoch total loss 1.2596699\n",
      "Trained batch 10 batch loss 1.26621413 epoch total loss 1.26032436\n",
      "Trained batch 11 batch loss 1.08442938 epoch total loss 1.24433398\n",
      "Trained batch 12 batch loss 1.07566118 epoch total loss 1.2302779\n",
      "Trained batch 13 batch loss 1.07687163 epoch total loss 1.21847737\n",
      "Trained batch 14 batch loss 1.10513663 epoch total loss 1.21038163\n",
      "Trained batch 15 batch loss 1.17348373 epoch total loss 1.20792174\n",
      "Trained batch 16 batch loss 0.996641636 epoch total loss 1.19471669\n",
      "Trained batch 17 batch loss 0.989091873 epoch total loss 1.18262112\n",
      "Trained batch 18 batch loss 1.16347492 epoch total loss 1.18155742\n",
      "Trained batch 19 batch loss 1.14828575 epoch total loss 1.17980623\n",
      "Trained batch 20 batch loss 1.11798632 epoch total loss 1.17671525\n",
      "Trained batch 21 batch loss 0.944960952 epoch total loss 1.16567934\n",
      "Trained batch 22 batch loss 1.04567695 epoch total loss 1.1602248\n",
      "Trained batch 23 batch loss 1.17491555 epoch total loss 1.16086352\n",
      "Trained batch 24 batch loss 1.14583838 epoch total loss 1.16023743\n",
      "Trained batch 25 batch loss 1.18245304 epoch total loss 1.16112602\n",
      "Trained batch 26 batch loss 1.04660845 epoch total loss 1.15672147\n",
      "Trained batch 27 batch loss 1.1101532 epoch total loss 1.15499675\n",
      "Trained batch 28 batch loss 1.18357563 epoch total loss 1.15601742\n",
      "Trained batch 29 batch loss 1.19038916 epoch total loss 1.1572026\n",
      "Trained batch 30 batch loss 1.14403915 epoch total loss 1.15676379\n",
      "Trained batch 31 batch loss 1.15259933 epoch total loss 1.15662944\n",
      "Trained batch 32 batch loss 1.2645154 epoch total loss 1.16000092\n",
      "Trained batch 33 batch loss 1.26693666 epoch total loss 1.16324139\n",
      "Trained batch 34 batch loss 1.15055859 epoch total loss 1.16286838\n",
      "Trained batch 35 batch loss 1.17418027 epoch total loss 1.16319156\n",
      "Trained batch 36 batch loss 1.13010764 epoch total loss 1.16227257\n",
      "Trained batch 37 batch loss 1.14415574 epoch total loss 1.16178298\n",
      "Trained batch 38 batch loss 1.36856544 epoch total loss 1.16722453\n",
      "Trained batch 39 batch loss 1.26418567 epoch total loss 1.16971076\n",
      "Trained batch 40 batch loss 1.16080105 epoch total loss 1.16948807\n",
      "Trained batch 41 batch loss 1.24668837 epoch total loss 1.17137098\n",
      "Trained batch 42 batch loss 1.10407948 epoch total loss 1.16976881\n",
      "Trained batch 43 batch loss 1.29181 epoch total loss 1.17260695\n",
      "Trained batch 44 batch loss 1.31777608 epoch total loss 1.1759063\n",
      "Trained batch 45 batch loss 1.2943821 epoch total loss 1.17853904\n",
      "Trained batch 46 batch loss 1.12157798 epoch total loss 1.17730069\n",
      "Trained batch 47 batch loss 1.05825114 epoch total loss 1.17476773\n",
      "Trained batch 48 batch loss 1.15691662 epoch total loss 1.17439592\n",
      "Trained batch 49 batch loss 1.30427647 epoch total loss 1.17704654\n",
      "Trained batch 50 batch loss 1.28640628 epoch total loss 1.17923367\n",
      "Trained batch 51 batch loss 1.28688657 epoch total loss 1.18134463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 52 batch loss 1.2113812 epoch total loss 1.1819222\n",
      "Trained batch 53 batch loss 1.30056739 epoch total loss 1.18416083\n",
      "Trained batch 54 batch loss 1.17946744 epoch total loss 1.18407381\n",
      "Trained batch 55 batch loss 1.30541682 epoch total loss 1.18628013\n",
      "Trained batch 56 batch loss 1.1723851 epoch total loss 1.18603206\n",
      "Trained batch 57 batch loss 1.1955719 epoch total loss 1.18619943\n",
      "Trained batch 58 batch loss 1.1260035 epoch total loss 1.18516159\n",
      "Trained batch 59 batch loss 1.18131924 epoch total loss 1.1850965\n",
      "Trained batch 60 batch loss 1.22346044 epoch total loss 1.18573582\n",
      "Trained batch 61 batch loss 1.2433511 epoch total loss 1.18668044\n",
      "Trained batch 62 batch loss 1.26389086 epoch total loss 1.18792582\n",
      "Trained batch 63 batch loss 1.25917149 epoch total loss 1.18905663\n",
      "Trained batch 64 batch loss 1.27842665 epoch total loss 1.19045305\n",
      "Trained batch 65 batch loss 1.19530892 epoch total loss 1.1905278\n",
      "Trained batch 66 batch loss 1.23303866 epoch total loss 1.19117188\n",
      "Trained batch 67 batch loss 1.27152133 epoch total loss 1.19237125\n",
      "Trained batch 68 batch loss 1.24436665 epoch total loss 1.19313586\n",
      "Trained batch 69 batch loss 1.21803296 epoch total loss 1.1934967\n",
      "Trained batch 70 batch loss 1.40310574 epoch total loss 1.19649112\n",
      "Trained batch 71 batch loss 1.4134022 epoch total loss 1.19954622\n",
      "Trained batch 72 batch loss 1.26877165 epoch total loss 1.20050764\n",
      "Trained batch 73 batch loss 1.30156112 epoch total loss 1.2018919\n",
      "Trained batch 74 batch loss 1.07815325 epoch total loss 1.20021975\n",
      "Trained batch 75 batch loss 1.02250314 epoch total loss 1.19785023\n",
      "Trained batch 76 batch loss 1.1123004 epoch total loss 1.19672453\n",
      "Trained batch 77 batch loss 1.03650784 epoch total loss 1.19464374\n",
      "Trained batch 78 batch loss 1.07099521 epoch total loss 1.19305849\n",
      "Trained batch 79 batch loss 0.854506612 epoch total loss 1.18877304\n",
      "Trained batch 80 batch loss 0.989353061 epoch total loss 1.18628025\n",
      "Trained batch 81 batch loss 1.05864811 epoch total loss 1.18470454\n",
      "Trained batch 82 batch loss 1.05681765 epoch total loss 1.18314493\n",
      "Trained batch 83 batch loss 1.17412901 epoch total loss 1.18303621\n",
      "Trained batch 84 batch loss 1.20270801 epoch total loss 1.18327045\n",
      "Trained batch 85 batch loss 1.23880029 epoch total loss 1.18392372\n",
      "Trained batch 86 batch loss 1.25092387 epoch total loss 1.18470275\n",
      "Trained batch 87 batch loss 1.24576473 epoch total loss 1.18540466\n",
      "Trained batch 88 batch loss 1.15689611 epoch total loss 1.18508065\n",
      "Trained batch 89 batch loss 1.30455828 epoch total loss 1.18642318\n",
      "Trained batch 90 batch loss 1.35087276 epoch total loss 1.18825042\n",
      "Trained batch 91 batch loss 1.1664567 epoch total loss 1.18801093\n",
      "Trained batch 92 batch loss 1.20339441 epoch total loss 1.18817806\n",
      "Trained batch 93 batch loss 1.3293798 epoch total loss 1.18969631\n",
      "Trained batch 94 batch loss 1.26298749 epoch total loss 1.19047606\n",
      "Trained batch 95 batch loss 1.22976303 epoch total loss 1.1908896\n",
      "Trained batch 96 batch loss 1.19050801 epoch total loss 1.19088554\n",
      "Trained batch 97 batch loss 1.18990874 epoch total loss 1.19087553\n",
      "Trained batch 98 batch loss 1.2485466 epoch total loss 1.19146407\n",
      "Trained batch 99 batch loss 1.27744901 epoch total loss 1.19233263\n",
      "Trained batch 100 batch loss 1.27896476 epoch total loss 1.1931988\n",
      "Trained batch 101 batch loss 1.30239856 epoch total loss 1.19428\n",
      "Trained batch 102 batch loss 1.11685503 epoch total loss 1.1935209\n",
      "Trained batch 103 batch loss 1.01881897 epoch total loss 1.19182479\n",
      "Trained batch 104 batch loss 1.07685065 epoch total loss 1.19071937\n",
      "Trained batch 105 batch loss 1.06219018 epoch total loss 1.18949521\n",
      "Trained batch 106 batch loss 1.1869508 epoch total loss 1.18947124\n",
      "Trained batch 107 batch loss 1.2196238 epoch total loss 1.18975306\n",
      "Trained batch 108 batch loss 1.22277808 epoch total loss 1.19005883\n",
      "Trained batch 109 batch loss 1.3803544 epoch total loss 1.19180465\n",
      "Trained batch 110 batch loss 1.29647541 epoch total loss 1.1927563\n",
      "Trained batch 111 batch loss 1.22376955 epoch total loss 1.1930356\n",
      "Trained batch 112 batch loss 1.26591766 epoch total loss 1.19368637\n",
      "Trained batch 113 batch loss 1.35577571 epoch total loss 1.19512081\n",
      "Trained batch 114 batch loss 1.24414706 epoch total loss 1.1955508\n",
      "Trained batch 115 batch loss 1.20139635 epoch total loss 1.19560158\n",
      "Trained batch 116 batch loss 1.32458186 epoch total loss 1.19671357\n",
      "Trained batch 117 batch loss 1.22387195 epoch total loss 1.19694567\n",
      "Trained batch 118 batch loss 1.23433936 epoch total loss 1.19726264\n",
      "Trained batch 119 batch loss 1.17775023 epoch total loss 1.19709873\n",
      "Trained batch 120 batch loss 1.16126096 epoch total loss 1.1968\n",
      "Trained batch 121 batch loss 1.29759741 epoch total loss 1.19763303\n",
      "Trained batch 122 batch loss 1.16411293 epoch total loss 1.19735813\n",
      "Trained batch 123 batch loss 1.10745859 epoch total loss 1.19662726\n",
      "Trained batch 124 batch loss 1.06494737 epoch total loss 1.19556522\n",
      "Trained batch 125 batch loss 1.04630339 epoch total loss 1.19437122\n",
      "Trained batch 126 batch loss 1.06833959 epoch total loss 1.19337106\n",
      "Trained batch 127 batch loss 1.18731081 epoch total loss 1.19332337\n",
      "Trained batch 128 batch loss 1.16288638 epoch total loss 1.19308555\n",
      "Trained batch 129 batch loss 1.04298365 epoch total loss 1.19192195\n",
      "Trained batch 130 batch loss 1.02412808 epoch total loss 1.19063127\n",
      "Trained batch 131 batch loss 1.17373157 epoch total loss 1.19050229\n",
      "Trained batch 132 batch loss 1.29578459 epoch total loss 1.19129992\n",
      "Trained batch 133 batch loss 1.15600824 epoch total loss 1.19103456\n",
      "Trained batch 134 batch loss 1.2347343 epoch total loss 1.19136071\n",
      "Trained batch 135 batch loss 1.27355361 epoch total loss 1.19196963\n",
      "Trained batch 136 batch loss 1.1457969 epoch total loss 1.19163013\n",
      "Trained batch 137 batch loss 1.26047826 epoch total loss 1.19213271\n",
      "Trained batch 138 batch loss 1.12619805 epoch total loss 1.19165492\n",
      "Trained batch 139 batch loss 1.06253874 epoch total loss 1.19072604\n",
      "Trained batch 140 batch loss 1.12365389 epoch total loss 1.19024706\n",
      "Trained batch 141 batch loss 1.14844525 epoch total loss 1.18995059\n",
      "Trained batch 142 batch loss 1.12993646 epoch total loss 1.18952799\n",
      "Trained batch 143 batch loss 1.24654984 epoch total loss 1.18992674\n",
      "Trained batch 144 batch loss 1.45956802 epoch total loss 1.19179928\n",
      "Trained batch 145 batch loss 1.3663305 epoch total loss 1.19300294\n",
      "Trained batch 146 batch loss 1.29166186 epoch total loss 1.19367862\n",
      "Trained batch 147 batch loss 1.24015975 epoch total loss 1.19399488\n",
      "Trained batch 148 batch loss 1.1474191 epoch total loss 1.19368017\n",
      "Trained batch 149 batch loss 0.996750176 epoch total loss 1.19235849\n",
      "Trained batch 150 batch loss 1.00022483 epoch total loss 1.19107759\n",
      "Trained batch 151 batch loss 0.969716668 epoch total loss 1.18961155\n",
      "Trained batch 152 batch loss 0.995009899 epoch total loss 1.18833125\n",
      "Trained batch 153 batch loss 1.1576972 epoch total loss 1.18813109\n",
      "Trained batch 154 batch loss 0.997578382 epoch total loss 1.1868937\n",
      "Trained batch 155 batch loss 1.09065986 epoch total loss 1.18627274\n",
      "Trained batch 156 batch loss 1.2298646 epoch total loss 1.18655217\n",
      "Trained batch 157 batch loss 1.22283125 epoch total loss 1.18678319\n",
      "Trained batch 158 batch loss 1.25316679 epoch total loss 1.18720341\n",
      "Trained batch 159 batch loss 1.24042487 epoch total loss 1.18753815\n",
      "Trained batch 160 batch loss 1.0616262 epoch total loss 1.18675113\n",
      "Trained batch 161 batch loss 1.07625771 epoch total loss 1.18606496\n",
      "Trained batch 162 batch loss 1.060956 epoch total loss 1.1852926\n",
      "Trained batch 163 batch loss 1.11664975 epoch total loss 1.18487155\n",
      "Trained batch 164 batch loss 1.21796632 epoch total loss 1.18507338\n",
      "Trained batch 165 batch loss 1.21793568 epoch total loss 1.18527257\n",
      "Trained batch 166 batch loss 1.23626256 epoch total loss 1.18557978\n",
      "Trained batch 167 batch loss 1.14276314 epoch total loss 1.18532336\n",
      "Trained batch 168 batch loss 1.22935593 epoch total loss 1.1855855\n",
      "Trained batch 169 batch loss 1.23184311 epoch total loss 1.1858592\n",
      "Trained batch 170 batch loss 1.11528623 epoch total loss 1.185444\n",
      "Trained batch 171 batch loss 1.11826444 epoch total loss 1.1850512\n",
      "Trained batch 172 batch loss 1.25325739 epoch total loss 1.18544769\n",
      "Trained batch 173 batch loss 1.29262936 epoch total loss 1.18606722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 174 batch loss 1.00713468 epoch total loss 1.18503892\n",
      "Trained batch 175 batch loss 0.901521325 epoch total loss 1.18341887\n",
      "Trained batch 176 batch loss 1.06121457 epoch total loss 1.18272448\n",
      "Trained batch 177 batch loss 1.19828963 epoch total loss 1.18281245\n",
      "Trained batch 178 batch loss 1.35160768 epoch total loss 1.18376076\n",
      "Trained batch 179 batch loss 1.5958755 epoch total loss 1.18606305\n",
      "Trained batch 180 batch loss 1.1131649 epoch total loss 1.18565798\n",
      "Trained batch 181 batch loss 1.21872234 epoch total loss 1.18584073\n",
      "Trained batch 182 batch loss 1.19759512 epoch total loss 1.18590534\n",
      "Trained batch 183 batch loss 1.27814519 epoch total loss 1.18640935\n",
      "Trained batch 184 batch loss 1.21612942 epoch total loss 1.18657088\n",
      "Trained batch 185 batch loss 1.23355627 epoch total loss 1.1868248\n",
      "Trained batch 186 batch loss 1.21762681 epoch total loss 1.18699038\n",
      "Trained batch 187 batch loss 1.27839136 epoch total loss 1.18747914\n",
      "Trained batch 188 batch loss 1.18929029 epoch total loss 1.18748879\n",
      "Trained batch 189 batch loss 1.19153774 epoch total loss 1.18751025\n",
      "Trained batch 190 batch loss 1.11335659 epoch total loss 1.18712\n",
      "Trained batch 191 batch loss 1.07202387 epoch total loss 1.18651736\n",
      "Trained batch 192 batch loss 1.13228905 epoch total loss 1.18623495\n",
      "Trained batch 193 batch loss 1.1920687 epoch total loss 1.18626511\n",
      "Trained batch 194 batch loss 1.10924292 epoch total loss 1.18586814\n",
      "Trained batch 195 batch loss 1.0967772 epoch total loss 1.18541121\n",
      "Trained batch 196 batch loss 1.27860677 epoch total loss 1.18588674\n",
      "Trained batch 197 batch loss 1.33022666 epoch total loss 1.1866194\n",
      "Trained batch 198 batch loss 1.32926655 epoch total loss 1.1873399\n",
      "Trained batch 199 batch loss 1.17134035 epoch total loss 1.18725944\n",
      "Trained batch 200 batch loss 1.16858149 epoch total loss 1.18716609\n",
      "Trained batch 201 batch loss 1.16414833 epoch total loss 1.18705153\n",
      "Trained batch 202 batch loss 1.25709713 epoch total loss 1.18739831\n",
      "Trained batch 203 batch loss 1.10015023 epoch total loss 1.18696845\n",
      "Trained batch 204 batch loss 1.21332955 epoch total loss 1.18709779\n",
      "Trained batch 205 batch loss 1.26703608 epoch total loss 1.1874876\n",
      "Trained batch 206 batch loss 1.18292069 epoch total loss 1.18746543\n",
      "Trained batch 207 batch loss 1.27219045 epoch total loss 1.18787479\n",
      "Trained batch 208 batch loss 1.20826221 epoch total loss 1.18797278\n",
      "Trained batch 209 batch loss 1.16072464 epoch total loss 1.18784237\n",
      "Trained batch 210 batch loss 1.01799691 epoch total loss 1.18703353\n",
      "Trained batch 211 batch loss 1.09771633 epoch total loss 1.18661034\n",
      "Trained batch 212 batch loss 1.13672137 epoch total loss 1.1863749\n",
      "Trained batch 213 batch loss 1.03257549 epoch total loss 1.18565285\n",
      "Trained batch 214 batch loss 1.02814186 epoch total loss 1.18491685\n",
      "Trained batch 215 batch loss 1.12395132 epoch total loss 1.18463326\n",
      "Trained batch 216 batch loss 1.17034411 epoch total loss 1.18456709\n",
      "Trained batch 217 batch loss 1.23378205 epoch total loss 1.18479395\n",
      "Trained batch 218 batch loss 1.22698438 epoch total loss 1.18498743\n",
      "Trained batch 219 batch loss 1.0939362 epoch total loss 1.18457174\n",
      "Trained batch 220 batch loss 1.20387387 epoch total loss 1.18465948\n",
      "Trained batch 221 batch loss 1.21482897 epoch total loss 1.18479609\n",
      "Trained batch 222 batch loss 1.15334558 epoch total loss 1.18465447\n",
      "Trained batch 223 batch loss 1.14422703 epoch total loss 1.18447316\n",
      "Trained batch 224 batch loss 1.04288173 epoch total loss 1.18384099\n",
      "Trained batch 225 batch loss 1.24107993 epoch total loss 1.1840955\n",
      "Trained batch 226 batch loss 1.24579442 epoch total loss 1.18436849\n",
      "Trained batch 227 batch loss 1.17543304 epoch total loss 1.18432915\n",
      "Trained batch 228 batch loss 1.26557279 epoch total loss 1.18468547\n",
      "Trained batch 229 batch loss 1.05193388 epoch total loss 1.18410575\n",
      "Trained batch 230 batch loss 1.14402342 epoch total loss 1.18393147\n",
      "Trained batch 231 batch loss 1.16022992 epoch total loss 1.18382883\n",
      "Trained batch 232 batch loss 1.12936831 epoch total loss 1.18359399\n",
      "Trained batch 233 batch loss 1.20482457 epoch total loss 1.18368518\n",
      "Trained batch 234 batch loss 1.20452321 epoch total loss 1.18377423\n",
      "Trained batch 235 batch loss 1.03235984 epoch total loss 1.18312991\n",
      "Trained batch 236 batch loss 1.0946275 epoch total loss 1.18275487\n",
      "Trained batch 237 batch loss 1.16246212 epoch total loss 1.18266928\n",
      "Trained batch 238 batch loss 1.11736429 epoch total loss 1.18239498\n",
      "Trained batch 239 batch loss 1.028826 epoch total loss 1.18175244\n",
      "Trained batch 240 batch loss 1.0519377 epoch total loss 1.18121159\n",
      "Trained batch 241 batch loss 1.13713479 epoch total loss 1.18102872\n",
      "Trained batch 242 batch loss 1.00761497 epoch total loss 1.18031228\n",
      "Trained batch 243 batch loss 1.23768878 epoch total loss 1.18054843\n",
      "Trained batch 244 batch loss 1.20130396 epoch total loss 1.18063343\n",
      "Trained batch 245 batch loss 1.19098043 epoch total loss 1.18067563\n",
      "Trained batch 246 batch loss 1.20876455 epoch total loss 1.18078983\n",
      "Trained batch 247 batch loss 1.33251381 epoch total loss 1.18140411\n",
      "Trained batch 248 batch loss 1.17950749 epoch total loss 1.18139648\n",
      "Trained batch 249 batch loss 1.29506624 epoch total loss 1.18185306\n",
      "Trained batch 250 batch loss 1.21566164 epoch total loss 1.18198824\n",
      "Trained batch 251 batch loss 1.14719 epoch total loss 1.1818496\n",
      "Trained batch 252 batch loss 1.03331804 epoch total loss 1.18126023\n",
      "Trained batch 253 batch loss 1.1891942 epoch total loss 1.1812917\n",
      "Trained batch 254 batch loss 1.20608091 epoch total loss 1.18138933\n",
      "Trained batch 255 batch loss 1.37005246 epoch total loss 1.18212914\n",
      "Trained batch 256 batch loss 1.24498844 epoch total loss 1.18237472\n",
      "Trained batch 257 batch loss 1.30801809 epoch total loss 1.18286359\n",
      "Trained batch 258 batch loss 1.12858069 epoch total loss 1.18265319\n",
      "Trained batch 259 batch loss 1.12056136 epoch total loss 1.18241346\n",
      "Trained batch 260 batch loss 1.29630709 epoch total loss 1.18285143\n",
      "Trained batch 261 batch loss 1.15264392 epoch total loss 1.1827358\n",
      "Trained batch 262 batch loss 1.23753834 epoch total loss 1.18294501\n",
      "Trained batch 263 batch loss 1.28571033 epoch total loss 1.18333566\n",
      "Trained batch 264 batch loss 1.45660424 epoch total loss 1.18437076\n",
      "Trained batch 265 batch loss 1.42533064 epoch total loss 1.18528008\n",
      "Trained batch 266 batch loss 1.27087235 epoch total loss 1.18560183\n",
      "Trained batch 267 batch loss 1.26326334 epoch total loss 1.1858927\n",
      "Trained batch 268 batch loss 1.24449158 epoch total loss 1.18611145\n",
      "Trained batch 269 batch loss 1.20279539 epoch total loss 1.18617344\n",
      "Trained batch 270 batch loss 1.09424686 epoch total loss 1.18583298\n",
      "Trained batch 271 batch loss 1.12100434 epoch total loss 1.18559372\n",
      "Trained batch 272 batch loss 1.32458591 epoch total loss 1.18610477\n",
      "Trained batch 273 batch loss 1.2615099 epoch total loss 1.18638086\n",
      "Trained batch 274 batch loss 1.13757992 epoch total loss 1.18620276\n",
      "Trained batch 275 batch loss 1.14648461 epoch total loss 1.1860584\n",
      "Trained batch 276 batch loss 1.12511027 epoch total loss 1.18583751\n",
      "Trained batch 277 batch loss 1.04531586 epoch total loss 1.18533027\n",
      "Trained batch 278 batch loss 1.12507486 epoch total loss 1.18511343\n",
      "Trained batch 279 batch loss 1.10551381 epoch total loss 1.18482816\n",
      "Trained batch 280 batch loss 1.07058 epoch total loss 1.18442011\n",
      "Trained batch 281 batch loss 1.11216843 epoch total loss 1.18416309\n",
      "Trained batch 282 batch loss 1.05802405 epoch total loss 1.1837157\n",
      "Trained batch 283 batch loss 0.981015682 epoch total loss 1.18299949\n",
      "Trained batch 284 batch loss 1.14482045 epoch total loss 1.18286502\n",
      "Trained batch 285 batch loss 1.26688433 epoch total loss 1.18315971\n",
      "Trained batch 286 batch loss 1.219244 epoch total loss 1.18328595\n",
      "Trained batch 287 batch loss 1.38698864 epoch total loss 1.18399572\n",
      "Trained batch 288 batch loss 1.2905494 epoch total loss 1.18436575\n",
      "Trained batch 289 batch loss 1.35269642 epoch total loss 1.18494809\n",
      "Trained batch 290 batch loss 1.16165435 epoch total loss 1.18486786\n",
      "Trained batch 291 batch loss 1.23609209 epoch total loss 1.18504381\n",
      "Trained batch 292 batch loss 1.30704331 epoch total loss 1.18546164\n",
      "Trained batch 293 batch loss 1.25488985 epoch total loss 1.18569851\n",
      "Trained batch 294 batch loss 1.1206938 epoch total loss 1.18547738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 295 batch loss 1.14456141 epoch total loss 1.18533874\n",
      "Trained batch 296 batch loss 1.11670876 epoch total loss 1.18510687\n",
      "Trained batch 297 batch loss 0.973087549 epoch total loss 1.18439293\n",
      "Trained batch 298 batch loss 1.09574544 epoch total loss 1.1840955\n",
      "Trained batch 299 batch loss 1.21810722 epoch total loss 1.18420923\n",
      "Trained batch 300 batch loss 1.19437182 epoch total loss 1.18424308\n",
      "Trained batch 301 batch loss 1.21798754 epoch total loss 1.18435514\n",
      "Trained batch 302 batch loss 1.24006248 epoch total loss 1.18453956\n",
      "Trained batch 303 batch loss 1.23669147 epoch total loss 1.18471169\n",
      "Trained batch 304 batch loss 1.40644383 epoch total loss 1.18544102\n",
      "Trained batch 305 batch loss 1.38362312 epoch total loss 1.18609095\n",
      "Trained batch 306 batch loss 1.25446081 epoch total loss 1.18631434\n",
      "Trained batch 307 batch loss 1.24165893 epoch total loss 1.18649459\n",
      "Trained batch 308 batch loss 1.30006409 epoch total loss 1.1868633\n",
      "Trained batch 309 batch loss 1.31177843 epoch total loss 1.18726754\n",
      "Trained batch 310 batch loss 1.2927115 epoch total loss 1.18760765\n",
      "Trained batch 311 batch loss 1.10260248 epoch total loss 1.18733442\n",
      "Trained batch 312 batch loss 1.21879137 epoch total loss 1.18743515\n",
      "Trained batch 313 batch loss 1.21323514 epoch total loss 1.18751752\n",
      "Trained batch 314 batch loss 1.33103228 epoch total loss 1.18797457\n",
      "Trained batch 315 batch loss 1.17293477 epoch total loss 1.18792689\n",
      "Trained batch 316 batch loss 1.32037449 epoch total loss 1.18834603\n",
      "Trained batch 317 batch loss 1.22144651 epoch total loss 1.18845034\n",
      "Trained batch 318 batch loss 1.23869371 epoch total loss 1.18860841\n",
      "Trained batch 319 batch loss 1.37894678 epoch total loss 1.18920505\n",
      "Trained batch 320 batch loss 1.12014163 epoch total loss 1.18898928\n",
      "Trained batch 321 batch loss 1.15367854 epoch total loss 1.18887925\n",
      "Trained batch 322 batch loss 1.06692171 epoch total loss 1.18850052\n",
      "Trained batch 323 batch loss 1.22869885 epoch total loss 1.18862498\n",
      "Trained batch 324 batch loss 1.16472 epoch total loss 1.18855131\n",
      "Trained batch 325 batch loss 1.21347833 epoch total loss 1.18862796\n",
      "Trained batch 326 batch loss 1.10134041 epoch total loss 1.18836021\n",
      "Trained batch 327 batch loss 1.25530279 epoch total loss 1.1885649\n",
      "Trained batch 328 batch loss 1.36315238 epoch total loss 1.18909729\n",
      "Trained batch 329 batch loss 1.16952896 epoch total loss 1.1890378\n",
      "Trained batch 330 batch loss 1.16756177 epoch total loss 1.18897271\n",
      "Trained batch 331 batch loss 1.00776517 epoch total loss 1.18842518\n",
      "Trained batch 332 batch loss 0.988477826 epoch total loss 1.18782294\n",
      "Trained batch 333 batch loss 1.21359992 epoch total loss 1.1879003\n",
      "Trained batch 334 batch loss 1.25518274 epoch total loss 1.18810177\n",
      "Trained batch 335 batch loss 1.31746924 epoch total loss 1.18848801\n",
      "Trained batch 336 batch loss 1.15480876 epoch total loss 1.18838775\n",
      "Trained batch 337 batch loss 1.2205106 epoch total loss 1.18848312\n",
      "Trained batch 338 batch loss 1.16768849 epoch total loss 1.18842161\n",
      "Trained batch 339 batch loss 1.11898947 epoch total loss 1.18821681\n",
      "Trained batch 340 batch loss 1.19084728 epoch total loss 1.18822455\n",
      "Trained batch 341 batch loss 1.25307572 epoch total loss 1.18841469\n",
      "Trained batch 342 batch loss 1.3061378 epoch total loss 1.18875897\n",
      "Trained batch 343 batch loss 1.13832021 epoch total loss 1.18861187\n",
      "Trained batch 344 batch loss 1.10410738 epoch total loss 1.18836617\n",
      "Trained batch 345 batch loss 1.10792387 epoch total loss 1.188133\n",
      "Trained batch 346 batch loss 1.15962255 epoch total loss 1.18805063\n",
      "Trained batch 347 batch loss 1.11773515 epoch total loss 1.18784797\n",
      "Trained batch 348 batch loss 1.283903 epoch total loss 1.18812406\n",
      "Trained batch 349 batch loss 1.34667981 epoch total loss 1.18857837\n",
      "Trained batch 350 batch loss 1.37373424 epoch total loss 1.18910742\n",
      "Trained batch 351 batch loss 1.38131189 epoch total loss 1.18965507\n",
      "Trained batch 352 batch loss 1.45807111 epoch total loss 1.19041753\n",
      "Trained batch 353 batch loss 1.21967316 epoch total loss 1.19050038\n",
      "Trained batch 354 batch loss 1.31080747 epoch total loss 1.19084024\n",
      "Trained batch 355 batch loss 1.25992799 epoch total loss 1.19103491\n",
      "Trained batch 356 batch loss 1.28239679 epoch total loss 1.19129157\n",
      "Trained batch 357 batch loss 1.16471446 epoch total loss 1.19121706\n",
      "Trained batch 358 batch loss 1.1916399 epoch total loss 1.19121826\n",
      "Trained batch 359 batch loss 1.26018095 epoch total loss 1.19141042\n",
      "Trained batch 360 batch loss 1.16246879 epoch total loss 1.19133008\n",
      "Trained batch 361 batch loss 1.12842035 epoch total loss 1.19115579\n",
      "Trained batch 362 batch loss 1.13155258 epoch total loss 1.19099116\n",
      "Trained batch 363 batch loss 1.04591489 epoch total loss 1.19059157\n",
      "Trained batch 364 batch loss 1.05255437 epoch total loss 1.19021225\n",
      "Trained batch 365 batch loss 1.25717056 epoch total loss 1.19039571\n",
      "Trained batch 366 batch loss 1.1868844 epoch total loss 1.19038618\n",
      "Trained batch 367 batch loss 1.29607534 epoch total loss 1.19067419\n",
      "Trained batch 368 batch loss 1.27676892 epoch total loss 1.19090807\n",
      "Trained batch 369 batch loss 1.27033281 epoch total loss 1.19112337\n",
      "Trained batch 370 batch loss 1.21622729 epoch total loss 1.1911912\n",
      "Trained batch 371 batch loss 1.23438931 epoch total loss 1.19130754\n",
      "Trained batch 372 batch loss 1.25220561 epoch total loss 1.19147122\n",
      "Trained batch 373 batch loss 1.12746525 epoch total loss 1.19129968\n",
      "Trained batch 374 batch loss 1.20252311 epoch total loss 1.1913296\n",
      "Trained batch 375 batch loss 1.24019051 epoch total loss 1.19146\n",
      "Trained batch 376 batch loss 1.24703193 epoch total loss 1.19160783\n",
      "Trained batch 377 batch loss 1.33419025 epoch total loss 1.19198596\n",
      "Trained batch 378 batch loss 1.12616897 epoch total loss 1.1918118\n",
      "Trained batch 379 batch loss 1.00992167 epoch total loss 1.19133198\n",
      "Trained batch 380 batch loss 1.15774906 epoch total loss 1.19124353\n",
      "Trained batch 381 batch loss 1.16576266 epoch total loss 1.19117665\n",
      "Trained batch 382 batch loss 1.16439152 epoch total loss 1.19110656\n",
      "Trained batch 383 batch loss 1.11075795 epoch total loss 1.19089675\n",
      "Trained batch 384 batch loss 1.25197589 epoch total loss 1.19105589\n",
      "Trained batch 385 batch loss 1.24380279 epoch total loss 1.19119287\n",
      "Trained batch 386 batch loss 1.31305206 epoch total loss 1.19150853\n",
      "Trained batch 387 batch loss 1.18313086 epoch total loss 1.19148695\n",
      "Trained batch 388 batch loss 1.27662301 epoch total loss 1.1917063\n",
      "Trained batch 389 batch loss 1.45446873 epoch total loss 1.19238174\n",
      "Trained batch 390 batch loss 1.30420089 epoch total loss 1.19266856\n",
      "Trained batch 391 batch loss 1.24246049 epoch total loss 1.19279587\n",
      "Trained batch 392 batch loss 1.16527534 epoch total loss 1.19272566\n",
      "Trained batch 393 batch loss 1.08078825 epoch total loss 1.19244087\n",
      "Trained batch 394 batch loss 1.03235185 epoch total loss 1.19203448\n",
      "Trained batch 395 batch loss 1.13216352 epoch total loss 1.19188297\n",
      "Trained batch 396 batch loss 1.09730625 epoch total loss 1.19164419\n",
      "Trained batch 397 batch loss 1.26472569 epoch total loss 1.19182825\n",
      "Trained batch 398 batch loss 1.18972254 epoch total loss 1.19182301\n",
      "Trained batch 399 batch loss 1.36264729 epoch total loss 1.19225109\n",
      "Trained batch 400 batch loss 1.18428802 epoch total loss 1.19223118\n",
      "Trained batch 401 batch loss 1.21006298 epoch total loss 1.19227564\n",
      "Trained batch 402 batch loss 1.08142245 epoch total loss 1.19199991\n",
      "Trained batch 403 batch loss 1.21967614 epoch total loss 1.19206858\n",
      "Trained batch 404 batch loss 1.22359073 epoch total loss 1.19214666\n",
      "Trained batch 405 batch loss 1.01699448 epoch total loss 1.19171417\n",
      "Trained batch 406 batch loss 1.0142858 epoch total loss 1.19127715\n",
      "Trained batch 407 batch loss 0.860831261 epoch total loss 1.19046521\n",
      "Trained batch 408 batch loss 1.10636246 epoch total loss 1.1902591\n",
      "Trained batch 409 batch loss 1.36869323 epoch total loss 1.19069529\n",
      "Trained batch 410 batch loss 1.27010894 epoch total loss 1.190889\n",
      "Trained batch 411 batch loss 1.33889937 epoch total loss 1.19124913\n",
      "Trained batch 412 batch loss 1.17239749 epoch total loss 1.19120336\n",
      "Trained batch 413 batch loss 1.30981231 epoch total loss 1.19149053\n",
      "Trained batch 414 batch loss 1.21966207 epoch total loss 1.1915586\n",
      "Trained batch 415 batch loss 1.23407233 epoch total loss 1.191661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 416 batch loss 1.28900945 epoch total loss 1.19189501\n",
      "Trained batch 417 batch loss 1.36207986 epoch total loss 1.19230318\n",
      "Trained batch 418 batch loss 1.28253675 epoch total loss 1.19251907\n",
      "Trained batch 419 batch loss 1.30419707 epoch total loss 1.19278562\n",
      "Trained batch 420 batch loss 1.26652634 epoch total loss 1.19296122\n",
      "Trained batch 421 batch loss 1.15955412 epoch total loss 1.19288182\n",
      "Trained batch 422 batch loss 1.11712539 epoch total loss 1.19270229\n",
      "Trained batch 423 batch loss 1.19992852 epoch total loss 1.19271934\n",
      "Trained batch 424 batch loss 1.14586818 epoch total loss 1.19260883\n",
      "Trained batch 425 batch loss 1.13750279 epoch total loss 1.19247925\n",
      "Trained batch 426 batch loss 1.13828754 epoch total loss 1.19235206\n",
      "Trained batch 427 batch loss 1.00868893 epoch total loss 1.19192195\n",
      "Trained batch 428 batch loss 1.00028479 epoch total loss 1.19147408\n",
      "Trained batch 429 batch loss 1.1086278 epoch total loss 1.19128108\n",
      "Trained batch 430 batch loss 1.16692901 epoch total loss 1.19122446\n",
      "Trained batch 431 batch loss 1.25844133 epoch total loss 1.19138038\n",
      "Trained batch 432 batch loss 1.14866281 epoch total loss 1.19128144\n",
      "Trained batch 433 batch loss 1.28106713 epoch total loss 1.19148886\n",
      "Trained batch 434 batch loss 1.19951034 epoch total loss 1.19150734\n",
      "Trained batch 435 batch loss 1.34775734 epoch total loss 1.19186664\n",
      "Trained batch 436 batch loss 1.04522729 epoch total loss 1.19153023\n",
      "Trained batch 437 batch loss 1.00995588 epoch total loss 1.19111478\n",
      "Trained batch 438 batch loss 0.96483469 epoch total loss 1.19059813\n",
      "Trained batch 439 batch loss 1.06037641 epoch total loss 1.19030154\n",
      "Trained batch 440 batch loss 1.2144053 epoch total loss 1.19035625\n",
      "Trained batch 441 batch loss 1.23772645 epoch total loss 1.19046378\n",
      "Trained batch 442 batch loss 1.36159539 epoch total loss 1.19085085\n",
      "Trained batch 443 batch loss 1.18456089 epoch total loss 1.19083667\n",
      "Trained batch 444 batch loss 1.1198144 epoch total loss 1.19067669\n",
      "Trained batch 445 batch loss 1.08682489 epoch total loss 1.1904434\n",
      "Trained batch 446 batch loss 1.27893817 epoch total loss 1.19064176\n",
      "Trained batch 447 batch loss 1.16926 epoch total loss 1.19059396\n",
      "Trained batch 448 batch loss 1.19396508 epoch total loss 1.19060147\n",
      "Trained batch 449 batch loss 1.22508645 epoch total loss 1.19067836\n",
      "Trained batch 450 batch loss 1.35999358 epoch total loss 1.19105458\n",
      "Trained batch 451 batch loss 1.37083411 epoch total loss 1.19145322\n",
      "Trained batch 452 batch loss 1.24446201 epoch total loss 1.1915704\n",
      "Trained batch 453 batch loss 1.19339108 epoch total loss 1.19157457\n",
      "Trained batch 454 batch loss 1.12169421 epoch total loss 1.19142067\n",
      "Trained batch 455 batch loss 1.08185124 epoch total loss 1.19117987\n",
      "Trained batch 456 batch loss 1.20031977 epoch total loss 1.1911999\n",
      "Trained batch 457 batch loss 1.16130829 epoch total loss 1.19113445\n",
      "Trained batch 458 batch loss 1.0488019 epoch total loss 1.19082379\n",
      "Trained batch 459 batch loss 1.0778563 epoch total loss 1.19057775\n",
      "Trained batch 460 batch loss 0.996069431 epoch total loss 1.19015491\n",
      "Trained batch 461 batch loss 1.01782596 epoch total loss 1.18978107\n",
      "Trained batch 462 batch loss 1.12829518 epoch total loss 1.18964803\n",
      "Trained batch 463 batch loss 1.23532891 epoch total loss 1.18974674\n",
      "Trained batch 464 batch loss 1.26871157 epoch total loss 1.18991697\n",
      "Trained batch 465 batch loss 1.42718756 epoch total loss 1.19042718\n",
      "Trained batch 466 batch loss 1.26862431 epoch total loss 1.19059503\n",
      "Trained batch 467 batch loss 1.28600729 epoch total loss 1.19079936\n",
      "Trained batch 468 batch loss 1.21645021 epoch total loss 1.19085407\n",
      "Trained batch 469 batch loss 1.10361683 epoch total loss 1.19066811\n",
      "Trained batch 470 batch loss 1.05830693 epoch total loss 1.19038641\n",
      "Trained batch 471 batch loss 1.13175797 epoch total loss 1.19026196\n",
      "Trained batch 472 batch loss 1.1928705 epoch total loss 1.19026756\n",
      "Trained batch 473 batch loss 1.18868268 epoch total loss 1.19026411\n",
      "Trained batch 474 batch loss 1.13046145 epoch total loss 1.19013786\n",
      "Trained batch 475 batch loss 1.21150398 epoch total loss 1.19018281\n",
      "Trained batch 476 batch loss 1.24308491 epoch total loss 1.19029403\n",
      "Trained batch 477 batch loss 1.23521328 epoch total loss 1.1903882\n",
      "Trained batch 478 batch loss 1.25753486 epoch total loss 1.19052863\n",
      "Trained batch 479 batch loss 1.08428609 epoch total loss 1.1903069\n",
      "Trained batch 480 batch loss 1.19055629 epoch total loss 1.19030738\n",
      "Trained batch 481 batch loss 1.29170942 epoch total loss 1.19051814\n",
      "Trained batch 482 batch loss 1.308725 epoch total loss 1.19076335\n",
      "Trained batch 483 batch loss 1.17715514 epoch total loss 1.19073522\n",
      "Trained batch 484 batch loss 1.14544892 epoch total loss 1.19064164\n",
      "Trained batch 485 batch loss 1.12275612 epoch total loss 1.19050169\n",
      "Trained batch 486 batch loss 1.06402314 epoch total loss 1.19024146\n",
      "Trained batch 487 batch loss 1.05815661 epoch total loss 1.18997025\n",
      "Trained batch 488 batch loss 1.19842148 epoch total loss 1.18998754\n",
      "Trained batch 489 batch loss 1.30999374 epoch total loss 1.19023299\n",
      "Trained batch 490 batch loss 1.21091545 epoch total loss 1.19027519\n",
      "Trained batch 491 batch loss 1.25055027 epoch total loss 1.19039798\n",
      "Trained batch 492 batch loss 1.16591871 epoch total loss 1.19034815\n",
      "Trained batch 493 batch loss 1.22929 epoch total loss 1.19042718\n",
      "Trained batch 494 batch loss 1.18512 epoch total loss 1.19041646\n",
      "Trained batch 495 batch loss 1.04073632 epoch total loss 1.19011402\n",
      "Trained batch 496 batch loss 1.11124694 epoch total loss 1.18995512\n",
      "Trained batch 497 batch loss 1.2061317 epoch total loss 1.18998754\n",
      "Trained batch 498 batch loss 1.15384281 epoch total loss 1.18991506\n",
      "Trained batch 499 batch loss 1.28803718 epoch total loss 1.19011164\n",
      "Trained batch 500 batch loss 1.20492232 epoch total loss 1.1901412\n",
      "Trained batch 501 batch loss 1.12142491 epoch total loss 1.19000399\n",
      "Trained batch 502 batch loss 1.02580333 epoch total loss 1.189677\n",
      "Trained batch 503 batch loss 1.2595942 epoch total loss 1.18981588\n",
      "Trained batch 504 batch loss 1.23106146 epoch total loss 1.18989778\n",
      "Trained batch 505 batch loss 1.25006938 epoch total loss 1.19001698\n",
      "Trained batch 506 batch loss 1.19500029 epoch total loss 1.19002676\n",
      "Trained batch 507 batch loss 1.18992257 epoch total loss 1.19002664\n",
      "Trained batch 508 batch loss 1.25988579 epoch total loss 1.19016421\n",
      "Trained batch 509 batch loss 1.24130225 epoch total loss 1.19026458\n",
      "Trained batch 510 batch loss 1.2224586 epoch total loss 1.19032776\n",
      "Trained batch 511 batch loss 1.18517423 epoch total loss 1.19031763\n",
      "Trained batch 512 batch loss 1.11347413 epoch total loss 1.19016755\n",
      "Trained batch 513 batch loss 1.19309807 epoch total loss 1.19017327\n",
      "Trained batch 514 batch loss 1.03344691 epoch total loss 1.18986833\n",
      "Trained batch 515 batch loss 1.22395504 epoch total loss 1.18993449\n",
      "Trained batch 516 batch loss 1.09822249 epoch total loss 1.18975675\n",
      "Trained batch 517 batch loss 1.07699168 epoch total loss 1.1895386\n",
      "Trained batch 518 batch loss 1.16572571 epoch total loss 1.18949258\n",
      "Trained batch 519 batch loss 1.08166385 epoch total loss 1.1892848\n",
      "Trained batch 520 batch loss 1.10095727 epoch total loss 1.18911493\n",
      "Trained batch 521 batch loss 1.30654931 epoch total loss 1.18934047\n",
      "Trained batch 522 batch loss 1.33491313 epoch total loss 1.1896193\n",
      "Trained batch 523 batch loss 1.30881572 epoch total loss 1.18984723\n",
      "Trained batch 524 batch loss 1.1765306 epoch total loss 1.18982184\n",
      "Trained batch 525 batch loss 1.18514323 epoch total loss 1.18981278\n",
      "Trained batch 526 batch loss 1.05713606 epoch total loss 1.18956053\n",
      "Trained batch 527 batch loss 1.22298098 epoch total loss 1.18962395\n",
      "Trained batch 528 batch loss 1.17585158 epoch total loss 1.18959785\n",
      "Trained batch 529 batch loss 1.21731019 epoch total loss 1.18965018\n",
      "Trained batch 530 batch loss 1.23845172 epoch total loss 1.18974233\n",
      "Trained batch 531 batch loss 1.17831683 epoch total loss 1.18972087\n",
      "Trained batch 532 batch loss 1.10595226 epoch total loss 1.18956339\n",
      "Trained batch 533 batch loss 1.10052872 epoch total loss 1.18939638\n",
      "Trained batch 534 batch loss 1.18480492 epoch total loss 1.1893878\n",
      "Trained batch 535 batch loss 1.16636908 epoch total loss 1.18934476\n",
      "Trained batch 536 batch loss 1.09355056 epoch total loss 1.18916607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 537 batch loss 1.27304184 epoch total loss 1.18932235\n",
      "Trained batch 538 batch loss 1.09567547 epoch total loss 1.18914831\n",
      "Trained batch 539 batch loss 1.18546379 epoch total loss 1.18914151\n",
      "Trained batch 540 batch loss 1.15387177 epoch total loss 1.18907619\n",
      "Trained batch 541 batch loss 1.19570982 epoch total loss 1.18908846\n",
      "Trained batch 542 batch loss 1.04909706 epoch total loss 1.18883014\n",
      "Trained batch 543 batch loss 1.00183392 epoch total loss 1.18848574\n",
      "Trained batch 544 batch loss 1.03450608 epoch total loss 1.18820274\n",
      "Trained batch 545 batch loss 1.12044263 epoch total loss 1.18807828\n",
      "Trained batch 546 batch loss 1.08850753 epoch total loss 1.18789589\n",
      "Trained batch 547 batch loss 1.25594282 epoch total loss 1.18802035\n",
      "Trained batch 548 batch loss 1.27385151 epoch total loss 1.18817699\n",
      "Trained batch 549 batch loss 1.1929 epoch total loss 1.18818545\n",
      "Trained batch 550 batch loss 1.34934711 epoch total loss 1.18847859\n",
      "Trained batch 551 batch loss 1.24124813 epoch total loss 1.18857443\n",
      "Trained batch 552 batch loss 1.16338348 epoch total loss 1.18852878\n",
      "Trained batch 553 batch loss 1.18975639 epoch total loss 1.18853092\n",
      "Trained batch 554 batch loss 1.13310456 epoch total loss 1.18843091\n",
      "Trained batch 555 batch loss 1.28128409 epoch total loss 1.18859828\n",
      "Trained batch 556 batch loss 1.26281357 epoch total loss 1.18873179\n",
      "Trained batch 557 batch loss 1.28361297 epoch total loss 1.18890214\n",
      "Trained batch 558 batch loss 1.18395 epoch total loss 1.18889332\n",
      "Trained batch 559 batch loss 1.15317786 epoch total loss 1.18882942\n",
      "Trained batch 560 batch loss 1.25356793 epoch total loss 1.18894506\n",
      "Trained batch 561 batch loss 1.31591475 epoch total loss 1.18917131\n",
      "Trained batch 562 batch loss 1.31068969 epoch total loss 1.18938756\n",
      "Trained batch 563 batch loss 1.15527749 epoch total loss 1.18932688\n",
      "Trained batch 564 batch loss 1.09750557 epoch total loss 1.18916416\n",
      "Trained batch 565 batch loss 1.19852901 epoch total loss 1.18918073\n",
      "Trained batch 566 batch loss 1.08667445 epoch total loss 1.18899965\n",
      "Trained batch 567 batch loss 1.05230618 epoch total loss 1.18875861\n",
      "Trained batch 568 batch loss 1.08981335 epoch total loss 1.18858445\n",
      "Trained batch 569 batch loss 1.01925206 epoch total loss 1.18828678\n",
      "Trained batch 570 batch loss 1.02654386 epoch total loss 1.18800306\n",
      "Trained batch 571 batch loss 1.03420615 epoch total loss 1.18773365\n",
      "Trained batch 572 batch loss 1.07223296 epoch total loss 1.18753171\n",
      "Trained batch 573 batch loss 1.05031669 epoch total loss 1.18729222\n",
      "Trained batch 574 batch loss 1.04208231 epoch total loss 1.18703914\n",
      "Trained batch 575 batch loss 1.06154966 epoch total loss 1.18682086\n",
      "Trained batch 576 batch loss 1.10229492 epoch total loss 1.18667412\n",
      "Trained batch 577 batch loss 1.30318379 epoch total loss 1.18687606\n",
      "Trained batch 578 batch loss 1.38676643 epoch total loss 1.18722188\n",
      "Trained batch 579 batch loss 1.15316963 epoch total loss 1.18716311\n",
      "Trained batch 580 batch loss 1.20646501 epoch total loss 1.18719637\n",
      "Trained batch 581 batch loss 1.37602949 epoch total loss 1.18752146\n",
      "Trained batch 582 batch loss 1.30190372 epoch total loss 1.18771791\n",
      "Trained batch 583 batch loss 1.11126053 epoch total loss 1.18758678\n",
      "Trained batch 584 batch loss 1.21762586 epoch total loss 1.18763828\n",
      "Trained batch 585 batch loss 1.10128164 epoch total loss 1.18749058\n",
      "Trained batch 586 batch loss 1.25450575 epoch total loss 1.18760502\n",
      "Trained batch 587 batch loss 1.16676044 epoch total loss 1.1875695\n",
      "Trained batch 588 batch loss 1.19883108 epoch total loss 1.18758869\n",
      "Trained batch 589 batch loss 1.24996352 epoch total loss 1.18769455\n",
      "Trained batch 590 batch loss 1.2844795 epoch total loss 1.18785858\n",
      "Trained batch 591 batch loss 1.04293084 epoch total loss 1.18761325\n",
      "Trained batch 592 batch loss 1.1785996 epoch total loss 1.18759799\n",
      "Trained batch 593 batch loss 1.15880775 epoch total loss 1.18754947\n",
      "Trained batch 594 batch loss 1.33675122 epoch total loss 1.18780065\n",
      "Trained batch 595 batch loss 1.10213149 epoch total loss 1.18765664\n",
      "Trained batch 596 batch loss 1.22144866 epoch total loss 1.18771327\n",
      "Trained batch 597 batch loss 1.27510095 epoch total loss 1.18785965\n",
      "Trained batch 598 batch loss 1.22466636 epoch total loss 1.18792117\n",
      "Trained batch 599 batch loss 1.04938054 epoch total loss 1.1876899\n",
      "Trained batch 600 batch loss 1.20667958 epoch total loss 1.18772161\n",
      "Trained batch 601 batch loss 1.27508974 epoch total loss 1.18786693\n",
      "Trained batch 602 batch loss 1.16916621 epoch total loss 1.18783593\n",
      "Trained batch 603 batch loss 1.25730014 epoch total loss 1.18795109\n",
      "Trained batch 604 batch loss 1.12805605 epoch total loss 1.18785191\n",
      "Trained batch 605 batch loss 0.984933 epoch total loss 1.18751657\n",
      "Trained batch 606 batch loss 1.17419684 epoch total loss 1.18749452\n",
      "Trained batch 607 batch loss 1.20232558 epoch total loss 1.18751895\n",
      "Trained batch 608 batch loss 0.950749695 epoch total loss 1.18712962\n",
      "Trained batch 609 batch loss 1.01008308 epoch total loss 1.18683887\n",
      "Trained batch 610 batch loss 1.14623785 epoch total loss 1.18677223\n",
      "Trained batch 611 batch loss 1.03728282 epoch total loss 1.18652761\n",
      "Trained batch 612 batch loss 1.13063657 epoch total loss 1.1864363\n",
      "Trained batch 613 batch loss 1.11905992 epoch total loss 1.18632638\n",
      "Trained batch 614 batch loss 1.03490829 epoch total loss 1.18607974\n",
      "Trained batch 615 batch loss 1.09307218 epoch total loss 1.18592858\n",
      "Trained batch 616 batch loss 1.22526622 epoch total loss 1.18599248\n",
      "Trained batch 617 batch loss 1.04823267 epoch total loss 1.1857692\n",
      "Trained batch 618 batch loss 1.1250366 epoch total loss 1.18567097\n",
      "Trained batch 619 batch loss 1.10385108 epoch total loss 1.18553865\n",
      "Trained batch 620 batch loss 0.98976481 epoch total loss 1.18522286\n",
      "Trained batch 621 batch loss 1.13499558 epoch total loss 1.18514204\n",
      "Trained batch 622 batch loss 1.17617905 epoch total loss 1.18512762\n",
      "Trained batch 623 batch loss 1.24259543 epoch total loss 1.18522\n",
      "Trained batch 624 batch loss 1.38328266 epoch total loss 1.18553734\n",
      "Trained batch 625 batch loss 1.4795239 epoch total loss 1.18600786\n",
      "Trained batch 626 batch loss 1.25774801 epoch total loss 1.18612242\n",
      "Trained batch 627 batch loss 1.14843011 epoch total loss 1.18606234\n",
      "Trained batch 628 batch loss 1.1068188 epoch total loss 1.18593609\n",
      "Trained batch 629 batch loss 1.26782155 epoch total loss 1.18606627\n",
      "Trained batch 630 batch loss 1.39298272 epoch total loss 1.18639481\n",
      "Trained batch 631 batch loss 1.21016312 epoch total loss 1.18643236\n",
      "Trained batch 632 batch loss 1.24607778 epoch total loss 1.18652678\n",
      "Trained batch 633 batch loss 1.1767118 epoch total loss 1.18651128\n",
      "Trained batch 634 batch loss 1.21716046 epoch total loss 1.18655968\n",
      "Trained batch 635 batch loss 1.24414134 epoch total loss 1.18665028\n",
      "Trained batch 636 batch loss 1.09352124 epoch total loss 1.18650389\n",
      "Trained batch 637 batch loss 1.09657431 epoch total loss 1.18636262\n",
      "Trained batch 638 batch loss 0.977710485 epoch total loss 1.18603563\n",
      "Trained batch 639 batch loss 1.10990191 epoch total loss 1.18591654\n",
      "Trained batch 640 batch loss 1.10813367 epoch total loss 1.18579507\n",
      "Trained batch 641 batch loss 1.12771702 epoch total loss 1.18570447\n",
      "Trained batch 642 batch loss 0.997647762 epoch total loss 1.18541145\n",
      "Trained batch 643 batch loss 1.12235284 epoch total loss 1.18531346\n",
      "Trained batch 644 batch loss 1.27168095 epoch total loss 1.18544757\n",
      "Trained batch 645 batch loss 1.17630959 epoch total loss 1.18543339\n",
      "Trained batch 646 batch loss 1.09941673 epoch total loss 1.18530023\n",
      "Trained batch 647 batch loss 1.2683183 epoch total loss 1.18542862\n",
      "Trained batch 648 batch loss 1.15946209 epoch total loss 1.18538857\n",
      "Trained batch 649 batch loss 1.26180387 epoch total loss 1.18550622\n",
      "Trained batch 650 batch loss 1.13560963 epoch total loss 1.18542945\n",
      "Trained batch 651 batch loss 1.13929558 epoch total loss 1.18535864\n",
      "Trained batch 652 batch loss 1.13202381 epoch total loss 1.18527675\n",
      "Trained batch 653 batch loss 1.09807932 epoch total loss 1.18514323\n",
      "Trained batch 654 batch loss 1.3019284 epoch total loss 1.18532181\n",
      "Trained batch 655 batch loss 1.11074364 epoch total loss 1.18520796\n",
      "Trained batch 656 batch loss 1.25650096 epoch total loss 1.18531668\n",
      "Trained batch 657 batch loss 1.12184858 epoch total loss 1.18522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 658 batch loss 1.09058142 epoch total loss 1.18507624\n",
      "Trained batch 659 batch loss 1.19427395 epoch total loss 1.18509018\n",
      "Trained batch 660 batch loss 1.23500788 epoch total loss 1.18516576\n",
      "Trained batch 661 batch loss 1.1198622 epoch total loss 1.18506694\n",
      "Trained batch 662 batch loss 1.1037401 epoch total loss 1.18494415\n",
      "Trained batch 663 batch loss 1.06564319 epoch total loss 1.18476415\n",
      "Trained batch 664 batch loss 1.09158456 epoch total loss 1.18462396\n",
      "Trained batch 665 batch loss 1.17777085 epoch total loss 1.18461359\n",
      "Trained batch 666 batch loss 1.16742241 epoch total loss 1.18458784\n",
      "Trained batch 667 batch loss 1.17848253 epoch total loss 1.18457866\n",
      "Trained batch 668 batch loss 1.00079334 epoch total loss 1.18430352\n",
      "Trained batch 669 batch loss 0.961824298 epoch total loss 1.18397105\n",
      "Trained batch 670 batch loss 0.940251112 epoch total loss 1.18360722\n",
      "Trained batch 671 batch loss 0.998496711 epoch total loss 1.18333137\n",
      "Trained batch 672 batch loss 1.01107168 epoch total loss 1.18307495\n",
      "Trained batch 673 batch loss 0.981502 epoch total loss 1.1827755\n",
      "Trained batch 674 batch loss 1.00674033 epoch total loss 1.18251419\n",
      "Trained batch 675 batch loss 1.39529705 epoch total loss 1.1828295\n",
      "Trained batch 676 batch loss 1.19251382 epoch total loss 1.1828438\n",
      "Trained batch 677 batch loss 1.16502833 epoch total loss 1.18281746\n",
      "Trained batch 678 batch loss 1.30777144 epoch total loss 1.18300188\n",
      "Trained batch 679 batch loss 1.23540771 epoch total loss 1.183079\n",
      "Trained batch 680 batch loss 1.11757016 epoch total loss 1.18298268\n",
      "Trained batch 681 batch loss 1.05029535 epoch total loss 1.18278778\n",
      "Trained batch 682 batch loss 1.07221138 epoch total loss 1.18262565\n",
      "Trained batch 683 batch loss 1.22972 epoch total loss 1.18269467\n",
      "Trained batch 684 batch loss 1.16034007 epoch total loss 1.18266201\n",
      "Trained batch 685 batch loss 1.27443874 epoch total loss 1.18279588\n",
      "Trained batch 686 batch loss 1.26168644 epoch total loss 1.18291092\n",
      "Trained batch 687 batch loss 1.21369 epoch total loss 1.18295562\n",
      "Trained batch 688 batch loss 1.35094988 epoch total loss 1.18319988\n",
      "Trained batch 689 batch loss 1.28158021 epoch total loss 1.18334258\n",
      "Trained batch 690 batch loss 1.30234933 epoch total loss 1.18351507\n",
      "Trained batch 691 batch loss 1.29263926 epoch total loss 1.18367302\n",
      "Trained batch 692 batch loss 1.28633904 epoch total loss 1.18382144\n",
      "Trained batch 693 batch loss 1.30514491 epoch total loss 1.18399644\n",
      "Trained batch 694 batch loss 1.25822306 epoch total loss 1.18410337\n",
      "Trained batch 695 batch loss 1.36145043 epoch total loss 1.1843586\n",
      "Trained batch 696 batch loss 1.32132983 epoch total loss 1.18455541\n",
      "Trained batch 697 batch loss 1.33031964 epoch total loss 1.1847645\n",
      "Trained batch 698 batch loss 1.21910512 epoch total loss 1.18481374\n",
      "Trained batch 699 batch loss 1.32613754 epoch total loss 1.18501592\n",
      "Trained batch 700 batch loss 1.26716471 epoch total loss 1.18513322\n",
      "Trained batch 701 batch loss 1.10181975 epoch total loss 1.18501437\n",
      "Trained batch 702 batch loss 1.14298582 epoch total loss 1.18495452\n",
      "Trained batch 703 batch loss 1.01600647 epoch total loss 1.1847142\n",
      "Trained batch 704 batch loss 1.05499387 epoch total loss 1.1845299\n",
      "Trained batch 705 batch loss 1.0364877 epoch total loss 1.18432\n",
      "Trained batch 706 batch loss 1.08393884 epoch total loss 1.18417776\n",
      "Trained batch 707 batch loss 0.96364677 epoch total loss 1.18386579\n",
      "Trained batch 708 batch loss 0.938158035 epoch total loss 1.18351877\n",
      "Trained batch 709 batch loss 0.879356921 epoch total loss 1.18308973\n",
      "Trained batch 710 batch loss 0.922183 epoch total loss 1.18272221\n",
      "Trained batch 711 batch loss 1.0908078 epoch total loss 1.18259299\n",
      "Trained batch 712 batch loss 1.13742971 epoch total loss 1.18252957\n",
      "Trained batch 713 batch loss 1.11383343 epoch total loss 1.18243325\n",
      "Trained batch 714 batch loss 1.16570044 epoch total loss 1.18240976\n",
      "Trained batch 715 batch loss 1.21777284 epoch total loss 1.18245924\n",
      "Trained batch 716 batch loss 1.18778038 epoch total loss 1.18246675\n",
      "Trained batch 717 batch loss 1.09544039 epoch total loss 1.18234539\n",
      "Trained batch 718 batch loss 1.11897635 epoch total loss 1.18225706\n",
      "Trained batch 719 batch loss 1.14055467 epoch total loss 1.18219912\n",
      "Trained batch 720 batch loss 1.04570329 epoch total loss 1.18200958\n",
      "Trained batch 721 batch loss 1.09837627 epoch total loss 1.18189359\n",
      "Trained batch 722 batch loss 1.1550777 epoch total loss 1.18185639\n",
      "Trained batch 723 batch loss 1.11263299 epoch total loss 1.18176067\n",
      "Trained batch 724 batch loss 1.15414202 epoch total loss 1.18172252\n",
      "Trained batch 725 batch loss 0.866224051 epoch total loss 1.18128729\n",
      "Trained batch 726 batch loss 0.972463071 epoch total loss 1.18099964\n",
      "Trained batch 727 batch loss 1.16763902 epoch total loss 1.18098128\n",
      "Trained batch 728 batch loss 1.24236453 epoch total loss 1.18106568\n",
      "Trained batch 729 batch loss 1.23776019 epoch total loss 1.1811434\n",
      "Trained batch 730 batch loss 1.14256859 epoch total loss 1.18109059\n",
      "Trained batch 731 batch loss 1.18625343 epoch total loss 1.18109763\n",
      "Trained batch 732 batch loss 1.0926193 epoch total loss 1.18097675\n",
      "Trained batch 733 batch loss 1.06155765 epoch total loss 1.18081391\n",
      "Trained batch 734 batch loss 0.988857031 epoch total loss 1.18055224\n",
      "Trained batch 735 batch loss 1.18396068 epoch total loss 1.18055689\n",
      "Trained batch 736 batch loss 1.15792811 epoch total loss 1.18052614\n",
      "Trained batch 737 batch loss 1.24443114 epoch total loss 1.18061292\n",
      "Trained batch 738 batch loss 1.32652342 epoch total loss 1.18081057\n",
      "Trained batch 739 batch loss 1.41084516 epoch total loss 1.18112183\n",
      "Trained batch 740 batch loss 1.17462397 epoch total loss 1.18111312\n",
      "Trained batch 741 batch loss 1.22103596 epoch total loss 1.18116689\n",
      "Trained batch 742 batch loss 1.2783854 epoch total loss 1.1812979\n",
      "Trained batch 743 batch loss 1.12577152 epoch total loss 1.18122327\n",
      "Trained batch 744 batch loss 1.22186351 epoch total loss 1.18127787\n",
      "Trained batch 745 batch loss 1.21054208 epoch total loss 1.18131721\n",
      "Trained batch 746 batch loss 1.24855042 epoch total loss 1.18140733\n",
      "Trained batch 747 batch loss 1.33697855 epoch total loss 1.18161559\n",
      "Trained batch 748 batch loss 1.43441117 epoch total loss 1.18195343\n",
      "Trained batch 749 batch loss 1.25875425 epoch total loss 1.18205595\n",
      "Trained batch 750 batch loss 1.27634597 epoch total loss 1.18218172\n",
      "Trained batch 751 batch loss 1.15705109 epoch total loss 1.18214822\n",
      "Trained batch 752 batch loss 1.16437805 epoch total loss 1.18212461\n",
      "Trained batch 753 batch loss 1.13813078 epoch total loss 1.1820662\n",
      "Trained batch 754 batch loss 1.20049238 epoch total loss 1.18209064\n",
      "Trained batch 755 batch loss 1.16819072 epoch total loss 1.18207228\n",
      "Trained batch 756 batch loss 1.30946064 epoch total loss 1.18224072\n",
      "Trained batch 757 batch loss 1.2155503 epoch total loss 1.18228471\n",
      "Trained batch 758 batch loss 1.20286965 epoch total loss 1.18231189\n",
      "Trained batch 759 batch loss 1.19257057 epoch total loss 1.18232548\n",
      "Trained batch 760 batch loss 1.32363224 epoch total loss 1.18251133\n",
      "Trained batch 761 batch loss 1.23748207 epoch total loss 1.18258357\n",
      "Trained batch 762 batch loss 1.22441578 epoch total loss 1.18263853\n",
      "Trained batch 763 batch loss 1.21556759 epoch total loss 1.18268168\n",
      "Trained batch 764 batch loss 1.24215019 epoch total loss 1.18275952\n",
      "Trained batch 765 batch loss 1.25474358 epoch total loss 1.18285358\n",
      "Trained batch 766 batch loss 1.2394042 epoch total loss 1.18292737\n",
      "Trained batch 767 batch loss 1.0726577 epoch total loss 1.1827836\n",
      "Trained batch 768 batch loss 1.10232866 epoch total loss 1.18267882\n",
      "Trained batch 769 batch loss 1.17733753 epoch total loss 1.1826719\n",
      "Trained batch 770 batch loss 1.20681071 epoch total loss 1.18270314\n",
      "Trained batch 771 batch loss 1.33502603 epoch total loss 1.18290079\n",
      "Trained batch 772 batch loss 1.1967783 epoch total loss 1.18291867\n",
      "Trained batch 773 batch loss 1.20959365 epoch total loss 1.18295324\n",
      "Trained batch 774 batch loss 1.19819927 epoch total loss 1.18297291\n",
      "Trained batch 775 batch loss 1.21819603 epoch total loss 1.18301833\n",
      "Trained batch 776 batch loss 1.05625796 epoch total loss 1.18285501\n",
      "Trained batch 777 batch loss 1.09439051 epoch total loss 1.18274117\n",
      "Trained batch 778 batch loss 1.1957171 epoch total loss 1.18275785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 779 batch loss 1.31746888 epoch total loss 1.18293071\n",
      "Trained batch 780 batch loss 1.23063779 epoch total loss 1.18299198\n",
      "Trained batch 781 batch loss 1.19562793 epoch total loss 1.18300807\n",
      "Trained batch 782 batch loss 1.17415953 epoch total loss 1.18299675\n",
      "Trained batch 783 batch loss 1.17008364 epoch total loss 1.1829803\n",
      "Trained batch 784 batch loss 1.10742164 epoch total loss 1.18288386\n",
      "Trained batch 785 batch loss 1.06854153 epoch total loss 1.1827383\n",
      "Trained batch 786 batch loss 1.03333986 epoch total loss 1.18254817\n",
      "Trained batch 787 batch loss 1.09190655 epoch total loss 1.18243301\n",
      "Trained batch 788 batch loss 1.04834652 epoch total loss 1.18226278\n",
      "Trained batch 789 batch loss 1.0269891 epoch total loss 1.18206596\n",
      "Trained batch 790 batch loss 1.10246253 epoch total loss 1.18196523\n",
      "Trained batch 791 batch loss 1.12873518 epoch total loss 1.181898\n",
      "Trained batch 792 batch loss 1.12071872 epoch total loss 1.18182075\n",
      "Trained batch 793 batch loss 1.07557344 epoch total loss 1.18168676\n",
      "Trained batch 794 batch loss 1.07992756 epoch total loss 1.18155861\n",
      "Trained batch 795 batch loss 1.22624826 epoch total loss 1.18161488\n",
      "Trained batch 796 batch loss 1.23621964 epoch total loss 1.18168342\n",
      "Trained batch 797 batch loss 1.20305085 epoch total loss 1.18171024\n",
      "Trained batch 798 batch loss 1.17056274 epoch total loss 1.1816963\n",
      "Trained batch 799 batch loss 1.18437 epoch total loss 1.18169963\n",
      "Trained batch 800 batch loss 1.18757057 epoch total loss 1.18170702\n",
      "Trained batch 801 batch loss 1.11833143 epoch total loss 1.18162787\n",
      "Trained batch 802 batch loss 1.14775217 epoch total loss 1.18158567\n",
      "Trained batch 803 batch loss 1.17161751 epoch total loss 1.18157327\n",
      "Trained batch 804 batch loss 1.17005587 epoch total loss 1.18155897\n",
      "Trained batch 805 batch loss 1.16132665 epoch total loss 1.18153381\n",
      "Trained batch 806 batch loss 1.00733817 epoch total loss 1.18131769\n",
      "Trained batch 807 batch loss 0.9962008 epoch total loss 1.18108833\n",
      "Trained batch 808 batch loss 1.13826442 epoch total loss 1.18103528\n",
      "Trained batch 809 batch loss 1.29943359 epoch total loss 1.18118167\n",
      "Trained batch 810 batch loss 1.1979723 epoch total loss 1.18120241\n",
      "Trained batch 811 batch loss 1.15992045 epoch total loss 1.18117607\n",
      "Trained batch 812 batch loss 1.14653826 epoch total loss 1.18113351\n",
      "Trained batch 813 batch loss 1.17436957 epoch total loss 1.18112516\n",
      "Trained batch 814 batch loss 1.13192 epoch total loss 1.18106472\n",
      "Trained batch 815 batch loss 1.12296796 epoch total loss 1.18099344\n",
      "Trained batch 816 batch loss 1.13286757 epoch total loss 1.18093443\n",
      "Trained batch 817 batch loss 1.17689908 epoch total loss 1.18092954\n",
      "Trained batch 818 batch loss 1.16239262 epoch total loss 1.18090689\n",
      "Trained batch 819 batch loss 1.15245855 epoch total loss 1.18087208\n",
      "Trained batch 820 batch loss 1.28622031 epoch total loss 1.18100059\n",
      "Trained batch 821 batch loss 1.15514195 epoch total loss 1.18096912\n",
      "Trained batch 822 batch loss 1.14349425 epoch total loss 1.18092346\n",
      "Trained batch 823 batch loss 1.12325573 epoch total loss 1.18085337\n",
      "Trained batch 824 batch loss 1.11806333 epoch total loss 1.18077719\n",
      "Trained batch 825 batch loss 1.20261061 epoch total loss 1.18080366\n",
      "Trained batch 826 batch loss 1.20361865 epoch total loss 1.18083131\n",
      "Trained batch 827 batch loss 1.16482544 epoch total loss 1.180812\n",
      "Trained batch 828 batch loss 1.21169722 epoch total loss 1.18084919\n",
      "Trained batch 829 batch loss 1.41101635 epoch total loss 1.18112683\n",
      "Trained batch 830 batch loss 1.34217811 epoch total loss 1.18132091\n",
      "Trained batch 831 batch loss 1.31938279 epoch total loss 1.18148708\n",
      "Trained batch 832 batch loss 1.19378734 epoch total loss 1.18150187\n",
      "Trained batch 833 batch loss 1.17914069 epoch total loss 1.181499\n",
      "Trained batch 834 batch loss 1.12799287 epoch total loss 1.18143487\n",
      "Trained batch 835 batch loss 1.19394481 epoch total loss 1.18144989\n",
      "Trained batch 836 batch loss 1.28730965 epoch total loss 1.18157649\n",
      "Trained batch 837 batch loss 1.40162671 epoch total loss 1.18183935\n",
      "Trained batch 838 batch loss 1.47234511 epoch total loss 1.18218601\n",
      "Trained batch 839 batch loss 1.23270106 epoch total loss 1.18224621\n",
      "Trained batch 840 batch loss 1.1373837 epoch total loss 1.1821928\n",
      "Trained batch 841 batch loss 1.27017939 epoch total loss 1.18229747\n",
      "Trained batch 842 batch loss 1.21326387 epoch total loss 1.1823343\n",
      "Trained batch 843 batch loss 1.33677125 epoch total loss 1.18251753\n",
      "Trained batch 844 batch loss 1.2143681 epoch total loss 1.1825552\n",
      "Trained batch 845 batch loss 1.14758027 epoch total loss 1.18251383\n",
      "Trained batch 846 batch loss 1.1576103 epoch total loss 1.18248439\n",
      "Trained batch 847 batch loss 1.07732606 epoch total loss 1.18236017\n",
      "Trained batch 848 batch loss 1.2316606 epoch total loss 1.18241835\n",
      "Trained batch 849 batch loss 1.26164865 epoch total loss 1.18251169\n",
      "Trained batch 850 batch loss 1.18508756 epoch total loss 1.18251467\n",
      "Trained batch 851 batch loss 1.07524574 epoch total loss 1.18238866\n",
      "Trained batch 852 batch loss 1.04839075 epoch total loss 1.18223143\n",
      "Trained batch 853 batch loss 1.08743751 epoch total loss 1.18212032\n",
      "Trained batch 854 batch loss 1.32764935 epoch total loss 1.18229067\n",
      "Trained batch 855 batch loss 1.31174481 epoch total loss 1.18244219\n",
      "Trained batch 856 batch loss 1.25356627 epoch total loss 1.18252516\n",
      "Trained batch 857 batch loss 1.25239277 epoch total loss 1.1826067\n",
      "Trained batch 858 batch loss 1.34285498 epoch total loss 1.1827935\n",
      "Trained batch 859 batch loss 1.23967016 epoch total loss 1.18285966\n",
      "Trained batch 860 batch loss 1.28932023 epoch total loss 1.18298352\n",
      "Trained batch 861 batch loss 1.21414375 epoch total loss 1.18301964\n",
      "Trained batch 862 batch loss 1.33590376 epoch total loss 1.18319702\n",
      "Trained batch 863 batch loss 1.16265213 epoch total loss 1.18317318\n",
      "Trained batch 864 batch loss 1.3239404 epoch total loss 1.18333614\n",
      "Trained batch 865 batch loss 1.24641061 epoch total loss 1.18340898\n",
      "Trained batch 866 batch loss 1.22529435 epoch total loss 1.18345749\n",
      "Trained batch 867 batch loss 1.20667458 epoch total loss 1.1834842\n",
      "Trained batch 868 batch loss 1.14327228 epoch total loss 1.18343794\n",
      "Trained batch 869 batch loss 1.15141261 epoch total loss 1.18340099\n",
      "Trained batch 870 batch loss 1.2262826 epoch total loss 1.18345034\n",
      "Trained batch 871 batch loss 1.27038479 epoch total loss 1.18355012\n",
      "Trained batch 872 batch loss 1.21407497 epoch total loss 1.18358517\n",
      "Trained batch 873 batch loss 1.24199843 epoch total loss 1.18365204\n",
      "Trained batch 874 batch loss 1.17249608 epoch total loss 1.18363929\n",
      "Trained batch 875 batch loss 1.25357854 epoch total loss 1.18371916\n",
      "Trained batch 876 batch loss 1.22650898 epoch total loss 1.18376803\n",
      "Trained batch 877 batch loss 1.24195147 epoch total loss 1.18383443\n",
      "Trained batch 878 batch loss 1.27906454 epoch total loss 1.18394291\n",
      "Trained batch 879 batch loss 1.21076441 epoch total loss 1.18397343\n",
      "Trained batch 880 batch loss 1.33403492 epoch total loss 1.1841439\n",
      "Trained batch 881 batch loss 1.22270799 epoch total loss 1.18418765\n",
      "Trained batch 882 batch loss 1.18997562 epoch total loss 1.18419409\n",
      "Trained batch 883 batch loss 1.19924581 epoch total loss 1.18421113\n",
      "Trained batch 884 batch loss 1.25643051 epoch total loss 1.18429291\n",
      "Trained batch 885 batch loss 1.1653769 epoch total loss 1.18427157\n",
      "Trained batch 886 batch loss 1.19707966 epoch total loss 1.184286\n",
      "Trained batch 887 batch loss 1.1863569 epoch total loss 1.18428838\n",
      "Trained batch 888 batch loss 1.1096375 epoch total loss 1.18420422\n",
      "Trained batch 889 batch loss 1.12487841 epoch total loss 1.18413746\n",
      "Trained batch 890 batch loss 1.0739665 epoch total loss 1.18401372\n",
      "Trained batch 891 batch loss 1.15319598 epoch total loss 1.18397915\n",
      "Trained batch 892 batch loss 1.14376819 epoch total loss 1.18393409\n",
      "Trained batch 893 batch loss 1.06255007 epoch total loss 1.18379807\n",
      "Trained batch 894 batch loss 1.01710415 epoch total loss 1.18361163\n",
      "Trained batch 895 batch loss 1.16201067 epoch total loss 1.18358743\n",
      "Trained batch 896 batch loss 1.21582282 epoch total loss 1.18362343\n",
      "Trained batch 897 batch loss 1.20820117 epoch total loss 1.18365085\n",
      "Trained batch 898 batch loss 1.23094118 epoch total loss 1.18370354\n",
      "Trained batch 899 batch loss 1.15600383 epoch total loss 1.18367279\n",
      "Trained batch 900 batch loss 1.06993878 epoch total loss 1.18354642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 901 batch loss 1.22149336 epoch total loss 1.1835885\n",
      "Trained batch 902 batch loss 1.25231707 epoch total loss 1.18366468\n",
      "Trained batch 903 batch loss 1.24965191 epoch total loss 1.18373775\n",
      "Trained batch 904 batch loss 1.25259089 epoch total loss 1.18381381\n",
      "Trained batch 905 batch loss 1.1648984 epoch total loss 1.18379295\n",
      "Trained batch 906 batch loss 1.14689422 epoch total loss 1.18375218\n",
      "Trained batch 907 batch loss 1.11882138 epoch total loss 1.18368053\n",
      "Trained batch 908 batch loss 1.07704544 epoch total loss 1.18356311\n",
      "Trained batch 909 batch loss 1.12557924 epoch total loss 1.18349934\n",
      "Trained batch 910 batch loss 1.273085 epoch total loss 1.1835978\n",
      "Trained batch 911 batch loss 1.22939539 epoch total loss 1.18364799\n",
      "Trained batch 912 batch loss 1.18500352 epoch total loss 1.18364954\n",
      "Trained batch 913 batch loss 1.21407413 epoch total loss 1.18368292\n",
      "Trained batch 914 batch loss 1.2228446 epoch total loss 1.18372583\n",
      "Trained batch 915 batch loss 1.21818888 epoch total loss 1.1837635\n",
      "Trained batch 916 batch loss 1.41793537 epoch total loss 1.18401909\n",
      "Trained batch 917 batch loss 1.2096746 epoch total loss 1.1840471\n",
      "Trained batch 918 batch loss 1.28076041 epoch total loss 1.18415248\n",
      "Trained batch 919 batch loss 1.3527112 epoch total loss 1.18433583\n",
      "Trained batch 920 batch loss 1.17581916 epoch total loss 1.18432653\n",
      "Trained batch 921 batch loss 1.2375946 epoch total loss 1.18438435\n",
      "Trained batch 922 batch loss 1.25350678 epoch total loss 1.18445933\n",
      "Trained batch 923 batch loss 1.14178967 epoch total loss 1.18441319\n",
      "Trained batch 924 batch loss 1.08481681 epoch total loss 1.18430543\n",
      "Trained batch 925 batch loss 1.19723666 epoch total loss 1.1843195\n",
      "Trained batch 926 batch loss 1.24973333 epoch total loss 1.18439007\n",
      "Trained batch 927 batch loss 1.18312311 epoch total loss 1.18438876\n",
      "Trained batch 928 batch loss 1.21693277 epoch total loss 1.1844238\n",
      "Trained batch 929 batch loss 1.10143423 epoch total loss 1.1843344\n",
      "Trained batch 930 batch loss 1.12244844 epoch total loss 1.18426788\n",
      "Trained batch 931 batch loss 1.22432971 epoch total loss 1.18431091\n",
      "Trained batch 932 batch loss 1.22506022 epoch total loss 1.18435478\n",
      "Trained batch 933 batch loss 1.24593163 epoch total loss 1.18442082\n",
      "Trained batch 934 batch loss 1.47049141 epoch total loss 1.18472707\n",
      "Trained batch 935 batch loss 1.29921949 epoch total loss 1.1848495\n",
      "Trained batch 936 batch loss 1.09924114 epoch total loss 1.18475795\n",
      "Trained batch 937 batch loss 1.11103427 epoch total loss 1.18467939\n",
      "Trained batch 938 batch loss 1.15413511 epoch total loss 1.18464684\n",
      "Trained batch 939 batch loss 1.21580887 epoch total loss 1.18468\n",
      "Trained batch 940 batch loss 1.20171583 epoch total loss 1.1846981\n",
      "Trained batch 941 batch loss 1.27449346 epoch total loss 1.18479359\n",
      "Trained batch 942 batch loss 1.22461402 epoch total loss 1.18483579\n",
      "Trained batch 943 batch loss 1.33364105 epoch total loss 1.18499362\n",
      "Trained batch 944 batch loss 1.38086605 epoch total loss 1.18520105\n",
      "Trained batch 945 batch loss 1.2569809 epoch total loss 1.18527699\n",
      "Trained batch 946 batch loss 1.23131406 epoch total loss 1.18532574\n",
      "Trained batch 947 batch loss 1.1136508 epoch total loss 1.18525\n",
      "Trained batch 948 batch loss 1.1595701 epoch total loss 1.18522286\n",
      "Trained batch 949 batch loss 1.23729515 epoch total loss 1.18527782\n",
      "Trained batch 950 batch loss 1.17444611 epoch total loss 1.18526638\n",
      "Trained batch 951 batch loss 1.08573318 epoch total loss 1.18516171\n",
      "Trained batch 952 batch loss 1.14418805 epoch total loss 1.18511856\n",
      "Trained batch 953 batch loss 1.11228311 epoch total loss 1.18504214\n",
      "Trained batch 954 batch loss 1.21577191 epoch total loss 1.18507445\n",
      "Trained batch 955 batch loss 1.1489172 epoch total loss 1.18503666\n",
      "Trained batch 956 batch loss 1.17995644 epoch total loss 1.18503129\n",
      "Trained batch 957 batch loss 1.20975637 epoch total loss 1.18505704\n",
      "Trained batch 958 batch loss 1.21038365 epoch total loss 1.18508339\n",
      "Trained batch 959 batch loss 1.10071766 epoch total loss 1.18499541\n",
      "Trained batch 960 batch loss 1.26659632 epoch total loss 1.18508041\n",
      "Trained batch 961 batch loss 1.28600836 epoch total loss 1.18518543\n",
      "Trained batch 962 batch loss 1.18936336 epoch total loss 1.18518984\n",
      "Trained batch 963 batch loss 1.14672637 epoch total loss 1.18514991\n",
      "Trained batch 964 batch loss 1.16301191 epoch total loss 1.1851269\n",
      "Trained batch 965 batch loss 1.23394763 epoch total loss 1.18517733\n",
      "Trained batch 966 batch loss 1.08676898 epoch total loss 1.18507552\n",
      "Trained batch 967 batch loss 1.20060933 epoch total loss 1.1850915\n",
      "Trained batch 968 batch loss 1.1828053 epoch total loss 1.18508923\n",
      "Trained batch 969 batch loss 1.19370437 epoch total loss 1.18509817\n",
      "Trained batch 970 batch loss 1.19409239 epoch total loss 1.18510747\n",
      "Trained batch 971 batch loss 1.35491788 epoch total loss 1.18528223\n",
      "Trained batch 972 batch loss 1.20593846 epoch total loss 1.18530345\n",
      "Trained batch 973 batch loss 1.28736854 epoch total loss 1.18540835\n",
      "Trained batch 974 batch loss 1.21870756 epoch total loss 1.18544257\n",
      "Trained batch 975 batch loss 1.19732833 epoch total loss 1.18545485\n",
      "Trained batch 976 batch loss 1.11517048 epoch total loss 1.18538272\n",
      "Trained batch 977 batch loss 1.17488861 epoch total loss 1.18537211\n",
      "Trained batch 978 batch loss 1.29751647 epoch total loss 1.18548667\n",
      "Trained batch 979 batch loss 1.32958674 epoch total loss 1.1856339\n",
      "Trained batch 980 batch loss 1.18343329 epoch total loss 1.18563175\n",
      "Trained batch 981 batch loss 1.22041392 epoch total loss 1.18566716\n",
      "Trained batch 982 batch loss 1.10526371 epoch total loss 1.18558526\n",
      "Trained batch 983 batch loss 1.3057158 epoch total loss 1.18570745\n",
      "Trained batch 984 batch loss 1.22230983 epoch total loss 1.18574464\n",
      "Trained batch 985 batch loss 1.32522392 epoch total loss 1.18588614\n",
      "Trained batch 986 batch loss 1.24095547 epoch total loss 1.18594205\n",
      "Trained batch 987 batch loss 1.08930099 epoch total loss 1.18584418\n",
      "Trained batch 988 batch loss 1.31502497 epoch total loss 1.18597496\n",
      "Trained batch 989 batch loss 1.19422185 epoch total loss 1.1859833\n",
      "Trained batch 990 batch loss 1.30908084 epoch total loss 1.18610764\n",
      "Trained batch 991 batch loss 1.22472036 epoch total loss 1.18614662\n",
      "Trained batch 992 batch loss 1.2054503 epoch total loss 1.18616605\n",
      "Trained batch 993 batch loss 1.13081312 epoch total loss 1.18611038\n",
      "Trained batch 994 batch loss 1.16992247 epoch total loss 1.18609405\n",
      "Trained batch 995 batch loss 1.24979782 epoch total loss 1.18615806\n",
      "Trained batch 996 batch loss 1.14658308 epoch total loss 1.18611836\n",
      "Trained batch 997 batch loss 1.18050253 epoch total loss 1.18611276\n",
      "Trained batch 998 batch loss 1.19668198 epoch total loss 1.18612337\n",
      "Trained batch 999 batch loss 1.14470553 epoch total loss 1.18608189\n",
      "Trained batch 1000 batch loss 1.22427738 epoch total loss 1.18612\n",
      "Trained batch 1001 batch loss 1.13233531 epoch total loss 1.18606627\n",
      "Trained batch 1002 batch loss 1.27080226 epoch total loss 1.18615079\n",
      "Trained batch 1003 batch loss 1.12801611 epoch total loss 1.18609285\n",
      "Trained batch 1004 batch loss 1.13607395 epoch total loss 1.18604302\n",
      "Trained batch 1005 batch loss 1.13388503 epoch total loss 1.18599117\n",
      "Trained batch 1006 batch loss 1.05076981 epoch total loss 1.18585682\n",
      "Trained batch 1007 batch loss 1.17055774 epoch total loss 1.18584156\n",
      "Trained batch 1008 batch loss 1.1472466 epoch total loss 1.18580329\n",
      "Trained batch 1009 batch loss 1.11376595 epoch total loss 1.18573189\n",
      "Trained batch 1010 batch loss 1.0723139 epoch total loss 1.18561947\n",
      "Trained batch 1011 batch loss 1.07414281 epoch total loss 1.1855092\n",
      "Trained batch 1012 batch loss 1.11431217 epoch total loss 1.18543875\n",
      "Trained batch 1013 batch loss 1.42844296 epoch total loss 1.18567872\n",
      "Trained batch 1014 batch loss 1.17525744 epoch total loss 1.18566847\n",
      "Trained batch 1015 batch loss 1.18574321 epoch total loss 1.18566859\n",
      "Trained batch 1016 batch loss 1.03997993 epoch total loss 1.1855253\n",
      "Trained batch 1017 batch loss 0.86819 epoch total loss 1.18521321\n",
      "Trained batch 1018 batch loss 0.872286379 epoch total loss 1.18490577\n",
      "Trained batch 1019 batch loss 0.925615311 epoch total loss 1.18465137\n",
      "Trained batch 1020 batch loss 1.12146485 epoch total loss 1.18458951\n",
      "Trained batch 1021 batch loss 1.22868347 epoch total loss 1.18463266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1022 batch loss 0.984597683 epoch total loss 1.18443692\n",
      "Trained batch 1023 batch loss 0.912273288 epoch total loss 1.18417084\n",
      "Trained batch 1024 batch loss 0.996071577 epoch total loss 1.18398714\n",
      "Trained batch 1025 batch loss 1.02096307 epoch total loss 1.18382812\n",
      "Trained batch 1026 batch loss 1.15629721 epoch total loss 1.18380129\n",
      "Trained batch 1027 batch loss 1.16290641 epoch total loss 1.18378091\n",
      "Trained batch 1028 batch loss 1.14855 epoch total loss 1.1837467\n",
      "Trained batch 1029 batch loss 1.23084307 epoch total loss 1.18379247\n",
      "Trained batch 1030 batch loss 1.18798733 epoch total loss 1.18379653\n",
      "Trained batch 1031 batch loss 1.32363749 epoch total loss 1.18393219\n",
      "Trained batch 1032 batch loss 1.29752 epoch total loss 1.18404222\n",
      "Trained batch 1033 batch loss 1.11854804 epoch total loss 1.1839788\n",
      "Trained batch 1034 batch loss 1.17505169 epoch total loss 1.18397009\n",
      "Trained batch 1035 batch loss 1.12751627 epoch total loss 1.18391562\n",
      "Trained batch 1036 batch loss 1.23858678 epoch total loss 1.18396842\n",
      "Trained batch 1037 batch loss 1.29066861 epoch total loss 1.1840713\n",
      "Trained batch 1038 batch loss 1.29919183 epoch total loss 1.18418229\n",
      "Trained batch 1039 batch loss 1.24104118 epoch total loss 1.184237\n",
      "Trained batch 1040 batch loss 1.11769116 epoch total loss 1.18417299\n",
      "Trained batch 1041 batch loss 1.08389866 epoch total loss 1.18407667\n",
      "Trained batch 1042 batch loss 1.05737758 epoch total loss 1.18395507\n",
      "Trained batch 1043 batch loss 1.09323239 epoch total loss 1.18386805\n",
      "Trained batch 1044 batch loss 1.22393131 epoch total loss 1.18390644\n",
      "Trained batch 1045 batch loss 1.14742947 epoch total loss 1.18387151\n",
      "Trained batch 1046 batch loss 1.23637545 epoch total loss 1.18392169\n",
      "Trained batch 1047 batch loss 1.24728811 epoch total loss 1.18398225\n",
      "Trained batch 1048 batch loss 1.24975896 epoch total loss 1.18404496\n",
      "Trained batch 1049 batch loss 1.33624244 epoch total loss 1.18419\n",
      "Trained batch 1050 batch loss 1.33316541 epoch total loss 1.18433189\n",
      "Trained batch 1051 batch loss 1.27177894 epoch total loss 1.18441498\n",
      "Trained batch 1052 batch loss 1.22943282 epoch total loss 1.1844579\n",
      "Trained batch 1053 batch loss 1.11558008 epoch total loss 1.18439245\n",
      "Trained batch 1054 batch loss 1.19551551 epoch total loss 1.18440306\n",
      "Trained batch 1055 batch loss 1.31848025 epoch total loss 1.18453014\n",
      "Trained batch 1056 batch loss 1.21948361 epoch total loss 1.18456328\n",
      "Trained batch 1057 batch loss 1.11644053 epoch total loss 1.18449879\n",
      "Trained batch 1058 batch loss 1.04916286 epoch total loss 1.18437099\n",
      "Trained batch 1059 batch loss 1.10093176 epoch total loss 1.1842922\n",
      "Trained batch 1060 batch loss 1.05761194 epoch total loss 1.18417263\n",
      "Trained batch 1061 batch loss 1.07721806 epoch total loss 1.1840719\n",
      "Trained batch 1062 batch loss 1.18583822 epoch total loss 1.18407357\n",
      "Trained batch 1063 batch loss 1.24295664 epoch total loss 1.18412888\n",
      "Trained batch 1064 batch loss 1.21497774 epoch total loss 1.18415785\n",
      "Trained batch 1065 batch loss 1.21622241 epoch total loss 1.18418789\n",
      "Trained batch 1066 batch loss 1.1650064 epoch total loss 1.18417\n",
      "Trained batch 1067 batch loss 1.19061017 epoch total loss 1.18417597\n",
      "Trained batch 1068 batch loss 1.0363791 epoch total loss 1.18403757\n",
      "Trained batch 1069 batch loss 1.02941549 epoch total loss 1.18389297\n",
      "Trained batch 1070 batch loss 1.04730177 epoch total loss 1.18376517\n",
      "Trained batch 1071 batch loss 1.05623043 epoch total loss 1.1836462\n",
      "Trained batch 1072 batch loss 1.07014239 epoch total loss 1.18354034\n",
      "Trained batch 1073 batch loss 1.08041525 epoch total loss 1.18344426\n",
      "Trained batch 1074 batch loss 1.05704165 epoch total loss 1.18332648\n",
      "Trained batch 1075 batch loss 1.09933555 epoch total loss 1.1832484\n",
      "Trained batch 1076 batch loss 1.10929298 epoch total loss 1.18317962\n",
      "Trained batch 1077 batch loss 1.22794378 epoch total loss 1.18322122\n",
      "Trained batch 1078 batch loss 1.32677007 epoch total loss 1.18335438\n",
      "Trained batch 1079 batch loss 1.07348716 epoch total loss 1.18325257\n",
      "Trained batch 1080 batch loss 1.19260931 epoch total loss 1.18326128\n",
      "Trained batch 1081 batch loss 1.15105534 epoch total loss 1.18323135\n",
      "Trained batch 1082 batch loss 1.11570358 epoch total loss 1.18316901\n",
      "Trained batch 1083 batch loss 1.21906304 epoch total loss 1.18320215\n",
      "Trained batch 1084 batch loss 1.14867687 epoch total loss 1.18317032\n",
      "Trained batch 1085 batch loss 1.29140091 epoch total loss 1.1832701\n",
      "Trained batch 1086 batch loss 1.31240034 epoch total loss 1.18338895\n",
      "Trained batch 1087 batch loss 1.10013652 epoch total loss 1.1833123\n",
      "Trained batch 1088 batch loss 1.01612759 epoch total loss 1.18315864\n",
      "Trained batch 1089 batch loss 1.09618747 epoch total loss 1.18307877\n",
      "Trained batch 1090 batch loss 1.01952112 epoch total loss 1.1829288\n",
      "Trained batch 1091 batch loss 1.10763764 epoch total loss 1.18285978\n",
      "Trained batch 1092 batch loss 1.13529825 epoch total loss 1.18281615\n",
      "Trained batch 1093 batch loss 1.16129315 epoch total loss 1.18279648\n",
      "Trained batch 1094 batch loss 1.10126936 epoch total loss 1.18272197\n",
      "Trained batch 1095 batch loss 1.19447446 epoch total loss 1.1827327\n",
      "Trained batch 1096 batch loss 1.23251188 epoch total loss 1.18277812\n",
      "Trained batch 1097 batch loss 1.2383554 epoch total loss 1.18282878\n",
      "Trained batch 1098 batch loss 1.41621697 epoch total loss 1.18304145\n",
      "Trained batch 1099 batch loss 1.41691113 epoch total loss 1.18325424\n",
      "Trained batch 1100 batch loss 1.47351122 epoch total loss 1.18351805\n",
      "Trained batch 1101 batch loss 1.15406251 epoch total loss 1.18349135\n",
      "Trained batch 1102 batch loss 1.18697429 epoch total loss 1.18349445\n",
      "Trained batch 1103 batch loss 1.25985789 epoch total loss 1.18356371\n",
      "Trained batch 1104 batch loss 1.38716292 epoch total loss 1.18374825\n",
      "Trained batch 1105 batch loss 1.29205883 epoch total loss 1.18384624\n",
      "Trained batch 1106 batch loss 1.27970684 epoch total loss 1.1839329\n",
      "Trained batch 1107 batch loss 1.2709502 epoch total loss 1.18401158\n",
      "Trained batch 1108 batch loss 1.281569 epoch total loss 1.18409967\n",
      "Trained batch 1109 batch loss 1.21103287 epoch total loss 1.18412399\n",
      "Trained batch 1110 batch loss 1.12367821 epoch total loss 1.18406951\n",
      "Trained batch 1111 batch loss 1.22372556 epoch total loss 1.18410516\n",
      "Trained batch 1112 batch loss 1.25705802 epoch total loss 1.18417084\n",
      "Trained batch 1113 batch loss 1.1090796 epoch total loss 1.18410337\n",
      "Trained batch 1114 batch loss 1.16749561 epoch total loss 1.18408847\n",
      "Trained batch 1115 batch loss 1.26648498 epoch total loss 1.18416238\n",
      "Trained batch 1116 batch loss 1.26512766 epoch total loss 1.18423498\n",
      "Trained batch 1117 batch loss 1.42830658 epoch total loss 1.18445349\n",
      "Trained batch 1118 batch loss 1.3466444 epoch total loss 1.18459857\n",
      "Trained batch 1119 batch loss 1.25366127 epoch total loss 1.18466032\n",
      "Trained batch 1120 batch loss 1.22711325 epoch total loss 1.18469822\n",
      "Trained batch 1121 batch loss 1.32137811 epoch total loss 1.18482018\n",
      "Trained batch 1122 batch loss 1.22859287 epoch total loss 1.18485928\n",
      "Trained batch 1123 batch loss 1.23179448 epoch total loss 1.18490112\n",
      "Trained batch 1124 batch loss 1.17069554 epoch total loss 1.18488836\n",
      "Trained batch 1125 batch loss 1.1138767 epoch total loss 1.1848253\n",
      "Trained batch 1126 batch loss 1.16459036 epoch total loss 1.1848073\n",
      "Trained batch 1127 batch loss 1.05013502 epoch total loss 1.18468785\n",
      "Trained batch 1128 batch loss 1.06466603 epoch total loss 1.18458152\n",
      "Trained batch 1129 batch loss 1.09874177 epoch total loss 1.18450546\n",
      "Trained batch 1130 batch loss 1.14594972 epoch total loss 1.18447137\n",
      "Trained batch 1131 batch loss 1.17541754 epoch total loss 1.18446338\n",
      "Trained batch 1132 batch loss 1.14258289 epoch total loss 1.18442631\n",
      "Trained batch 1133 batch loss 1.14941788 epoch total loss 1.18439543\n",
      "Trained batch 1134 batch loss 1.10762167 epoch total loss 1.18432784\n",
      "Trained batch 1135 batch loss 1.07561135 epoch total loss 1.184232\n",
      "Trained batch 1136 batch loss 1.08725429 epoch total loss 1.18414664\n",
      "Trained batch 1137 batch loss 1.12716794 epoch total loss 1.18409657\n",
      "Trained batch 1138 batch loss 1.13615656 epoch total loss 1.18405437\n",
      "Trained batch 1139 batch loss 1.08873057 epoch total loss 1.18397069\n",
      "Trained batch 1140 batch loss 1.04002559 epoch total loss 1.18384445\n",
      "Trained batch 1141 batch loss 1.05987954 epoch total loss 1.18373585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1142 batch loss 1.14269912 epoch total loss 1.18369985\n",
      "Trained batch 1143 batch loss 1.27339172 epoch total loss 1.18377841\n",
      "Trained batch 1144 batch loss 1.06723857 epoch total loss 1.1836766\n",
      "Trained batch 1145 batch loss 1.23248434 epoch total loss 1.18371928\n",
      "Trained batch 1146 batch loss 1.25791144 epoch total loss 1.18378401\n",
      "Trained batch 1147 batch loss 1.34705162 epoch total loss 1.18392634\n",
      "Trained batch 1148 batch loss 1.23905635 epoch total loss 1.18397427\n",
      "Trained batch 1149 batch loss 1.20242083 epoch total loss 1.18399036\n",
      "Trained batch 1150 batch loss 1.18603456 epoch total loss 1.18399215\n",
      "Trained batch 1151 batch loss 1.11150932 epoch total loss 1.18392909\n",
      "Trained batch 1152 batch loss 1.13795161 epoch total loss 1.18388915\n",
      "Trained batch 1153 batch loss 1.15831256 epoch total loss 1.18386698\n",
      "Trained batch 1154 batch loss 1.13150883 epoch total loss 1.18382156\n",
      "Trained batch 1155 batch loss 1.20299792 epoch total loss 1.18383825\n",
      "Trained batch 1156 batch loss 1.14479756 epoch total loss 1.18380439\n",
      "Trained batch 1157 batch loss 1.13793182 epoch total loss 1.18376482\n",
      "Trained batch 1158 batch loss 1.19655669 epoch total loss 1.18377578\n",
      "Trained batch 1159 batch loss 1.32265663 epoch total loss 1.18389559\n",
      "Trained batch 1160 batch loss 1.14151192 epoch total loss 1.18385899\n",
      "Trained batch 1161 batch loss 1.17498994 epoch total loss 1.18385148\n",
      "Trained batch 1162 batch loss 1.07791138 epoch total loss 1.18376029\n",
      "Trained batch 1163 batch loss 1.10318542 epoch total loss 1.18369091\n",
      "Trained batch 1164 batch loss 1.21465433 epoch total loss 1.18371749\n",
      "Trained batch 1165 batch loss 1.28894389 epoch total loss 1.18380785\n",
      "Trained batch 1166 batch loss 1.28895152 epoch total loss 1.18389797\n",
      "Trained batch 1167 batch loss 1.3276031 epoch total loss 1.18402112\n",
      "Trained batch 1168 batch loss 1.24020445 epoch total loss 1.18406928\n",
      "Trained batch 1169 batch loss 1.23966765 epoch total loss 1.18411684\n",
      "Trained batch 1170 batch loss 1.1783514 epoch total loss 1.18411183\n",
      "Trained batch 1171 batch loss 1.1436466 epoch total loss 1.18407738\n",
      "Trained batch 1172 batch loss 1.16218746 epoch total loss 1.18405867\n",
      "Trained batch 1173 batch loss 1.18297219 epoch total loss 1.18405783\n",
      "Trained batch 1174 batch loss 1.17631269 epoch total loss 1.18405116\n",
      "Trained batch 1175 batch loss 1.25431609 epoch total loss 1.18411088\n",
      "Trained batch 1176 batch loss 1.13767874 epoch total loss 1.18407142\n",
      "Trained batch 1177 batch loss 1.12743545 epoch total loss 1.18402338\n",
      "Trained batch 1178 batch loss 1.18619025 epoch total loss 1.18402517\n",
      "Trained batch 1179 batch loss 1.09319186 epoch total loss 1.18394804\n",
      "Trained batch 1180 batch loss 0.981096089 epoch total loss 1.18377614\n",
      "Trained batch 1181 batch loss 0.899887443 epoch total loss 1.18353581\n",
      "Trained batch 1182 batch loss 1.00252247 epoch total loss 1.18338263\n",
      "Trained batch 1183 batch loss 1.17143655 epoch total loss 1.1833725\n",
      "Trained batch 1184 batch loss 1.03158 epoch total loss 1.18324435\n",
      "Trained batch 1185 batch loss 1.01075029 epoch total loss 1.18309879\n",
      "Trained batch 1186 batch loss 1.08052194 epoch total loss 1.18301237\n",
      "Trained batch 1187 batch loss 1.08196068 epoch total loss 1.18292713\n",
      "Trained batch 1188 batch loss 1.14269114 epoch total loss 1.18289328\n",
      "Trained batch 1189 batch loss 1.13377714 epoch total loss 1.18285203\n",
      "Trained batch 1190 batch loss 1.24252069 epoch total loss 1.1829021\n",
      "Trained batch 1191 batch loss 1.24226034 epoch total loss 1.18295205\n",
      "Trained batch 1192 batch loss 1.21655083 epoch total loss 1.18298018\n",
      "Trained batch 1193 batch loss 1.18003082 epoch total loss 1.1829778\n",
      "Trained batch 1194 batch loss 1.21359444 epoch total loss 1.18300343\n",
      "Trained batch 1195 batch loss 1.03559113 epoch total loss 1.18288016\n",
      "Trained batch 1196 batch loss 1.1563617 epoch total loss 1.18285799\n",
      "Trained batch 1197 batch loss 1.00536096 epoch total loss 1.18270969\n",
      "Trained batch 1198 batch loss 1.28497 epoch total loss 1.18279505\n",
      "Trained batch 1199 batch loss 1.33435297 epoch total loss 1.18292141\n",
      "Trained batch 1200 batch loss 1.21996212 epoch total loss 1.18295228\n",
      "Trained batch 1201 batch loss 1.24279261 epoch total loss 1.18300211\n",
      "Trained batch 1202 batch loss 1.26457751 epoch total loss 1.18307\n",
      "Trained batch 1203 batch loss 1.26777899 epoch total loss 1.1831404\n",
      "Trained batch 1204 batch loss 1.2745955 epoch total loss 1.18321633\n",
      "Trained batch 1205 batch loss 1.19010556 epoch total loss 1.18322194\n",
      "Trained batch 1206 batch loss 1.2063787 epoch total loss 1.18324125\n",
      "Trained batch 1207 batch loss 1.21978295 epoch total loss 1.18327141\n",
      "Trained batch 1208 batch loss 1.21054506 epoch total loss 1.18329406\n",
      "Trained batch 1209 batch loss 1.1750927 epoch total loss 1.18328726\n",
      "Trained batch 1210 batch loss 1.17081296 epoch total loss 1.18327689\n",
      "Trained batch 1211 batch loss 1.20033121 epoch total loss 1.18329096\n",
      "Trained batch 1212 batch loss 1.09553528 epoch total loss 1.1832186\n",
      "Trained batch 1213 batch loss 1.12937403 epoch total loss 1.18317425\n",
      "Trained batch 1214 batch loss 1.09842801 epoch total loss 1.1831044\n",
      "Trained batch 1215 batch loss 1.15950584 epoch total loss 1.18308496\n",
      "Trained batch 1216 batch loss 1.04969883 epoch total loss 1.18297529\n",
      "Trained batch 1217 batch loss 1.28239441 epoch total loss 1.18305695\n",
      "Trained batch 1218 batch loss 1.20933199 epoch total loss 1.18307853\n",
      "Trained batch 1219 batch loss 1.26930404 epoch total loss 1.18314922\n",
      "Trained batch 1220 batch loss 1.33254409 epoch total loss 1.18327165\n",
      "Trained batch 1221 batch loss 1.08249176 epoch total loss 1.18318915\n",
      "Trained batch 1222 batch loss 1.11822081 epoch total loss 1.18313599\n",
      "Trained batch 1223 batch loss 1.02816474 epoch total loss 1.18300927\n",
      "Trained batch 1224 batch loss 1.10271943 epoch total loss 1.18294358\n",
      "Trained batch 1225 batch loss 0.968794942 epoch total loss 1.1827687\n",
      "Trained batch 1226 batch loss 1.15558 epoch total loss 1.18274665\n",
      "Trained batch 1227 batch loss 1.11348236 epoch total loss 1.18269026\n",
      "Trained batch 1228 batch loss 1.09550023 epoch total loss 1.18261921\n",
      "Trained batch 1229 batch loss 1.08602786 epoch total loss 1.18254066\n",
      "Trained batch 1230 batch loss 1.13260043 epoch total loss 1.1825\n",
      "Trained batch 1231 batch loss 1.0219481 epoch total loss 1.18236959\n",
      "Trained batch 1232 batch loss 1.11928487 epoch total loss 1.18231833\n",
      "Trained batch 1233 batch loss 1.21958089 epoch total loss 1.18234861\n",
      "Trained batch 1234 batch loss 1.28673935 epoch total loss 1.18243325\n",
      "Trained batch 1235 batch loss 1.15846682 epoch total loss 1.18241382\n",
      "Trained batch 1236 batch loss 1.1443429 epoch total loss 1.18238294\n",
      "Trained batch 1237 batch loss 1.10848248 epoch total loss 1.18232322\n",
      "Trained batch 1238 batch loss 1.18619919 epoch total loss 1.18232632\n",
      "Trained batch 1239 batch loss 1.42721415 epoch total loss 1.18252397\n",
      "Trained batch 1240 batch loss 1.41092336 epoch total loss 1.18270814\n",
      "Trained batch 1241 batch loss 1.26567936 epoch total loss 1.18277502\n",
      "Trained batch 1242 batch loss 1.21357203 epoch total loss 1.18279982\n",
      "Trained batch 1243 batch loss 1.14706874 epoch total loss 1.18277109\n",
      "Trained batch 1244 batch loss 1.08541751 epoch total loss 1.18269289\n",
      "Trained batch 1245 batch loss 1.14806163 epoch total loss 1.18266499\n",
      "Trained batch 1246 batch loss 1.18325639 epoch total loss 1.18266547\n",
      "Trained batch 1247 batch loss 1.1999048 epoch total loss 1.1826793\n",
      "Trained batch 1248 batch loss 1.03808308 epoch total loss 1.18256354\n",
      "Trained batch 1249 batch loss 0.996077538 epoch total loss 1.18241417\n",
      "Trained batch 1250 batch loss 1.0289104 epoch total loss 1.18229139\n",
      "Trained batch 1251 batch loss 1.01643014 epoch total loss 1.18215883\n",
      "Trained batch 1252 batch loss 1.26353979 epoch total loss 1.18222392\n",
      "Trained batch 1253 batch loss 1.51222253 epoch total loss 1.18248725\n",
      "Trained batch 1254 batch loss 1.46418118 epoch total loss 1.18271196\n",
      "Trained batch 1255 batch loss 1.29169357 epoch total loss 1.18279874\n",
      "Trained batch 1256 batch loss 1.28964019 epoch total loss 1.18288386\n",
      "Trained batch 1257 batch loss 1.42627883 epoch total loss 1.18307745\n",
      "Trained batch 1258 batch loss 1.19074368 epoch total loss 1.18308365\n",
      "Trained batch 1259 batch loss 1.32416987 epoch total loss 1.18319571\n",
      "Trained batch 1260 batch loss 1.26577902 epoch total loss 1.18326128\n",
      "Trained batch 1261 batch loss 1.22130835 epoch total loss 1.18329144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1262 batch loss 1.14214766 epoch total loss 1.18325877\n",
      "Trained batch 1263 batch loss 1.12672365 epoch total loss 1.18321395\n",
      "Trained batch 1264 batch loss 1.16169477 epoch total loss 1.18319702\n",
      "Trained batch 1265 batch loss 1.09761417 epoch total loss 1.18312943\n",
      "Trained batch 1266 batch loss 1.17912722 epoch total loss 1.18312621\n",
      "Trained batch 1267 batch loss 1.10441136 epoch total loss 1.18306398\n",
      "Trained batch 1268 batch loss 1.16056335 epoch total loss 1.18304622\n",
      "Trained batch 1269 batch loss 1.21721601 epoch total loss 1.18307316\n",
      "Trained batch 1270 batch loss 1.17787611 epoch total loss 1.18306899\n",
      "Trained batch 1271 batch loss 1.03963661 epoch total loss 1.18295622\n",
      "Trained batch 1272 batch loss 1.09363699 epoch total loss 1.182886\n",
      "Trained batch 1273 batch loss 1.14365673 epoch total loss 1.18285525\n",
      "Trained batch 1274 batch loss 1.14411604 epoch total loss 1.18282485\n",
      "Trained batch 1275 batch loss 1.16056013 epoch total loss 1.18280733\n",
      "Trained batch 1276 batch loss 1.09224641 epoch total loss 1.1827364\n",
      "Trained batch 1277 batch loss 1.09915674 epoch total loss 1.18267095\n",
      "Trained batch 1278 batch loss 1.16269541 epoch total loss 1.18265533\n",
      "Trained batch 1279 batch loss 1.23144388 epoch total loss 1.18269348\n",
      "Trained batch 1280 batch loss 1.2008338 epoch total loss 1.18270755\n",
      "Trained batch 1281 batch loss 1.22628784 epoch total loss 1.18274164\n",
      "Trained batch 1282 batch loss 1.29496121 epoch total loss 1.18282914\n",
      "Trained batch 1283 batch loss 1.2549634 epoch total loss 1.18288541\n",
      "Trained batch 1284 batch loss 1.17116714 epoch total loss 1.18287623\n",
      "Trained batch 1285 batch loss 1.35462356 epoch total loss 1.18300986\n",
      "Trained batch 1286 batch loss 1.15316296 epoch total loss 1.18298674\n",
      "Trained batch 1287 batch loss 1.20392585 epoch total loss 1.18300307\n",
      "Trained batch 1288 batch loss 1.12343 epoch total loss 1.18295681\n",
      "Trained batch 1289 batch loss 1.28772712 epoch total loss 1.183038\n",
      "Trained batch 1290 batch loss 1.28987026 epoch total loss 1.18312085\n",
      "Trained batch 1291 batch loss 1.232499 epoch total loss 1.18315923\n",
      "Trained batch 1292 batch loss 1.16864467 epoch total loss 1.18314803\n",
      "Trained batch 1293 batch loss 1.22516632 epoch total loss 1.18318057\n",
      "Trained batch 1294 batch loss 1.23746574 epoch total loss 1.18322241\n",
      "Trained batch 1295 batch loss 1.16020322 epoch total loss 1.18320465\n",
      "Trained batch 1296 batch loss 1.21097088 epoch total loss 1.18322599\n",
      "Trained batch 1297 batch loss 1.38276124 epoch total loss 1.18337989\n",
      "Trained batch 1298 batch loss 1.30931842 epoch total loss 1.18347692\n",
      "Trained batch 1299 batch loss 1.20593333 epoch total loss 1.18349421\n",
      "Trained batch 1300 batch loss 1.03533268 epoch total loss 1.18338025\n",
      "Trained batch 1301 batch loss 1.08186531 epoch total loss 1.18330228\n",
      "Trained batch 1302 batch loss 1.23616028 epoch total loss 1.18334281\n",
      "Trained batch 1303 batch loss 1.07189751 epoch total loss 1.18325734\n",
      "Trained batch 1304 batch loss 1.16954744 epoch total loss 1.18324685\n",
      "Trained batch 1305 batch loss 1.26249969 epoch total loss 1.18330753\n",
      "Trained batch 1306 batch loss 1.20351398 epoch total loss 1.18332303\n",
      "Trained batch 1307 batch loss 1.11053371 epoch total loss 1.18326724\n",
      "Trained batch 1308 batch loss 1.19601452 epoch total loss 1.18327701\n",
      "Trained batch 1309 batch loss 1.26336145 epoch total loss 1.18333817\n",
      "Trained batch 1310 batch loss 1.18924057 epoch total loss 1.18334258\n",
      "Trained batch 1311 batch loss 1.05140173 epoch total loss 1.18324196\n",
      "Trained batch 1312 batch loss 1.09883678 epoch total loss 1.18317771\n",
      "Trained batch 1313 batch loss 1.00365674 epoch total loss 1.18304098\n",
      "Trained batch 1314 batch loss 0.99168545 epoch total loss 1.1828953\n",
      "Trained batch 1315 batch loss 0.983441234 epoch total loss 1.18274367\n",
      "Trained batch 1316 batch loss 0.950291753 epoch total loss 1.182567\n",
      "Trained batch 1317 batch loss 1.05516112 epoch total loss 1.18247032\n",
      "Trained batch 1318 batch loss 1.10324037 epoch total loss 1.18241024\n",
      "Trained batch 1319 batch loss 1.14103913 epoch total loss 1.18237877\n",
      "Trained batch 1320 batch loss 1.2003 epoch total loss 1.18239236\n",
      "Trained batch 1321 batch loss 1.15799952 epoch total loss 1.18237388\n",
      "Trained batch 1322 batch loss 1.2338779 epoch total loss 1.18241286\n",
      "Trained batch 1323 batch loss 1.27787399 epoch total loss 1.18248498\n",
      "Trained batch 1324 batch loss 1.12035763 epoch total loss 1.18243802\n",
      "Trained batch 1325 batch loss 1.2192347 epoch total loss 1.18246579\n",
      "Trained batch 1326 batch loss 1.33323395 epoch total loss 1.18257952\n",
      "Trained batch 1327 batch loss 1.29825139 epoch total loss 1.18266666\n",
      "Trained batch 1328 batch loss 1.42887092 epoch total loss 1.18285203\n",
      "Trained batch 1329 batch loss 1.34057844 epoch total loss 1.18297076\n",
      "Trained batch 1330 batch loss 1.28681099 epoch total loss 1.18304884\n",
      "Trained batch 1331 batch loss 1.19612491 epoch total loss 1.18305874\n",
      "Trained batch 1332 batch loss 1.14100993 epoch total loss 1.18302715\n",
      "Trained batch 1333 batch loss 1.26664042 epoch total loss 1.18308985\n",
      "Trained batch 1334 batch loss 1.2713939 epoch total loss 1.18315601\n",
      "Trained batch 1335 batch loss 1.22337198 epoch total loss 1.18318617\n",
      "Trained batch 1336 batch loss 1.29168105 epoch total loss 1.18326724\n",
      "Trained batch 1337 batch loss 1.31530917 epoch total loss 1.18336606\n",
      "Trained batch 1338 batch loss 1.38241053 epoch total loss 1.18351483\n",
      "Trained batch 1339 batch loss 1.352772 epoch total loss 1.1836412\n",
      "Trained batch 1340 batch loss 1.39598894 epoch total loss 1.18379974\n",
      "Trained batch 1341 batch loss 1.27187264 epoch total loss 1.18386543\n",
      "Trained batch 1342 batch loss 1.37606192 epoch total loss 1.1840086\n",
      "Trained batch 1343 batch loss 1.25611222 epoch total loss 1.18406236\n",
      "Trained batch 1344 batch loss 1.3293345 epoch total loss 1.18417037\n",
      "Trained batch 1345 batch loss 1.15970087 epoch total loss 1.18415225\n",
      "Trained batch 1346 batch loss 1.22461569 epoch total loss 1.18418229\n",
      "Trained batch 1347 batch loss 1.0817374 epoch total loss 1.18410623\n",
      "Trained batch 1348 batch loss 1.11166036 epoch total loss 1.18405247\n",
      "Trained batch 1349 batch loss 1.18084311 epoch total loss 1.18405008\n",
      "Trained batch 1350 batch loss 1.21514153 epoch total loss 1.18407309\n",
      "Trained batch 1351 batch loss 1.32552052 epoch total loss 1.18417776\n",
      "Trained batch 1352 batch loss 1.17602289 epoch total loss 1.1841718\n",
      "Trained batch 1353 batch loss 1.3252449 epoch total loss 1.18427598\n",
      "Trained batch 1354 batch loss 1.19788587 epoch total loss 1.184286\n",
      "Trained batch 1355 batch loss 1.11772609 epoch total loss 1.18423688\n",
      "Trained batch 1356 batch loss 1.16169667 epoch total loss 1.18422031\n",
      "Trained batch 1357 batch loss 1.02904797 epoch total loss 1.18410599\n",
      "Trained batch 1358 batch loss 1.0933485 epoch total loss 1.18403912\n",
      "Trained batch 1359 batch loss 1.23923731 epoch total loss 1.18407977\n",
      "Trained batch 1360 batch loss 1.2044282 epoch total loss 1.18409479\n",
      "Trained batch 1361 batch loss 1.32791805 epoch total loss 1.18420041\n",
      "Trained batch 1362 batch loss 1.18487513 epoch total loss 1.18420088\n",
      "Trained batch 1363 batch loss 1.17860115 epoch total loss 1.18419671\n",
      "Trained batch 1364 batch loss 1.19376969 epoch total loss 1.18420374\n",
      "Trained batch 1365 batch loss 1.12479091 epoch total loss 1.18416023\n",
      "Trained batch 1366 batch loss 1.06546831 epoch total loss 1.18407333\n",
      "Trained batch 1367 batch loss 1.10460293 epoch total loss 1.18401515\n",
      "Trained batch 1368 batch loss 1.26067209 epoch total loss 1.18407118\n",
      "Trained batch 1369 batch loss 1.18867707 epoch total loss 1.18407452\n",
      "Trained batch 1370 batch loss 1.06167293 epoch total loss 1.18398523\n",
      "Trained batch 1371 batch loss 1.16410124 epoch total loss 1.18397069\n",
      "Trained batch 1372 batch loss 1.12137139 epoch total loss 1.18392503\n",
      "Trained batch 1373 batch loss 1.27000964 epoch total loss 1.18398774\n",
      "Trained batch 1374 batch loss 1.21373463 epoch total loss 1.18400931\n",
      "Trained batch 1375 batch loss 1.24458098 epoch total loss 1.18405342\n",
      "Trained batch 1376 batch loss 1.23468924 epoch total loss 1.18409026\n",
      "Trained batch 1377 batch loss 1.32657981 epoch total loss 1.18419373\n",
      "Trained batch 1378 batch loss 1.28727841 epoch total loss 1.18426847\n",
      "Trained batch 1379 batch loss 1.29924881 epoch total loss 1.1843518\n",
      "Trained batch 1380 batch loss 1.29953241 epoch total loss 1.18443537\n",
      "Trained batch 1381 batch loss 1.25451183 epoch total loss 1.18448603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1382 batch loss 1.13440371 epoch total loss 1.18444979\n",
      "Trained batch 1383 batch loss 1.126351 epoch total loss 1.18440783\n",
      "Trained batch 1384 batch loss 1.0649637 epoch total loss 1.18432152\n",
      "Trained batch 1385 batch loss 1.05921388 epoch total loss 1.18423116\n",
      "Trained batch 1386 batch loss 1.11934912 epoch total loss 1.18418443\n",
      "Trained batch 1387 batch loss 1.19967914 epoch total loss 1.18419552\n",
      "Trained batch 1388 batch loss 1.12452555 epoch total loss 1.1841526\n",
      "Epoch 5 train loss 1.184152603149414\n",
      "Validated batch 1 batch loss 1.14203215\n",
      "Validated batch 2 batch loss 1.15011108\n",
      "Validated batch 3 batch loss 1.13107514\n",
      "Validated batch 4 batch loss 1.11382675\n",
      "Validated batch 5 batch loss 1.10829258\n",
      "Validated batch 6 batch loss 1.22585416\n",
      "Validated batch 7 batch loss 1.18618989\n",
      "Validated batch 8 batch loss 0.956409276\n",
      "Validated batch 9 batch loss 1.05565155\n",
      "Validated batch 10 batch loss 1.12334275\n",
      "Validated batch 11 batch loss 1.07411766\n",
      "Validated batch 12 batch loss 1.13792\n",
      "Validated batch 13 batch loss 1.15839946\n",
      "Validated batch 14 batch loss 1.1273948\n",
      "Validated batch 15 batch loss 1.27300346\n",
      "Validated batch 16 batch loss 1.22777069\n",
      "Validated batch 17 batch loss 1.16769087\n",
      "Validated batch 18 batch loss 1.27140677\n",
      "Validated batch 19 batch loss 0.973011494\n",
      "Validated batch 20 batch loss 1.09010041\n",
      "Validated batch 21 batch loss 1.04551244\n",
      "Validated batch 22 batch loss 1.18628168\n",
      "Validated batch 23 batch loss 1.29001081\n",
      "Validated batch 24 batch loss 1.20183444\n",
      "Validated batch 25 batch loss 1.08353472\n",
      "Validated batch 26 batch loss 1.18139458\n",
      "Validated batch 27 batch loss 1.08389699\n",
      "Validated batch 28 batch loss 1.16752481\n",
      "Validated batch 29 batch loss 1.21188891\n",
      "Validated batch 30 batch loss 1.16295505\n",
      "Validated batch 31 batch loss 1.29564321\n",
      "Validated batch 32 batch loss 1.22090077\n",
      "Validated batch 33 batch loss 1.13813913\n",
      "Validated batch 34 batch loss 1.21326447\n",
      "Validated batch 35 batch loss 1.28845835\n",
      "Validated batch 36 batch loss 1.26490283\n",
      "Validated batch 37 batch loss 1.27392054\n",
      "Validated batch 38 batch loss 1.2285037\n",
      "Validated batch 39 batch loss 1.27979028\n",
      "Validated batch 40 batch loss 1.25432587\n",
      "Validated batch 41 batch loss 1.11912131\n",
      "Validated batch 42 batch loss 1.21214497\n",
      "Validated batch 43 batch loss 1.25815296\n",
      "Validated batch 44 batch loss 1.19317663\n",
      "Validated batch 45 batch loss 1.1579957\n",
      "Validated batch 46 batch loss 1.157251\n",
      "Validated batch 47 batch loss 1.14802706\n",
      "Validated batch 48 batch loss 1.18594873\n",
      "Validated batch 49 batch loss 1.11523294\n",
      "Validated batch 50 batch loss 1.178321\n",
      "Validated batch 51 batch loss 1.14471436\n",
      "Validated batch 52 batch loss 1.19780803\n",
      "Validated batch 53 batch loss 1.23326802\n",
      "Validated batch 54 batch loss 1.21988344\n",
      "Validated batch 55 batch loss 1.21622443\n",
      "Validated batch 56 batch loss 1.13426387\n",
      "Validated batch 57 batch loss 1.20838404\n",
      "Validated batch 58 batch loss 1.17240965\n",
      "Validated batch 59 batch loss 1.18374538\n",
      "Validated batch 60 batch loss 1.27793121\n",
      "Validated batch 61 batch loss 1.24518609\n",
      "Validated batch 62 batch loss 1.16448057\n",
      "Validated batch 63 batch loss 1.37635946\n",
      "Validated batch 64 batch loss 1.05327356\n",
      "Validated batch 65 batch loss 1.25825584\n",
      "Validated batch 66 batch loss 0.980520368\n",
      "Validated batch 67 batch loss 1.15658903\n",
      "Validated batch 68 batch loss 1.25703502\n",
      "Validated batch 69 batch loss 1.11026168\n",
      "Validated batch 70 batch loss 1.12281203\n",
      "Validated batch 71 batch loss 1.06319594\n",
      "Validated batch 72 batch loss 1.1787765\n",
      "Validated batch 73 batch loss 1.10656917\n",
      "Validated batch 74 batch loss 1.11514163\n",
      "Validated batch 75 batch loss 1.16992569\n",
      "Validated batch 76 batch loss 1.17712474\n",
      "Validated batch 77 batch loss 1.0877701\n",
      "Validated batch 78 batch loss 1.18977046\n",
      "Validated batch 79 batch loss 1.10813\n",
      "Validated batch 80 batch loss 1.18093193\n",
      "Validated batch 81 batch loss 1.17784238\n",
      "Validated batch 82 batch loss 1.12520218\n",
      "Validated batch 83 batch loss 1.13893104\n",
      "Validated batch 84 batch loss 1.20117331\n",
      "Validated batch 85 batch loss 1.13597918\n",
      "Validated batch 86 batch loss 1.33640409\n",
      "Validated batch 87 batch loss 1.18873763\n",
      "Validated batch 88 batch loss 1.09617949\n",
      "Validated batch 89 batch loss 1.25583029\n",
      "Validated batch 90 batch loss 1.17342865\n",
      "Validated batch 91 batch loss 1.08464897\n",
      "Validated batch 92 batch loss 1.17214429\n",
      "Validated batch 93 batch loss 1.28651071\n",
      "Validated batch 94 batch loss 1.19353783\n",
      "Validated batch 95 batch loss 1.12290668\n",
      "Validated batch 96 batch loss 1.15612161\n",
      "Validated batch 97 batch loss 1.08798921\n",
      "Validated batch 98 batch loss 1.18089223\n",
      "Validated batch 99 batch loss 1.19787717\n",
      "Validated batch 100 batch loss 1.11468387\n",
      "Validated batch 101 batch loss 1.13622677\n",
      "Validated batch 102 batch loss 1.17923737\n",
      "Validated batch 103 batch loss 1.18925655\n",
      "Validated batch 104 batch loss 1.27114511\n",
      "Validated batch 105 batch loss 1.1590991\n",
      "Validated batch 106 batch loss 1.09967947\n",
      "Validated batch 107 batch loss 1.1066227\n",
      "Validated batch 108 batch loss 1.21732807\n",
      "Validated batch 109 batch loss 1.13484335\n",
      "Validated batch 110 batch loss 1.20166636\n",
      "Validated batch 111 batch loss 1.20695305\n",
      "Validated batch 112 batch loss 1.36174572\n",
      "Validated batch 113 batch loss 1.30409086\n",
      "Validated batch 114 batch loss 1.17902219\n",
      "Validated batch 115 batch loss 1.08930802\n",
      "Validated batch 116 batch loss 1.12881851\n",
      "Validated batch 117 batch loss 1.20626628\n",
      "Validated batch 118 batch loss 1.14552617\n",
      "Validated batch 119 batch loss 1.17733812\n",
      "Validated batch 120 batch loss 1.24607718\n",
      "Validated batch 121 batch loss 1.32259\n",
      "Validated batch 122 batch loss 1.14463389\n",
      "Validated batch 123 batch loss 1.23288369\n",
      "Validated batch 124 batch loss 1.14975524\n",
      "Validated batch 125 batch loss 1.22166324\n",
      "Validated batch 126 batch loss 1.20421195\n",
      "Validated batch 127 batch loss 1.11736453\n",
      "Validated batch 128 batch loss 1.26525545\n",
      "Validated batch 129 batch loss 1.22234845\n",
      "Validated batch 130 batch loss 1.24303019\n",
      "Validated batch 131 batch loss 1.18666828\n",
      "Validated batch 132 batch loss 1.22390866\n",
      "Validated batch 133 batch loss 1.12526596\n",
      "Validated batch 134 batch loss 1.16045058\n",
      "Validated batch 135 batch loss 1.18980551\n",
      "Validated batch 136 batch loss 1.1303947\n",
      "Validated batch 137 batch loss 1.2087698\n",
      "Validated batch 138 batch loss 1.15823495\n",
      "Validated batch 139 batch loss 1.28106475\n",
      "Validated batch 140 batch loss 1.17596734\n",
      "Validated batch 141 batch loss 1.10764861\n",
      "Validated batch 142 batch loss 1.13083792\n",
      "Validated batch 143 batch loss 1.18141532\n",
      "Validated batch 144 batch loss 1.17603135\n",
      "Validated batch 145 batch loss 1.18209124\n",
      "Validated batch 146 batch loss 1.16522884\n",
      "Validated batch 147 batch loss 1.08696413\n",
      "Validated batch 148 batch loss 1.31539667\n",
      "Validated batch 149 batch loss 1.12902117\n",
      "Validated batch 150 batch loss 1.05327511\n",
      "Validated batch 151 batch loss 1.16563606\n",
      "Validated batch 152 batch loss 1.26597786\n",
      "Validated batch 153 batch loss 1.25636649\n",
      "Validated batch 154 batch loss 1.32055259\n",
      "Validated batch 155 batch loss 1.14179647\n",
      "Validated batch 156 batch loss 1.31805766\n",
      "Validated batch 157 batch loss 1.17713022\n",
      "Validated batch 158 batch loss 1.2960614\n",
      "Validated batch 159 batch loss 1.2350713\n",
      "Validated batch 160 batch loss 0.981563926\n",
      "Validated batch 161 batch loss 1.11587512\n",
      "Validated batch 162 batch loss 1.19677877\n",
      "Validated batch 163 batch loss 1.12495279\n",
      "Validated batch 164 batch loss 1.21664858\n",
      "Validated batch 165 batch loss 1.14109206\n",
      "Validated batch 166 batch loss 1.16160131\n",
      "Validated batch 167 batch loss 1.37170696\n",
      "Validated batch 168 batch loss 1.04502833\n",
      "Validated batch 169 batch loss 1.17042208\n",
      "Validated batch 170 batch loss 1.18070567\n",
      "Validated batch 171 batch loss 1.22082198\n",
      "Validated batch 172 batch loss 1.2122941\n",
      "Validated batch 173 batch loss 1.14882267\n",
      "Validated batch 174 batch loss 0.90342176\n",
      "Validated batch 175 batch loss 1.18546748\n",
      "Validated batch 176 batch loss 1.07863128\n",
      "Validated batch 177 batch loss 1.15150702\n",
      "Validated batch 178 batch loss 1.24002826\n",
      "Validated batch 179 batch loss 1.0516541\n",
      "Validated batch 180 batch loss 1.20071471\n",
      "Validated batch 181 batch loss 1.29927206\n",
      "Validated batch 182 batch loss 1.19814444\n",
      "Validated batch 183 batch loss 1.16942704\n",
      "Validated batch 184 batch loss 1.06536424\n",
      "Validated batch 185 batch loss 1.16716385\n",
      "Epoch 5 val loss 1.1752301454544067\n",
      "Model /aiffel/aiffel/mpii/models1/stacked_hourglass-epoch-5-loss-1.1752.h5 saved.\n"
     ]
    }
   ],
   "source": [
    "train_tfrecords = os.path.join(TFRECORD_PATH, 'train*')\n",
    "val_tfrecords = os.path.join(TFRECORD_PATH, 'val*')\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "num_heatmap = 16\n",
    "learning_rate = 0.0007\n",
    "\n",
    "best_model_file = train('hourglass' ,epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)\n",
    "\n",
    "# 예측 엔진 만들기\n",
    "\n",
    "# WEIGHTS_PATH = os.path.join(PROJECT_PATH, 'models1', 'model-v0.0.1-epoch-2-loss-1.3072.h5')\n",
    "\n",
    "model = StackedHourglassNetwork(IMAGE_SHAPE, 4, 1)\n",
    "# model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "# 이전의 학습하는 코드 블럭을 통해 학습하고 그 모델을 사용할 경우 아래 주석 처리된 코드를 사용하면 됩니다\n",
    "model.load_weights(best_model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671ac628",
   "metadata": {},
   "source": [
    "## 학습에 사용했던 keypoint 들을 사용해야 하기 때문에 필요한 변수를 지정해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d309658b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "R_ANKLE = 0\n",
    "R_KNEE = 1\n",
    "R_HIP = 2\n",
    "L_HIP = 3\n",
    "L_KNEE = 4\n",
    "L_ANKLE = 5\n",
    "PELVIS = 6\n",
    "THORAX = 7\n",
    "UPPER_NECK = 8\n",
    "HEAD_TOP = 9\n",
    "R_WRIST = 10\n",
    "R_ELBOW = 11\n",
    "R_SHOULDER = 12\n",
    "L_SHOULDER = 13\n",
    "L_ELBOW = 14\n",
    "L_WRIST = 15\n",
    "\n",
    "MPII_BONES = [\n",
    "    [R_ANKLE, R_KNEE],\n",
    "    [R_KNEE, R_HIP],\n",
    "    [R_HIP, PELVIS],\n",
    "    [L_HIP, PELVIS],\n",
    "    [L_HIP, L_KNEE],\n",
    "    [L_KNEE, L_ANKLE],\n",
    "    [PELVIS, THORAX],\n",
    "    [THORAX, UPPER_NECK],\n",
    "    [UPPER_NECK, HEAD_TOP],\n",
    "    [R_WRIST, R_ELBOW],\n",
    "    [R_ELBOW, R_SHOULDER],\n",
    "    [THORAX, R_SHOULDER],\n",
    "    [THORAX, L_SHOULDER],\n",
    "    [L_SHOULDER, L_ELBOW],\n",
    "    [L_ELBOW, L_WRIST]\n",
    "]\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eff7bd7",
   "metadata": {},
   "source": [
    "## 모델을 학습할 때 라벨이 되는 좌표를 heatmap으로 바꿨던 것이 기억 나시나요? 학습을 heatmap으로 했기 때문에 모델이 추론해 내놓은 결과도 heatmap입니다. 그래서 이 heatmap으로부터 좌표를 추출해야해요. heatmap중에 최대값을 갖는 지점을 찾아내면 되겠네요. heatmap에서 최대값을 찾는 함수를 만들어 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3232ffdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def find_max_coordinates(heatmaps):\n",
    "    flatten_heatmaps = tf.reshape(heatmaps, (-1, 16))\n",
    "    indices = tf.math.argmax(flatten_heatmaps, axis=0)\n",
    "    y = tf.cast(indices / 64, dtype=tf.int64)\n",
    "    x = indices - 64 * y\n",
    "    return tf.stack([x, y], axis=1).numpy()\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ca5be73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def extract_keypoints_from_heatmap(heatmaps):\n",
    "    max_keypoints = find_max_coordinates(heatmaps)\n",
    "\n",
    "    padded_heatmap = np.pad(heatmaps, [[1,1],[1,1],[0,0]], mode='constant')\n",
    "    adjusted_keypoints = []\n",
    "    for i, keypoint in enumerate(max_keypoints):\n",
    "        max_y = keypoint[1]+1\n",
    "        max_x = keypoint[0]+1\n",
    "        \n",
    "        patch = padded_heatmap[max_y-1:max_y+2, max_x-1:max_x+2, i]\n",
    "        patch[1][1] = 0\n",
    "        \n",
    "        index = np.argmax(patch)\n",
    "        \n",
    "        next_y = index // 3\n",
    "        next_x = index - next_y * 3\n",
    "        delta_y = (next_y - 1) / 4\n",
    "        delta_x = (next_x - 1) / 4\n",
    "        \n",
    "        adjusted_keypoint_x = keypoint[0] + delta_x\n",
    "        adjusted_keypoint_y = keypoint[1] + delta_y\n",
    "        adjusted_keypoints.append((adjusted_keypoint_x, adjusted_keypoint_y))\n",
    "        \n",
    "    adjusted_keypoints = np.clip(adjusted_keypoints, 0, 64)\n",
    "    normalized_keypoints = adjusted_keypoints / 64\n",
    "    return normalized_keypoints\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03385a6",
   "metadata": {},
   "source": [
    "## 모델과 이미지 경로를 입력하면 이미지와 keypoint를 출력하는 함수를 만들어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98d4f230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def predict(model, image_path):\n",
    "    encoded = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(encoded)\n",
    "    inputs = tf.image.resize(image, (256, 256))\n",
    "    inputs = tf.cast(inputs, tf.float32) / 127.5 - 1\n",
    "    inputs = tf.expand_dims(inputs, 0)\n",
    "    outputs = model(inputs, training=False)\n",
    "    if type(outputs) != list:\n",
    "        outputs = [outputs]\n",
    "    heatmap = tf.squeeze(outputs[-1], axis=0).numpy()\n",
    "    kp = extract_keypoints_from_heatmap(heatmap)\n",
    "    return image, kp\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5127f82f",
   "metadata": {},
   "source": [
    "## 이제 그림만 그려주면 완성될 것 같네요. 그림을 그릴 때는 두 가지 그림을 그려볼 겁니다. keypoint들과 뼈대입니다. keypoint들은 관절 역할을 하고 keypoint들을 연결시킨 것이 뼈대가 되겠네요.\n",
    "\n",
    "두 가지 함수를 각각 작성해 줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6556363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def draw_keypoints_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        if index is not None and index != i:\n",
    "            continue\n",
    "        plt.scatter(joint_x, joint_y, s=10, c='red', marker='o')\n",
    "    plt.show()\n",
    "\n",
    "def draw_skeleton_on_image(image, keypoints, index=None):\n",
    "    fig,ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "    joints = []\n",
    "    for i, joint in enumerate(keypoints):\n",
    "        joint_x = joint[0] * image.shape[1]\n",
    "        joint_y = joint[1] * image.shape[0]\n",
    "        joints.append((joint_x, joint_y))\n",
    "    \n",
    "    for bone in MPII_BONES:\n",
    "        joint_1 = joints[bone[0]]\n",
    "        joint_2 = joints[bone[1]]\n",
    "        plt.plot([joint_1[0], joint_2[0]], [joint_1[1], joint_2[1]], linewidth=5, alpha=0.7)\n",
    "    plt.show()\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f92fc2",
   "metadata": {},
   "source": [
    "## 테스트 이미지를 이용해 모델의 성능을 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb668e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAD8CAYAAAD6+lbaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAEAAElEQVR4nOz9W7BlaXLfh/0yv2+tfS5V3dX37unpuQ8wGOJKEBcSJEGaJkXKlMjQhSH5wZKsCDzY8rP45gg/8cEvdjhCYYStMBkOWaTtkMkQGTZNShQpXgxAQ9wxwFx7uqfv1XU95+y91peZfshc+xSA6RmS4Ej9UGtQ6KpTp87ee63vyy/zn///PyUieHw9vh5fj6/H17e+9H/oN/D4enw9vh5fH+brcZB8fD2+Hl+Pr29zPQ6Sj6/H1+Pr8fVtrsdB8vH1+Hp8Pb6+zfU4SD6+Hl+Pr8fXt7keB8nH1+Pr8fX4+jbXdy1IisifFpHfFJEvi8hf/G69zuPr8fX4enx9Ny/5bvAkRaQBvwX8SeB14OeBfzcifv1f+os9vh5fj6/H13fx+m5lkj8OfDkivhoRC/CfA3/uu/Raj6/H1+Pr8fVdu/p36ee+DLz2yJ9fB37ig775xvkczzx9BhEIgAhBEAGGYB54gAPhIAgQiAgqgiCoCk1AJWgKAXg4qznDA3Mnf7oA+fdUEi0IIiD54kQE4U4Qv/17NH9tP8cj8n2EcEzII4iIfBm5fp+CUP93/JkI+Xf12iL13tyJCMz8+H15W+rn1Oc/fq3+Xb68170LvN5LeKACIoqIoqr1cyDq/W0/CxFEND/xb3s9uf581Odme+3I+7Z9sLptx890vIfbh360ehHk+uZx/VEeeX3R7dUIB3ACw8PrEzx65ecm6v1sP1u2T0w9v+OXrx/Goz8lHvm7+J2vcf09/La/id/xU463A7b3/8jDl+NXa23H9bMMIr87op4px3ufS2u7N/Lb1kd+/+94W/yuL1zfD9meXn5LHJ/v9ud8Xsc98sjnCfL7t7t3/Sq1AKJ+sjz6Ir9t+dd9jPon189qe0NR60PykeZ/t+955Iflz7heRzzyPduT3/6/H78ex5ULcPf2vfci4jl+x/XdCpLf8RKRnwF+BuCpJ0/4X/3Mj9Kbsus976k5B4MLlPsH58pgb8K6AK4gSm8TO53pwLwTnj1r3NytNFlovXG1Lrx3ccU7FwcuVmcNZbVGhBAGHoEqNBFUoTdFpRHDMVtZbMWGISE07UwnE22aMDqrBcsYGdDWyM3r0CxvuKsQCo0VnTraG6JKA3oIRGAStF1nbo2TqaEirDEwc2wd7C8uEYWVldZmdv2URsdHLsdgoArzNNF6RzuYD8JXxrqwP6wclpVhgy6Nqc/sTs443Z0y0xAVnAyq0hrTvKNNO7R1pO3oMtNlRqRDKHjgNgDLQCxBF0U1D4xFjBhOOEQTXIOmSguYtNGZM1BIbXw3JKBJ0CRQgknleHioKrvWod/A4gQbwro6KguHcY+9X+AajDCsNom4MXwQLpjloUFA7z0PBxFA8xB1Px5StfMIB/c8WJqAam4l13xPXgeYe9TvM1CjoJIbqgtoCOIZBk3ApWHRWN2JAK3NP4XS+8QSwbCOykTGjJVQI2LF1gO+DoY7Lo6K0Fv+7N472rfw1DATbBhu0FBcAiSfWYYJI3AUyXXTFAmnIUiAubN45Od2ZT0YQzIwN4EmypBguDIsv5+6B66CC0gEunrexxBEGkgWrQGYZiKg5D4Iq3u6Ba2mqAASOAKrox6YOFr3ctBQCxhGuDPGwMNobUtmoMkEoRX4ByoQdFYEbcqkgoUiYWgY/8+//Dde/Vax6rsVJL8JvPLInz9aXzteEfGzwM8CvPzSzViH4WaICE0VsbwxswinGojnQzoorLESrQ4KhdaEnSgRC+YQKqwjWAyChmqjqbCa4JYBmBAExSOQrqhILnxGbuAIaFqbOZ+xBeACqoQ7Eoq5McKICJTc2CqKAoaDbodiEG6Yk0diBIPARYhZEG00d9YIVjdidbRNuK+oKs3B1xXH8SG4DxBnnhvDRr5IBYHoDY9+vZEBpCFtomkGY4/K2kRxt+tMwKmTXJHKOCNyA+EgIRCdpmD5CYGGhTE8YDgejofgHYYbrc5qF0PINN/d8x5WYNmSVSdPfvfAPL8/wvKXK4GxXxesqoxhKx7BimfQc4d6HkHLn/ZIeiciNMnnfszOHslGwnN9hHsGt2PGlN9zDJL1PPMfRB6CTelNmJswS6NH3j8POAD7EDDFre4njm3rwhxBM5aI4CFY5H8DwWmECKggqoTkeyGcHlV9OHjkh1UC8xXEEXUQB9dj5aCSwVQ8mJvShazA8iUQDaQLXSZWah15EJKfxz1yL3lUNqr5PfJoRldZceTBgEcufQssop51/oxj5VYPy4mqMJTwvN8uIG17GEZY4GMQ5lg4slWQ5L2ksnGg7ln+vlfuHiEZqLfF/QHXdytI/jzwWRH5JBkc/x3gf/rt/kGYQ2sQQtNGnxpE0GgEhvjIDSj5IImO0JlEON8pN2VF/cA6BJOJfZ7/DKBJozdonjdjW1CBoq3hrgyUJgNY88FXuadILhyEFopYlqMtjyosHFMjf1rFF3dyCQQjYyodQRxWs1wU9dB1EQxh0U6uZaFHY4QTkqdwj0Bt4L4nuuIx4+FIgLtAtMw+KvCJCxJCR/E2odFordNaRytTWyMXoajiCg1Yh+G+EiF0qeJRNWEP3+5b0LXK3/DMS9zxADHBLXC3zGA8l6g15SCwks8zN4YXDJAZd1AZmAIV2FWUZZ0q+IOEEzHq/pFloCtbVe2R30Pk/d+2ROM6a3T3Y9kb7hmQKvBlQAaozSyZoXkk1pMZZGZI0lrVyKABbpLBpWVmPTXYaa6b4U5YMCKwcMLl+FohlY2R710RXBWl45avayGENjLXtgzaUs9mC06eJW29ZSIcCaero5KB0QWG11qpYGQurOFEk+OBPnXQ3q4hriAzVDI4DvPMIrdMfYOSJOGuLdOO2IJkViwSGRAffTpSD86i7gGC+qPwhiXcRuANdiEoTnPBhuPDjvBWQB46Gwwmg0YD6YjOiNa6ccHNMAbaDBHLQ+QDru9KkIyIISL/EfD/IffffxoRv/bB/wCkSsgxPDeKgnggYzAF7FVoBDvXypBAutEIJhFmHGFhrHC5BguON8VQlJYPQxzEsMgyOXGQKc+cUDwGEUbl5exiW8yBFhji4WgEqg08y54ZIXzQIlDP7w0ckUCl0VE0HHNHXVg9kKZMmhmZADEGgaDh9NZQn7AIRAcRyoJy0ifWcYHIDpEJxLH1imiBh6LRaZHZz9xmwgTpDZnbdSYUgq/QpLOwZJHmndUDmtOm3GneRz46b4UJ50NRcbw26iCx4ghDInAxokWVUJawiGbW5lGlUpV6GywZEhUkFaId76+EZKmllR3KyNeNFZEVwmhRmHQETqvcQQmdMTcsHPcVF6G75hro4F6l55bdDKmcI8EHqWwro15kJuyZtUYkFqqmmVkfF3FmJh5ZvYQK3jJ4uCXOp9HQUIZvAT3vleI0ray3DbpMRHTAsFA4loQB0lDRKuXzQBgWaIC60yRLaheHpjSZ6JrZpDdBXVhGsNa903CGOc39eKBPk+ahLoprpfixZlAyCG+4O2aeWXcFbO8ZxrOw3gBEx8MI+hEfjwhMCx45HkBbkJICBjZMtk5QyaPN6t65B2a5jx3HWt5DkczemzS6QkaNhpN7N4vPrFYTWhmFnV+H5d95fdcwyYj4W8Df+mf8bhSypDzUw5AACxozvc90nFXrZJfM0zTyQR0WZ+3O3BrrurAuKyvCKsEK2HDGMMYYxPC62XbMhghHPPA1U/6mmUVexYGmCTaFBspAAoSBaiA0JpHcFBKIOy3TO9SzdGiaATKBZcssRCSz1doY4YGZ1cnbieiIOn3Kk285BN/78vfxI5/+Yd66c5t/+Ct/HenOcMHtlMUkS6XCVEUcbdC7EMM4Np1aR11qkxo+BrTG3gMxJ1ToEYg0JlsZkRmju+L1WVqrwFQYYm7+qpYfKYu0aX6egFgTq/Sm16U8FWBUNjjwCN4HjopWNpGlNgGhdeJLIBJHzK+JMNfreSTqRggW63VpTOGg5mSOvQXJ/FzuJFRTn0o0n5/W5iSytN5+hss4lnKZfCZu6w7rUNQ1g1JPuOJYOm+nlQraBCwThHCht07XjqhiASMUHdCOB4pm+b/VqQjD7LpxExAx0Bb0Lqh2Go2uK60FIY3FBIvAjAocmd0ZwSCD7GK5X+Z5xkJxZtbVMQt8+/fDGIXXS9uaZPn8rhtnjsSWWfoxYwdo1RM4Nop8u5eVCeq2Jhwss9LY8Gq26iGfkajSuuThUSFapbKPakSG58G7ldZmwRgDuiS0EI9gMr/j+h+scfPopQJzeBZGopmRiRDaCe+MoYQIwwZ7Mw4BCUtnan5YjTtj4bQBzFg4BwsO4SyRZaMNYSyPPCiRPAHDWZclwfTQLOciM62mRusUxphNHm2BMMg6q+45gkueYorhw9EQem0w3dqNDdzGsREUYQzPE02MOvmFXW8EKy3gmSc+wo98/0/zPeefp10c+PyPfp6H99/l1177eQ5+H50mlug0F7B8zbl3VGDqCjEwy03oAWZ5Dw5iTB7YWFmbMjm4A61lKRRB2CDqEOCIF2XgjMhAoiIQmplMKEP82CX3NYNbwqXXXWypL4pWjRZSi/mRzir571prZDHSCAKzJUtJEVqfszQX6JpZx7DMbFUaXSNLKQrb2p6H5KaQag7AhulKBSkI9WzWEBk9MVSScZAY24KEVDAXkLxX7oI5LCh2zJid4Y1RQXTLZkS9mASABYoxUa8fQZ+VOTrDB8O3Tqxghd2LCiGdam8ARuud0MIAReiq9KZMHcwDc6EV+Ojb85DG8LxPEqAj98hwK5KgsqzZCHOHdTXMguOjiiqTq/mSlYNVlpzMjy1IOgnx9OO+ieN75VgqJ/4flW1nbhTYiHqGHA/+aIJ0ofVrlsnGEHA0+xtSJb05ESsamZi4G2M4vfe8Jx9wfTiCJHCqhvbOkMzCmkwM8uTbE+ybsIRw8GAJMDN6bUB346orh6E0gsWNvcHenIM77hDDWDx/wfVC3ShE24PtFTjVHaThliWjap7yrfXEqwgiBmxlS3XIIyiML8H7EE/Mqg4q7UGrjTJwzANGYmDMHZ8MiT03Tm7yo5/8CX7ie3+a8eCKN77y85wO4cknfpQ/9SP/Op/62Kf4m//4b3Dpe9aAqQ1mhRgnhMA6Eif0AWZRuA6oV+YqA28NN88uYS3UsMJ5ZGRDq2VmF5KL3yo7QILFIvGz6GgFumia98EDpgL8s+OFkA0yUTKTEkVlyq8jqDhbmyJCs0yyLYAqSDvSpVTbMSt1BuhAaYkVY6gMVBrmhjNy0xGZQ0ZSxrQaJWZeAd8RzUZZYrVbeeh4y8Vmlg3EDduUjbaTOz0DeWXqjAwqGyYXsh7pVa1lztNbMPVcLy2ciYFLYuQWebBq12RceGWxG4aqivW6P2TQdzSrGRFEJ0Y46jCJ0jq0UHooDcH9keAlep3lxaCFgjXCO2bBOmAMxwaM2BotldVpHu5SXzEpyMYzo6RyhGpZJw57pIYpWmX4dkUEujU4gQ3XaJr3WSUZKaHtyCJRcVrLZqVqdbSl3ouPwsozMJoVpcir/I7cFx90fSiCpCjMRZNRCcw1I82oLppCFbm4NFqVdWbOgWCNFTdh6IyY05rgmvzK1Z1lsQJ1s+XftDH1ljeHBLQDo3nQNwgmRjZFpDpjTZDWUNX8fs/TqUWVz0I+QBfYGidbJxIINyKyjOwtcb7YOmrSUZ3w5tCMs/YUf+KH/yd8/tnPcfnqGyzxHh954Sl0Ffb7PV0aH3/y0/ybf+zf5ue/8jc4f+J1nnrywBtvnfLFrzzP4jMtoFWZY5YBo7eWzTFJSGEIuHYwS7hAsjuuXsd49tLZOHURK3vbZ/krAr1lwIkZiaT3ZNYtSEs4A+rkiMxI/dgpD6RtYH910bcAVsyBkEYwIbTaMELXiULdEsfSOGaqG/8zvEg+1RCJChxNJPPgSCpLk2wiTb0XLanoMfVfO2JldsTQmmaQO3L7hCwDi9XQQgmD1Q03z6bLMfN2mjrSK2sOI0yZ58x6p2h0BAvQalaYJJ2suC/HZ3TkUK6OdK2us2aAlsyoevjx4LbF6K0OG80mpEU2DR05NqlytXaGC0arA65OfmuVPGy9YEGaFg0yuZRK9gxyk8TxPuXPzv0UktW1av2mArxtfYIKrFpZdrJAYKpEJAsQyUO/4AkRQ1tDWv08d0zyoHGzLNmH1QGT90/a7+aafqvrQxEkQRgyMeuO1pM+I5Hg9BpBdyVW6nTt2BgMy+zAp8xc1MEEeusgddoiiHbQ62wKb6CdpnMuonCcxHEQqQ44mAZr7fGEQrIn57EBvnX6VWfNSfqIjAA3Go603MC+kc09QfhqDVS5R3XYg5M289T5U/yZH/szfPTsJe69+pucjodM/ZJf/gd/l1mf4GPf+6d5cLii3XyfuPl3+cM/sGOJW7x99z2ee2bPL/7mJeHOCcKpQlNDWp7CrSkyNZCG+e6YIZqPolA0Wmu0nv/N0rtoLwzMrxjjkjGyA96miWmqRcqUi/76ltAkg49FAf5RgVEL8wNUGtoMCmAPJ5sw2gnp+fsoXMMTN91K75DkZmV2mhvJONazRMu1JaGoZAaSVK3aXJHZ68bzO8oEZEuApOAJK/AOVLM9FNETR67Gk3ZDNZsH4Zr3rZgUoyC3HjOKEhbH7CckWA06gfshqW0tOR3NjBUrVmpeXrjoBvMglXvXRjessNnALSpr1kwAIrFrizwAzAs3lry/YhWkpDG27E+A4l0GQqgi5CG7BazYfgUJJXlyLDOSRjEPHiHBV/msshEEtv9t0WDbbRl4j9QnkVo/1dlFkGhkm6kXqlrPOLLCtMh9H2OAJfS0BUWVoNWxYPrfPwXon+uKEPY+4+2MNs9J6AYOPrjylTUE0ywFQ4UlVpYonlU4p62jDVoXTvpEuNGWQSPJztEEj5EPSvO8o07k5k7DUbHckJ6lV2uKtY62huqUp5rnw7Pqrh+BfCmKbj3ltnW2q5x2V8yzASLVkJCtPNeOi3HSJ148f4k//9N/nif2wsU3v8z7b34RPdzmvXff4re+8It8/OMf5++/8Ze5WhfMLvncH73LM7ducPb8C2gETY2nb13y3nuOTI3WlHlWpp5Ecp0appVBxGlyLbGEFMhMWbSh00TvJ6j0xK1swf0KswO2LqzLBe7BbKd0TpHZMtAlmJfPlCrFSLjDV8djoJGHWjavBCn+QbRr5c+iWSohyuQbETk3kRfXTkTzYEpoODE0ScqXSx5wSW7OrnaBBsfDE0BxJIxeOOqx4x5JJVmLpBxjgF8fdlHB0iQyK2vC1JMQH5qNJXWuKWHVVQ0GHj1pS4fAW6QAwFaidQZrwjdFAu6FZ4c7q0VRgja6EgXxKGOjYcsjip0IlnDC2hFampomyw6O8AP1d8kkyEhnlfHJFvla7jWr7FUiSnwRgGEtD4WwQAq6EerARKo0l+OqoDL6ZJhEZZxHWBJqfyDZrFFa/Z58j9qBVg0dJaKyWcun7BSXdVihIPX83StYX/NRpQLmhs9+q+tDEyRXOWXICV1Ps6EFLDgLg0VWhliC/82QnriYVgrfRDjpjZNZ2LXAV7CujDBGOJNCTI3WtfhbgWPZfpE8OZHEVbIkA1riOKq9grYyQhCDUeW+1mkIHAm6KSlUTIThgrZUL2hsJWIVJprlRtsptIkbeoMf+8wP0967zTtvfIXY36VdvsvrX/t1vvT2W7x3z3n7l7/EnfWS1ox5J7zwmad58tkbvHf/Haw6wK88d+D++zt2PTg5gfNTuLHrnJ+eINOOJWC/Bgef2R/AXYk+ofQse0WRPiHTTLgibsAetwVbFvbLwmGsCM7kjWCXjYJmiG+lYHYZo9LKwHFPepVbclS31/IC1F1adrqbVj4gtGiITEXtyIxOY8lFLZmxDx+MygYXg7XW1LAi+ZPgf1RACxXECjLJXBErbIrCayMCCzgMT4GDJ5a5kfW3EKs9mwaTCCeaCqNt43kFANFsaBVMh/Zg7rkehieRfKxw8M7UJ5QZkR0aygT0OLD3xCMTqmjHZhii9PoURdmkaaOR0NLAWT3XJB6EAZpZ7LU0NPJgk/yVlbEfaTH5Wbc+PkeWBiLQKuEoKCIk4QGjCOf176ISkiOgLFl8u9vx0HnUaCdIil00zXK+9rhV0guppBFZj+8uNkgnJNkNnqU1mkyKVmCApK65YKKE8jSC/sGJ5IcjSIKwysR+DVQGFkuddsowZ2UkERcDMaZJEcnu8MnUaGLM2jjr0CN1IEOCBUuMsStNYQlnHc4Yxd2KUtFor1LAj5Im1VTxSJtAJpwkoPqxCRJ0iWssbOvO4VgoZgmMT8Hx7zxKfSKOSGZ6rTnaTvnEC5/mladfYv/6V3n/7d/krW/8Bqfa0VX56LMv8LFXzrDDytXB+a3b36Q9ecY3l1Oe6Zn1WG3eF59d+OqrcDI3djvl5tmOp2+ccz7P6DSzMHEw5eHBeCjOMiDo9HZyPPll6sWBzKaFxYqHY24sPuq+BsaCx0Kw5okuqa3JQNLB18rKSYaMVybmkd2PysyyI5pKnSTJNlLE2JPjqolVi4KaJ3eSlOj1bqDOiMBHBjdzz1K4Ms089bJ0g6Sw4Fak/+37klIUI1LJQTYobFR2pHEsLb2yttaUPmWQnFvHxKsqF2hrBoiir0gknt27cDJlQjSsM9wIEw6LYKNhbWLqEyaJ3+Z9WYFBforK1CXxvAjPZKElPWtqyXAwQIsdZFBc18GwILRUbZIYYp701xxGka2Y3fK/VHchlgFJkqJn0unaUB8VJIWhMLQkiSJ130leYv0pn3fSoiIkcd+CQYgo3FSzB9BSftAyJac+fNKhetbrjuHDUM/7ZWFFTvdr3qbHBtJAHYriEJrrtV3H6N91fSiCpEvwMIS9D+RgrL5mOWtbhy8lYhYgOjOp0yZDWBGx3IiTZFnpwWLOZMG8Ad7SEnMLwVsxOobnqQzZPCtKkG2bUWOTiBcmmVhSakSpDJHC7zoJgjmBsko2S9IYoCGeKoGpTUgEQwTvSQ6fWuO8n/HZ5z7GHBN69jTWlDfvvsHDywPOxJlOtPMZPT9lzBMnn3yZh7tTvhET3zPu0JtlySnJj3vxeefyotNbapbnecfJbqI3OBNhiYldb5z3zn4JPBotZlaEg8ASGRg0jOELB9uzjwOrX3LwhxzWPRHClQ9kUtpIvqfrlM2hyOzEC5xsTWBu+FC8cK+uPaGH48FijLGgkwI9ydWVYbgvhCwgV8CKJBM7lT/SMQYSI8tn5zpQbaWbOyEjm4BVDWypl2lGhLBAR4AVhy7KFCWCFsIIaFHqoGyv0hUmgXnSwuSSnuMC9Ao0EZkR05BJmHvjRDLr7ChDhcUFN2WhMXxiZSJ6ViJLtIQMKFghQxaQ67S4GQkbtEZrQmuZUfZVaG4stFr3IzHbUMQzeNjWsCl4KMSJR5tTAC2KRpMqKZGSmRb1aFLwUDwaYKCGVwmOJ7dVKlhFZZnh10E5Io6ZsADSFemNpp1WEt/M0BNu2TatiRA6kp9bwU/NC96og62+38NKNWZEQTxiStM8FHwrCb/F9aEIkibCZRHExzI4HFaWYYyRDYepUzcI9EgX2UphQcSwJlxh2NSqy5fgdtK8gnClWRLQm1fHUa7T/M1FRPWao+UJphWxuLMCQ/IEakWjSNg4s53wzGBlk7O54SLHh6bUwmn12j2bFU+ePc1z58+wv32Pw8U93nrrTW6c3IRnX+CbvnB3FUwnrJ0QbUdvDdEJX52335r56MtXBFRGq7z03J4vP7jJssLlIXi4DE52E6d9ZpLOLhJaOFFlzNV3dGN1Ye/Kg8W59MHBD9hYWJfBhe1Zl0tsPbCuC2bCfgQLDZMTTk92TNOCRHLwshzcSL3JVXMtOlBEltuaB1NU0BMJsJESStFs2By19Aseezpeh1bRQI5YsTBJZ/WRON5whlnSQSSKwpSdzSgS+uagFBb5M4LMRkdtwE07ItQaSOqRlhInO9TJH1w1KTGrlEyutMitJR4d1UhxYJrmzNCSaJBeA6KY7DKb9E3hY5iRzb5oiWlWV3d7T6pb5p5CCdPUW88nM6ZgMojVQHrGrw38o4KSgMRIiapkqEpKlR4J3psKiUfw96wInIVUvOX/UtviBW1sGR+UwqiecxTnM+pNHOWKKlDNQy0mCWwQCGxa/CjmxTyKARCBmzPsQDPPJhUQmhCORUopzfPwj0jIQdAk9Geq+YHx6UMRJEvLgvnK5WFh2RtX62AxZ6fCrmmVwcqk5KbTDXTNgHcYlnxBM9Sy2+eb0YSCaM8Td2RTBa0zuLKFowtJZRBE0GTOh1lE2zwplZAU5nWkSqLCvaBSz8Q9IrLsm8Ry00vDJU+u2Hh+0fj0K58h9gu+PODhvTeQ9YqXX/4Yb8wnsFwwRmALxAIaUp3aFbrx6t3OR1+55moiwlO3DqDGxaIsLOwjO6S97bixa6jAaThzWJZpXRkajBFcmeBtZb28YvE9bis2DhyWA4fLK2I9sLilAKUl4VrnHfQZWpqJbEZsrWcXUqqKjhZVItbGCDkaKmg1TlKeWUYnmdskYbt4I0M2Mn4FuiqhQauhIUcOHJakaqlmqBbXku2ALPxZgKPyQ1sBftXMoVgILY74Fp4Bt/dkKhzMoRemGlLvWRBtCIpLcQ4jStmj9N7YlFemikljmKT5RaWN7l7vY4tZm4RRS7qZhG0kA7KTDZ6schUs2QGZofkRc889V5dA6qMHYSmSkOjJzKhvGmEJc5glJWlb7+EMzY53l3Z01AqN1KvXcwtJipFeA5sJg2yApHuVu0q0zZCmZSMxONLnVmfDbQgWum1C0sJEI44BvUhSjzBRsrK45oYmDtNaKobaByeSH44gCdmuP6wHDiO1pIsbi6XsqUSLdE3MoUUpdeuhgGIjg9ISzhz9GgdqinbFdWKopbbaC9cJMoMozmOm4pSbSqJV2tqxvKBKlEEZRHiWViaSsr5K58cwzAZuA7WgNaO1KYMBWxYr+Bicnj7FJ1/5FMvr76PTwoPLt7nx5Ck8+QR3Hiwgp0y2QARrW7Dm9OmE3TzTVLi6GCzLntMT3xIEArj11CWvvnmGhLOIM80LJ/OCiXK+mzjtimE0cXZz0HrHF+fKUoWz7wt7PRCxMMYeP6z41cDWtM4KoEnJdGwQtjB8onunSQbK8F4bVMpg45r+EduJXkEoRRGW2YdZYkWlQBKxXNzmrJIwRgtJuzfXlNR5sIw0Qxjrio2R5Xrx4khcP5sRcd1E2BQxUU01NKWElIQwvy3VHap6lNmpKFhyE6UJnk4q2awoCeKmPzcr3m8IhzG4byudpD+t0dhbZ9CSr2qOqOXPk5Ha81gJBuFZaHepstY3k5OBSVn6GckZjsQUPTp4O0pmowJEQLpcEQzydSgNfrfAe6fsCjDN5lUdRUDyOLXwZIvs6M9MtKJduRZUUnvHNhchz4zO6jlv3fCGIj150BtvlohySfLrQ4wy+YiVxTaucXJjpaSImwmOPwK55DmpeON4mEbAGEGfHjk0vsX1oQiSiR+srOEsw1jMOYz0VcQFs2DadXwIw1d2TdCpE56ZnWrjwGBxSclR5AbWIs82b0jvTF2ZpjRrMDNwS6UIglvRAwK0sEMjgeFWROGQLBlMQEJTD+5G97Q5C1ty0ZljJuBzyZ8iy456QE13rLEiMvPKy9+DP3CawbK/ZP/wkqf7U3xlNe5bNouWLIAQnZgVznpnnqajE9C77+/4xMtXbPwygOeevuCrr3VEOiM6q6cX4+FguAt7WmVkK7GDG81oLanb02TM3Wl9EH5FLHtkSXuygaKx0qYy73WwdbAeDpl1NdApkN7pnIB2Qqdqkm3KpA3jyk3ZSPJvxAB6ZR4kpkTQCYyBy2AwiiaSzbEQx1TZ0zhEYLEk3YviP1ZA1GhFThbQksBWmZYVQBHmcaxrBv+MNEkho/h/Ud3a0jsLjmrLoFBuSBaZmQianMkhJQsVxIWLENplrk8QxnCGJSQhWnZ4DsGKef5yH2UdJ2jpyJOLnZxgcweVVKxNygkKsrICYXVIhELxPl0cp6UzUCyELYhV80qcgR+FELpGYpxN2HmaU6QRrnAIOJCfu+HsmjD1zWIw4Q43R5PbUQR92TKRonClcmarCY6n/SM+kxZly1deCynkcNYKnS0KJxXFBAhJ702CFtm4Gr4xK3rt5+RdD/eKA9/6+lAEySDytIxrxn2Tns2RKpfMkhA6k9nHSsrImm7Ug+yOhiRuiKQNlIUy6w71UtrMjSUOGEXqtjqtS66YbygDTUu9EimicYyUsy0USdcLpxlrEtVtVGLl2MhFIh32HWYfnK0N6WmvJtI5aTf5se/7cfzt++x68MbtN7h544xJhfcv3uXSB0NIV6AkA6aRw7qm5Zakqub2+yd88uWrrYYF4NaNlSfPnX2kbldbdjVHqVpiXapAO7CPPYvP7LRnl5iFrTZJz8SoYA9Cks3nLkXJ6owwLtdLFhtMbWXs9pzsOme7W/R2VrSU+bpzKltF29LgwSJ11mjhzlJdyTS+nURTJBA9A+zGdY1UYyyWpVj12TOLENj62VpdTKgGnaeP47ERoAVVaJQBbJHcdas4ckHlBk+gO2TDNDUhnyxGqjkUiUBHGjxvXPTN+iwsaGJIy46xxdYgGhAdZzDqWboPkrsTx2cybFNvkc+8cMrkCWYAMBGipaons3CDwh43xYuNkcKHWMsxKSs2aY1mWSE0nJnOXPhxsuXqOPHMJNdI27eucKrBpLCbG1cKV8MSrw1jkTRXGaOaULpJFL04umnRJ9u+2rJIr8BYMIJ4VorDE5opKUdKRP2Rsr6OPYRaM5lUYcVCcGgt9ezL+mEPkh4cDgtjFFZcciqiTohwfCTNZASEOfOuMYceswBVpxU3aolH3Y/zpO1xXUaLKL0aNEMSO3Hx6ngmDpRUgUj6yabcqP+1uvcZiJ3VlnRIXpcSbwhYgcljoCcN71IM/8KsTPncK9/Pi/OzPJCHvHfnLdb1kidOTvG58f6Dt1PdIyOljEUbOWm9sNB0DhLg4aVycdU5Pxts4xRE4KMvrnzz9vkR/zqE5UYEpnZNzj4sB277ytwmVnMeLgvLyIXdJO3gVGAqWkYC/H6EJmyshF8hMaN6YPUTTHdov8l531pt6UqTeGwFEqmOp+cB16VtxkhJ62CU2gYg0JaVgkRWDyFSbtlZtmWcK2OK0OMG2/TJGdQKs6omTFMpPmUGPBU5ej4m1pVJ5YY5B3oksqeTkGTZTWGsJPVLqlmzwW6Q5Xp4HqAOSbNoSX5OJ5oZib5tCogsgQkjfCBlJmxjpGEupH9l06M0UqRz7QQutZyz9I/K4lLX7BtAd8T8snVRWL5UZ14bk2bw2c0TR6/IbQUUzhmRnOAmxk6DXRPmLuxWOAxjsRUxZQ3Fvb6/GmBJL0mvUyGDZGDXunKPslsjIYzItWkFD2htuTjmotuhUrcSUilU64KCAoDsxMcM44ND4YciSLrDsodN7dt6doTXdWARzCjujTUSCzQPpHnJqqZSbqw0bxDpUrxWeRI22I8DzZTWJ5p0OjkyYHW/Fu9beuvJNYyR9lVA86RHexhNGmiddlhRVwIZ+VphSS/gCBAP5n0QpxMP1bHlwK4JT+3O+aM/8keI+3vksGccHnLz/Jxmzjg/4Spy5EGrDquK0zOiJE0DJ8TydFfl9p0TbpxfABVTgOefueLtu0/SWydc2Y8VmaBhDHG6KrNkhnO1Di4Pg70JlyMQS0yv98Y8Tey64COO5ZCLsIjhNoixEBywWNB2grSJyRurT8CEhBZyVOVuVJm4OboHbJ6TmaU4qpE+mV5iM8nGSY9dst9UEW3AoGljrmqklZzUEIiikhX+lA7sJbmM2lRbI2c7RC1La/HMKo8E6Oqq+nZ4btmbR1GMenV0qWpoIzjnaorIEhr3LD8rA8Udryx6Ta5AGS6kb2X4SOqOLbiVcW1U8A7IOiwqwDdkKulnZC6+MSrC4+iInkhGQkuOskbDPJs2Wqy4QLFIBkmO4djaY7lPraAF1+I5EgzKDyAM/MCsym4nrCpcrBngxlDMND1VJUneOIV5Jnzh1THyuLZY89gMNco1hJEy5NDCmHvSs2QL9vX9dZ+ijDCwpAwKdY7gJA528oHx6UMRJM2dy4OlP2R4YlJRAqOW2SQ28JHGB9qS+rO6p/6aTjPFrfSgvhzxrmWs2Y1bQfueNk10OrhmwJWG4ay+pgtL43jTO1qzcLIELJQoFwabFCr1u2bj2pTA1yMfsEmdiuuKrKRTSbvi85//kzx/4xku3n+VGAfOTs+5XO9zctq5vHnOjsbogepUIHbaua2egRlNfmmblF1v3H1wzsfl4gi2A5yeGDdOV9Y4xXGGrYzVWdTyxJepSrbGYOEwgoMrexemSA18a8bJTnnCTwiC/YYTBUQ0TMuKbTQCQdVQUU6mJ5imM1rb0XROSZ9kFiFbdWBVxoclj400eUCFxdZUSpE6+sCZmDAtHuLG1St9uLRBi4RXosT8giRmWllfbpiR3VvRo9kB1ZxBkuN+rahSCM1xGFueIpklbtkfJTwQt8L4JP9NbPCNF2Mi3b0lPNVDheNl66RhIQhLNqw8iJEYohVWfnT33kpeqM554qHagOYEjb5hunVAbHhk0HBd65DNmlvzTYAEkyWUtd1taR0TGC2t+MbIpuXBlQ1ltBGENawHbawJz5wEk45s3oWi88TKyn6VgjGSXyqaFVFo1ldUo7bVwZXjMypAHjmaKfkUE4aOKsMTxgo2hkJ9bisfd5U6fBNzro5tZtZ0upbD0AdcH4og6QGHNa3PBtXLDtiRkq6WbAZ6Pm0EZ41sQGApY/OxViZSG4EElwnHxpr0G8sSFd2h0qE6kCpJKZm8sZMcCBbSyQZp4lfUwzJJpYA1obsQ0ZLIS3Y8zYRluQJfcrCYd7RpceTSBGEnN/lDP/JTHO5cgC0IK1MHt5Vbz7/Eejqlfb6PmoljKc4fK3gUT5J8+D0zkmU0HlzuuHl6OKaSgvDsrSvefP+JYzdvNedyXRnNsaacSNJUxBu+LizuDGlJzO2Nk36SyZYKK0osg/1hTyxLyjZ7jogI3dHaxDztON/dYNdP2PUdrU+ITGgIo2y+YMPmJaVplSlsDj0SAzfngryvEg2PSMMM3TIz2NIil0hOYP1Kb4XS0ihsYyTydSUd4ouIDVszabMKiyPWl9BFZp0bVWhz+TeSR2hSRGz1chKSwhILA63MUgqbSLOMzWXIcg1pw3XQJKGYVFnKMYgHkvzBoq2FZbAQaUd6zZaYSuTfG5ZQiEPOBkqcNWQkNacWSSMwUSL6se0XkuopbT2xvDUNLxYVrsSyq2yVotVsHpNgscHDGDjCya6lI7pE8jmnXlhuqoOkQs9xGmRsvWsKitnQr+tsUihObWWem9lzlSJHZdUmUEDLVWp7DpULS8vOt0sgmpVO/Pc9vuGf+wpYLKk4ErD2chiJ9PXrrdLy1o8Yi0tUcFzYL1meIJ5lgSatJAK6pKu2j0HBEZisdXf78SZO0tip0MUQyxMsnaDJND6CnQsdYRSBOFzyPVbXEZLKMMlEsNJ8oKV/NhLsD5wf/N4f46NPv8z6zbdys/Zg3e9pU+fZ517inYu7LGOwujE20DpqUFrAFMo0dbooO53SGVqF2/fOuHl2YLNkCYKnnrjijfeqbLV0ak+D38G5CTdall6+Cqt33FP7Gp5KkqnPaO+gE2t0BnuWZdmKlHS/7hNNZ6b5lN5POdndYJYTJs1Ji3YkZTdU7RH1Q/HYoGCOJEerrATK6tWdtFTK0Ir4nV5ouXDa9b9dIxixZV650ayGXG08OgqP2/CrTQGS8FpDm9CrInDkGHQ2K7GqdAuD3KBpQaf8FxDVeCj8Cyn6T5XOMQoDzPWah+zWUlAy88xFJ2XkjCTXsnpLGUiLDJ1BzXK9DgcMEyu4oeNJq7728ZTM+DeBQ3KGp9qHI/FiyaCs5df4UDrNoVugRlZTQcIOztGMOE1tjYcW7A5w0p1pEnR4DubzngFYM0gdWyk1tiMZCbmvbEOAj7BCdqgjIml1Jqi24oQWfGM1BVMyOEdpz7f4F5qCC62+hBR5vQDND7x+T0FSRL4OPCCR0hERf0BEngb+KvAJ4OvAX4iIO9/u5wTC6ooPo1sCs/Syt2/Fio8cFGXbeJJwwjV9+4aDQdNB07ToyoyyTqij3tqTl1ULb/MT1EhcL+vyDHZJRuVIOnYkJV0OmFdmkQ9htSz7Bmvqv6UVgG6IjHoNTxsy7fzxn/zTsIK27PiZpK58d+Mmu5Ob8OA+to7C6dL+SnG0J+UmmtJ2PW3lyjrfCN67f8LHX9xotPn/exucTA+5WG5CT7qJl/rkqgWXc44T9ZFE5q051hpp0OGK6o5pEqYp6N0SMqhO0jR3Tucz5naK9BN6O2c3n3Myn9GlZ5lNIJZZQGZw1VCxfPp57hcJGkN94Jr68XBjihqeZhlEKF5eyHW5q6L1Mw3M6VXem2yuOXL8+6jQlrV8ZkKtC63l2N8OjArE4nqEA5zKckjD5GtThrxPGzaXDkAVzEMI08JfR9JvIlVEEsljTGFIVIa5jX4F2DZy4q/Ve6ZpNWSCXJXB8cDZZvCEJEdAZQWy200ZB0c1dDarslXANhmoljqnDo8o7NYFvHiuLS2wMtvTLXPOz7qvhpkt2f2eHVgKr/SWE0vr2WxikGMg3G4ZedgRwXzkJm/2b57Nfs+v9SLZW9HhqIYgrTBur9EZPd+rVpDtJGKbAwH0SLL/Vte/jEzyj0fEe4/8+S8Cfzci/pKI/MX683/8nX6IW7pemxin0eheOEuQOFbhS1SzxYkiMMO6BDIUaUZrOZmwtSBsUCKuPO1NElRpUSNJSsFQWafIcV0n/060FkqullG4ZAR16iXutMkYE9w/5AIMzfJoImdwaHZiX3npFT750c/A23cxP7BfrzisB2Y6J/MJ+2Xl6mrPYb+weJ3qbdB6Y5qUSZVTFaY55+qs1dl1CQ4o79+feObmQjWECeDWEw94//WOqTIKr5EQVh34SA/NMbK0DBTRzogNJ+u1lIpCJRNdJ7wN5tY4bWeczuf03Qn0M+CMNk1ENIYDS5oXlyItp/eRPD8Xx6WChpfeNsp/cQSMwYiVhcQwBb+m3AjQjG3YmkgOO3MzGEuNGvCihRRetZG7A/B0oVc8DZWjmnH+CKgbKdEz9ZqXXVmeAHh1kQvD86QdCbksslTO+0Z0wp0WQfOcGDksuX/ma5kJyHVKXQectjy8tU+Earp1s0EHkQa4HvmClU1h2dgQadDWatwUqSrSFDo5qzW5sdLixG4ForERualDuo3Umq/kx5GStaY5jOca9aBLK4gjZcFGqW0QlsVZzFk8y3ht6V9kFXA9tuy7gp5lE9U2vlIdAhnKvJI/Z18HYJpdFybZpEYnR2no0yRjSMaPLL8TAotwXNaqAr719d0ot/8c8Mfq938Z+Ht8hyAZ4YivlR4nsdsE8FTMjJqYlg4vwvAyH7BSWhyMafWaSyIExkHiOPReWmaDab66OVhDLvSgaQVoKgCXO4lEjnHY5jAfoLKQDLsbjaV2Z3bCSeJzlqFJedE2pRBfhB/+gT9I84mri/vsL+9xuHrIur+iu3BjPiXGYH/1AGePFz1pbjO71plFmFtjFqrbXo82ksqDwO075zxzc6G+TABPPXHFYb3JQmBaBPtoWY4e8mQFz7JLZqbWmSQIDRY70FvOLEd2zNOBs1nYycTcZ07nU05257STU4aeYHGKtDSIGPvlyMbw4hW6Ol28VBHXFmp5T7OJ5w62rMTBGTZyc4rQe2aioEccMAOmlUVXlvBauFVSX8hTLxdavk6Rr0eBWpvx6makvCmstgy9vJKT00ne++ys9yyFY+TBmABgukUVs6FJjZSog91W4zjRjxxLG+H4ArSaalmSxq3iES05pXJ8X8fnW83O9FBMcwetJhTirJ6BurcpNe21Zyy85s/Xt0pmhpSz+iZxBWXIWiV6OpoPlcLwqolS+1alMyoTjFgSSpeNapa/okYOt1DQQLaMncSLfWvQCkmhq4y5bktWBHmOcGzFVHDVDTbZft8hpvy5ujml10KrpDOdksSOufu3un6vQTKAvy3p6PB/jIifBV6IiDfr798CXvhW/1BEfgb4GYCTs5nOmooEKg0nMzi3a8gg02o9lj05ID1P0xBjrRJOMbokKZaSYukmzjwSkSNlXmXoSqSTiq9JlbAiqGuxhC1yMNK1USgESYDNwbWlHrF0QQHFw9lJT8rB1OjTKT/4+Z9kf/tdLh/eYSwX+HKFr+nVuHv2jLPTJ7i8WGrKHWhvnM8TvWnhN0maZjWODh6ihCXd487dM8ZH76KPGAmoBjdvXPHmvSkTj+rcqytjtZo6CENX+gRdGybPcHno9OkmJ/1pTs6ukPV1Ft9zw8+RPpjmzm63Y7c7ofVTDpyxxMxgZVggq6dTuyUtwxVGd0Ynwfvi2PmWjcGR5EvBI15Sw1Q7QfQNS9vwwHRPzynKW0d5ZsNKklc3arUmPNJlK/LTqHcbdSri17Z3AFrWb1Ed503GKJtOvgyUIyliuObasZEHrSdtbJvE502JNuVbq+poS5SapZIrzUAqo6chRXHZerc5xCyzKCNhgLFhnNSwOqpzXJ3wvLE5HTPPjzrgKzvLDZkZ2KPEeNEMaqYjFUtUGd42QEfrc6+VkWmOAwmvxszALIPUkQIVJCZ7lIRmwLeRIxbECjoosNoDpGnu28JRkboXNKbQR+hWTot8T90arsYxRxTYzJ+2hp3HNstKts7Ot7x+r0HyD0fEN0XkeeD/KyJffPQvIyLkAwbaVkD9WYAnnzkPbVmvPDrpTXQ+4pFu2Q30okKkkSuJ8fhgXXOWsEvQW8mMKgBqnYhSRGQ8R0xuHS23IvjaINbif4myF2euSYBrUQfCgxhW84Zzmp9qMGkS1lWS4hGeaoaTkx0yKd6Vlz7ycZ57+kXWr30D7DKxuZL4IWl0671x9+I+0zwx0dhNE/OUtJjVLbvPNbFPWzrlRHkdTgh7h3fe3/H805c8euM/8uyB9x6esLgyrBGqTFYBLDVwLO2UZ176PJ//1I/w9dfu8Ms//0u8+97XuXHzPs898zSf//yP8/xLl1w9+GWm8S47EabTHVPbIb5jtpnLMbOP6rpqYrJO3tvqtmBbk8azAUFTzC1de46cOUCD3soNPiy1vo2cY6LgBfjjqXLajFeHGhuFPX0wCxeWxC49a3W2TrG55bwebYzYXJxSlrcZqYjpMXvZTC82ez0Nklpj+fpBz/cVUo2kdG0XJGWa4TUYTqFJ6aDTDzMPj1YdfYXIxkdseC2J0blfewVsdLfjNErZ3h901+MQuKQ9ZdPMIrJKzzkSOY/SM3wsWma4nrOi8F6fKylw4sIW8bZwFTolPmwjDzwVnHTGQhQTZQjlNE4FOjkehGPkgdpCwT37DJF4bHD9HvPeVSrpVIbIsdGTaitlSKX+bJg3pVDV6rpRyU9BMt8mlfw9BcmI+Gb99x0R+S+AHwfeFpGXIuJNEXkJeOef5WeJBNIrY6DY+M1B09oMcazVl5CiYABlnquetJWVxBxUqfnIBcxDze3NmiWGZBkUhpln2V61axIo8jTqniXMJFmSZwd+KyHyMRNBV2FqSTtIJ5dsBDDBNDfo8JlPfR/j4RUP77+NkhmAhbGMNUvc0x1DFi7We/Qp+aFTT9t9q9N4ROFj5nQEVDbvhOT44bz13gnPVZDMrCN45tbCendhGWd8/Ht/iAfLFfuL2yzjPaZu9GlHxLN87Usr//Qf/BPG+oBhD7EHt7n38G0evn+Dd958g1c+9gqf//xP8fJHQJZfp9mbtFBW7zTroDsYgcbE4OqYJbbKPo6EXy9Sr6T3oVSn0i2zd292VChJCMOo+iiQaui5awKBFHZrrTZzYcayBQ0/BrYgMx5tDZWJNBvRI2SRktEq60VSZQQ5NKoMLrbTJ70ZN15DkvwzGHYkNo05OVFSW3VSk+vYtRV8lJnV5rK/qbVUEkuMID0MtnxZa4WOkSW9WTonbeYXLe+PSLrziKR2ensvIRRbA8Kz/ZgNmRzlvEmDK4pU1aXVZPKsrkwySTh+VxmBePYBlChVUiUnUubBkllbhskKXsdDP5MZH8bwkp56q+ZOKbYk8JYD/DKzr0y/3uc2d90lat9XKtq4zv4LYmODZKjP/G0K7n/hICki54BGxIP6/Z8C/jfA3wD+PeAv1X//+nf+YZutVp7iTXo+6N4IlXT4sezCRquHK6DqSX8ZSqijlvwz8RxTipJcL8lVsZXp6o63zBAp38GV1OYqWVZ55Kk4PCciHp3NlCK7a552ifjTWpa1QepKUSd6ZSKkQezHXvo09956lxiHbLSMgfmSoxEideiHq4sEvyUnjxjZhlRtqTyylc17rNVml7kfSw435/adif1B6NOG9eXie/drv84v/JNLXvmBPT/y03+OJ579IaYXF8bV+7z79lv8xq99g8sH7+L7PcMuaWJJhg/hcv+QcXmX5f6bvPnal/mez3yCP/yTP8KN3QlT3OfqANIFl5aONrFDW9T8k0C8JVWlZRWg6jnDXHObtUyysAqAMpwWRkzK5AMxx0NTy0w5+cR2YPnxoNhA/i3ZkMJvE8YpSo6AaEfpaDSGUDOKcuNrAVdO4WdAVCl/LM1DMamRwiGESc4xknS4cd8CRKsgkWumZAiZxdJynZRP8TaW+PjGSaiI7fV9lN7ZcVuQCpBmaQbTmmIa5RmZEsWFxF6lmh4qLT0JIth8NdfyfvSN91n2auY1IkXSeZzaCwkXJLaZgcloGjlwLIrG5JHeq5WiuVezxZ3wlg07SdbJGn6kFFU8I7mheSu6CF0U6cJQwaIhw3HLNYUqSjBGyiuT4wqob4BA7R/BVWttBDCo+b/fNau0F4D/om5CB/6ziPh/i8jPA39NRP5D4FXgL3ynHyQCfe70rbPYpkybq2PlknbzfWQXN2FkKqAW1iXbaetZfjTQll3ujSOXQ4zyJax5DUbPDPLIy6psM6fqOToiS3cttm5dESknowIo6jWVrueEQhn0ZtxomnOLOOfpJ17g4Wvv0peHR6DdlgesV3fwaDRx7t2/x7IesLDUzLaUU4kkPjkLOdVOU72jPbW6ni33BPnXwTvv7njppcwmVYTlMPjUp+AL/+3Cl3/pH/P+w9u8/Okfo50/y+n5KePhOSanXK2vwbqnhx7pMk4wunG1XBCHh4zDfV63K77Qn+cjn3iOT7+8Y1pvs4wcLBaSrknEjPbGFJCD2BagLMwU1jDGWClefFn8Z6BoEwhTTbsrio0JfQhJyl4Lm0wHdElxeW2MpAVJAZfi7Vg+tj7Re0r4oCYbCpVBbaTmpCvFGgyiNP4pvdqYDlIPJe99LT1a0rlkZBlONgkRKcMN8nOIpChB0sgFVUZ5Km6qmuwubBkSiTn6SEKFUBMMF8wHY6wVhGrKIU7fOsFRfEJ9BC6oz+r1911JOlZGE7a0M0rvLUXH2bLo3Jtezlk1zcgG9H706t1+XO6YHC8SBhhErImtUllo5OHjtVZ161AJNeIk9empvqmDwyNpdqol2TRCrDL+rLAykWrFftDK+vPwoRpVpmWS/N3AJCPiq8APfYuv3wb+xD/PzxIKTG/pAhOR6XzSA4Rt/MI2DlSIY/mQXc4i1+pGsYiqy/OGKKmUEZGaa5IPEc/THQkmScrFXGYQizm2bm4/gCq990r/K0W3xHdq5ZGEGanyUWmSuNFqC0+c3+LG7oz3DndY9neJSRiHK/aX77N/eI9JOm03cViT6B5aaE9LPmSQmWOeCnGcA95Fq0FQTQ8RBOft2+d85KWrLGoiS45PfnLm5pkQF3Dny19iNyaeePEzXO1uMOKS4Ip517i8HIhXJ9Mck4GFoZYad7Pgvt7hrTde5d1D5/T0kzw/71mWhyycYKq4DkrukiObvfiJRaVZbWX1w3HDtFK4hOe40i4dlZ4da01JpYuBbo7v1aggbfDUFbH0rTyO+qXoQrSNX5/ZYxW3ITmlkdjaxgG+YtXIikiIhSrTo7IpoQIugqjXuIOaNx21zlrmn9vGz1J9U41xbDEJkpQrsaNre7qyS23eWltFjMz4UCX+keBePEUriMcpwwxPYYPokWW0NS57JDqxMV+SwF4NmYIsNkHGNaPjuMnZpgMQuR/TVi3z7YS1rqXFqRsPYiRENiTVdZC8xWYFNUiKIiqGUZX2cb+lP2X2IlpQDaCR2HdLHm3CJ7mWkmyu9UPqbpdumxAcRcuHVq4/3e+6PhSKm+3EGZEpPGNNKk5RMroY3oK1SQ7WspSxbUWLConb9ZyJ3VWZdhOtZYDc2luZfRbk4pmCCtDVmJowzcquZ8exrbAWZhkeSeZVzUzzkSDtkRmripRfJGU5VYt5DOjO6ckN7r37Dvv77yL+kMbEbjIWTTOHdVm5uLjgzoO7oLCbpgwW8442T8VnK/RFZrwwM6eoUY/ALL5rXIxTLtaJs5PUu+xOhNPzEz73Q2f83D/coyN45xtf5MbpoJ89g3PC0M5pP8fP9ty/8za7MkA9kN32cMmZ23TuPnQOX/7/cfLgGc70Jj/xQ09yefEeD9vEQZLgL0zkvO6lUN6Na2isNtivB7ADKuly48WDzIp7ojPjmh3dw7I/GnrEEW90lIldn1KBEUKnpwGDpaRPajxxSvgycMYxNa/FUL9ic9/2bUZ7BanaqCmzgm1EBRE5Qrb3wlkzSE6RfIeQTfmVD0Yjub5bE0FlgwYKQwwr0i25xmrULUeytmdWa0ETzwPfScy9JIvNNId8FVMkzeAD22ZwR8FHbN3oOhCaXuOWW+VVqWfIo1QhyoNTjvsvM/ltL0fBGoVXOrkpjCLmB9GCQzn+4Blc1fLPVlm3Io+U6pb4plCUuy3RHEnS18S3lV15AcRvD3pbkihxtOnbaENN2/H3H3R9KIIkoli07LoNh3WwjMCiEzFwLOc1y5wfqExE3W2DBLPj1yRtwXqhPrLpXjen6DRRIFJ3LcTWcGW3a5yfTpxOPb0G26AdAreFQ7kJpf5542kVdhYZ5PrU6CHZMRbyNHYhmBiRnoD7995gOdzB1ivkYkV8Yb9/iF8u9HaDYcHpE0+ye/IJpnsXjAY6jDHlAz+IYgfJDVxNjJwRo1X6WMFZgkjwzr0zPnP2ME/oBk89d5M/9Cc7/90X32Lcv+KlZ874V3//K7x/f88vv/4eb61zOov3c85uPcXFO28yi7M7mVnWBNRbS63rYVkQuWJ97z6/Zf+UT37sj6B9Zn+1Z6mFO7UTIlZyxm8Oil9txfyQ/x3Jg1Q/MMaeNUa50zS8dU51zvIpqpmmC5NQROFemZaADFQmWu/Y6ik+KCwwIonQuQkqEGzZYJVv6aXoR5rKsJEd4Y0XWdzb7g7esmkYGcRyOl+kF0D5vPWSEDqFxVVhQwh72fTZzlTsaDMvibhXM+MRN5xIl/thK9sbcnOOE88Ksz6GLC0eIymqiDoUkqifGZ1vdW9BNVoluosgxZbKsbhRqq/kfaomZzPECUscViKQdi3zzMBXZPZHiPyuiUXm0DJoyXdKal1kBz4pUdWZbylfTEXu1ngqwwrya1NljZlkKxJ2pJUldpzHaOsZA0RyWCAI6zLo2vGe5XscuVC/+/pwBEkE1blMa5Nis64pA2twDGSb9KmFoN5SVVEnnuHQemJArbKEtG6GbQFFTuVLp/Eoo9206593E+cnM2dzy1NratwjaSljlJzRytqrF7Ado0aiJJ1l0iSrS32mlP9N4Il9me05OZ/YXzxg/+Auh6sLms+czDtoysX9hR//iX+dw7Mf5ed++b9hfnDJj+oz/MLFm7yuex4eDsQI9tnaoUlmzU16Kk3w/Fxd0Knx7sMbfFYvKlgE0pVPffacf+1/9gf48m+9x0d2Z3z6ky9x9atf4tMvzpzcO/Dg/XfRRZhkhzzxJLfv3eFk7TUn2tlNN7l562nu373Hao4tey4u7vDm26/z4stPsD/cY9hC74LPKShLkErKqqwWZdGo1nUBP7COA6sNmq+IKweCpU/0NiedRwPvhsXCPE2ozDTt9KZFBp5S6WI5ng2K7+flL0mO+pDY1DfFwfUUIHjJHBMji/QfrX8fw9OwOJLb55kfp/mGb6qSKtvKdEIDxMr2DMrwIo4l/AYdNb3GyKQlBpjUPanPUB3gkTNotpngRR0sx6Nr8ndW4FrNEdK8t/KuGH7EXiEz0TwtEou3SDFrE0kX75Aj7pijtnM8sG6zvyNHTSQcoLXqK9ssqEw1pwDkPHeKqJglsHtWZNs4Da3KCLlO/jKjzkaOR86M0jp0Rs2acpHCtOs+qNSIiHwt1ZzfvWHBIunsRORBMsb63aMA/cu6BKHrKdYyWzCNCjxC06Dphi3VInNJBUNsHcnNKFSPeKD0dATaNN4S+ZBEteRnRXUoHz7VOeVS9e97NKQtRGuEWw6lGmXTtU2/C09MrFQsSfGojp8FI1aiXWG+45mnXqTLTLSJuU0wn9H0hN35TXanE9J2vHfxLtNv/Ao/9PLn+f1//sfZ/5Nf58n/03/Fj730ffz6R4z/7P4XePXkAUZn8YEInGpjF56HSRhTg0baq+2XmYvDjpsna50zicd+6qMLs3yKj/Ub6NWekzB+8kd/ktu338Yuv8k7r77K/mLl7f2Br3Pg7tUBkzMWTvkTf/bf4Mf+0B/kP/nf/2+xi3s8ePiQ1oQ7d+/z3EtnLOuSdC4a+B6w4rzrkccHFAjmVfo4Iyw16iNL3piEK3NmtyQyl9OxycJYjXmSnFIZoKMUPAvgHAPWZhKxdTvSrp/iMLKZCLGJlCUSG/Vti2orbl5K9lzyAE3zjKpSAiT6sQT0ouhQUNHW6Dkm/+Smc4Ro28TIlSM4KFoDxCpTrhZIRI4zNo8jW0NazdgRkhqlWy+3gUzFKc7KKYNv4vwNaKJZtVXmNjyzsKmR4yGIbCiZH30osxOcASuCbJSUfYlUR3y7D5CBfvPNzII5jg2ubYoAknS/eGRtbA1Wtzi6KFEBNWN8eTGo13hdQelET9oU5cWQYsT885aJ+vFnlZdAjLz3H/YgmUdHrzkaQBv0XiB+WG2kbPEnKJMLSjQ97Zwi+3rUIHOtRoEcF42KHPlTRMqpItJp2+lYNIbnPJiIpBT17smnSyfRzIRau+6U+0YQTg6caTaBwnLOzShLqTQ32HP7va/Q1/fx/UPMjCef+yinN15gd3qL07NzJK548mRFlgfIMnPx9V/m2S/81+ymF/jRH/gE6yc/yv/j7lf52nRA5lxcXlQLx3OkQlcm6UBHXHnn7k1uvvg+tZMgnBeeOvCNr8GD+5ecTcHdq4dcffEXePG5l3jmk5/jB77/D+MH5fbd9/jS61/hV7/2Jb7x5m3uPDjwa1/4h7z4wjn/5r/xJ7l5fsJf/j//NR48WFkPcLpr3Lw5sdrKvJvQypjGyIABkYOuKIpGlYsWWbZ6gDLRNLjygTVYxpK+jjWmr/XBvMvmTDRhJzNhU3IKR76Ge1rjVdu05p8I0dLsAODoI+YUy6Helxdfb3N/UCksLyGhnIOU2KkKYKBF16pPmA2Moya5yPqS2FsfSUEzwE7KMGwregikNZSpOIJJw5EqcyGzrrSfs2oIJbSSEzTL6CM6Qj8Gfo+U92VTpWXiwPXBkdZpxiTCrFnib9ZlTSXllVTDcIzMyihXhAo6yoYXRzEvJkDqPpCwST1334bvUfHPPNU2skltM0GqW5MHkW/ZaanfzLJxo4rqlMkNvdzv012eigtBqdeblF47Dw4cbFlobD/7W18fiiApwNwagiUexUw0Jw4LMQxzBW+VcWRp0Mxg2ZQ11cVuKUlsteA8hBFBI7lUaJF0RVklLaWQdD4fi3E1NWKXndAlPaCIqTMvE4c5vTG6B1MZX3SV9Ixs1TMNYbVgrMI6hBFKyISvC1/6zZ8npnOe6MLJ2cTZE89w6+mXeOLJl2k3n2DuE6cErTWuTgcnalz8xldh/w4WB+ZffcBPPvgkH/vsD/J/nb/MP9I7YIbudnTSDmzuyqQN1ynHuzbhnXvnfOqF2xxLLheeeeKUn/rcZzj88pc4Pz9Df/D3c3rjSc6mM568+RwnN59hdLCTmace3OZ0PuGpJ3cc9he8+ls/zze+90Ve+ewf4LknP8GNJ865//BtYgxunJwhkoeMMghgKc6ijBzE5GMzfC0Z6HDWMRKnGo6TmHJHU5Md+e8yYxyopnJDToW+DXpqHV1bBh4rvKyA6iNHtojMSXspSaKviHlJ+DK7aBWoXZIzuDVAUmteUlBPM2WLrB4CxcsYmEhcsUORnh2toDNslFlLrfowQhtaFc4Ua/5sVbRLdmzXtBmL1mj9hK4wao68OfVvszGVFKTi+QLNOybGqBLdq0zeOJQb/glRHN+U3U6aai6GEU3QKde0a6pYnJoiEEE3gdbSEyBIp6bIWTbp0qSlsomkgln6L0hIZrLUwUMS48fGVaXmrhd3NAS8PULB4hqOoPTpolPBFGnokdy7PPyODdXI8RpRmGm0FY+F4esHxqcPRZDMD5Wmn9qcyYWJnqx6D/ajTrbSTYfkB8U2Fl/QCzR3kkdJbOBtHHEVgepSCrGmbAoNXI2BczWcOKypFUVp2pm6Eb3MNCIVD0N6PgTJJrn22qDD8CUHHbkJjHRiXrXxzsUlq1/ydDzkIy/e4uzZm0SkUuf09ITdyc2EFTwz5/tvf5OHX/p1DjzkcizM611ufPUBH7/3Dv+LH/uDPH3j6/yd/nUWFfY4s2T9OCpQqiRn76F13r/YcetsnyA7wtnulCduPuS91nlwecULn/o8L33i+zidTzhcXrEue67efYPDO9+gX93hVhs81Cs++XzjzvvO4Z3XuHrueV6XPb/vB3+Y9975uxzWd+ntFZ4+Iz02Q7ARHBwuBR4MQ8YjNJYBZllCrmMlLN1wcnhVK5kdWaKXDNNYoc3MAafRUO1Yy0CEgms1/3K2ZOY6m2uQkwTkrUFD4D5qxPBW0eXm3Wa8pyJow/miysVU4yRVZdt0KZkVPW7dbDZYEGk8Wi3VslhrgjZlFs8DvwnSnElKNrtlqtrwNtGd0r1nc2craPPY2zrKhelFZsZSB4uQOJ23YmLUGojaCnr8aQVPkuW0iGbSEUGbe95NT9d2rDQzFYy9Mnb1JK0jj3AVIw+aJNlnLR6RgygdiHWASzq7u2FmKfggsXbatQAgZaaZeUpNiwJJMxBN9yqhZ58iyLlHXJfsJpu8U8plSI+wmX/4GzcFsGOlqPBqSjQWTUdjMUerZEjD1iqli8JgPhKsdoVRQ9KLeR8ReJXMSFTXuedYiEh8xkVy7sYKLZTeGqGD1id0TozLg+RrFs6h5HS3pj0Z/xWgA2qRKRGNqZ/gE9wP52oJHrx9l8PFr3J2udI/eSB2knZYpzeI3rD9yoO3X2f3zde4YsBQLjjAVXDjtnHjn/wy/86f/iN8ajzP326/ytd3qVpYV9i5QAt09jTFCOGtO+fcOjscNdrv370D+/e4PW5xeRV8Yr7JSTsnpOO6sL98yLh8hwfvfQU5vMPT7Q4vfeQG3/vxj/P+2w85u3WTL/7WL/Hr84v8qX/t3+bv/Jd/m7OTxvnpgSkCWQXEMY00sFXnagwYji+DEYPF0pDEqENsjBzTGp5adE0zWrFAqkTyKSGGJp1JJ6Y2o21CZUKiJ+5MYtNW+Jt70XaoYOFeIxGyeQHlELNV4bWJw52Q+nopdTIYpWuSq5RXYR7UG40nsykvzfZmJJslttAIzfsSXdAOvQetpRPVrmWA9GEQHdD05MxCKvm6fk3wPxoBSzmdk3hlBrn60JHzdLQlHWjTxYsniuhsXp5Snz9YRjoJpRRd0npsihyp6zkuovtWxl9DC90zUEvxJ/FrnNEjWBG2cR3m1X0eSf4nNvfxDMwbJ3I7VKUaMhvpvImiMiXDpLWUKNa0gfDNwjAdpqTwaSseplCBVmr07bfj//ChCZKBx4LFAbO1AFUSB4wk1zZPhHEtYrIXvyyi5gBLyhZb0RKiSQnaUw3QvBHiDHVCO6LGHGlQARAh6ZDsKYNcA3KKaUPnoEXnZASrlzUTQaiytpYejUXjsJYgcWtZMiA5fiI9aoPltHO1P+Gd/QVfeucrXO4mnp+TG/bk9Ar95hNMOrF/cJ/ziysugqTIaPDAL7m8XLgVKzf/nvM/evIZPnZ2wmvf9zH+0f5NfqNfctUbF7vscu8imN157faOz7wYbOy10/ObnD15xtWnP8at/jx2c2KKB1yuHZeRm/b8Fjeee5GHD97mmd3E80+/wN333+Wjr3ycp3fP8Marv8nP/cY/5pe++hXcH3B2qilfc8NC2VvatS02WIdnEFdn0QP7GBxiSRqQpUmsRA4+88hsxFVYATXNZ6qKN03uZm/41Oky0WOHsMuSOIoSFjMSm/GDo7YmHt0oBLvwPSmsObJDnY7cKVeNStPiSK9pRJWYqiVxpYJtwZfiGdAlrimYUtXgsHTNVyVL2QbMQpuEs0mZW3pb2uaYNJK+40KR7Z3oKbLIrrRjEiDpcA6BhNGqWSOyzfEuvqQoPQRrhRGS6h8Vyj2pyNoRaXGGpSHFlKqWFtXFFiVq7lR3obuzhnKUgtY8GTk2uKLK58zUk+jvNNOjA9HGAYWtS5+daNi4klvDNtJopjUIzfakbphqmnckL9cKakns1YraZaLZ9C2sVsl9l8XGB3duPhRBMjDW9ZKDJaCd9mQcW/iClV1SYheKJr8Jp0lpVWtoEQQ7jyotczZxssKSf5fzLARplWFoelaKKtYky6HhTO54HJhag5YTHD0qoJrXJkhqgcXAw9OXUJJc3lXovae+XLxIrElXurjRcIczO7B79zXi7Aw9uUm/8Rw3zm6ipzvG5SWn5kRbeVhZbKgwu+EXr3PjtQPn917gU5d7PvfNld/3/I7Xv+dz/KJc8bVxn1cvHvCgPWSNwb413rx7yotPXqIIrQDrp19ceLB/jgfre8x33oX5KQ4XD3h45x0uTJC5cfArnr/1Ih994fP8ymtfJHTH269/g69841UevH0H6yvPPPUkt54648HVXZopw+HhuGQMZ7XBMuDyAGaCjwNuxuoH9n5F+CEDW1MmUpHRSf9KF0F7upr05kzTRG85yK1Fh5ghChMsgn3kormGViKyNN4UM9VN3YQE0hIv2/h3VVFnhaeSZXwVodmprTECHtflbpQKyPN7pKCe7e8kUqo5tKXQocE8C60rJ3Pj/MSYJIPG6o0hPUvR8qM0aYha8X4nXA3zpbKkTZNeRhLkhpdSFFFzsntLwv1qa75PvZ4AmiV3yS+jDnevAVwyaPOMaq974vQIWkCfFLxMm634uxnbkuIk4JLNTAlAygTEOUodVYQowv9m0tF007UXW6Sei0YwR0dah97Tsi1SfYOn29PGlEBq6qqkAAM3DC93oNg8oIjjA99UOb/7+nAEyaDGZjoDL+5YejrSMnU30u4+qnGTcKKUv14qEXJ2RtICehFLXaJA9SqVqNO8upNahLMRjtjmEJslvUS+pzrTcmEVh1dKKeCxIi2zWJDUmvbOPDXmiVzIkqdnhNFozCJA5+6YkPWK87u3eXDzLeTGs4RMnNx6Fn//wGGlsNAck7rYykR+5of79zmPwbkIV29cMr658v1fu8OPPnGL9aPP8fYrH+eX+yVf313y6uE2b745eOGJGjk7d85PnuDA61y8/0ksHtB5H/e3We68x9WDe0RfuXf3Hpf37nHx1A0uWvCZj32K8dpb/MZXv8k/vX0XF2PcueTl7/kMz710xsOrh7AkbnUZCw+uFtZhjFCWRThYsN8vZWqwEhrMbRsINZhcMtsiJ+ZlCZu+gIkPBr2dMLcTJplomiNrI7ZfmT2pgqqBy7GTqkEVllrznTMoZolczYAgF1EFQ9kG6JCk9Aw8UdSVOJa04mkEwcZdNE+Px3rFLbtqHfoUTBPME+xOGnPPjn2TSC/FKZsevjU/iKIfSaW3FTSq1PZMfkm6U9GiRFBNznAooA3fnNqTzAYUYYDMWDfQ0j1nBW0u7SrBkCX1z6rJf/VNEZMTJ8WSr4sVvUrKxCNvVNnCbXS9LOWz0nN8bIeNlKpNtrMtDxrJrBTJ59ejdPeirIW2pdt6jd0liDBokmOiN3K5U6/NseQmAunfvtSGD0mQzKtKhwiGl/26Nmwp7z2pgVtSoxCoNYMVWz855EjefCFngeQhscm26mUCeo2tXM3xWKGlckB7cu8sArE8+VyFXg+rrFBzfGw1kzQoVU92p3WeaXOn9VKzeksBvi0MHzXLeMeddsIyVm68/ir7/QVPLfdZnvgYT774CdZXv0yPK1pkieMKizlrme/OGFfLXUSU+9N93l9XTt9dmN89Z371jJfPn+FjL30c/8izPPjEy/zKxT3eHf81Fzp47723ef/ia8QykP1N9vEkD/QO6+GAPXiLywcPMXX2FwaHA229z9W911iuLnj3nbf4xbfe434MdmeC+J5PfuJZZLdnsawt9+vK/eXAvcNgfzBWE5Y1G2w20hN0jUHrcDrNTG3Gw9LgxNLBvUuj0yAmrKUBcmLVJ0yyo8WEuIJMhE2ET1C+gDk+dKTxsFINhTz8PPJwi8p2tsZC/vikClmtI9nWnWS5va1TKUudYAtaRQ+DUr/kurB6HZnSpGHSoHdozQvmTDVIb454WcZ1iAFIIza7sdgsy4yt0E/Sd/oUVPLG0Uy6tNchGRynNmGRajbZ9kRxB5MfkBhdDMWtsco40p7UNEvvVp2nwuBbKxuzkGqwZslmxV8+/vzIho0GiUd6BkSjzCq2914HomqaVbtl8PLKyLMCSMxZMstJjJiE1bISSOmrYMd74FHmHvWZt99W/+aY9R55qt/i+tAESZGiG0ZKx1SUhlaWmHwrqbnasGUFXgVsHAckbZQDKWC9uxQnsowW6gQcUnyx4YSsx046NujHF1HSozM9GzVabYks4DdtbLq35ENs84TuJmRqaX6A4KNjJgwGa2jSTVSQIXg8yxsnD1gvbnP5pS9w/+Y3eOLNL7P7lV/g3JcsPR/FyMJZAyzS3u3QhOHGQ4x78gBwhl8h997lZH2bM/kcu4dP8b2v/wbPAW/8gHK3O313guGcP+3ceTNYlgNjPGDYXa7GBZdLI5ZAm3F1dcm9O3fQOHB7f5d3baVPO566IfzwT/0Qz37qJqtdFWg+WHywmLNf9lxcGfslWMYgIo0zpj7RurLrnVM6JygjuSHEVMFIevI9fWZodWyBmYlJJ9LmrBM1NCMD5NZgqUww0qfRJelGVHd1k6hRlUk41PyHUt5QQVLKt1lqWFw8kuFsK7dKcbSaQlUCb+44AqpKb0pX6C1nHaWngFezKcvycVCWoCz0kpAvXnaIlcUmzzdnfquUDjtrWZoU/ONb8Msy3IZmpz2SS5r9lC07TYNos/J1LB7yNnYhfUCTAxw1rbNNm8wzMc+myWTwui/qknPDt5B+NLZN5ZRUI0avozt5mpC7WRJay1ubEEkeMuWPqdmEaSF5GNUv/R0i7KaPlNAbr7WR1amkAg+yufOhlyUGsJKD1gWheeIzo2gBzYuUXcRfLYcT3VoRAd6cJps1VUsXlTIc2BpAJoFpUhvM8yTTjeJhTsRgq8clFKYsz0zIMqweOiLQlFZ+UNsDz+CcN36UMsJCWMdgHTlDe5BOR82CE1NWOl9lYugZ521ivtnpfcXuPcCLgDyK0tAUJhceSGAtXXokcgIiEbjC5Freio4d7vHw67/B+Suf5tanXuLq7/8Cz70489StG9w+OaW99DTtJDjce577D18lLh+w3w8eXB0Ye0vpJxM3nvk4N556muXeG+yvkllwdr7j9/3o9/C9v//7WGUlPBsKwwaX6+DhMrha4bAO1sUYVp1G7UjADimOXcITTdL2H58KK0xah8WOHgm4VyWXeJXMBKdE9Apcdn2SkLZjEcKozC8y6TkGym1SX1SXthKho2GElkNOWkamDfNWsjuWaq5WWn6vzZ3dgqq5k7coIkyi7CKhBFoj2lr6Z1j3zsGTCiamycJYJ6aYWDzx7hywOqpD7rhaYnt4ab6vy8e0QBPS49SIUGyMyuq8DHgdEQOdcvM5hFuyDCwZHi7C6OQBAaWpbhmYRh7MooJMymitOIxeWu1E+wYbYamw+lrPSGWWYdWviYIEKzcMoW9EeKg10mitmjqtMN+1sOANJtNs7jZJ+lZspPd6jVYSziwiNxXUphT6sGOSwOopGZPqWg8JTJMOIiPtlvKQy45lLy7VpveyKcsdLcA4O99FF4qcOe2Q1lgSSOGSSOEo7jkQq1NZRI14qLIo5xWPGj2wGWgk3lgeyBmIx5reeqL0aSZcWceapzRCj2xGLpHzVSRWOie8uwrPXF1yY7zPLvac37vCAy5Ix5RwYY5gF3BQmAN2ZFPgAmdGmNghOrGjeGguyHrBg69+kX54kRdufZL7F6+jT8CtV14h+szVg7vcvHmHy7tnjPvBeoD1arAcDjTOuXXzo5yf3eLw4B5uB+JEiRle+vRLfOSzn+HhVTY2ehGvPZThyhjBMGW1egZmuA2kC9adpjNdJpCGidKbkDTuazJ1NGW1mTE6MpQRuRHSimvGaUQC0YkrVuNAVIrNMKEY6TSTXVKRHJokrR2D7kYvMQ0YcBwH66kXpilRozvzcE4d+1YGZiNQcuBclZAarbq0WR0lWl6xIDKzWyKQEcQIVAcWC/tVWUdDLWksaVqy4LEmyUc8XW+S5Yu2NLslAjNL+KHmvqRbhbJZL1uNxd24gxLXeGfyD8FWMqsWsElSRdYjbQizFZ77tBKLXP8ASZsbnv2F4VHMBSBqnoxuI3KjurJ5pkjT35bJBUnVCbx4yJLGxArSMyHRkUlOjqOwjf6cdURTRIoTK5tzF4CXX+x1xWADthlEH3R9aIJkhCNrMv5Ny/S2ov2I5J1ZwDJWCMPq8KkG5BE30t5omtSJnNMbZRCaN1+jpp+0BI9FIDQXrZIpeMQjDtl9SpwSSczGW5keFLbRiqoRJaov4jvamCwHR6wRqY6I4OAG9dC1KdqC02UC7dx/+JD3fu4rXLy18tT9h0TmTKwFJ9wIYSednTjiKT98qIM7EbwQO86903oaLLS4HuupbYE3XuXi/pPMX5t5+Lzhl1cc1tvs9/dYuMfV/hS7vCQOC3pYuXn+JE89+2lunn0EZYE16PPEs08+wUsPOy985lNc6YwtMOmU5XJkE8TGChY0auodgARTz/vet64zOQnzsGZ3tHWlTcG8a2jPoVk+TihXYyg+oraS0xUmXIzmDGzlDTm2pgkC3rKbehwKvGl5q9rzVKKkmUraiUFQrg5AQS6kaqSVf2cu3pwSuI2iiK0M9XZ8W9lwl/QEJmgVYIcKI8BWYUSO1h1DMVuBhV1MmQVrGrOYjhpLkFhkskCS4hKShPNtFIGHlGmQpyooKuutTLo+YRlERFYtUd6Pta+KjXPMjkWBHoRU82U4vua9EanVWhikFfSwTd+KlpWYRBybXcXsZps9lXORtsQFcnRtcSKp763n0aIeOVEc5lReyXFKqdVazCxTaq+3ScswYyPc54rg28TJD0WQJEjD6pGdNTWj+WbqWbhJlIJh5GQ4iyKLa55EIh2YIKaqqHLzuOXD2nDObTh5HDdcdjC9TqFOrY6I+lNimkLU4HtLZ3DzozIgU/rUa68jg6x2wJSpe8mOAx/OotlEmCKYQunitBNjdXjw9DPIi7B74zXe1uBlgmdbQ1ZjpkafinApyoUYL8qE0dEwbkov1/KVPk2Ju0aOfzioo8M4vfOAm1/Y8c4PLtx+9Uv0s04/mdDdntffvM361lvoAIkdT5w9w+mNJ2k75fBwRaSjp+c8//zE9+zAnn6SOygDZXVnipSAdWkptdNGV0seW6sRqh5Mug3lU0YIMdLrUCVNjx2gG72laYFMRRBH6UfTwi1IdojMqigKTTYj8pkmdjyq5JOqBq6bNDiIy9HwZOuEwlY+A9V08EhHTCsRwWb/jEhmNzV06rjXNGWqEpmxbL4B5iM9KEvAkEWMYjGBCbIK08jwBUAHj4FJGg1vgoCN1rZNFpTyOvUYickes2cvXXOawIiuCMX8IKcnBiSW03vhswNRR1rBdyhNg95ylMLm6WgCawQ+sopbiySeWOtG+0kYKoLiNnN9cFa0dgqSTAgVkZSHbgO6ji2CJoxWqiZT0HQi18JSpMaBaMugp5HHyfA1D+mmTJJZlZHVlmi2en5PmKSI/KfAnwXeiYjvr689DfxV4BPA14G/EBF3JMP8/w74V4FL4N+PiC98p9cgIEYpJMjh9I1cZGle2suY1aqrXHQGpThw0Hqnt56niZQTcnFUPSi6Rkm1PEBSEF8fMjEKoKOl/a4dNywt3qnF40Z5cuVCWVOCZlK2UpZZbgtFw3Lr9Mx6xINuJDY6BWsXTthhkhnW+5zyjY8rn553nP/CV7n7+m0IuEVL7pgq+wjuW3A/jKkNzl25ifKEdnaShFqNloRiUhIna84GuRgPaV/cw+0btCdmYnfOgmDDaOfCq+/tmWkYjQfLe5zdep75dMfqgw488/Tz9M8+x7RXfm59yMSUmK3vOaxK1+IioujUUFemNiW2pcbkztxnpmkmWslIa7V6eHaiVdLcRHJTSmnoN5MlD1KGVhvjWIVUhuQRhG67M4nWvjVcJE0flNR351C3zHa1PBh5xGA2f0o6ijffsq/aVFQZXfOwgcpWOToERXK+E5ppyc0NRppn1KiKJArl4TCUYlFk+ZxWfs6QgbVUoiUuGhv9m81pnHKMp8w6MqtvuUdWI6TmuNR4g6TDOb18Ib0pMVXnf00xglS107vSSxUkpHeBRWJ+mFXiApAWa2NkpWVllutlJiFS4xiq5E0Cv2/pN9lXqcmRUiYjUhxn0vTCRyKwUhr5kO0egPbCklt+fV29xviWXEnIA6IOjXAY1TjyrbT4Ftc/Syb5fwH+D8BfeeRrfxH4uxHxl0TkL9af/2PgzwCfrV8/Afwn9d9vewWZhVlps9Wjythq5QsgyQ/sVTp4WLmeJMDfJLlx6QKSmcewUSd4bC9UOcC2CPPGUYtWZSu/E/g2X5IYbNmE0a1BGnGUTiUBtzZ5geIhPR1KLCVckKeob2oKyQmQ64Arcbp4dSUP6Gp87dbM6U98ko/cPGX9rbe4Z4MncV6wxqUY+4CHEdwlidg76ZzJxCkTF+IsVmBbE1r0dFnpgelKjAV/96NM39s4rCMdhCL4xKdP+eoXOs8+/xw3Tp5g7A/g8PD+BeswTCYknuapj3wfv+9u595rv8Kv3Fzoq3NCsPS55IY5PtbCOWijt/QnhxMaTm87upZrD9k025zmPWA5UAed0NrAW1pleBkGSiQ25kZhdC2zppFNiRH5uVOo4RVc5dgE8+I2btZhIlYjQ6gAnx3bbdtmYpnNhKl4f0Ee6tshGw2sbW7g6T2pZawRG5fyGBSUphvnd2v0RE48jJ7wiOZIjpA8pEOtOrDjmmMYW6MkPW4iat6ikE76kY3MR+cjSdt4lBwPg150GgtL0YNGehUAOuVhJy276VvpbZFsDxcQkxrrkW5Og80r4RHDroBWY1Nyzwkcn4MXW0CP2ODmPh+kZFSQOqGMZvnaq+Q+ct2wzcQiIRMcj3rWniKPFtDESzYcx2rApfiivxfFTUT8fRH5xO/48p8D/lj9/i8Df48Mkn8O+CuRq+2fiMitbbzsd3gR3MutBKd7UTrUapFmA0Wa0iPBCCvlRGtJr9jIH0nbUKATYkfhusRG7s1MLrH54ruV+YW0tN3X2Phm1AgJL7pF4l0aeRqaJ5hupKa7BpCgklwtZMUtaTGbQ7WjR42th7PCEd8aQEhj9eDubOy/5wUudxM3fu0bXBwGr2jqy5emXA24sOBcOrua85L2aKO4mEm6FTot0ommtVMOfsXN/+qbLD/1MXYmeG3qJ2/Bk7eeph0a09x46sYtTvrMnQcPOekzLz7zDLdk8NH/8r/lI9/o/MEf+xSvtTe4O68wbqByyYi0lrCYGK54HHIh97Sz6pL/JTR7CkeydGm2Izu864ApGuZ6xAfTuMGY6hDzSCNjKdebKGVFWG5IhNpAVbLFxqsjM05JzW7EtZ1XroXES0Xkeh0kETZL+ML1UhSXOJ5GmomEbtmI5+YnirNbAcMcbdlpvkbZrq9tVLFJFftVCeU6zCaKVILsUI0nuS5dZQMbS59cZPA+9cSIVbJBVklH4QnlAJ6HNRKsUWTxbNDXNMh0ZGqaB3+ollDDjzDEKBJ9ztvJ96mRYElS2J1wy89XNKxNHkjr+dk30j5RuPXGUY1rdVCV6BvPMrPSMt+omx0EOlI+qZo8VJU0IvYxGFuGW83b7wYm+cIjge8tcnIiwMvAa4983+v1td8VJEXkZ4CfAdidzvXJa2FYukRq33hqOfva6iGm69l112obEo9KzhDWbIxI5JTF7CBuUjW5RqV59GRLYL5mtSfvjcwOk2Ig0DwnMGpytJo3xjIqu8lFo1Q5n/7TuTw0jSYMjlQIrRLJpVzVw7KTT0t6kEzc3Q345NN8YnHe+63X+HVbedFJt3SBgwr3zXmiTfS+I0a+j8WDq2VP751pStmlmyEyMaty+PoD3nkX9LngHGXvSdf4gRefpv2/vs7Jzfc5u/UEceMe83pgtwQvr2/y2btwcz3BPvuj/P53n+f05Bn+yuE3eS8OWCw57H4YY3EOh4HptXt6rzEBw2q2tRXwP4xRB5hGSdQ0mQ6rO9386P4kTaA3huT3QWqZvcjMXs9s63KHJ3magM18QkonvrEnpOqtqGbSxvXbtuo1KFbfV0ErpyVaNRcDs8wIRTwPpcK+MhJdU5B0i1FUE+V6PyTuXcFdPYoErSD9mMWlomQL5sV/hGPZnV4TmeblRypF0ZTvLcvkVKHJ8HRsapqltZDYcGXO2/90+xSlgaYlX9iPjR7JQOllhltzeiQkewuhJXHMiiYFPvXTozjRkgdmZS9lrrHdvczfY/uO+vzb1ES2g3TjthbO5tFwzSx4u/FapX9+HoDMxvWDIcnfe+MmIkLkO9hofOt/97PAzwLcfOo8vBoi7RGmvUdSBtKPz1jTbz9Pp6I5ZAofbACk1vCkEMuxpKqYJCE9O5GZaca2Wrlm/fujn8JzUcRI+yZB8C5Mc6dNLecPL8qJTMhwlsXSTaZKHQ/POcwxM7XCQGoh6BFHCqyMs5Vg0gZd0NOOXC14E+7H4LXPPcPNvnD7V9/kKVV2EdW8Cg4izG1m6jO+XNE1ydomzrBD6sjnHe4CQ2kinHPG2RcuuPxXznK8wJ2bXL5xg7gtPP/+r/Pke3DCBZekBvbJUD45P8Wt86eYbt7A3n8f/vEv8YPxU/wHf+B/zF/7+t/ki23QxsgVbY54TpJUSZx39jSOWCMx5/BsfoWnbZlUVdDmRp87ocEI5xDZLNv0talfzuCllclts1iG52ZV2SguW3JVnefCvypsJb0kBO2dwGtmkmxJYz5PTf/R63SjghJZ/rauDDPce7IKtkN26wbLdZoSteMzY4ykwlD4XOVMW7UjQgYj3bKdxOihIJ1wIvSYRQpV4iPXUxvTTjaltZpKtKiDyGtGjlrSyHJOzTUsVTI3IoLFFqgxDUhxLauUzf5oqwCZ/y4isdbkJNTJkKz6PDg6RCmZVISpddS9jJkTyzxWcqXckYxwiXF6lsjpilQZZ1S1Kco2syaq0aeadK6RpQK9ONZSDdnt33/Q9S8aJN/eymgReQl4p77+TeCVR77vo/W173AldhI2UBlJ8BSpkyoXlVkOohJPLMck54j0qSXO41Gd5yVNBkTSlQcIa9k8KIG3SNqvOYYfZ3sm1rPNyFh9oKuj7hzEkSaYNuautHnDjMhNergecp42WZvWGGRkYLByNnHtQKSNE5l1bl08ND+rRnDShTaUpTUue9A+/xJv3t3z0qt3mHFagzaEro2n9bQ+Wv6czsyuKVfurGbQR9rBRTBEaNOOl//B+3zhY5/gwds3acvMTjs3ToKbz32E6e03MJyZbCTMAovtWS/u0z3Q/cqqdxlfPOfTT/0x/ucv/1v839/+O/zT/etctRxkL57KimXu7Op5mcAyGsti2LKCO12VnTZUnWlW+q5tnK7cLCM7wsMGXU/wclwXt6R3WTVJKhaFp+OQVsm4ZYIJjWVpNWTzqk499WYF02pERG4cwfuE6MwmJCj0vNomSSgy5ygiyEeYTZCU2DkuNW1TSt0fNXq2AT7yvXmwhuF+khaAJkV7aUSbSySwENIYvjBiOUI3UaNqKZesKaRs2hImCEm6jFkq1CxasTsMfGWEQ5NsionkQEgvepEEoVkpxVrNE5HC2bOiG1qcZqppF5kdZoNZsZb6aHEQbdnskTQxaaQRjPYMxl6yxZBkHCTVKirA5TroIclbbQ3xfoQ0XFJx43UQeI2I0MQvshotCMMLK45y83W9br59q+tfNEj+DeDfA/5S/fevP/L1/0hE/nOyYXPvO+KRQJ6OVkqX+ch9zJsfWE1tiJHYQubyhvRWqXrL1v+m7Yyig1AnDIFoZxPwUyeIkG4mkKdSSJR3YdlGUZpfTayw9zlHnbbMGsIS8EbSAd3c6uwuHFM1x37KwEuLaz6KD5Ygf7OaQIfSl8HcJV2vFUI72WYy7k8gn3+Z2+884JU9rJ7zuV+SHc/2UybPhz1iIKH0SL3w3hdsDc77OdPUk9Q+Bk/fbtz8BXjwwsRCOtic6ox+5nM8/e59TmrWduDcEOXW7km0nbK4MF9cchILD3/pC8z397zwiVf497//8zyvK3/bvspDd5Z1Ykx5SrUQpCmrCocxOCwjJaaFbWmfmJswn8y0nvZ1TRpuOQUSp0hAU26tKrXNavSrpQS1lYmDVRMo6ystI9hMyIIiNldpds3k2UCpyuhCCMpcmQ2aIcv6DSeMEi5oyu1UM9ik6i2hoaY5RmIrQVMUcY035oEZNepjpB49BCRfvUknyo5vbJmPj0zM6n/bMCwTSq4ox1rVkGwQ1dRCI82jw5NvHDixRkEFpRd3v8aC1Uq9lHCXqCCWg9JENAdpFdnDQ+pw0qPIQsgeUes9DwTx6yy+DjGB9EBtZJd+bJnnVmZLOrx71d+SuP9GDfLYoBTZsBAkImeclyDA6+A4+mlqHXwqiSX/Xho3IvJ/I5s0z4rI68D/mgyOf01E/kPgVeAv1Lf/LZL+82WSAvQffKefD4kvuA1EpsRWJLOwScsYtCVhdbXCQSSOEkTR5OVZEc+lJhtmtZDcNd8QjcIxjFGGAg4b4mKWDT9PKsrwxCom0lFF2kTRoxnV5U6ubCvbeCNiTWpGbAC0IJET7lw7Tsdp1WiIIwYVqlUqOUTa+ZskvqpkeX0gODx9gwefeJb1N95jF/CMdj598iTn0rN5pEnKlcJXVFqewmMwdOVEO5NqlcSNT7z2Drdfep4l0jb/IlZuv/wSHzs541fXuzwvMx/nlF0Ed8eBy+WCtQVzg3OZeFqfor31a7SLdzh952X+rc99jqdv3uCvLr/Bugv8MLC5sbTULKeVltJbzzK8wdQaU2vsponT0xOkk0ocb/gI1hiYD4TUOZsVCTgHj1dXd0NOsszCt5K6vubJesCTX5noZQbGHMtQANhWFh9L1lw911zdhDmybq51Wl1fkWz8aQptyOZNBogNC80A62XcLGzAWzJ9pLDXfM+OEc2z2dWSupSfJ0DWTBIkg1/SaqrZ4aNw8esGh5CHCKHXDUSvtSLZ541yBN/8HyM2OKrw2ipdw4OhjktneN770NR4S2zyyJR7RlP6Nkyt7q4UE2Vz+IlWShmpf0exBwpL9uO/bTn7vQK7APR8NuqkyKPUdFGBuG0Z8W8PaByZLRtEkfX8B17/LN3tf/cD/upPfIvvDeB/+Z1+5u9+kXQP6d0TtJd005m0ZQgrnfVKcCh3lVYdXe9VcnS//vBRNB9xqIFH2ckqXCM24m+B5ZaKXAW8KAYWyc+bJTNH2oRpmk24+5F/OSpYNlK6NiwtTJEE0SUqkySIaIVDwdF5RIShxd8cgzZl0M8gOmjA4gM1mNrM+9/zDPrGHr97h0/qOc/OZ9gIpHfGUotHjU1HO8kJix9Y1z1Tb3TtzF05rMazb73HyQoyTRCDNYwHDS4/9hIvfP3AW4eHvCdXPNV2vDCf8aQ+gU8Klxe8evYE/92NZ/nDr3+Z9uAO53feZrx2h5/+7Ef4fR//YX5xfZd/xG1+yx+yPwmIwUYxFYwuTpckl59OMydTS9u0PtFiIqxViXTIDV4YWBQUlvBGjo9NCM0ZLTLgFA7JBvy7V5e5A4kVbsPcbOuyJvcLjqV74qVSh+vR5aekqI18T6qbU1TNiW5SqpjchLaSQZ0kzdsYrFFjbj3ysxWfJrY58gIqktmjwFwd4hRMrEAZRaQnHCpC1+TIjm1sK7nUkuET2SiL7a9SJRTVJlepLGsLSlIHvGqJYhxw+mZY60FDITreQNQLtijVtifmmJhQR0vFtiXlScHJzxgKowVqPaEVq3dYJ49wHbCdlClKF1prRK+Ms4T33bcgmYeb93SO9xF1OEQlmnmTJZJitCWgH3R9aBQ3SRkRTlp2mkQEnzhqnV0VmSakAqaQoLurJkdNJE03rbJFX6/pISTpV4XUutaJ7aVs2NpO6WycnTVHabuOzUlSbT1t4s0Tw44CmgPSGb0rO9nR1hxZO5AaSZEkYRVhrs3iUbSDGlOwSKCh9LZDpxnp5bYsC4xDLr4mXOlgffqEu595nk984QHP9iKNW5kSRxybAqqNnQo9sgN75QewPTfaadq5obTFePGNd/nGZz/FfOt52lgYY89Xvv+EP3o5871vv8p744oLVu5dPuTh+cr52ZP4zef4m9/3Z3n7xvOcnf0cP/21f4pc3qdd/jLn97/I+S/e4OMvfYw//pGX+MUXLvmrvMvXzha0TfS9IzLhcWDyNLlwAW//f+r+POq6/LrrAz97/37n3Huf4Z2rSjVJJVmDJcuzJdkWsRUbMBCmhoZAN3QnEJzVHTornV4rndBrdTqhSbxCIJ0mCQQ6CcPCGBJwoBMgMRgcY1myZFuyLFmzqlRzvVXv9Ez3nvP77d1/7H3u+9pIthPSvaqvllSl533eZ7jnnP3b+7u/Q0F0RMsqOope6VrYSgEaajM2B2+VbpgJk4L4jBAdfZgg276TCOcfYtzshjNRSlj8G/F9u3nSUGK5ph4YWrAcNBQ5SaIOF5w43JTk6hGBcCGJk9wMR6GwvmTqCFhEVMx9Zk439rpIF7ODGmehlUpXYSXKkA/2ki0fFSY23qIWPpJYLqeCeSEm4d4tTvVccuXzsiif4ndJjjA9YBXXoBmZg460TEiUMmDsAr8lurbqGhp9wLzlqFzjvm2BtZvH8SXeU+mTE+OyRZYonG5CE2Jx0+dwXtfFDlFZBp8gnSdmouBaKA/Qd6xEMVzgNZe8FgR1bJEpy/1vj7gzqcESXftVXq+LIhk5GrntIk6+hV9WhkLRGn5x3eitZe6J5gmznF4CXVIMEzeOSSgNpGTXKGHqGc7UsRWNdL14mIob1mcQ3WOYSJxaQ42x2qzT5uTXERpvHStDKZTeIx+6Z7vTo0vQUigCg8Q/zSSzBMFlYhyVcVVYDRaZJ7WgdcR6dJkMIdNy4ob77JtWfP1njhhbxdqMdGGg5CiddlqSD58JVUY2pWK9s5uNYShULag5j37xOb78rq/lg1/zX8XPk9fkR7+zoe0Q5QiAh1+Bb/uY8qpDV3gv/w0fepvy0BMrbp/BtR+6lk7sHd/umJ5/mmuvnPLdj9/gkW/5Jn7w7Av8dHmV7sbYFGmduQiMFe0BtDsV8SEs6bzkgLXwJ6NIRVFTnMDPAp8SqucCQwtdS1BZfFlA5IHVe8r2sltcMDNi4RXw5v0ArQclW76M3tmhNtkvgDGJ9MTsQ6NIBjEyBQbkoWx4iwLl5sy9xWifXdO5C2PzCHUbs+Ox0EE3WXJ5fHloYjudE1Iju6VcBLr7A/ZnUeBYNuWQG2fdd9Ep+Y6uL+W+Tvy8UpOPmsNZcAzzyyQ268sCdOmwZbmb4lnOf9vLKCPN0vcbaLcH3vcHvxQJZahgoUKNhS2SbAX2B4GyQLGLut2TVJ62cDlqL1Qjd+hzu4+LfpXX66JIigrDKrJgyBtWSowyUhVqkLjDqikMcRd6QICxBl6DZ+d5wRMEkXJfLxqSt3jwrIM32+eZLCfLcreoSip6lkSUxZ8uOlanpC9kBC0VNWoJCs8iNdBmaAcdgsGX9wXhzZImG0OhDoV1YnK6KmipmMMsCdwZISErBSqc3YDDS5fR21NgsRgDFjGs6cIeB7YmiB+YYMOYeseaM0pHRXnDnVM2dv82WG6WmKwMRLlyV/iWn4vtbE8Dgtrh/R815KGZFx4+4off9BC/9elPsV4fcnxwyMiKLheU517ia9eX+APf9S28dvN/4PNyytYnaimR8tgb3js6zdTSkvs6gNc4JF2jgHoUUSMCnNBY2i1PRkUjglVL0EDEwXooo1iuf9DF9pnsEpjZgr1BPnDEdB9Fsse6Y4+PxZ9bfl8h7ke1TlrjRzfT7xPPF2QFU9w0/izY8ZC+qY4wl4pYDRK7pcLlQS6lknh9fG3rUZBNPWNj43621uitpztQ4nwllTyeZVYiW36xCAvH9axS3vbOYdEVxwiLS9rapklEduChkbblIdkXPPIdXd7QENrcTyYMc96QG2qO98LioxDFNH+g/BkTY/X43j0hEN/rxcv9b5ncaU9KYNGgUUnCKIuUdZ/4+MvUp9dHkRRhtWaP1wWfEYo6mXqDk7zIHhK0cAWKmyQkTwsFI27l1ltqgQfEYoQtqUNVj4uAL9pZ4p1X21vDU8KXruRSJVgPfU/VgejerAfuKRojsVoUYh2gz8bgMFRHNeMyO2iTyGwuitSKjAOrobBZDZEIKELvEYQFYS6gIugAOgBXNtx+5JA33Npx7IZpdDzSA+MUDW9GEaFUz/E03p+qMYI1932H/OjF+I9dk1wu0jzc0KfB2WwTG8yCIsDwTMd28MG3v48uwvf8/I9xrsdc3lxmVVdIFeQZ48ZPdn7ft30jf+7mT/Hcak61kka4VXKmTWLzqgne91TFROugIBUtsWBAwpnbVVHPyFOJ40Gz24vRPK5zbK9LFMi+gFBLJ5K/jwvFDZYJJItcNCwBdu612540l6TTWJwnMd3EW07L+IjQUscE0V0xKp6iiOhig5UxyApqoRMGs64ZfWDLBsiW6h2BYZauRjmSk78urdOmGakF8YJpdFPVJPHy7JwXA98sxKFWi9Y44ApQi4WiZ2coJIYKRLBeiYM4W8sYtf0XFXc3CYI8QdAPjXuIL/DEdxMTXRrQ4CbHs082RPlDpGIuvS/jVojkSgJmiVpBdqLRMZcstvFlckIQB8qeyfLVXq+LIqlKFAjvtG5IC81a054OxIZZZZ6NtjNszlFZAjdyF0RS8p/FE+6z6wWnjAlGW3QfppZGoWSXSpz0MgAFU0UHCVszCd+8iPPMMSTRnaHEgsZMmZEc7aF0UI3lA8WpCa7PqesWwIfg6Wnt6EoxzQ2oe2aSCKG2kHC1HoBRuXDjxRuFr+tzjP3m8SaKhxTRoGql9TlI2kMJCoUveBLM0jE1Zms82i79oushEHnUufm7e2T82Puc7/jZwuV7IY/zPWVC0JeM9+vn+cjbvpNxdZXf8bG/x/n2Jr0cMIwbNt648innve/49bz01m/mr778Ye42YxzWEdNRB0pdUcrATKX0HqPpsmwb6r7jKZKWZhJLC0+LrVbiIdeuSI/CKgT1yEyTJpSGFip7vtzSie1HMGy/2FNLvb4lqyLnv2i24oGLhzooXX3RzKf6JzwGNAnRSUVJrmYMhPH+LehZMYVa9hQoTW6rmAEN1x4dU+942zL3Oek9WeaXBVQPLLO3FkWwaEJYnrk3ef3yEgYiEYWziNIyrGt5V8Q6LhJGLMkmsOUZ2E90sXlevIDj7cwHq6SJrspecWb7irgYIiwHFvkMQ8xwuQSTUNktX757Q3s0MM1iOauez6eE1k08qEzxMy2KndwluCzD5r43+2qv10eRFGFdB1ojzVmNqWfujCszc+ArzemTIy3ezSXISHzBHZPX2JPrtsjZBo1RTQquAy493fp7HE6a4L2EHT7uoIQsUiIDZzJDfQgciJB4SalJXUiVABJRshqjtIqG5LAELtOmxqR6X5RfJLbt6RHYlxznvEmaJ2VFIwtFSoxFO4x7NQF3W7qi6EhUNUi4stxwcTOGaYLfPxAkIlj7as0Rm72Criycs9YA2cvotiv48fd03vvxwsOveYLp95GcJ85fYv3yjg89+Q34uOJ3/+yPMPWJNgv4GStx/Gc/xvd9/W/n8ycv8UG+wMCADhvKsGKsI45ireCzh7sSOU5Hb0gp9zve+7kzEhSxEmTqklvrhQe1kI3R5Ofl+xHsgfyn7BGz5Mj2/YNkfn/cg/sdUgzIMcIpQ47j6SWandi+yHiJ66SafeiiLpHk9sWBKimprRQKoXF3W6IUOm4NrMVyxBrW58iUSZs31RL3c255862La7hAShJdtyvpKBTA6nIlXTMGIjF7h6BjYQk7pAdCvv/F4nfwvB/M28K9QrqxRMJK2R9BLFjl0hmaW/Z5+f9J8r/FVFBr0vQemGJwR/IQ6T2kAXNOSS49FHctsVInS3oeistCDcLeKUUqX+31uiiSIsJQY7GAO7vWQ+Y3KAMlDTzDmNV76iyd5FTGBW6WJg651DEi+mHZ+rrFTnIm3vwILIrNtySe7QTQX70HJmIe+E66Aok51ZxBIkO5S4r7LVt/YoyQZSbXID4bjS0w10pvjVJgyOI3i8WYaAYtsSV1glkbJ3stYUIr1TBpdC1MOQCq6t6efgGqEfYORwtYTvYrqplC6JlHfHgNA/6tH/8X9gVf773G+ON/GcNRmai7wstVuShn3Jte48alRxgOj3nl6Cpf2hyzFJEb29t84MWP8BOPfBPbb/4+fs9HfwSbtvRmmJ2yfuHjyE++nd/yLd/KF05ucc4mLO7qChhozejzOT45bQ6ZodTCOKz2A75LbPQViXwX2MvLFlqPQyxOfBmRw3QhQql6jqe2v+aLS/byOYs8znLMkOx+fvE9a6nxjs7QIHDTzEGKL5lqqjiJE2svBPfSWJTRca2GMIHWoNaI14Q442ftHj6QnjzL3gkacJ9pGKKFIcTXeDJEwt4tC48FVGR7nPOBpY0mRuoPvIfLYUN0it0F94hKEBV6KaH3dsliSKqH4mBRuD8+G/eXiQtFL98fiOKaj/Me4+1pLNMTSqhFHyiecZA3wgmsEOP+2CRhtHhzOkPkY3nbZyQV/8X3iVkISPT1XiTjMJP7/y0gNXCfnjgb6eSBaFIfoiUqJQ+YvlzkPMP3xNz4b0k0qVsDD6nVffZ9cOfCUi3oDdFlSDqbk6fznMocoVdNqVeht4I3j7tWiBGohIWK9cAimzhTkdSbkhbzAaxbN7oanTC3XUj1VWDQwlAEGWTJu8INVhMc9MD04qGJjBl0iT2NTqpbTyVSkj9ykRApgkI5vrHnzkVWtKCndxHC3Gyna7bjEfaHfiflk5/lqf/hJzi9fYuzuXGtN7DOzcPL+0t5NJ/zgRc/wo8//A38hff8Bn7fh/86Fzgn/ZR68jLHH/8J3vLG38AHjt7Ojw63KAjeCjuD7WSw69gcXfVs5JhbMpc6DifT2PoPWSSRODwjt4joMpKUmTYYsfW3TmsNJ81R8n5Zng+X+0TmgGaC8iP58fuvpR2Pax67McG8xvifLhiLyYXn6A0xugdunGoiv3+YqdXgQkqEXaGhhOpEPhN0rDhzXx7uOCC8hIGvuiMtNu8LDBD3o++76GrRrYpn2uEiW4m5OUffX1woFzEGrqnzDSNlwymeIXpCNhEt7kMLcUcaZ+WyJSfwNFQpufhqGgVroeyEBPE+hLD8e4TfhX9SNcn7PXFKN6aS3VPirNI9f9505pIs/O7suUj9fsH8aq/XR5H0hQslmSWSgV5LixzvFq6G17g5FMI3kMDPJEeoLpabWQ/9a6796SHFCjQwvPYW5xFJ1q2ogKTVfQ4AluO/9Pim3YU5hK4pbcqUvJBuBAUjQWrE8LnlSRqyskphVmfOB2nIxxiPsKkqQ3BEiSzvIWAqyAtcXPCurHZkFxLkePe9CAzn/pgTLIAwWFWpufkF3Kkodnj9gQsRN5ye3g7XHnMwZd4U1m98FPtt38fJb/61XProx5l/+qPYK0/zEDdR67x8fHX/Vca24wMv/gwfvPFO/vR3/GZ++0/8l1z0CzYXzttf+hL2yU/zvve8hQ/OL3FWR3w3szNgq8zzcuCUfce3myYocVhoF7yGh6dbi31OT5zMPaOA2dNnIExirae8tcUkISXWQ6KenqNxDaQnzi1R3JRwvm77dW28p0HvJkZnOs4YD9tCG3NJnm4wAvYGvzygNWfxt8xrZjEbm0JXozpxiFhMF+FwH27zLX+O9kDn24HSlV4lHbc1v3Zqo3OhIWnOuxT/JQahEtDX4qZjthSQmEQ8OU+GPCCpjEXaXtZrRu2+ty3zZaT3WK6UxX6OpXhnbc46oNk5mwd/UUWRUpl7YNSa97IQU1bIPDO+oc+pY89FjrX0qLWIzigpDc7xfnkG9k3aV3m9PookRGHKEbTWEDI5cVS6a2hgAS+B/YiHKN0THI68Xr3fbu/RlsAPLcexxQor6ADxIMWNHWD1wiVTKfQeZB23lgeUpH4n2vNg8rcMG4MlHS8exBzrMiq1SZz+jQgjcreIGU+7+eo1yLoEhcOlxzIgncaD0xZ6VfXQKbfiDJbgvC6WVHFSaokbfhjGPKU9MfLYVBaJg6EfXcsb5oGLcXYrcbsMG2snzD/wHyNHD7G+ep3y2DHDm97M4ekWP7tJkTOKGy9cur4f0dQbv+bmz/ORa2/lL/xTv5vv+8m/wrZN3Lq4yWOf+AUee+IxvvHqZf7hcMJ2rpzMMPbC2isutpeqhbQyIjgKde8i1DNSdSFo+TJupzONR9XE3Wnewl6uBd2oq9JbcvlUkC5JH+zJliCpVVEQInCOpMgE9WTB+VzSBg2PCQWNm3S/nV7sxIwiMRYH1knIDVNO66Q1nEcgSHhKSlLU4j7q9AiZ66Hg6iVCI0ri5Dm8MtoySnuyNzwPjRysRHJJnhNTyQ5vuQeyaCywUSzRcskZYAHFggBuxM9WzbHFaQiwmkqW5IC6Rqe4NDuSfpvNA5vc667dIP1bJTFb7wEtBfsg7uGuYcDs+XfEeloOEpiCgducS9KA1TzFJRh7LHjB1ZeD5iu9XhdF0j0oE4ij1VLid58+4ZlJs5xp8QAv2FJ0f0uexTJBGItaIboGzyMm/PXi6y+EYizH0wLBBKuojKHyWeJDe2Q449Bb2IB5+lL6Mq4R2A1zbC7doUmP8ULCxGCx0Yqv5djir+cRMqW9EUT3EKB1cXotyKqkTji6o3HuKIFRuoP1dDzJTtn6Mu4koG89/C5LxU2YFebi9EvXWd6G5TYpZ3diIZYFed1gPZ/D2RfY3fw0qy+sKT063sIRD506g59Q3Hj20o394wrOt936HJ+49AR/4/2/n9/0Ez/Ia/MFj772NP7Zz/Jbn3iUk+Mz/sEojL1STahSkaJMJPbV5iwSxuwtf7d8GOt97uJyrWOE9Ry5ARcmtzBg7RpLFY/Dz0qle9C0lge+J91lyfA2j1hgiGvkHqYRZstiKMfJ/VLBce/MCd2IKwvYsSygnHhfl3F8X3BTs21o0OiTIlQ8t+y90fpMnydoPWOTo0hG8mHYg62ScD2NcX8+2ChZFowg75d9VrV7dI7Lwo/ET/GgAe0PIU8iBdE1Lu7okN+k5KSi+XYkOKlJ48M9vQ3i86Xn0iQPip44cFbzfEeXnz0pPPsvbXs4QQTECssKqrvjFovMReIY5bvvfXYjWiIbh1+mPr0uiiQe3ZN5KBToBmlf5wngLldZREMU7zE490V3LZpeuhYdV1lUN8lps+gaO+S2MByA1GKk9iV4LF3FQ9Ov4D23hgnwEh3ankKR45ItPDELkDwb3ChObrlsYG8U7GXJIk7YBKP2ThELwH1SdtaZaPShoiTfDWPlMF4k905yy7csHZIGRJLglw5BJHmHGOGkoxSp9PXxvvtbfmY5u43ley0EHxAJ1/ZqYbOvLJ2wsraZG3cNsVNw49nLD/2im+7r7z3HpcNH+Eff9Qd4x4f+GlM75eizn2F9s/PW99/gR/qrzEU5lkMahaFUBgYaRtGMA17cfSR6+YV03PKXU3RPAA8u5LI4EGY0CqFHRyOZYhlFoO3pQkveu6cppHhQjPoS/WDZ3QGLnFVyelg6L89xLw46YZ/yRwqxiGVOkeU+Yn+oSMlmIDuk+xLMyDOfzWgWv5/ZHBLcBVsXYzFOmdQDEpcQRYhoSitl4d7jkFlS8bN3gre53IsmhJ2REQ7lMR/Hdjihiqg0nnDOvoXZa7JdHRZ6VVK4glVMRnGQhrceOGx2qYEHk7qOeC6jiZWMdI7fZcm+keRNLphmAAuWO4Z83hSW4L/9tAMhAuAXL+V+6ev1USSXU6mHEqYF0yHx1RxZU8IkeewuOb6eRHJdXFC60b3lQkeASmSXx8hsNYxMJTds8fWjc+uAD04tQtEJIK3QwjZ+2aTHj5w3tiTeAixOyT11sSLETZ4YYRGJ0CsFqiBDSYVM3BHdowhKd6yVMEOQyIspMmTkQCxc6g4WNcVy1roEvSHb1RjdE6TWEjdY0EWCACybazG6kvUekPN79HlH8BBlaY4QT/9HU0ppcQ3KCvEt4o3ulaNb24jwdOfZyw/Hg5Y/3ZNnLzP0Lf/xt/8O/oUP/1XedXaL+pbrfNub3sd3P/tBfrYLp2XDpgbBvqLQG405rlsnNLg0VKKQhg9n3BNFYjSWpGJhPXimKqErTvpUF5glLMzqAKKW/EOnJCd1yUQSKTTVNDKJQzcV4nvitSREZLJ0QLLfvi8PenR4QULpEqIszdZ9rzXO5UfI/NKbUYWmzuTGtjhTHrgugSP2NI6IUhDXSnHmAq3CmCPCg/et7kdiyw5KU7YXWmzE0cQ6XO/nhu9ZA8t9lp9rOcLGMxjLEfWlG126N9//b3TrsO/5RLLo3e9GxSUjYBfSetL8WKIqgivby/3neGEPBDYfDYlpHlqZ1a7pMLY8vntc81eoTq+TIglSC5761LlG0WwGWxpjy1GnlCBfSxB9xY0xoYwuEdwegXhLES1UiVGoJZdrIKgjQdDVALNFic6gQVecOW8sxYnTu/Y49cKQJvEs4b7lVI535stNEh2tq2R0gzMRxUprQQZBapB8MWByepnZlnjQejqPx/Nu6EWLk7VWTGDsEYa2kHM7HfUa7i5LdWLpFDyJ5GGpFls+6JeuxwO2HLgCnN0iEkAWcD665JJdScv3O4LQdgC5uW1Q4PhkR0aj8PTlh+jLuAc8tr3LcZ/5a9/x+/i9n/pxnjx/lYc+/DG+H+WHLw/83WvKIBqd5GTgyo4g13czZozRYrNdxYOnykBJ/A2ZQWtcC7XwWCyVUlZh0koQjgu5GNSWnNdpn9eCgZlSFpN1WZ74IIovbtoKWAnpqGaBlJxTl6UM1omIjkJXwWs++B5FoeP7jbK5sSMgl7UII8Kw0HRopK0mO4tYguVNjTMsaEcqziDO6FkEymKUwjLW5MIn7odSwvovlkfhvjV4ofiMS+DnpiUXnGkIkraFMecqvYeJL8yIbMNPtep+zM4FAEuLHW9RmGTHGkDSLDqD1lyS3C+BlS7l02Fx8hIigSDML+LE0HgYo3EQTRPhmIKWQyUw5CjokSwZOVi/3NIGXidFchk5VJRSCmNenAlnbuHVSDf6PGNDZ9BIP9vzvCB5hYE0BPMhvfLyIlVZ5GGNohUR248Yy/atWnZ7AnNrgV/mjRwk75A0FovWPnIxktOTwPNybzjRwfXsFtAgZtehUusQhTLJ5i25Y05s9OiO9HCI6d2gKhcVxGDsnZU41Z2dGCup+5ssZmr2yoaFMCt7UrQmlqNUOtvN1b0kbQF65OS1MERtc/DVyFs7IQYxzW7KQrrp5EMCbVDWVIYTx9oJ4p1nrjyS42p8i6P5jG+6/Rn+8ju/k+//5D/iiec/x9Wrb+F7f/238wl/mZeH65gOuO1AGmqVC61MZaY0YxZlUihaGMsIdUyjCdv/rOZCyfdXSkV0AGpqg+9jaC4SxdQssUEPxVNix7Sk8uSWdTGDVneqhgZ/yZcOB6D7muZ5wcuXMUMzS8ajy20syo/773/AeJKYXYzkELgyNfHNEHTvO0iXkvHL8TD74jO5FCbxDEELVkQraQ7dp4B8slB6siGaBzHd4y1FcFoaHISz/rLXz8Myn52IWhkXfjjhg/VAl2z3aT5kwRX1fVAYPiaI0oP6tCx0lu08S1ca93YXGJZF1KLkIWI4untGxRra4tmLxWYsQvdUMYKoHxF6X33kfl0UyRiKgxgdgnnHqjC7MKTHnjVPuVWnVacto07+fZ06bpr4lLEUzOgAWmCZefpB4G1Fa5B7TcDCw3PReE75RgpxMcwicuH+iAR7gh2StKHlIi7/bizO1oWgDNVSGIeQnoUW3aC3AO3zpiz5U5TEUXxQyiqUNLXBpnWG1qOzIrpXI8YviQaZfZux4ENLmcrW0RTa8ZVfBITjwMlreDcuQufEZJ0pRzNMKFIYESrRzQ8SIWfVhbJ17hXhtu+4vdsxTmsetsYLVx+ja2Ep08d94v23P8sPfuOv5fc8fZM3rS7z1MuH/LNveBs/tH2Vu8cFhiEYAqXiVnApNOkx+klI5GZVXAq1KKV6ktbzgaBQSkXLkJuGIPe7KMWykDi4h7vTAxY3UdeKgzWkL4a/vr/XFgoVS6MEeNrfLUsN96AVqSwMVVKhKohFEWotDJnDeCKWfSVd6k0KLK5VOHhyH9yxFsfB8vfCPctjQ68RpObZPpk3kMqSf+M9Yg5wo/kMSiw8koPbe2dOSplbvCXF0yIu7ctsYZp4TCW6uGxRkp/r+834fq5l+ZzENZcHX5bbMiEOZV/QFjrVIoGVpHSFZ2d8AclSvD/4yINygTR0gVNzOcV9ClbYKvZ4vxa+6Fd4vT6KpMRoAXsGDlaFtQR43V2ZW/hBkpQalhF3+d06sQUXw5kzbP5BYkTFpSB7PKXk6BSGFqZBGtfcEgtptuChBS4d1FPDnRd+TzLKTngfcUme9niYqsYviSRHDM/RvXfUG6W3kKOVuKI1i39X8KHig3JYh1jQdOfwXBjnwK3UFrJvjiYLkXnZvBM4TWwYjcWJWjv44bX40fItdEDvvYa2eDq6N3Y2c+GxQDJ3ildWAqNDtcqglSISZG/p3LQdd/oUQMXFjs3LO95ozovXH6dpzWsB4p1veuVj/I1H38xv+vxP8o6f+jTf+t2/lqcfPubvt1OmsWIT2CgMvWBW2YqzsoAvnMJk0S2bONp7mGZ4pxLvpZRKSQzac0myGC2QXo2CgA+Z7RLvRixVPFxycrKQRamjgpbAujwpNjEuO5ZGKD0t7Uh37aWhVJdQwfUIIr6/MIt/Bnc3N7GiqIxUiWxomtJbONgso70kVSY+H6TCPgs8LnzkLSXk4bkhX561Jg3pAT/FJBaZ6bNlHkNfvsYcz8Sytt67ekezofKArFCCWbLY0izkbdWk85jfX2rmf5o4pbQ9xzF2rAvvd0F4YXDfD21tzxuNiY2+8F8CCNae7wuSiqF0/8m73T0OqSqGl1hifbXXrya+4T8HfjPwiru/Oz/2fwP+EHAzP+2PuPvfzj/7N4A/SLzF/7K7/3e/0vdwc+hxnYYSKpPZR8QPUBvZ2TnYnCf9RPh9ZBtNQVq4BZlOuHcWmDpO/8iU6RrYVSS4EVwqJzhbOZJ7iY6u52lbJaIwG44VR3t2qpkb1LB0Uo8ApQCROzXJquYazj8AWgI7s8iLnpMPVkTpqpSxMg7KsBR3rdQaoEoY/gZ8MBmMNkeR1BILAodgtYQcMxjRyw1TYgyxvj9ZVQtYhcNreRLff1C5d3vvshJZ5TPdjVk86EzubD2+V/XOqneOdOASyl1xXrKZCWcgtOfTxTn1pWe4bp2XbzxJKzWvTRxE777zRf7hW78Juem85XOv8H3X3s3NAh8ud6iqHE3CrAdoaaxc2Xp/QCRi4J3Wlu7IybUsXQ2V4FaGy3wPqKU3fEnj0yx6bqgOdFYUWTqWWNaNvdO8Lbz0+52POt5T4y1BcEEsNuNJeu7FmPcUA4FcmtA9Mm+WIuARBbzo+AMJ91gyOvEEq9N9SoldjwWVOcK432qbOkWDIiUpzxKg+y6bglAa9X2hzVHcQaZYCunCzLDA0WdpySk0Bk+VC9HDuUcHq2r0dBpy6Qhzbr1lf1+JxPVaXN37/Zsgp7y8B7NLN3rSkSLDJw6v5DZ3cIsmSffGxEpnxx7XyXF9lsBl432wiJowMAuuaXTnyvwAjv9LX7+aTvLPA/8R8Bd/ycf/A3f/9x/8gIi8C/g9wNcBjwF/T0Te7n7fkvMrveJxTpwvSUxDycREBvB1AODh/R8WWUK0nF3o0lL/uSBu+QDl1VlyNapK2Nnrgh2RmtYc25NiZ0BXQTvgIQ90kcivlgWwhyFTHXuAMyzOy/0BztxClYgxI7qehYKkuSEtdUVZVbRoqIi0RCFTEDXGUUE8xrDuHLoymrP1xszAuKeo9OSDyn3dMYBE5xFZ4VFs7fAqsvdSTKLw7gKZtqBQ5gH6jKvSpNMtsr6bGFUiUmBkxeVh5BIVBG5PF9yjM8W9QKXziAtXZ+f6y69yxZSnH36cqQzLHQMIX3PnaX7y6mO0u/f42o9+ln/ufd/I5W3nR8d7mCpzKcxD+C4OOmAFvEYqYVgwRWiZSEc9Dh5Jb8duU4xnpuksPlOsg8bftyo4FWQM2zonnN59igPG70dEkAa6HehtSrmc5G6ix/3oZX8AqJfEDfO57UHl0Sxw7qn/XmCVBUsm1FdmjbCXzWvnlUYJr0iL+zM00YuDVLZihOMQ3jALaWMcjgAKvUcevUuYzpb4Hbq1/F0Cyqp4jte+/50CEwryjXksRMvSEwqodyQfd88W2r3j4XCR+HhgpZ5Y6bLcWaYgMyKidimsDrGaSfZIshQQJ+h6QZsLJZDkGx74qZhQZ6MVwwpofm08DWh6duNLvfgKr19Nxs3/ICJP/Uqfl6/fBvyQx9rzSyLyeeC9wE/+8t8DdnNEyWoqaSLHQhnXG4oOqFdm5rCCl6C5VGKLNovGhbM5OYpxQsQkork0iW7Ca0lTzzgdo1BajsD3uZWBacT2+b6hc2ChcTMrIiWLT2hDk9uQpOO4sQaN09tL/lP6HhdZBl0thdi0Fabkimr2eEWi6zAJvK01Z9x1VjgnmfbjZtmFOHObqTJEspzEDQohcYzlQ7j6zYdX4sldsCBATm8lvcOZFC4ctmJMOFO2b0euPETloXLIoW5Qh4s28WXOeZnGmUYO0OSxqW04J2q85mfsXnmaQ9sxP/IUra7uHx4Ij529yMePb7C7qLz7I5/gd731CeTawD/kNbZDwccN1p2hZQdfF5zKlvs0xixZ/l1z9OvQPQwa+kyxwAH3RhISGF6MB8FOD/gufUU1sEBPXXwE6wm9B4c2J0yiGCymFYtaJrrb8DmMlEXmBr3nw+85usdXsLyOmt6R3cJcZc+tzK6HxNDjy4e6KqAjcryX7EWjOse9HqOuSYBQGiRXvAdcE7S6+0a9IdNdfBiDCYA3Oi0drzQ7Pw1HrXRaUsIkJjic9+k9sVeMHzD2nTlGJ4UOcpp0Ug6ZixTLZRkL3zK7TYWZTvGeES+2x+qWhaujGXO1/J2gZcWeUdLs2LOt+icokr/M6w+LyP8G+Cjwf3L328DjwIce+Jzn8mO/7MuB1hOz8Rgt6aFv7lYoOrKqTllXWlM81RijRychSfzFiLE3ZYaLzMoAUccr+BA3TbEAdt2TkO4ORLKbeKKKMSPEdl3j80uJDTzc7yKDlA540E5aFhT1NNbQ5bQEvCdJWVh8BEVKqh0El0KXTptnVIP3aHPiXwZzc6azLdo7s/reJzHyeZxmHelJmM3QKmHBXoM7hir98Ap7FUVeBT29heN0a+xkojEhvXEoylUZuFJGrtYV0DnrM1/qt1ArzCif0IkXTNjljdw0us1Xi1AdvobKu33N4aunnNjTvPCGN7EdVr/oPrh6/hJfHE5pN2/xnhe/xG//Y3+A6exV/sHnvkQbBtrWKMMENsVD16JL8uT0xTY0uK2WG/fuExlJmTzHoEstzj9aKp4hWsvib5nW8EWKF2bKlqYN4h7+iSw8PVlWaPE+uu3135ILQCcLWzesdaR36v70dXojNthYdqWNpi0ZEL7XU0eB8/uTCYv/aEBQNW3NEnXYb6IhOcF0VLPCdgUKrU33b08L7qAVkJqihEgtwwkly5zvAeZ7pgdqWGnxDng4U8VGO5qMQTxNidlT9HzfJ9T4fRZTDI9ipl2yC02ZqN1PuSweEAPZacYvYPc34MRm2y3YEOpC7VESWQ6PKAxxffnqoOT/1CL5p4E/StS3Pwr8CeAP/I/5AiLy/cD3A6wORnY7w2RGdA76Rle6FpokzcQV1c4wxHZTpTJAgLEF1AZKq0xaaL7bO7jgQaCVJUNHkpe/2KwtoHsqVqqHlMk0ycni4fSa+IhKZD8vYLkT3UvJiAl6Z7CKLb6R0inpJxk61hj7AHpSdnx2pKbPpYaPH4mNdvUYX+ZOs0iL1LMWuX9WaAVWqdl2GuZT/NwMsZnUkgWyBF/P0x/z6PIvOjvdQe69Su+N5h18xwFwpRxxKAespXDKzMtty2v9nLkaN4pSGfgknS8avCpKF0vMVti5sZLIX3mhT9yk80/5mrfd2fFwf5lPP/4YZ0N4RC5k4svzOS9ddv7B176d97x95J995LsYrl/i7//sZzg7WNHnE3QaEDsP2zONLiCMTKLYRfRsGBg3K1SGcBw3ZxJhSLmpSogXJLFao8Uh7ekWlUUvuJPQ28IQFDzjVE3S5FmT1m/L5HH/UAy/QomiZPnFCN2y9lxkqEY0qgTZRXpH1MLSJ5VGXbIgSmBrmDJ6SCQ1ZbxdDJ09sDevDF7oEqT0Ja6g5wFQxYJmtOABSIz+NZZxQngYuHhQLVxRKyH160KT3Prbcs/GgiwajvQRIMbgKKxLF04WNssPehjPeGjVs9ImVzOur+TUh0uYknjPTr2GH4MKQ4/3vEmsemKx1hKqykYKgtecs5xld/vLvf4nFUl3f3n5dxH5c8B/k//3eeDJBz71ifzYV/oafxb4swBHVw59N3VmjRNpZZ3qFS8B/jbipi5FMumPfWy8a/R/VgPYHeeQJHkWQ/NczGgw8jVb/PisvNE1RykL/seCr5TEE9MLO2kCC29r+Tfbm1mQEkExQsIYzWlumjUKVbqbAwHGi9PnGSzcm2viQy7CbE6fw3qqtBy7zTjcOUNSHqRoxKiS4xaWI3aOjst4FS1zoL8m9MOr+1EI4uFsZ6+hZeBQRq5zTEE498bNPvFqv8OZb7lM5TE9Rlvn5XHmE28Y+EdXD3j2fMfpzTOunnYecqEU4YWhIDOMDByK8RERnrWZr2vnfOu58q7nb/MLTzwUhTK7Ai/CajROv/x5/vZf/4d8728q/M73vIdNvcTf+NjHmMoGtYrudgGv5QNZkFSGBF4Wmkn2rtrhcq5BhxLJPKX8nrm5domlRmTgxLpbs6j1Hvw63W+KBdJVphHJhFoiN6aRD/1CPwEWzl/XEnp9Su5se/Ivs7txWCivy/JwUT+ZeByi0hd79sShSRwxV5YeK2BBghepOUx6HOrRmYVBb9aouB2zcTC3oClJ2NSF1ZvmsvMBI5bocfP7O0iJxmxZxGbhje8bP0DsgDwlh/nHSdgPgj35bC265LCfi5+zB43Ho+koecovrA7RBbu3vUw47n32C9vmuRQj5IzDHpf/n5knKSKPuvuL+X//F8DP57//LeAHReRPEoubtwE/9av5mt00zEO9Y60zNIubkE6XGhbwgUpQF3Lr8h8Naoc0T9C+YrXGBV8ciHMzFreOolrpaCgZ0pB0v2Vbbh6WrmEpcpY4V2pMl64gRw8xwnTUCMwJIuMFwJMftnC9iKeh4UzumE6MvUKtlEHpNYp4d6GZpImsIF7Z7BqeJht7vEniq4byZgYb2PPU6Em/CEVTF6EfXmEhGwsR3bs+vY0Pla3DzemE1+ycW77D1LlU4O1l5FIfeUmMj9qOLz5+g0/8lm/itbpGrbC5ec6tZ1/m7vOvMt58jfXZObe1cyYTb3DhDePIl3vnbjvj7vacb51OeWeb+YWnHuN0NcQiZSxhPjvtKB/6PH/+3hv53u9+he/7hm+j+wU/+MGPMvdKcwkllAzInpAch0YT6KWhfabYTKcFJpy4mCUrIUY1ywVJ3BlzGmSIpT+n2/4ei6ybOKgkj2lZ9gTuOIWuypyO2iFXjMcz9t/hPu4WW2tv2Ylp3J+dHB0X7FCyHBmBSfrA6Os0hMgOrOaonBh4JIYG3ueJbw45YlpuKyX9MuPWXQ73xHhlGVqVZavkKtBLTCeuOT7HYdO0pXY8K20e1AtTeHHpIv+9t7Z3Ut/P+Bq4PsgeclUsYYsS8RtZ5ZcAlWAgyH0KYAwS4NkQSLg9RbxJQB7lAe9Ol8CQ+76T/CcYt0XkrwAfAG6IyHPAvwl8QES+Kb/y08C/mG/CJ0XkrwGfImi5/9KvtNmOvwdzm4l85R2tDHGjtYbqEEL5LDKy3yQHTmuJVyw27UGHyNNXNMDC5GbtOWYaJhaLlpS4fbEi9B7u43XffUj6TUZ+R9j95/2DIITdFRa5LL0ZU94X1cP/UY1s9S1xofs5PE5sEhUNX8Qi6aYsqBfW7kx9DgPaKIkMCTjHCghGKcwYkxs7+p7nGYsnkNTqdu+03pg2h1jNsDDiZ51t4tmTL7HzLL6DcMkL32AHHNhAWRfu+AWfsXN+2jqfOhzR976DV4+OGaYVmNEeucL6DU8xfLNT7t1Fnn2Jh27f5piGXznm/MajrE9POf35T/Kh51/kE8OO9559gbd+/lW273wnPqwDDjHj7PApdte+hRs3Z37sv3uBvv1xfsN3vp9nXnieH/n4pzkvTu3KYV3jpTKXAcpALUF3MtvC9jycf3C6hvyskDpl8/Q2bNlxL4dZlLRCdNdesvMUDc29ZdJmjbkw5Q9RJJI4XjS/tuQyaInArQWxIW5Jc/DImTYNcv9yMIcXaRygVYRaKisfmMtEqxLxJRZF2DW1Ii28D9hv3AMiwkgnnJRG5v2rxD279G0PPoueE5RnIQzyQnTqBXBrFDLIU1IivC9wls+n7TFcfEklTTMZd5Y43qjKKQzJiheLGk0qFDGtZd/qhNSwmMe2WlP2mkmQ+5A/CXJ+2insn3VhyUnK0TzjKOSB9+CXvn412+3f+xU+/J/9Mp//x4A/9it93V/yt9hHbJrQ+wTDGhfFdMZrJui5ROc3SMSypntIMHVsL32SxA5DmidJg4BeFm4VuM8s81AERMW4qhKk3ugmchRIyCZuoKj5aoKnO1DxgAW6leS1hg+miCOt0EomLhpJYk5ulwQBmZL637CNREUYk5bkKCtVVsWYcktb2oyKM0kBHRjEA1tT3edBR4MQBWLZCjaMSTrz0aU4kx8Yy/qdVxi7caSCF2E9rzisG2pRLmzi1d0ZX/SJpwfYeeXJdz7Fzz11zMqdNhg7JmBg8IF5qGwfuUZ57A2szJES490rvkFk5tLb34h94RlOm/G3bz1Hf/FzXOs/xQfq+zgy5fzat7A7/Jrl1uDKychH/87nOLh6md/7az/AZ57+Er9wds5cRs5ckXGDjBt0XIWzz26H94QhuuDe9tGyM3HTlz33MBYt+32oQJUWEFwBEw1Jastuqyha83gyoWeHqJqHt4Ay5vdbIJGK6xhfK/E2jX/B54GwwICFGIUm4cVDNlt0YKJgozP3Ti+GSshm8bTo8XyzBHqFXnxvKBwc8LJnbQSVJpIWqwQ7IuS5i7FtZs674FqxHsoj73MaescIjy9xIPExUU/C9v1GQjVI3I0YsZc/W/ih+5l7+RpZrjRLpYgEvcktnlvNHUBSfCLPRvbqI2BvkacWyh0LC6Bc6mUn6sSCaEmM/J973P6f/5Vb1ux6rTeKGF5KYkwtimGp9JBDxDjTPIqOhMFFzxE2Ru64qT0VO2F8KxQNQuwieNccb5ylU81xWpPCcR84SaeXpHlkSBOe0kInOlhNPDIeHQSleYzfJcdt85geFqVMZXGGiXvdln9qOJ0oymjCgMSDv9syWg/rrVLoRBEYfBH0L6YAttDmWLwSO0Y/uhrLif3pKmzPXmbyxuzCwzZyqR5wTzuvzifsfOaMwG9uWOPao1f5kV/zKOdHyhAsGLwU5t0Uz5ZVpJfkcwyoFagd9S2gnK6PkHe8lfPZoF3j6Dlh+9xn+enxQ7xr/B0Mh2/+pbcH6/Yof//v/By/96m38r/+jb+eP/7D/w13dIONh8h4QFkf4FWZRbBa6TvBW0fNGOZzpBGLCyIPqTaJnCA1ai51PKcGKdFhL6olJBZ/tn+4Y3sdSYiVTmW/WZVC8SRAp3mCuWISHEdLByq3LVoE8cxVl1jITEmtEJw1wkgk/ukylfTABpeYiCWuRJa7xoUZAwlwquQtbOYJbS5KGbIwKM1mSh7kruGoWjwtzFpu09P30bMzbImBFqkBaWUuFL6Q23Q/wbj28OS0oBVJYvf3ieYLRpy1YOFNQsJFMSaXXIYGaygKqBN2Yb3V7EqXZktppLVaPtdKPu/LgknynrAFHPjKr9dFkRQR6hCRnNbApaZDygx0ioEUoUkPKsRiatsjXraIposL0ZVp6ks9QOjZYoS2DBGL9vz+Q/Nghknb8+6i8wTiBo2mKw/tOOETAgkavIBKBA4VTfcWjQueGDsuaXiRW/aiYQjrVdGxMowVrXHit+4LoYRmBA3DBJlnZE5XIg9umCdJvia+aMRDJx6+ihSh0wKP9A5H13Ncj6wRB7Z3X0IpPMwBp2q80F5jwLlshUtSOamdyWfeeuWQD37fk/zckyMbNwotQPo2oF1ouzlCnNK8YO1BAdqlZjkFE3SLA2wYjpkffzt3ph3t1S9xOv5Nvv7gUS6NX5f0m3jdOzzi1sGj/NSHP8L3/pbfyE9//mn+9mefx49vMNQRqQNL1+zSkWmXRSRcya0FiVzzvpm7MnkDmXMqgapKHZeMdYfFMFeEojOL5Z152Q/aRsG8oJR82OIK7CV64klrdGoJjfi827IYSli0TUEvE029dJzeLuBVEw+Nklac9BEIhsfC4AiKU3Sgg9YAW1wjVllgcfhHgrqGLmSZihAyyR78nPSBDIs45l1MS/aAue5S3LhfXDx/8+gSH3DWyvehWsFSzhmnQnwvhfuMk+ULSPSU7nFdBssjQBfifpLJPbtSJxkDSe/hgcIo2Sfk+xQwXXyPnu/bEpT31V6viyIJkpQJAR9CmeAhSCoJMndzWmtgSq3xC7aezFAL15BWAj8J4nYPkvaysVPdY4HFc6+7eFKSb6pK5tbI/WVX3oOd5cSJ6xjGAvl1UnJYFLSl4Stplebs7do6hg6LKUF88bEqMiqyFmQIdY8lvlkyi2QWY0eMQ6LGYc9NpxAONdmDGp1dsqFzjUCRErJKDy12tw6Xri+/Wrz7Ikz3XuVCG89ym6tWeURrdjLC3dIxZt4ia6an3sBPv2nNeir42iiyi9HQRqQ6vjW8x1JAPagnYXQ77Dv4BbqAxnrntOEGvOUbme6ecnH2Mi/c/i+Ynvw3uD5dB4ez9YrbVw5REz7y+WPe/unP8Xu/6/38wqs/wvPDURDCIRRCbYbdOeX0HuPFKbY9obcZ60GG9u77MXyWWBQOqsl17GyZqAZjKWmnJgmbefhOJu6497KkRIcUPJ6cBDoa+22qRn52M0EI+WTrLRaUaVgrxEEsEN4BZsgAkxjbagxDoZsikyKlhGN/RtQuU9jiY+AiaK05QAhNNUxzSe6mL5Pt4hEZDkeL01M0y4ZLYu3pNrpAnNgy2SdKmF/jflRs3OsuLT9PcK+pLtO9K1by5+//PFkg92wkPJuQlF6IA0EHjPc4pz+Lzwv+6/6RxYkCqSbZdS4fj468WzwT5DLzl6ZhPvj66n/y/+NX4AMFLQNah9gCpgpg9h7Li973WJt7AkCizB4RlNYNa8bcegLHDUutri9KGZJmkDSEENtIUg/SWqtURGvmeMRNuFyUmM5j7AgTdcEoeB1gWFHHFcMwRCaPp0W/WWQle4xFqjBWZbMaOB4rB7UwilAwXEKbGye9pT64MXnjwidU4bJV5izQQ5LYycXMheZNZYmJlvidzSMjpUnHj6/nwup+wTo9vUk14d0c8pSu6Qa3MV6VRne44Yocr/nQNz3EhYygQWBXh7XUiMiVTIVpDZlmZGr0bszWkWaZOTInHuaoVM7qyLlUZDhk/canWOtIn7bY2X/Oy8fObhx57fplyENNpsp/+eO3eeRwzW97/3sxb+yGwq7CuU1Muwvs9C52dhvf3aNPp7SLHbadaNuZi+2W3bTjYpqYW6c1Z9o25m2jTY157uxaZzc35rlhLYLgWvL29vSRvG+FZWLI+8OMyLqZUGnU4owqDEWgT/i8pVrHW9LNlH0MyIxnhk9mMlkHW0Kv0jQ2p5Q4ZJSle1qs8lzTA6vERJLTeXarqQ5bqgiSGKlkPbQwXekN6z1c0D3oT9aTBpV/ZhZYo2WRWULYnDxQJCSyLim8iG+3xyr3914WefI+XJpVcXkg4mLp5nNnQFoaeiyrPH/ugObiWXCJa7bDmTFmMRod8zQuNs8lXMSleG9ftTa9LjrJZSUvSPAKl4WLSziSAKqFUStCYfl91MOcdlr8rVygR/bLrpB0BUl/vADLA4MgXVaUvTcegQmJBOE3DerJe2jfjSaBCC2h6S1eoAzosIqTujWKTvi8o03ObDPI4jyTG7wSuuGqhVLjnxDYjrWgVFQqqjVMC0icCeFSFx6dhGaNwZ21Aj5TUSqVnQrrHqFTnaC7zNLY+YR5i7F0cznxyfi9Boc3n205Gi7zom95sZ9xgHBFBo5kRLUwS+XsG97Mp954wDmdcW50LxTdMDKwcwOPjqTl2IZ1SqtIj6yfUtLw2IPZGOaqHaFxzsBw9c349RdZ3f4yr9x8jiv9T/D82/5tavLkklRCuyv8pb/7Rf6Xv+Xr+PHPP89H70xB/j45wc7OKNvb9LM7zHMQzq0ZZW6oZnBVhoqpBQevm0PvmckdvqJWLeAdLNxziqeLdYCwi3u4lCiapRewWIIsKquA75xwH0nz4N7pzeOQ1xbfq8QcQItsIlcPL0v6/dFW7y8ytOR6QwmakLG/W0s+QDGeKurp5pMuTZJ8RqeGUbUb5HMRVCniXkyUU/DQvGPIPOeP43t2h3vG3ZZoBizDnfbbdaJrDL5zEOuX0r5g4pYFGu4PvY7QfAFQ4mV9Zu+i76nG6SCiQbbP/Nr8tvE3k8oVYYBEbpIFG0YjTwOQDP37yq/XR5FMrHXhWqkk/tfyF40VX5xEyesy62EV5XFTWn6heD57lLIaBN+YJCw0s+aZ1CZYKRQLDLOqJw0khwcnO89lTSdJSA/zhKIV9UKrhTYMrGVkxcAsnW6aruHTHlBXhMELDYESBaKVcJGOlEP2F4yliwCKxMNXtVBUOCqVK1OnuCEFqrVcEOUtvbCGEUQqeA3VgToDwvb4RmCRAoMrh16Q87u81rc87ROzGccycEMOuFLXXCkj3WfsypqX3/U4tw5mxqnC7Ixe0BqdS2+WUNOSrSPUHl1WEwsoBN1zRc2jw4nRLDbvF3XAbzzF+s6r1LNzzuVZ1s/+GfoT/zK63KrZbrz8uQs++LEX+Z3vfCOf+vsf4q6tOLzYcjrdwto9aOf4xQWLObI69KmH36MJkrhdRL3GwRmEe9AmmUcT1BUdYlxrGqOiCswWDkBhOOwM9JQuwuydIQ9p7zFCxkbZ2Hng6sUF6cpAYMOShK7Z48EeWMbpmHqLRGKoapgHq4dstcoQh/ce8w2IJ2g+WUzz+Zr2CZPkWCt7XmZs3GMoaav8vpZ6ceIQcbPsPC2xQdmzNEIJE9/TJTHxfcvoVI8JrON70v4SptbyudbUils6+7gRcc7xkybn2RPTT2OZnNsXiXH+VnGb2MTebzMbnfjFkvokjvuDXflXfr0uiiSimAyxWRRPInZQR4rWUIOk/KuqULUgpntDimJEBxaOp4DAHLZpbiWVMpbji+/1toUA65Fg64eeVJKQAUjNBUyc4ENu9ETiZjUBhsowjCgDysAgFZkddBcFPkenrkE+rqVGolyJ061LMDZbNzqBVZVc7EiOGVUKzSdqCXek7jNFChXdj0+Ssbt7vE9ymPGOdhiGFaey4+z4CkfAkVcGLXQzXj15npu65WFWbKgcDQcc63XGoSDtBB+cO0eFL1ytOOFY2DV0wmF6KWhzptnANJUvgEXn5A6VuFn3mCRLl+U4DekzNjfa5mG2178Ge+FTlLNOfeUT9MO/xnDl97A/QNzofebj/+glfu1vfRPvOi588NmXmOct2hs+TdAb4hZOTkkNw6M4oQO9DJiW4Py5RWfSoqvaFZgcht456OG4NBvsmTHWYyRu8fArzjY7ojDNNVqaAy/RrqZG61BaSPoWzmtw+dqeD9j6hKMclFxEZdFUX0ZuKJo8WqKw91w8lsQ1481NnF/CxmFxbfceOGx874RlWBZIyfP0MK6ORiRwQZtnsFQzOUHcFkkmRdrwOegSiZDg5fL8lOaMWhMHdHY5UeCxcDUlO/0kQXvgvjh4y35yKcxkF+pCRC2XhVuQj39KRkSQEoekJ3thEZAvzAAYEvcsX7U8vW6KpNRNCO8JTCQuRqC0Y2ImS16w9x7ge4tfflGx6NJBAaqOePhDisv+4pInSnVJE6qFpJon7IIxkW7iRdO2TFl5fNSlhDJGlM2wZmDN3Ets5FsLK/1A4zEvtOKYFnqmGEozatIVJpuQZMhVHKkEudgbqFHKchIaRYTeOnfVER1YWfK7rMeuVcryC1I0iL9dZqooO1PO7Yyj40c5kCjYWw/X8c2927yNQzZeOawbCoW5vcrOhXE1Mq8qd77hCT58uIU+IF2R5mEM0jr4jDTDJg+5Xl4F1xhLaUbdzdF9KCkTDPemjqE2o21CW+dChf7QG7k030FffAHvdzicf5izd72Bw8MPZJ204CjuJv7B332O97/7LfzCpz/LhSj1vNMnx1pY0UGoqfrykJDjmSqzgGgJpk6AJ1FYGkBcxMkMm50xDU3cBW9C64JPlh4B0GosBr10xBo+DGmJl6meRXGrjLuYLC80rnUzZ06PyKG3UJoA3ifcNtGpWW4rFq9QydYw7nRcU14qnuqwB8ZWib8SAbJJS/N0BLIO3rGUx1o+F2uLSaaZJc4/Y/MUXF598Cl7kDhzv3PUFHIsyhpRZacWIoUs9pWSB2QsIAseU12+9c08P3/BeqM91ppLyoWyxQP3myeVcL+lWQ6S+/NcLJICo7eM6ujd9ymmX+n1+iiSqpT1JYrvoF/gbUAxijSkx2jc0zJeenRHxgK+xi8ffntJzVk0pHEd967F4SpdknIAFg6r4QpekyMm97mT4kEZUVUYhNY1bjhZRu9KKWukrNDucdr6TGuB/4X5wpA/xEION6QV3AZmUWaNTGgDSoHaghvpQ11o6wFQS8XEOFt37q6E3bzjqIThgJfgbQYXU5L7Fx12qbAtEztzrtjI6vKbuEA4D8MxDhDK2WushjWGcXe+x6GsWA3XGTZHuDnl8Wt86c1XOa0naBMmc7x12lRo3pgBn6FYoaV5h6DUZkxYPFgWFBQXz1S9cHEyM5rNdIcLlKE551TKQ2+hTs7t115k2y7Y/NSf4uQ738Dh+I6wEgs+NP1i5ktf2PC1l6/wiReeYZqM2md69yDTq0deUZqqWh5CKsaYN8lQhlzOhR8lWEwusyBW6atCso9ppkwzTABzx+cZsYBuppVygbOeC2XSjBmw3L4KTTvbROJqlzQuD9rOzoXSCYMVFHyILssbXQpdLNyzTVIyOePEsgcLUrd7xqyKxEICRWRIKKszEiTtsLLrBEVnccDSZQWEzZlfriUylvouYixKTF0sdoW0vXN6NBMKNNKrCBWPLj2nPO1hDWc+BZRlBXFlTK4zBRo9hpN8VpZFjJUIVBs0FjY1NdqyrNvNqVr2SjZ6Z/CU8xKHwERjyOI5q1J6KtNLNENf7fW6KJIiSl2vkSYYjblMdCLHRPOkiJFZoRHbtd73/MWF97RoUIMDeV+HHc7kyUesNQoc4dWIFkTD/Tt4XLEpVxNWOepI9wC+nb2ssLqhpSQTLEZwsznGybJYPuWPBYlzBgYS+MocF9kiv7pL2Nh7xg6YRufSEq0K099KQ7izViY3SohcsSGUHOLCqoFbYSfKpqwC5513XNKRvhbuHl9ipoEIa4/MHTu9xavzXS4xcHk8ZigbtDfatGUeDlk9/ja240w9P0XcKabs0igeC+9IQelzjFLFgDlca1wcNNLpnEjhkw7uNYLGvLHkx7jDNnXmZ+Mx9sRbWc2V7a1nqYPjP/Vvw3f8BxyWhxACZujzjNxSbtx4H+tnPstk0Ocd1lo4YGeeu3hlwWwFkG7UGp13T4dxIW38vdO0U5Py5T36QbdQbPRutD5TLLwtZw8z3WFXcvRO46ge96RncHUXaNr2nViZjCrKKIK0eG/6Ehtb47PMfB95sOzUA68zllWDEj6XyTbEvIcTjirK4q+alBcM26d7GvgUF1EH1AdAmEpKB3tLxZpDLan0DRpS0Z74c2zdXZedwlJ0ia2xhYt6Pp5J2UsyebprWE6MaiH2wBdD33iAPInu5qEkKkOl9U7t2TESS9dk4bO00nvYKT/HLb1apYTfajpFaSnU8joft0WFMoxxcvQhNrsypFxssWOSBIrBTLOgpB28QEpdWM6gRVi/ZJvUEhrXakKtFS0xiqEhp9I0xSVvKMHZWWxkFaW7MVBBjdk7Nu1QQkmx0kLVIS+M4bTodt0p2H72iWsVY82yOVSJG6OoYzV/jlqgpmVbixNRYmZkUwqVQknDX5ZiOTUqxhUqKzouOy5sDr2trnAdeHk+haPLIDB4xOtuvdPv3OS6XudIKutWYa60sQQssO68JDf5mO84qc7cG2WStOCXGHvnwFabwEzmHpdwznbP6dhiExz8uhz3Yl6Ijn0vJYufa2LFadnQ3rJmt1EuXniBRy7OmT/yRynv/QHWukmbs8bsUG+NvP2t38OHP/7/jmgFMbqFCUbPEZb0ZpTEtq1NMWam0UWsFeIesr0hM3iH5iUPv6XYBA5OD+5nV2HM/J2dwuyBdaoUusbBHMYpufRwiWiEXB6595SzZjDYgouToV652V6iRmIxF0skN6dZdnC+GGM49DgMY5AJpoP1eJbU2Hdpml1ZbNOj+100PJLFmn2ESDpxJbUNJznOgfMtJrpOLL6M6Pq6NfCSWu5lgRKWb0toWbwvmnCZUBc1DyEb3kjkXNnc9z1mPFf3h/6UglAkVHhSYovteDxnEnEmluVi4ZVK/eql8HVRJN3jhBatSB3RYZUOKTEmZSJG3gC55XNhLo1FCqOETRbYnoDqZJFUSTxK9x2LeYyE3oPvVXJrqRp0k946zhAXUIWam+3AWnrgOX3CS6V0DRMM70GnyNMzHqCw/1q8K9VgLuGqrCrRRYgwlALFGYINhJSQkbX9QxUqYfXGo/OKY11xahf0eUKlhr9ejaXWqkXC4+wGw8ipGs+3V7l96RKPirAOfQgd52C747KvkF5oOnHCluLG1IxDVrRR+NLjxmc2jdW8YXbwFnhm4L01bLXSWKEQhq09HVZUctTWIL1L3saxoCPjEYiHeYmhCACFoa3odaS/6T3Y4YvceuHnuHT+PHc//R8yvPNfo0jo8gVhnmau1Ud5+NGv5/mXfjYoOGZ4XThl4f6uJcbe7pG53aTjrcf46B2X8JmM+y1ZDi1I2Z4cu+7R8VXLra0kkUxDghiRWj2vWYySRhgrCz3ikE2o1RE1pt4ouSkmFygLdi4LeT0L4yJEiGCtUKR0gl9JvqekBLNqAQ3EvUjNyhV+mxiZVe9pEJx/EU9D2yFG6CEmKq/KsB5CmtgCE2xI3J9ucRLm1hmPZ3U2Y+4TukS7RiZq3s8evFqJ5VLE1ZLL1iDqlxJ4pufCRrqkRDL4ufN++6+JkS39iAdK1cMvUyT0+a6aNK1UpRWNjw0FHV/nRZLe6aen2ADVg/7gWmilRDfZgR6GE52eGTLRFWrXMBQVIoQ+qTPR1YUUMagOnu4vlYKhLRxyKIQRAAZlgM6elC5EoqILYZxQ0sw+sVBRAjPyOW+6xiwt7eyD71aR9ATM0diiSy1JYg9LEkEHjQ5XYa66N20dhxHzGe1xks+9c3KszHWNWWc3CrQdOpQwXzDlrM0IgYneKjtuts5LwMHhwxzKwJgYVEc4PXuNn+cuB2myexW4LgNrOcCuPg5v+2be/NCbOT75Ge6UKEoTYC2tt5ZGOR3IiwcHsHkJilbx/UZbZGG5KeaSLAZJyCM4rSW344MGggZwrxzAG95GOzqkvfBxrnz5o9y+9IPceOL3h1rCO96jC/+6S9/KycVL3N7eZNgptioMLRgOkShYGNuCURfoCWe0GD/XGIODl4E2Qu9GVWXWFiO3htxrkAJDZ+4NqYrXwuQe0sfMoHEBKwbaI35DPByckhu50M20xtgZbnxKody/nqXEw5zb6pDmlZQkhoLH1NEaiYCSyqEgpzeUjpaKWacuK0pfsFDLjBwYyKWMKlRl0IIWqBtF64phVRg2A70bF9MFdiHodmBqM21RiKU3o7rB1MIPE8WTfxz1MzvTVLkI2ZEKmCtOjWVX0oqqBrbrOW1J75EXTkSjLMuiBZZYpjZzp+gYzkpiDBIZV0vkiswWfg9N8Kqw2tuL/GOv10WRdOvY2Qm2Cs6dtQn3MJv1bgEUWUiQujvNwlTXc2R0glS+z6rJrhBy2rB02xFivMZJT6XYillItxazBxLf26sBJBj9lLhxRUfU4vT1NGnVWihV6JNHOp/D4oTuOX6WccCBNvfU1BZKgaEO9BpYj2qoCVwkulw3RAtejF6E7VA5/4O/j5f+ix9DPv5jzKZs3/wtrJ58J9OtM16990nsCz8dm/HeufDOPZloAkeXHuEc55bCDkKmePoCl+dzjjAG2eCsuCNrttV4WM9Y336Omy9XpitBzwgGRxgzhJmxUweDQfZBahGHQXTSSb8pNSMlcjTSQt7sSS3Og6ToQcSqQlKl4LCumH2gb55ge/kSdz//c2x+9r/m7tFbuHTl18R1F2jTxHq14pse/nV87PTvotMOxnhIUc2Y14rIcWw324zttvRdZ9pFhIJ4Dfx7HBlqQdwZXFGPIhegX4zR5Ba4iITOvxt9u6PZDkvSN4MjQ0rsLEQRpSQtrbek/ICUnCa6UKxShyEODk2ur5UQMJQwyTDNoloV9Sgt0h8gsS9bcYkDyaRTSmcwo/Qw0xUJ31JPFyohtv51LKyGgg7KeDiwOb7M+nBk2Aw0d6azc+7eO+X8dMt4odTJ6AuU0loU4RLvj7RwqrdFqy3BFnF831GiiVcuz28Szkne8l4jvrz/ebCWB4qkSEwrpZbgY1qP4tqiwy1VotHJSVG0ZdNekLFQV6/zTtLNsIsT6BHS1dwyc6RhbU7+2gKsW0gQRekaA57nQ7VkIIc22+6/gQTusXjdmRPk9BI2T6GoCb7bAjDHUqLvxx510uU8DHtDB2v7otvbFEB4b9A60m2v9pGhUFaKjkoDapUgR/c40eswIqsaPDaPjsgWpMUJVUgBHQsjytu+/QP8nTsDJ5ev8S2ifOe/+v2cvutrObt5yhc//GGG//q/5jO/8HG+7t3v5u998uN8/N4Jrx1e5te/41t5x41HQgeujkyNn9k9wWe+55/heHdOXQ14MT72sz9FqZXfevoi/6sn3sCzmzN6aQg1fj6cUoPgPIhTFaZVdNdmTpsSm10wPR44cMjDKd0HopuIjwtCkVV23sTPMwrjakWTDba+TLUnqDeucW8s1B/7f8BveJxL41NxjQ28d451w7uu/zpeXP0kFWesBZfI/hOtQbOxDtOWPu+Ypx1n08z5FNcsPByVYTXGMsQljUkyH8Y65ql0MRALVxybO9uzM+6dJme0CJSGFGcYBirKIMo4DFAE7xqxJW7UUgKKUKX0mhZkC88y3HO0lFycSLjekpgaQjUwlZDJWhLKi1JlwEfCXq0UdM4bXA1koNSK1ji0JBUrVYRahbIqbI4PuXbpMpevHLE+XOHA6fkFdXWPujlnPr3ALjptNtq0Y7q4wKzv+bFuZAZ6aNUWPNLyui/Q2FBrEO8tOs4qUdSkSoTrkepwB3LC0yL7iStcRAw0jXKKUoaKa0hAPd8zrZqkf0N7R0WwSrhOf5XX66NIYrTpFGvx0NjCjM8xyvtCS5ij0DmojCHnklTouGXwPPjcogjsbzJhsZRyemq50+d8WX6Z5jIB8CDdmgUeaAClYxr8Qy0ti/GyQIlNoPeOzbuQFUqAxKUWyqpSNgpDFmRTtIE0YsQnx6g8fcPZLTCUojFuSTVUnSubQ5595gv80H/7ozz2nvfyhl/33Xzy0cf4of/0L/C5T36O44eO+UP/l3+Fv/z/+k/4/X/wn+c///f+fZ599mX8vPF//I5fwxPjdS7OLnj5tZucl8bPXF7z7KNfy1G5xENHRzx5ZcULTz/L5oriv/Yb+ZtffprPH7/G2SCs5oT2St8D8hstFK1crBfVgzPvhEGdrRjz3NMBO2gWSyOQuAWqLdRLpB2YRdEdhjXrw0PWR4XV8UhZHVHGiklH6w2Gp57gxb/zw7z8o/9Xhu/7UxzIldj4TjtWmwOutSPK5fdz6dEvsxoDCwOS6mFUc/puYpondtPM2TYKpaowxKViGIZYnnlIGdGIM5ZutG5RlB3mqbFlYr7Ysdts6OOMXsz7pMFhGFhtNgQqJ6zXI1oizvX8IvBUkcDltQ4UG1AqpdRYkmTIWXgNSYyNQwlBjmh03hZdXJk8cEJVhmFkGISyigKKJze1xL2KFGrmu2uV3PiSCjSljiMHR1c4uv4w169f5fLhhkEKr13sODg44+Js4uT8jJPTU07v3ePi5B5mRp8m+hyQTik1lUHR/XUJDqSLZMpEXG9KLLBiQR1di6viVRCNvCpZGC4uiVPyQCe5fMyRIRqY5h1VR8dCKYqMsRAtJuGJ0IVSlfb/D0USPHC9Jhl29AAA6xZvqi70ix4tcqYOGj24k3miLB1MbK6iWwllYgDorukwjefYFF2LLafagn8iga2RYHva1LuDac8xoNCNxEEXdlhjMV6TUtGhUEehjBJRDhqnpSE5eg1YOj17SW5db/lwBvY0FPDhHDNH/Tr/2d/8u7zw0mexD93kR+++wvNvfTf//d/8L7jYvsjXvPHrOF79Dl579RmEM05f/iL95ZcYGzw5HnD9eIMdr+n9jM9//gt88sN/izulsR6OeEaVj/rMrXs32djATzx7wo0rD9OrcVg00W72+SqlCHU9UKqzKT064ObUku9vGZAttCm6ij2RNwH3WjQs3kosHKzHIkNkpI4DR0drLl29xOUra9ZHa8pmoAzCUDaYvYHHr/1+fvI//U/48k/827zl/f8ug6zAjXmaGNYrrt45Qh96K296y3lqr2MBgwSty1tn7p3porHd7thNO7REkRSDUir7TBWLTXAF6I3ddmJujWbO+XZCWmWllVEL3Rsr2cVILs5qHDi4dIyrsFFlvV5FgNiuc3Kx5uT8grk16BfR+c0F65ImufFehZFEi+lEC5gwjLmZRZAW9++uNLRVtCp1A+sRyioumjVBuzFbCY/TXAdF1HBKTNVi0ZmwkrDC6xHr8ZiD4+OwpVt1joaJ3dHM7dMTVuMdHGWad5RpF8F23lIiG9dcrcdGOU16vWduoQxxQKgiA2mSbMzJ3IhmJIrk7MEZtmQUqIVYVYhOs1jGTpTU+ltOkxa0LWkQO/4aDmEExi+lBFH+q7x+NfENTwJ/EXgk7nz+rLv/hyJyDfirwFNEhMPvdvfbEqX9PwR+E3AO/HPu/jO/7PcgcERvLZQRuRQhqRCS7H13p5SaPKv4i4uF+5zLAc3ZuRhJYO50Sc019/WssfmON8ogt7O+dwdZ1BeWm/Xe57Axm6JgV83ozr5oUCU2dhZUAylKGQu6UsogedorXWFWwcaKWmEkMKeStKCAKqM99hojeFtNaKmUfsRLLxjPfvIFtrdPeensnNdePeH7ftM/xW/8nb+OZ5/5JLeeucvP/sSHGM6dn/57H+SNxw/xwskXODg65rlnn+fO0T3mNvPyCy9xsb3g5r3b9FKYR2e1GtiMI9cfeRJrE9vzY2689e2cbr7MdnUnDBiyK8QDN/NBsDE6R1TQYnvWCcWppTAVpbc43afWqCWjAFQDq10mBwHXcFsvq5HV4YajozXXr1zi+NoBejhQSvxXVBmfeAj+d/97fuwH/jgv/tyf4olv/FcphJO2TUpdjdgXN9x5fMNjb4VhZ2zKyE63ezGCu9F2nTY1+jwBHha6LbiRU+vMrcdWmFjEeW8MOnIxTUytYQh9Gqj1kG05C35feDoxjJX1OHJwtGG92XB5tWG9WdG80XaN8eSEcq9yfnrONBviA20O1oWU2GBbutmzmNsKudiJQq51oIyClUa3C7xBLYVh9LRhL2ituPfohFk28AqZpqkSmnC8J5d0BKu0i87u7JTp4JB2eIlaVtQKw8GAlZl1N46acXZ2xokOdK/0to3nNh3WUaEl71e8o73jPiTtZ3kqNT0bfG+nhocskoRjNPnR3vtCXtrXj70L09zxnrxK4oCTnjBGcjBnjWly9hlcYlve/sk6yUbkav+MiBwDPy0iPwL8c8Dfd/cfEJF/HfjXgf8z8BuJALC3Ae8j4mff98t9AxVhqIW5x81oc1h8SYWutrcs0yUHI9f9XWKzh8JoGphEJwHrpPOU2CQWVSqyp/H0EiFNC6SxlyUKqfEETesv0pbMFodUF1rvuMfFXYi67jGOuzhUxwdHxhx1enB7PKVdIooXpXnAAkUSKgK8Kl1DPbQaAkfb3au8+MwJpzd3bE92jMMRUzvn7O5t/tJf+tNcf/JRTqbGK6++yr/5b/1bSFE+9vGfw1vwO59YP8yLz7/wgMhfePHsVeZ5h+g6VElTbPwONhvGzYrbt27z6U8/zxPfuGFc3cbLDjdFvTC3WFZ51byxezjOiAfgj1BqoY3KrirTTpl7g7HGJtQDjgiMNyg/KiEgEC1IHajjmvW6sjkaOTxeUw4GpK5RTSytVN7xnR+g/h8u+OB/8AO8+uwP88gbfycQtCObGzoO3PlJ4cbjMB5Wpt4YqDRxTDu4UqXAOOBtpM0zNndmm+nN2E0zuynwZhWl5fvXTZhmYzs1ppRA1lo4PDxk8kbrMyowrlYcbQ64evUKB5cO2IwrxnHE3Dg7P2EKvRLVjZMLo0+BmbfWoVhQ0Zbi6E4Vpw6KjIeU1cBmdUjRSps753aOSWCgWmKx4SqxJddCY0pydwwDJfFOtLAnGkmJxdskoVWfJ/q8ZXex5e7dc7ZTKNZ678xtjp+vd1rrtKnT54b1CeiUKkHryk4RjGIdmRsR/7uYVQwR5UvuCyT/2YI/axUgpjxtlrDYAp7td36hIfMF7ybD3kI6K+opkRSsGN0mTBqaqhyf/wmKZKYivpj/fiIivwA8Dvw24AP5aX8B+IdEkfxtwF/0QOk/JCJXfkm64j/+yu5JiyK+FC7fd4Zqnm4k2fFJ5FsUgigqvYUO28Mzri2yt5jl6NWhln0X2avQC+z1MsKe34UQ47ikdjs5ZE6+mW7BMvRU3iyjZ9IbpIYpB7XgtdI8DVelgkQoVAQ9Ra0PqnNs7QugWvES+dWDFkpTXn7mFi9+/oyT2xccHz3E2XQvirwP1CL83Ec+hXz0aaiKt44dHOE2B9l5VLRuePSRN8d2Htmbjb50/hrjeozlkYC1mRlDN2sGLbico2Yc+FVaPeGMKfOALPvvmcW0NDTAAbqLAEOlyIAOIzoOQUDfRsjYxTTFe8niF5jcyS4MvtBClN4ck8KEsnVn6LF4WxVlYMDawCgDT/3Tv567L7/AZ3/wL3Lz6lM8fPxtwZk1pU8TT76t8N6jx3m1nfPKxR3OW2MuTpeIvUjvWpiNeduYdhNn5xdsL3acn++YpxnzxE4XE9155mK7YzvPoRipRhflcBg4PljR5w3uwjiuuXZ8jccefoj1pWEfrgkwKLSeliEOcxWms47tGn1nWOt4aZEiSeSuG4qUgVrXrNfHHB5fYqUDbTeD32PeNnrfxv3rlVUZEGB3MTFfzLS57WMthMz9ZqbUSi0jdVSaEk72TJnVvmPXJtrZaaRYetz/U5s5uzjl9O4dTu/d5uzijGk6x9kh0nHSNMZDEAI5JTZBe0b+qiIaAgwj+5yebqdmeDPMUuM/x5QXjImAZkzi2pXsdhYceIlGKUuB8VTcxDsIs6NNUqdv6F6/9I+//kdhkiLyFPDNwIeBRx4ofC8R4zhEAX32gb/2XH7sqxZJB9qouIdphBbdZx+Lazr0JKds6Sb3m+h4wFoa6loJ38fqS0dSkJXQFvIykltxEA/pXJVU2xDYhJgldyjUrJ7bQreyN9wtoqk19cwOCZ5fHQp1NaacUGOrKppjZIliXSTjJ7JzttjcIbFBbU2RuuL09sSzn/girz53zqWjJ0Ln7Ft6O6dqYRhHzrY75tZZVWcllYseOJm4ouOacT3QpsYj62v78TK68cor8xmimyjqGifuNMVDhIycnl5wk5s88soVjq4e0/wO3Sf6NIWVV+/05ecOzgai4ThUxKjDGtEN1VfIKGjt7HYzg2QxnyP7RFzCk1OV0mIZVlyYZ+P0YqKe7bBVZZwNhsp6VKYaKqedGec+8sT3/A5eefEFTj74H3Hynn+HYx6j0Xh09WUee2Hg5MONt7zr7Tx55VGeufsiL52+zK12L0jtJE1sdrbnE9PcOD095/zslPOzi+DMCgwlzJSHoWJ9Yp4brQc/0MXRAbwYxWHYrNlNDcrI+tIV1pcucXxlQ++wm+fwtCwjx1ZwH2MRWQdO2NJ2O+puxudgVFQpsWEnrtsgQikrxtUhw+aYQ1lhOtGmzvlwygVb2tQYViuUAW/G+bbhFy2wT488JEkq3TCUyJiRyJKSmMWjkz6bsOL4zpjHAfeGNQ0ZbZ+4uDhnunfC+ekp5+fntH7BIFGiWg+DGbxnho1GB9mF1kL6qLkzUMugsmxkCtlN4iHQaMFdbunmjnjsGrLBkmxUIKh0iNIyk7zqkt8DqskaMQklVesZXfvV696vukiKyBHw14F/xd3v7cc2wN1d5JdBPr/y1/t+4PsBhs2AjzF61QLeFOkzHY1IyL7ItIJm4h7njluoVnrJPA8NrtlArPVLqUgttEIQmR2EQtGyRK4HPzENeON0CrAzRFq5+s5NXJixpPp+gb3TLVqTLEspYVyqGVwkQa5Gg+fWJHFTd3rr9DYnCVbDQcaNuh159YWbfO5nPoufd2489CSljIzDhu35WYz7bUZHRY8OGFsNKEEDW6laqMOa43cIb303/DPPn3O0fYq3HT/GnemEW+0cQ3j5/G5I4DS4naEKgvPzC248+hjrfsy9k3t8/nOf5an1VfyKcd5OcBd23RCpUVw0IAXBGcYV4gN1VVCNjsd0E7y5Al62gNDsAivRSXULpYqkGkg9JI02OxfbRjmfkNXIsDO0bNmOSh0rg2xRE078lH4x8uT7/hme/sTP4z/1R9m+74/w1PTzXJKRc67w/KdPeO3pL/LoG9/IN77v63nbpev8vc//HC/cu42VcLyZt43WjN3FzMX5NlzMdzuA4Dw6lCEO29WqUgrhIaCK1Mp6MzAOhe3FDs7nVFKt2WyOGTYbZDymSmXabsFmZDBWNrDaFtqucqDGhQp1rNg40fouzZWjGgT31JNxERj6PkI1Oyvtgs2OamFV1+E3KYKOzrx1vM0MRakSJPpmhvR0SvKwQmtCBJJ1qFsofeL07IxdFbTPSBfS556+a3hr7HZbxIOHKZ1IdUzDW7XOrLH1UxmCxicZqNadoTlDGTPyNhqc4sKcu4bFN1Y1NuTRjsfiQomFXJHgw5qHYqhYwGBdojEKCYmg2ZCYh6zUdvG1ejO+2utXVSRFZMgC+Zfd/W/kh19exmgReRR4JT/+PPDkA3/9ifzYL3q5+58F/izAwdWNjyJprCtJUhS0F1o0c1FYEuiNbs5ZqMkiuY1bJFwODLHup0R3U7wmTSDBYs8xO241MoE6xwLNLTQsG3aEDBlLblaRLHzBt3RfcmQSQ9XI9bA2BUZacpNoobk167RpYp4SiNeOUph38MJnnueFn38GmrA+PqYMSptO8HmHyMyolclnfHaGMQqimtPnMIdYq/PdXzux+u5DvvaVt3F99c18w41vpUrlmhRuzReICq9sb8VYfr+NBWC73fLcM8/x5JNP8dijj4HP+MVIWa3Ynk/Mnma0PhP0JbAijENhRaQI9jKiZYjbs6xY1VXErnbBx461TrMtIoa6xLGUOQNiGqYizSJeYeecXzRK7ah0dGusVsK6xqZ06p3d3TOG1SEPf803c+9n/xGrj/1Jdtee4PzoiHrwENtLD3Pv4JxnPvJ57l7c4q3f8i08fuk6n779PK0JfQp5q00RLlelsBlHxhrUMMUZh5H1aqAOlSF5rW255h4d2WocsF4Qze2urpCyZmoKszKOKyCyqkNmK2jpIR+0FUOBw0Oh+swk97DtNra0HtLZuRuTxXisk7OaFFSYdp15Z/QpZIN1MzCuRkQr62FDG1bc2+0Y58IIoW+HMMNohkqwP5rAVCyWi4RJbzWn7hrz5JQWhTni06IgLvePWBQ3zzzv4sm9RFDrQf8RZ65CnWWvBEID/gpdvSEG6kotMYHFIRxtUrESi5jeKImTLMYaD/pqFuIahie8IlbQrhTrgXXuHDl3pFek90xC/cqvX812W4ic7V9w9z/5wB/9LeB/C/xA/vNvPvDxPywiP0QsbO7+snjk8n3SMy8E7T0lV0ERsRJtnHoUuS4hOxJh70qyCNQNiU6xVkqtSFVWRPcZFnwZHORZtIhFjcUfJTE9TilJwwtIR+3l1BawoqniKHvZHS7oHLpl7Y5KcARb75ShxVYej5Ghz/Q2xw2qUcx7L9x88YSXn7sHcsB4NCKbFWfnF4hFFke3RSsb43qZCIKsC62FecHv+/od5//0MQ+9+gRPvfbrUISxVsxhqGuO6op7fcfLZ6/SpgtKKYiOQCzHcOP03m0+9fO3eerNb+HG9RuUdshGlPn0mexAgopVa0GHiqKsVhvWbKBvsHmF1UrbwxADZYQ+T7RWkKrQU7njOWCJhr8fHfWG24z2Nd6MPsfWtZTgKLbmzDoF3tYuqNMJWzlld+NR/sGzO9rpyzwsz/M1VwceecMRh1eucXR0heeee5Hnfu5HeP7nv5k3fd37ed+Nr+G1ccsrfou784yv1vhgiHS6r2hthzVj6JWSUkEvgi/qqH08QKGLczY520mYe2HXCzI797adMjnrHVw0w7dOSVnnPFfmVpiasrOB9fqAw9XAVBpnZWR7cg+ftrjNITnsnalN+JkxtoK2yrDasJsvOLl3j+35HfCZoW6odQyjCK2MKQKQLI4tG42INgmBBq7pkgNFg90hOL3PiBszHbOCoHGNCBqOdGGQgUbo4UEY06wkaHrxZLqEAQq+aKqzmSgh0DA8xuB8lgrB+uiq+JDKqVlCTqjcT2/EU20XuTjhu+kUdRxNNQ+5xDFs7kxT5zyfp0E0C+5Xfv1qOsn3A78f+ISIfCw/9keI4vjXROQPAs8Avzv/7G8T9J/PExSgf/5X+gahJU1hPYs5QHSIRSV5wGG31ayHhbwEfWQYK3Uo6DhGl2lOA0Zq0BqIbsMyAzgS3u4XNdzxNBxNq4Vcl2maGMfaOU63GElVY3GkSGyF02UkXIE0zIB7dBnuwuxG8Zna59Cf905vLbibJog63Qd6F/oJbPQIvXKEq9NU6VNjkFAJLAbDy9auEFb4Wiq9zaDK33/DEV8/KKePfJm3vnKHAw24ODpueGh9ic/d/Ayn56dUCWJt71O6oRd6C86jW+Pll57n6pUrfPxjn+br3/M4o4/s5tPokoqhZaBKRYeBsawoMuCMWB/owaiJTmAZz2xC1KmrArrapxeKh/GAmxFR9oqRoWGtYfOEuEY0hjRgpslZGNa6M1pnJ5VfeP42v/DKbTa18r2/8TfDzWc5n27x3Oeeww5v83PPvMbprvHtL93mu595gbd/+2/kvb/ut/CpV2/yr/17f5xydJlxteLyjWMOj0c2BysODw9gXXEZGIYYF5kXwKXiZuwISzbrzvl552Q2OoXd6QUv3LxFH2E1g1CpU2eTePVumrl7suXu2QWTVq5sLjH2gcHmWPRZYdtvRxFI82dzZ7644O7ZjtPzO0gZMG9cnNzBtxPdBesHaAkOqwClNQZvNAljilDqBETUCdhAUmffLBuR/LxiuTH22CCXhX+XGKMmDOAk19I6a8aEKMLiTDSgrOaN2TqtxDOvJVUwEga5TeNZakoQvMt93HHwks8qSSQnf45wB9M5tmIO9FQnWcovxT1ybFqLzbwYrTiDR1NV/0lcgNz9H7Fwu//x1/d+hc934F/6lb7ugy+BiMmELJKK1GjrxzrgJQO/hgnf7aDFhrnUSl1X6hgP9+CBje1cIu2wCC7GTFARpLcQyEuY+Opi2ZSRDuTWnIxNcE3+Ywrx90xL0Qi0Dyr73gNQKSCxeFAN6CDkVI73GdkF4Gx98dwTRKIT6SJYF/p2G3JIM9o808sK6LTueCl0jQexDgO7acrNMnTfYcVo1vjyRztf89QBh5eFF698jIfOfnO+z/E916sjtnpCcWWsA621/Whl1uhm9NZ46KGrnJ2d8fKLz/KWN72TL/zC82ze0KjrjtgKEaGW2IquVhvG9QFeVsx9oPSBvhW6NazsQgZIp/cdbjNVQ3ZILiW8Q9uFI496KDRUnGa74Ot1iQWTBzYd6Y95wLmwRViJw6Zx4/HHuLapfO2bL3On30T9BkwzD1+9wWu3HG5c5ac+/UW+fOeUb3jxLo997BN84sU7fOqDP8HswqYeInWka2xCDzdrfDNweOUSNy5f5dvf/35+6+/6zZgZ57sdJ+fn3N3eY7fbMXW4NZ6xsttsz8+40Jk7p6dsnzdWm9cYZOCgjFwaD1jJiouLxu3b59w8vcdqGDmqh0gTSqkcHR1jF+fpywmzFLoMaDdW0xlK5+JMmSQWEpU5/EHptN0Z24sL1scHNN9xvj2h9TkoQR52e4IlDSq6SfWIbI3nsTBLmNOKlNSjD8Ac6pcuVDQUOl1yGoh4Dy1jLEgU3EsUY3eK9LT5E3Ye11DVQ1TgMS5rKudkWZZSEEkISzQIImbQFfM5ZbJxW7QeY/ZAFN1JlN5LLnVSsJA7DFGo1qkFZFXw17vprrtjbccSshU5HpUqEe1qJcKGSq9I8XSDDtOEWgfGOoS7VI9Ob0XJXBxPC6hwXpHsToPtEaeOemAniuAlNtdCyCMLoRF3BUwC38gTT/sDHooeZp5B4YmIWUtCuGWAkrSOz+EYHqdddK8S3gUhkxLFa0jr+vkFVmasVBCh1gGVSnGh1jH8D0uMMqqLdX3c4O3Vzmf/q1N+2+9a8ZknPsN7Pv9bH3y3EYQnr1/l0mMHbF9pQSkpNUi+fcL6jmLCay++iGN86c4t5m3jG9/7LayuH3J3+jJCYUWh1BXDsGJV1mg9xHWg24B7JkA2YDdRhjAZNpuR3iJktCgyKIMqPs9MNuMrofWWPo/hliRW6T2CrCTNij3nghBPBS1s9s67v/ObePeveQ9yccrf+2s/xMXHPs9Dmw13due03T3esBGuXZt482Hl5uYSu294M588bJyt1/yaJ74Lu5hhC/O05fzkDvdu3+L89BXO7ja2d4QTK6ym2zx+BQ4PDzg8POBgHLkxVg42h1w6vsp6c4yrMs0zzcKd3XOru+1z3Huq3Jm2vHbzFkcjnIuCHzEOVzk8OoqOfrflVO/hrNACgwvjMNEO12yHC/o0AQ0pyb91Za7BGNhNF9y89RxiRwGnzFsED2yOQneSM1xAwoYvTKth9JLFLaannTTEGloi2qO2AgYjEvhg4tmpoUmdcLR6smejBI7oboxVQx3jYXitGp/XDcRaqt+W6NdonHrMfrgJ8yS0Fmo4T1MMPEx6B4h0Ai1pBpz7DRGkQNdCU2V0odyz4GGPhbpefdX69LookkLImESDHuNEXksUyUKv8TEXItEOYtzWVUSklhIjmgThe4nDbKT+Gg1nkeXv5suRvU7c2e+LAp8QDZNYyW22aBo46P7v9vQWtJ4BY0EmCcpQqnAGCQxn+Y77IDIsHdQj1El2M+rGcCi00pgXl+ceH2/eGWRk0CEspUQp4yq6Tg3HoMAUY9v+/B1h85ELvvVdDd/cAh7K9zp+ncOLG9Q7K9Ag8k/0pAjFz9fblqEMbDYH9DZz99YrfOxDH+HbvusdHB1dY5bOOKwoQ2VcrRnGFVrXmMQD1npguzJH7vk8BcfRF7dqCWu4IkoVxwqMg9Bao9c0LTZj7o1pdtpuorUB7cExdTLaYDmcvDOW4Bt2cWx9wGO/4ft4+pFHOXnuFe688Aq7xw/ZPv0a55cf59p738NbHn8b00OXuKaVea6UcaCMGzar6xyt19jujPN7r3Fyfpu7do545bKOVHVeRLh190Uubp4yTxeICb1BpcRYuL2AFlG/Wp314QGrzYbNZs2l9QFH6wMOjy7z5GrDO97yMOP4ZnR9xPHmEkebS5gLUzfufe3jnN65zcX5CRcXZ9w+PeHlW69x685dzs9PuDvd48KF1g3b7TA7xbcB5cyzUs7PKesCbnGNNGR/XfKIUaHKgNIxmcMNS+OQ8yRlr+yQlTjFD9iIsvMzmrWkPvU9Ve4+yJ9iCbcHPh6LGicEC9UWok88F64FbcbQg7nSS0w2odZxZnEagVdPOtN0RqeWVD6nqLLx4FzaStltMnAPiWmFUHbVUhBxaidMOeY5jEDq69yZHLL6l7SXkkLJN15KchAdqoQSx3VkArpUpBR2uYF2TTOQ1sFKuAWljVTNB2v//USTBOQskeaRNieJdwTfkiyYuDLMSvOQqXm6wQRlK8x0RaIISDe0hclA6cGVtibMXfaxDrn/icsuwjiFkG1VHOkTl9aHdJtD9iYTU5tADK0d9JAyjvgUMQWS+I7bEn4VBhn/5ecKf/KRHdcvn953sU/k5IVJeOrhd/LpVz4VpgTsAhLohjcQNbo1xvGA649e52x7ShkL905mrly/TB07UoewcRtGrAxhskAPeoUZ1rdIb6gSlA+J97dLRml0o3jHhxXmkbPc25zhqk5vztQbOguNmeJDGOJqaHV7D3yLNrPyjpcRGSpts2beKvXSMU98z3fhu8ZDu1A/TeczZTMws+YmZ8j5CejA4AP9whkOlKP1Adc2DzEeNM7WR/Ba5eT0JoOMrEUoTKxMOS3CHZnZyRaRgboeGYYNh4yU9THzrjN549XdHU7uvkS/u2WW0GBbd0RW1HlGdkZhhZYDHr36GA9feZyjw2sUVeZpi9nM0cGKzTBQVXniTU/wde9+O5dWI5thZK5r5k6Myu2U0+3Mxb0L7pzc42JqzDQu+sydO6dszy/YTudczBfMHj4CI+A+s5vPaDKjGmoy9QjoOijHfM93fjvf+M5v5KgU/vxf/Qt8+ebLuNbg5JLQVS5HFqHFsg8QzWakR0cZ8seUr3pwVKMJDTNdTSoQKkhxusbBLbNRpcEwU7WhcSOEjFiVvorbu44hCaYOmFSgBk1IA7KRbsw0duOM+4wqjK/3cXspMkuezSA18oXRPWZVRJAiYSPaffFYCGVFj211MPUd93CVKQ0qIU0sWIwdRZhTJL2kxmWJScsqYOFkyrgnoItqeANmTnfEWVq6C8E+q9GDF9aNzODQyEhpLZY1nqa7JZQejqNTj7HeGwfDmjo6p/duUcoGaqHYyGCKz53tPDFuDqleGWVgLjOL+3U4qsQIXmvlxXP40Eud75Q/Q9/9HrYH78Y3I5e88Ox0wddc/zo+8eLP4j7DfEE/O4cpHcdrOENvL87oPMJb3v4tTNPM8eXr1E3DyglFRkQLs0HrLYyBDVqfmFrHWpzwrSeNKlFRikRx88hpKbvQ0M5To+1m5imic00FZmErQttugzZTwkYLoHnnbNph6ek4DBMrGxm8IWXNhYXZSPMa5q87ZxKwqSO2xVGaN0yg9guqXOGR1eM8dv1J3vbIIxytCqfbU9ayYbrYMcxnrDykbM136G6Hn53jfRcGLZtK6ZXLwyWOjw7QjXA2XTAMBc46Z7vFpELZqGI6hAnIOGPziml1zNXrT/HUjTdz6dLj+LDi1r2bvPTKyzz9yvOcnb8QnfV2x9zOqN451jgYalkxBH0ASmE1rLhycMzxtctcu3zMarjE+KYnOTo84ni9YaUDU2s0U44Oj3CZ+eAnfpof+8iH6DIj1VjPlXc88rV873d9K1/4wuf40R/57/jD/+If4sala3zh3msMDgcGc0k63jIlubM3F83JRjFKj8+bovWPBiUhMhHDps6sDW9B/ZESTcGgkfDY64x2Z+yFcwRtRmmC9IiFKAV0HMJ0ZRVTqXjFfZ0/A9HxDyC7wqiRPjkzM9X5q9an10WR9OV/c9RVWQoIuRQh9cFB/zAjliTqkYLnS1pHUs7dGD1UHd4dBsPHeOgkQVtJB2zB9kFQi8OKJMXILTJCYvMWwHJPO3nvc/7Iwf8J3CQstgSJkKEeIiifG21uQdhWzU4oliglT+uYGwamacD1gG07p53fpBRlfXBEGZR5bvTe6Nub1OEKKjPYRHOj5endRTO0HVQKf/3pFd/x6BYb/3vu8hhtJ9wz57gY58MBD60v8+V7n0NtRRnXuHbabsLaTJ9nenOefeZLHF4+5tLVq6COlhXIFONajyWPdwvSskUnP5sxizCWgUElHarDD1RVkd5j2yjQ20UQ683ZWfBh0QGxStkpzSa2HvZe4sJQI09o1xrnF9ugh6mw3qwCQnHFdBswiIfDVHTSAVMgNRYIJcLIvHV664yHIzeuPcRTjz3CW24ccFgbF9MVxos3Mb32Khe3n2OVHdtWjXOHE48Hb64jY91wWC5x9fAG19dXsV2n1jvsSmNrW1waxSbEOlUiFyccxgd8OOR4/QjXLr+Jx598F1euP4KhHNy9CuVSoD39AplO8TVgnZXC1XrIOApaC1Nz7pwpt+/cYbedgmB9WDg+2rAZB1p3WmuIxUK01iHgIxPe/qY38j0f+KeZLowXXnieW7szvuPbv5m3XL3Bn/sTf4bPPfcxvv5b38OP/PgHudfOqJtYrIanQmCsTlgMBoTv+Vxo3ou2Z68UMSbte+zHPdIp2wCtFHwO2zYdK7YuVJuozbgYFLGBapVRLQj5zcOoONQbQS2rig9J0/KB0jeolVTShfGGqNJkpkul10Yr/4Rk8v9vv0TCI68kbiB7qDZHYSeoBKb0ZsxLUdPgCEouLiKLAcCZ1TMQKqzt9+wetyVKHWCfaxMOJclZlFwNWDz4Qpiadtnb8rKExstSGAhPyE5u+jzHbAtFAtYpQlpRaehxNQqCjko3YZDL3Lp1yva8UceRUox5e87pvdcYVmtWqxUihWk65/btc0DoLeM4a9iu9UQUnKBxfPlM+fDLle945BVW/mXE3ogDjx4rr+6Er3/4fXz5mU/RR2FzeMR4uMa6M2/PmHcX6Q24Y57O2O3g9LQxTFew4uyage3wudFnY9ZMSkxifSuhiKg+RNgbwW2rPeOAxekY83bH7mKHdYJmUyq1Q+1KK87UJrbzFusz1ZVWKq4RP+G7oItRFMbApOdGYNQ9tMKz9hgJUdbDmsv1iKPVIaUObPuWk/Nzpr5jPRxz5fgS1y+vubpxDmgclTXtyiVeOb7OK3deYdVmRgMVZzN1Dl2wumYYNqzKEUfDZTbjNQ6PHoa1YRcjW+1s5zMmP6d2ZeidSYNKM0hOIOWIG1ducOXaQxzfuMq1R1YxQR1c58Iqu90Fu+0tms1h/uudTRk4LAeMzNRauRjg7KyzkcowxkRRxoGj1ZrVqgZWr+Hs37sFnFQqc2t85qUv8tIPv8LjDz/Bt37zNzMZPPf0l/h//t//XbZ37/K2b3gnZ6b8lf/2P+PoxjG6iiKYpvA0iY4cC4rOvuR4NARdGpMGVad5rGFUJLwAWNg+wlDjWRAVZBR8lcs7bcwCmEY2uBoDhL6/B7bPYuihEmR7BqqtGHyN9KAmNTo06LNhs1CmoEIN9tUIPK+TIqkCo2icSq2H/jp4pXtNcMgRJQTwzWizIYUINK9C2PIXikrkOrN8gXQpX0ilHkOfu9GaQb+fi7yQx0O4pHhXZoWw6c/Q+BbJb916Etwd9+AfeokHNzSMEl533vdBSZGmmQVbYmttpYJ2VsOK2y9P3Lt5gmy3II7KwHp1hPWJ3Xbi/8Pcn0fbdl/1nehn/pq19t7n3HMbdVaHbIxN49iYYBsbO3SBSoJpE0ioUIRQCSSEFCNFKsmoVKVIX5VKCJUaleSFvLwqQpJBQUJ6yKOwgQqxLRsb2xgb23Iv2ZKudHWbc/bea/1+vznfH/O39pVAks17442h7SHfK917ztnNWvM353d+m93UGIaRJGvKvGUuO3IeHPOr5gugICSJWOipfgo/9UDm1bcXNvpW5nhf1yHDbUcB5MXccftnc/3sccqstFY43pxjdfGYVneUae/k7QnODRe57857OC2n7vZSKqWc0UqlFFdqJLWeJYIbqZr5OBY8oc5Eyc0pH0GEeS7MU2OelTpXQjLC4O91scA8zcw09vsdlN59DBlZrUgxI+LegDFF11aTaerE42Ce+ZMFxrzmOB5xaXXCrce3cOHkEmawnbc8Ol7j8tWrqIxuYhEVlQjNvQ6HVFk3JW0Lem2HzMKQC8elcksaCQhnmhht4Gg4IeYT2nBCXAWGQVi1U9bbkUGdHraRwPWsGAODiPM+h4HjoxNOLt7O+mTDyXlvAuYkbG6sWK+PGVcb0j65e3eJJE3EkBg1IDU5jTJticEFDMToxi9AlUaNwQUJ0mhZsJ4zHmJjtomHdlf5xIcfJDwQuWQjv/r2D/BFv+PrmdvEuVuVG/NlVimyCzOmwSer5g3OwkiIQzxIh10J06OT+11l3oMQyd7dmxLFBSHa8cgoCZOG4Ni+xooNhZUmmgQGC+RomA5oNiR12aG4FNKhrwAt4bN16nQkxWqAqkhziWSSTLOG1Oc4JmkilAFScz5gM+t5FI1IBDLFmmOOrTmHSgtRu2KDSE6OVYVuJGE948Kzf80voH5qm3U5WY9biKqYRFIcPMQrR2LrcaQLYdXcsNRlXAVrFUz7SeqdYxQ5JLxh1mkLy8XSO1AtBDnysROXZWUdYD7i2uOPo1VZpcxkkaqeFplSIMSR2k1itTViyuSkaC0HUxDVgiR6/IOHrwczPnEaePMjmVc978MkrlDtEgLcuVYe3yZe9oLfwf0P/JwvroIQxHHhmI9Iw9pNPPLIhaN7OJLbub4/ZVfPoMzMdXKCPw6NmIKG4KavQNUZC8okEW3qF3+CIUQijlfO8+z52K2iwbBm7K0iukWqUeZCnStUl8sNBpth5UqfPDIOK3KO7kA9ZJr1FL/osbwpZs6Px9w+nnDvpTu453mfxYXz5ynzzNl+YnPtKlOtXC07zm5c5cqNO7l9nci4Uev+bA/bHWFbCfvGGCJWjXXMrEYhBKgIqzhiORLHEYYN5IzIRBwTDBksQyxM1bOZmncAfVIRkoxshjWrMRNiY8yQRnN6VogOKbWu+Z8re1OuWqLURiyFMsZOlDZ22lBqN4eA2BJW1aNRxEUZutjEtRmkUnTGEMa4ZsyXeN1XvZ6SE4+ePcjl7QeJeUJsRSuddN4bgLl5A+P6ROtejtDC4vQvTzKpWR6tL0xdRumskIBon+jMG5IanCoUbCS1RBS3PRNNaDOG5kobCxDITo0ziLOxBIOU1PyebAa19uxvDxucxVVyNj1zfXpOFEknbke0s+FVnbgt5v52Ti83YqckSN9+BYPQ8GxsNXLuDkLc1HE6cOx0gyXDQ1qDIjAHqBEt/mHo0InLBLK5i09beF4GpsXBaDXqbNRaEPXhPeVEsoGQo3tcqnW/PI85iFGIFlHzE85s78yIkDkebuXaJyfirO6gEoLzvSQ5j60viVI0UoJS92DN8VPMRzAg5RGRjJ/BhiunnRL1Lz6Yec0dlY2+jevxd4G5Vddta0Nv/Xze+8lfZjufOvSRXDaYQu4RAZClcf3qw2xWhXm8wlSuQpNeIK1rXw8rdKy5QKA2xdq+G/ZWSBBzRGUgWUBR5jo5LKGNYBlpgdrwJUettLli1YndNcCQEvSQ+jSOjKOHdmlXZnkwlnSfSoPsuvLz5zbccetF7rvrVi6cv8BUKtfOJraibK4krk7XeOLqx/jogyOJu7h1syLs9zx25XGu6o59gqOjNZIi1oKbXaSJuey6r6EQc2RcrTh3dIxEqLPHclhOtL0fzmrOPzSmfpA2Wt1Sy5baJlozptIJ5BoQq7S6Z6oT21aYtVLqjO4rbd+Y1V9rW0VOdcduqtTi0rz9KrgZyr76RNNmX5KgKJFqGW0K4ktFBGa2lGHHg594h2/ux+yKrr1HOAVxswht3pj48tKho9YntWCummm9QRPfLPqWGrrHpBfX0Hr+keGu5sULXDNonW9pGrvKzVkrop3n2UInnUvnV/pIr+qHvQTz/QCGFcVmcV9KVWJVUlWk+Mj9TI/nRJGkt8etqo+N4nbvcfBxQsTxPIueCEcEy164BumGvaNQepSJib/R2rdpiI/T1g02tZqPbnOB5kFBnkDXeVzB8SuT5C7hdPMDPCZTWqPWSimuJPHgqiWbxqkLoS/ILbpLTIyRRT1QbWaIDWmVo9VdUI64/NDDbB+/TAwzRb0LFZEONjtuGsRH9dUwePa3ub1ckEBRc/dycVxS+4meJNBC5PI88vbLxhff8V5u8OWYrBDgjiPl8X3ms2/5PN714P39kFIPwop+QUUTkvnG9OzGdUhG2dd+XiwYVO+auwjeghsKl1pppSBzxay632YeiOIUjhaUGhuSQcTI6nGi1nzzWcqun/zmZHpxdZ4kIefEMCRyEmL0caqZOvSBdJuuSEIZknG0GVivE2M0TtaZul5RTdgMkVUEbM929yiPXolY3PHIufOE7Rn7a49ymibswhEjA+s00nTPyJ5cbxBPr5C1MaTMehxYrVecHK2IUWnTwPVhJMYVQTPSspt8aEG14JIVdQrO/ox5t2O/r5SSaFaZthEtM9P+KruzU8puciOTmgjqwV8yHHc/VjsQwgMeaEYNpDkRmwsXrHnTEc2cU2wBo/Y8p4SJiyYevP4oQ+rRCXNE2wA6kmQJ4ws9J8dXptopaG70Yoz+1tMNjNwOQbtrkUEV5z/SfQ4sdGJ793hsgBW/Pnz549vwTHLYrOmCwnURloENvjewLrkMbs8n6iEspVaKQcLQvtU284Xq3J7jaYnuTj2AFHcjCepSJAmEqH1j6ZZckoUcBQbn3GWEVYCUIpq8EGG+tLC4ULdczx2sh6o3x95qcwlgELp28yaBMXRZnC0M807AhYZYQeIMzeWDYuZmwa12JNvTFaM5HDCOntzWJNII1FKJIZM45lju4H0f+HVuXH+UqBPVGnta5216hyyqFLObiXlI55U5j3Mhp7uovRIl0Byf7p1mJSD8nx8Qvvj2mY3+CmfhNZi50/WlsfCi21/Kuz5+f0+5M8iRISWsefLf1Ws3eOF9K5rdYD/NroQqtTMQ/CaJ3c7L/TEbWmb2baZqIdRGMrBmSJl6+JfHWWgUBu08yyDE0E15rfr4JQEwUhyIMZIkk7qvYpaeUGCBIMntvqxnDjXXHQc804bgGUqlKGWuvuksM8wzUQ2qUaY9Z2fXCbEx7S5j+4LtCzEENhcusQlHHI3HaN1Syo5xO5K3lZHKKq8ZxkgeIA0wJGEzBNZ5xSqeY8357nAUsDJDm13vrTMhHpFaoO0LdTchzd8f2wpME7We0mojtgi2YsiJcyfHbNbH3HJ0CxKFbb1B2j6Olieo0ykAJomgyQ1aaJgOh2WJNNftS0gE8w5DtS8fG9RZCYy+3Oy4vmrqOnI3w6hWCOaKHQXUPPxNFFqUvlNw05dFQujrguQYpis0aAISk+vzPTiKJYPHH8kpe+LTE1I7xulLV7cfjP01a9d495iX6AewhI7Bdpep2HCZb1LIz/XtdhCG9cojAFpxx/Be+ARz2Z9B0EhI7psXZXH9CGCNFYkgHrZemm+PSxfzewCVHsLbpQaYwJowm+OIISVSTkjy2IFE9jiC4FSgrulxJQiVLL6llqRkfEu5eFRa84WJ4XhixvXNlhKNiOTKVI3VcAcPf+JRTq88TmAijYnSIkMUDlkmIbg9FLAgm8Eqs7a+l3LJW8ALQgqGKiRxL8tZGuAX0gdvNP7Tw4FXP+/tnMkr6WxT7tgoj24z9176HD7w2Hsc2N83hhRZDxsMo8wT73zX/dx+1wnHLzjyAKqQvUvUHttgAdSdBpsBNkOdXIeu7lVoVZHlqjN3kJEqaAEkoNljCxaWglOswkF+GNNATityTJ7wZ/1m74u3rI4nuyTOGwzmwHxauXLllPVwnaN0AmHAauP0xnW2168x72Z0MgqF/bAlWSXtTrEKUTObdI7N+pjVeJ7V0Tl03rPfX2Owyjpv0XlmtMxKBpIIQzJychPmVRpYx5GB4y7LN8wypitibdQ2I8OabAPRZqzsCW1FMGGwStDZ4ScNqGRCTpwcX+KuW+/i0vnbueX882hauXL9EfL1c2wnmLZKaMq+GiVEcgrMNhOqe07GIEQVb8hCBu2BYtYFHGbQGkkG3LqiYNawGHrRlD4dddzf3ObMMIjm163oAa4ZliLKkksvnS7XU04DfXnjE2KskARPt+xKnaRd3BEMl4h0SW/nzQouS3SVTfeDiIIMzk1OaiR1OKbOikwz1nnGz3nFjcTAeLKhDArVg8v9TY7U0rAy+wmMEKQisXnYlonfZNpHLa1UKcyM5I7j0XFNM1domAraeXGKdzFhTMiYCCmShohIdJs29c044oXZ3c5cI5pM+hjdyBIZZXBJlLmBazMDCSSLhDAwpIEw+kbQnW8CVx+5yiMPPUwtp2CNqY+6VroLM81lPHSfS+uEe6uOv8XgyxD13GanFnlRyTG4G3ug4z2+YfzJD8Jrbr/Oiveyi7/tgE3eulZecvcX8b6H3wFAyJn9fscQRy5duERtDa0Tn/rUp7jjlueRb9u4A3x2nqCZE9kDHvoVa2NugexoMFU8c1qij8mJSJtdUWMilAAWjIQiIfr36o7f2pxepdF9B0MMrGJmTIkhZuJiLKvS+XAez8IWOAAAwVNJREFUwmXBjVEoxk4rn3r0Otspce1UufPWiXVITKfX+NSVG1y9UWhTIKsS0uQd/GYkI1iZO1QQYRhhtSamiOmekFeM+ZhStoQqSBEo3kXbEq6Fu+yogVqX8sXki4ViBB3cFMWE1va0OmPN6WZRJgiFlAJDSuQYWa1X3H3Xfdx1yz3cdulWbr/jDkqtrC+vyes1l3dXuXb1FGpjzN0DNUK2jKbWIST/zGJ2M2iX73Z2RJ9KOvuQGgJiCRGjBSFiiDZPDxX/bBXH+UZd+JFC6AVQgNSpQW5k7fZkQbVTd5aiBqW6VZskgWAeA5tBaOROx7Pln+B8TAv0ycoFwGI4dc/63w/dp9K8rTTDO/YyUwtEImE9PGN9ek4UyRAD44Ujwt6wmjvHyosfc0H2fuGZKibqmurgY4t06WGrXqBKhCINc38ueqpL3yQ0J6Obm7cOKh6D0LEkSdCrCmYVcF224WP60MwBX+3+ez5Tu2Y8djv5GqjV/9ydbFZIHAgpkrvSQIrSdoVHP/oouxs3mMsWbYV53nv4WPf2Q2LHJv0dCdBTefyCsuZuzQOJOhdmgBFy9JvPT+GAVu8CCMbHrgi/9KDyyrvezDa85DDQ3HlkPLa9xH0nz+fhKx+ntILFFWdnW7QFVus1J0dHvODuezhLNzCVbiQQiJIBJUeXuFEb293MDU1YTe6GLZFNSow5kJPzO4sa0QJ7a75sMiNJYJ0j6yGRY6I1ZV+MWQ2GwLgaObfecMvRMUerDTkPh+VWMjdIKdVvRv+eCRuE0gLb/cSN7aM89MQ1Hnz8BpeOzyNl4vGzM67NhkkmNSOcNaI6F1GBVhq7yY1yRRIhjcxW2DWDNJLHEd1P7FrldH/G0e4Gu+0xrWTm3Z7SKlUEy6suMvC0PoIRbEBKI4ZMscrZ6VXPjLl2wmoI7E6vM+2uUesZpntiUFY5c7I5x8Xzt3Lb7bdw6bbMfhamesLpfEbIkRpdeifBdckhCQORmkL3P+2LTbQLN6SrtryLw3AYSUByPLBC3GVfOy2uQnRvyGj0hYgdoLHeV7rlIaGbE/eROXjEiMMhYBIozZBZsSquootCXiWPYw6ppx3SS2Q3avZSgQiUJaLFfNQOndfcrHX2ifOjW4+oHichlEhEOFo91zHJFBkvnifsI1p8F2/qRqstRVIQwjx7V6kCPVbURJjNKK1RtNJmsOhjseJ8Kl+qgDv+CLEZ0VzLHYNvklOEMQmsEk1d3ljb5Gqdqv3i0L5ldtmeJ9HhWijJHTAuNINJuyuQLJyxbrzRzLdxVZh3hbPTq+xPr/vrDe5qFEP0w6HTPCVEYh4OJ2RvRyBCKXtaKZRuvWbiBhFRfLtRW+v7bekUEle1/MT74UvvepRBP0YJzweWbtJ4yd1fzKce+xAxBeb9KfHohGqFs+3M/sYTvOAFdxHPr3jCbhDE3aljdJeihI9QSCCV5gB6JwaPQ+IoDxwPmZxgmmfKShnmRpzMpaIxsDpKXDg3cDIOjDFRWuNsV9lWI46Zo1XmtnMb7jh3xNF6Q85+CTvbwW+iYp6F0kyoCkamtMC4N3bbxq7suXHtCjrPxACzzX6z5+ifL/5Zzds9tEKQyGyGTlcxEYYYKTkwa8VSQAfYS6GYcaOeclJGtruBWhPTdErVU2Y7o+oeC27PZSa0ZjTpZg4JZpso81V2Vz/J9cGY88DZ2Q22j1+mXr+BzjPZgx2BPTEUYk5Uxe3urDDNZ+i8I+gMNvm1mwdYJbqylq7KBVxTr9INWRYsXmGR5hqGyR6LEAiMlmiiB/6vdJBRzA7G2X3RjS2hbh0ssgWgFEGDU+aSQSyVFoTSKV61+h5gNWRW60zIfvFrn6R8B+CFUcQ7WFSpMblh8MHG0OmEC7opat3U24gxIGP0ww843jzXt9sSiOsjZ+wnIZu/oBKLb6jj7FriNHrusvjarDahUlEttLlR1KA2mhbfMFsgdKux2qWLVPPUNRSNkBKOcyZ1OWR3kinqRhapKNY8sJ3kJ6pzCUNfGLgrM+qdUG2N0nxRYOKSvdYarUXn05kiZLbbUxpGGtzkFpYFhXQweuGceYxEwUc2aW4/70xcJdAtozC/UGbvaEMUp6VYI+JaczX/Xh89C7zpU41X3P02robns6Djdx7D5Usv4GhzwvXtZUIamfY7YspcODnH6RNXedOb3sJnv+rz2K9nEjMhRkyj40h5dJwI314ScEPkqKxXmdUwMoyZVRZGzZTW2O8qcRupDcK4YjzK3HKy5uJmYIzCNBVWuXCsMKzWHJ1c4PZbL3FxvWE9eKYMYpg4D0/VaDagFijNl0oWs18vVXA70kyIA4qPdJkAIsyzdd9Co8qMNCXbImWLEGYIO9RuAGtCbJjumfWUqtep5l3vvmTO9hGtiVp2lHKNpleJ8RpYNyRpjSbNx8pmzCbsy4Zpnzi7UrmmO+qwZrvfsX3icabTJwhanNZkM7vdFZ649knSkNjujpnKjseuPMrVa59C51M2uTKKUXIlrSJxhBQ99M7PEr8fmhhV6FBWtxNUr0BLbGsS5wR7lxadN3sYxp11YsGt+hajrdh5Pj3IGYIXqCBL2fRilxGGIVKDeC7OkJjn6u5Dq4E8ymFbH7UzPBTPu1+5R4NU54MOIfUu04ukJzIY1Sq0dtPkpQu9j2Lg+sq7y836OW6VhtEZ886XZHKbdc9sMefFiRODc3bOVpCRMgspVETPkFiRsEObdCF9c2NPvJA064x/9RNQHThhMCGjpOab2qKVVj1qMym+BQuCMwR8oRQI/eQNxDSQkutfa83QSe4uz6rU1npMAx1jgdAy+1PffGsfcdxTL6Fq7hQTfX+RqueFWPTte47iUIMIrVORHHv1q9OsUctMjE61WcYmExyzIzCJ8X9+wHjN8z5IjFdocot/7yDctoGX3vtqfvG9/5zk5RXdz6SLgdvuuZMrj1zm9PJjhNsTWwqWV+QkHBNozKxCxGqlavXo0BqQNBDiwCiJIQ3ETWJIsBZhNSnrnS+y4jhwvMpcOB45v8kkaUzTRN6MzCaMmzUna/dbPFoNHLk/hHPcRFyHbXSNv/XgNj8gYaZqYLUZkbBCJDv+FQIVIUWl7HfehfQ89dANGySoGzsPARsnpnQDlZlmO+bpCaiXuZCvEyxwJMEVUS166FXbQdiyHmdOhpk5zI6rdqPlYoZqIBA5ppHClmaV7TQjdc1umpn1OnG95zjNILAe9+R8laqRJ57Ycf1sRLKxr9cY149wx+3KhfMroCAhIykSVytIyeOabCmS1pkf/RoLRlNXrbgXoycexnje44nNk6Cszc7hVYeymoqLFyRi6k7f7kqF+yNIIKR+yIvQanXBQoguFmme2lhQX9w0yDEQe9cdLBLIqChLaB/+MblaTj0MjOayy2JOIwuC80SCU5loDRNne4gq1A1VL/giSuQ316X+eE4UyUjgWJWdzpQibOeZWgpW3brLs1kyq5RYp4HVagVxYLc3ok1Y7YnuGigdHG7q7selFlbVmVz9E3Y7syg3W3f1fBg3+RRiNZJWVCIh+4bdopNTseCdX3CLqBQjKTkHM8hAK4qFCc3e1RSbqTqyskwOmZSU6TQybWe0CVh2oFtvKtaRQFQjqQPRGoVFU1m1eejXEgFhNwncy6O1hu1mButKHLxjcAOPQJDGQzcCb3mw8UX3vZXr8rv7VxrPO4IXPe9l3P+Bn2O7P4XuDzlNey7dehsX1seQKtXgke0WBtCVk3+rdhPTpuislP5cA0IheKxAx6TSmNmMK+JxYG6N7VwxIutxZLUaCUN0pdGwJzehksirkZPNeeJ6JI4jIYNE96a0vhAQcUwqaUTVP1PBC+lApEkgxk66b4ZS2LcdajM6OmHd+gY6mJJCT3IelGFt5LhHrVIbmM6sh4nbLwp27AukHAKr1cywmhhHYJo4Xgu6Grhw/sTD4gKM4lriBr41zyNMxvmjI1IwsMZm5XaAt3OBIudRVXLMnoYZMzEGLF4hpEAeE9O8Z+Aiygn7soOgiFZiHChNWK2PyQxEIq0vGBWX2UrH+lUrVL/uhpRIIVE0uiJKGwAVT7xUdcin1hksEEOiVadqlebRtdO09y6VFaUUFKNWX3auhhFhydUJzNU5wqi5OYd5bMcQN5hlSlBSCHiXaASpTukr6rEh0py4T8/WVqd5hdgdXVsjZSfnZxrRjEpkyZH/G89Qnz6TILB7gX+M52ob8CNm9ndE5C8C3w1c7n/1z5vZT/ev+W+BP4JzQr/fzP7fz/YzInCikdgyu3lm3hZ0ntDOeTMz0mpgnQbODSObcaCG6Fm8OVCHSGuJOkVqce+6YMJQffxelASOnTSa+UY1pgEzZZpngiV3B5IEtSG1OrdKHE9J4vnfZr55E4lEyQw5k7Kz/MmR2BqxFXZzYwJUG3MtYCPrITOOmUeuT8w7PwgEPASp0yh8EeKJc6IuE9QO9KspTYvHreoz87rM/NSucyEOkZYjNbrjEFpdsWDwk+9TXn33uwjxy1FZA8YQhduPAl9w9yt42wNvoNQtpSbm3cR+N3Hp5CJ333U3D+8f4/L1xwlSXEHTEkVGp2NUZxIrARXP5WlzYTcI5+Oa24cNF8cN5zcbYorMUhnnhlkmB+/MLbhJSYiRFAbW44Y8juQ8YENmCoEaGilE14Enh1UarSukuq45BnT5/MQtuMwcQ4159M9nEmJcYVqw6uoopHFw1jaXUY6rFSkm5jIzDCuM7okoBjJ7LIh2l6EwkFMi5A2SjLN6yeNnOx63jgGphabKyfE5kgSu7RuSI6VOWKts1scOISzYWpuARo7ZC00avNDZhEhDRhDZYq2xxiitshdXLg1k1lmRtiPlTKmFiDBuNpTqm+sUvHhK8hmiTYVAIOF5OyaeOy9FWOU1EiJznQghEmUkWCLntU8uVsh58EM9CDn682mm7KeJbB76loeBcVgzSmRX9j1srHn2ugTOTk85Xl0iyQalksSY6xmGE9nnWjjd7lmgz1ILNGMM6RADEvHGQQ2GNHhZajOhNWJ2JkjwBPmnfXwmnWQF/rSZvUNEzgFvF5H/q//ZD5vZ33ryXxaRLwC+DXgJcBfwcyLyYnOG79M+xDz5rZYV87xnnBrlbE9ps0expojFhiUHPbS46a3zEV1uZYdMjIBJLwrNQJR9ApVuqtA11UEMqwWzQArJNdzeM3ZeZCVm6SZ17mUZxYPGJCVicIx0s16RnbqFGO5lSKRao4WImnciOQvnNgMpH3P9yjXKPCO0PoJYf+86k6FzLJv5Np7mEgSh+1faM48G/o38faitoa0SYySbuYlHNxCpVvjIdXjLJ/a89PlvZ5tfx0IsvPMYftt9r+QdH34jtVV2uz3rYWK/3fN4u8HJBeX41jtI+w8TM+TNQMoD59Yr4hDROpNZ+2cxNzQZR0cbJA+cv3SR88drbrt4nrtuuRWkMYWJ0iAzstZGHiJ5cO0+Yp45vtoQ88CFtCau1pTicsBh8EVKiLGTix1HC5bJcSAFz2+J9CIp3j0amRQ3GIHSzpESqBX3N/SyhCFM1YvlmBKph4BNpXg32iV22hRsAvGOfVcm6nzGpI08JPbzGVOZEHV1WM4j27n27x3Ynnka4bY29qeFmKKbTJczWvXJpzV1U5UgaFMPr4oJpBKToq2w303sWyXF1GMNhHNj5nTaIynxqVrQWRnz6E5aZmw2vnEXC5wcnzDkAbS5N+XinVr3qChTnZmmHafTGUcn59luJ78PUWIcqbNy4dwtWFGGmDyORCI5OYHdMM6mPVWVEeHqE9cYxxXH506YtltfIPXM+vV6AwhW4PEdHG0aU91S686t9dpEIlJaYTvvsGjkGBmHNUMaaHUmpIyautY+JUorxOyRGlUreUgcrda0svcG4hken0kQ2KeAT/Xf3xCR9wF3P8uXfCPw42Y2AR8RkQeAVwFvfuaf4SdAa/PB41GlUVrFqp9c1vWacXau3C4YU23s94X9WWHa76m10RrQnFpQRbAUiZ16qjjWkmt0o83odJ6hJpTEjp5tE4HYQAO5BVp3Vs4mrFImRkFJxFVmNWZWEgniagM1ZVcrQwXZN0px7mDMzUeibeb08eukOvlFT6RZ7clvfmE3fOOJVnc4V+vF8eb28NkenjK5IubKuAnMs6I20FJEo4PcwQrBBv75+yKvuuftbPNr/HIQIQflnpMNL7rz5bz/oV9Gp4nTsxusp1PG1TGPXP4o973wDl73spdznBPjOnKUN9x52yUIlRSEo7xiszohyZqUKqtVItnIer1GopBSIq/WzDJR9QZgRMlO4wkrchiJCDtpGP5eFYtcsHPkNLKlcLVcQ2juCo/7S9oA2vZs0hoNKyYL1LajaqVodes83OS1zlsW49fYXbNL3VPKhNZCXq2YS3WLuqa0rXfFIQRicC7hXAu7ecJqI+WRasZ23mJt9kJ2OlBrYT9vIQopj6y3I1q6bRcJdI1RKG12OtyY0Vaxsu1LSpzjJ4naCzGtwn7qUlR3xpr23plOUsnZzVNSSISwohZFZ+mKFsfJdZ7ZakWGRNBA3J8y10At6p6dJuSYsXZGi8b1s2tonanSCDtjdzbRUMZxZGo75loQ23GyOUFl5PT0jGmeSCkxz379Kr4UElNa85zzem3i7OwJ8pgheKNy9QaYZHR2UvmQA9NcSGlAa0PbTJbI9e0WEyVKgwC1jcQgXvyaUm3PVM4w1KNBSuNoc54yNVbjmtV6RZ32XDg6fsb76beESYrI84EvAu7Ho2b/pIj8IeCX8W7zCbyAvuVJX/YgT1NUReR7gO8BOD454sb1PXN1y61iI1Unau18MgQmZXd9z5QVGRJVK/vWPKdiLky1UotRq48m9FW/doPNWL1TRJ3mlSU7XB2EOSRCFAZz6RVETAdmlFB7l9eEkv30HscBE2GMkaOYGNNAM/OxPUTyMDqtJUxdOSioBqIc8fAn95ze2IIKkegSKlfM+YcqriCw2tzFR7vs70njtdtQyeH3v/ERDEz2XLz7Ip/z0hfzK7/869h1PJp2zJRWaNVHqw9dKdz/8ZmXvPA97NMXdpdo4c5jePnzX8P7HnwbWGVXdjxx9gQnRydshhVf/YpX8jv+sxdD8Pd1jCuEka3ufbNNRMIeIaO2R/BxmhApKJMZW91T6p5mW4zCPBdMBiSMoIEIPQnQLdKqJB6TiTbDrI25TdAqSSGLsJ12ntEujaOhEDhjbjDNW08KNN8OY45jTnMl5RU5rjzCQitNK6aV7dmWYdh7VIfBfvY43JiMFCHOc79xz7i+u+6LnjAS09qTM6VgtTGMaxRjv98zjhvUZsY4Y8UoIsAMZjTdc7q/TIqJnI4IMhBQVuNInfe+HDScTRADpVasVWLAcT2NBFkj4tPJPDdSypzhgWUpCZIdqqmtslqvsGHvbIQwUEpjOzWYZlpt5OhSTG1nNKukGKizsMpHaJvREshhRQ6B9TCSotC0MObAKpov5k7WnJ36CdbWkf00QQiUOpNCQDaJKIVpOsVkSy2+nJUQmOfijvbqlLrrTWktMgwb5n0hp8B6tH5/Rco0U1pBJHA6T7S5spuuEsdCioHt2ZYYVgz5mACsV0PnT1eKKpdP989Y9z7jIikix8C/AP6UmV0Xkb8P/BW8t/krwA8B/+Vn+v3M7EeAHwE4f+sF+8TDj3cQ2YtNmaDOgaa+ALBWsdIo4hLCWJXZ3HyX5sUsWKdGCx4gL77ZpZprevsfhpi63lmwkLAYSEkYqahBa4GqiYonzwX1DwKMUgrrcWAcovtFdq9Jp/94Nnip1nl6dEy10Wrg7FR44KEr3GDvShDBY2672iGYf52qQxDWHFz/rTzEtwzc8zm3883f/bXces8F7nj+CT/7T9/G1CBqoBJAMqYTjcI/ew/88Gfdzz6+bPmsGRK86PY7uPeWF/Hg4x9E5pndo49xtjphd+Ecjz2xZydHnKXrDDURQ6HZjjM5ZWtnzG3GLGF17Br5Cs15c1OpVDXnblrl6vVH3QyiVqJsSMPaTS1aY1LDdHZ6WNwwJLfI2p6e0erMkBNZnEa13+8IY6JKI9lAimtUArX50iGIE6ut+uHazCMfQrzhDITWWdQY87QnR18SBhFK2dKKEeNICIlpegLTmao7buyuuz1YC+Rhw36/J8ee3JlXLIFY67VzAXOciRLRoJS6xWxgvz9jatdoTRjysU8CjJw7PqbVQgyOU2tz5sCMq8YSEQkzhjKOG6adMuaMqRc2kcB6fXr4XLOs3QOyeyAMA+xOt5TSiDGiWlB8aVPmyQtlCoTm+P4uKSS/7zxzXDibXL1TZl8AGTuGuCXnzHS2IwRhfRwptTGMkZgyu/2WGAtDzl2BFBniivWwQlLm5CSx251R24QAN25cR+IeiUoaKrVOFDUkjly/sWXe72hWiekcu92W/c6TVHc3TjEau/2enE8IQwFmUrdRXMXCNCvj6vwz3lOfUZEUkYwXyH9qZj/Vi9wjT/rzfwj8u/6vDwH3PunL7+n/7RkfpVY++dgVl9UR3OZpmqEUjOZqlFaZakWrMriHuVuSAagn5mUJWAiUKAeXkGjapcBKMSWERJQEnUvpKWowRPdQVNfWd2NQL7JqfeusSowZnSuNSsgDO5uYS3Vsa66U0qjFOZa1uft0a41ajEcfucGVJ66htvOxunkeThCjFR+pU/QbXq35Rp6nTtdLB9k/g/6n4fD3BOGuey/yP//wn+VlX/oyclzxdV/6lTzy/v+et/7i+6hzJOcVtdutYcbHrglv+/gn+fzP+Rgl3NcneuHOc4GXv+C1fOKxD2EoZT7jxuNPkO94AU988hrvf/gjXNtcZl0zLZ1SZ8/g2c+VYG5CUaZALXu/YbNv6ffbmbKvSBCmunegPjrWliiEuOPsxhljgkmvA8W37HFNlg3BImaVIIU5CBIH5gbbfWGojkfpdMqQN8Q0gGpPmMxIjGyG3E04QEuj7ea+BXe3JgnGanOOsp+p1SjzDOLTxr4WSj3zGl6N3VTZFoja2KzWGLFzM406N1Rrl9/Bbvs41ehY6cBc96htac25gMP6nDscEYnRO/9pX0ihj6v4smOqEyXMbjLbCoTGVJSxwTxtuX7aWA+ZrlylzCuE7N1p3PsSZmvM+yfYrBKBRGtGSIFp3jslKkVaLYQgtCSs40CdZuKQmeczhuC5OqW6XDNJcpef6LS2PGZWaWB3dobWRroeffEp3r2ebm9gFNbjSI4jVQuZM9Zhxb40LEIpp9S2ZXN0xDQVchhYDU5BikMjhMR22tN0wijEJO4Ylowx+/0oAdIqUodELVusXCelvRvTkJB8juM0sH6WSviZbLcF+EfA+8zsbz/pv9/Z8UqAbwbe03//b4B/JiJ/G1/cvAh467P9jFYb1x676i4gIblRwuwYDf3EnFplLqVHKigpNGpSIuI5wSizKJaSxz1QCDG6H50JWj2nJsqExIJJxNSzjLNKt5JyqVMIHkSVq2+nRZ0kHiT3kPNKmwfHP8PsC50qlGrspj3T3LHRmEhpIKWMDBsevHxGna4jBaxO3V7CO1GnYdC33O0p3Ef6CPz0D0NiN7kIxxzfpvypv/bdfNFXfInHg0rDLkV+33/9Tbz3vR9i90ljyhMk99J0zq/yz3515m/d92bm8T7o4/yYAi//rBfzpvffweOnj4AJV689waOPPUawczz04GPcOHqMrFtC2DLXQlPBLDGOG0JaUUqjTDNjHqm7RimFGFxZVOtMmxoxjFgtgDE3I0jzALJcmdpVqgkprMkSKUl6xlFijCuaObc2pIQSaRqQlhiGzDisnas3JA46fhIiiaY7j0EgEkPGSukcuga1orM5x1KV3TSjWpEwUevesTVJxJhZDxdIcuwqoxQYhkiZK3Pb+bab6PlBgOrEahhYjUeIRUqFc5tjpukGMRhzDaS4ZkiZmLpphFZCzF2emtjPe862O3blOueORo5Xa05Lo+wnWj1lCLAvE0OO7OaZMAZSFVYpYbqnzBOYMgZB2xlXriub1UWqVrR0GlBtRLng3p5mDM2VTClkbPYJadcKmzTSmmGtEYeMNKMUpZpgTZj0BqXu0FKwrVBjwIiM4gswEM5aY7+/wuKSPobEPEsXbEwYe+Y9zJMyZOXxa3vyMLg+vylTqYSwppZMSmunDVVjW6NzYJvSJthPypiPSQO0ekokUuuWM/XF06Pl9Bnr02fSSb4W+A7gV0Xknf2//XngPxeRl+PzyUeBPwZgZr8mIj8BvBffjH/fs222wQvDfjvTmJGUSBII1bWnTStSm5OyS3FsTioaXTdMkL6QieTmo/c+wuJWPNeJJEJLnRhtzd1JUKIarUVmCaQ8MCBuNBCMuSnFemaG1yKajewKbpgBTnNYZ0qMyGrtelAGBoNzpqjA6sIxd1y8jeuPwHve/wHm/dwNLpwYHELoeKN1s9D6tDjj8ni6P0stk3IgnGt855/7g3zuN7ycX5k+jAFpcDrUC3/7F/Clv+dL+b9+9D+6C3OSDqA78f1j14y3f+x9fO6LrtDkEmZO3L37JPKFz38db3zPT4JBbXs++uADPPChD3LuCz8LzTtq9CwXMwfdQwxst2e0cuaONwTKPFNLwIcSz/WWIKQwcrabMJ2IoRENLAxsVmtCauhsZEmksCLYQMVVF0PKjHlEcB14igOjBUrdE0RcapqX93RGrTCO3lUGKhIL0zyjJRJloO0LecjkmJnmHVM58yjj1Rrajv3uCinC0WZNkEStbjMWY+R4vUbS0G9sJR2do5WBlDMiA0MYb0I+MZLTCAqb8YhxCGx3mXnaYSashzUhBnZn1zx7fjWwnc6Ym/M91WbGYWQcL3G8WZHjQNldYy6FdRoxg5wHmkamqRImuGETWz3j8o0raNuySZmjmInSMBmZ6g7CxG66xjgmxnhEkOtMu9K9OyNjHji33iAG+1jZ7rcELlPnCZ2NW8/fgs7KMBwjYSDELbv9FUq5wWbtdmvzbiIPmRZcKHF8dEQIgVIKOY0IiVKcErebCilmmhq1RgIDZVY0Cjdu7B1mS8EVbbqj1oqFPTlnpEKqkZA2VB1o85acMvvTSkojwkVKbJS2I8yNlBP7/1+cyc3sl3j6fepPP8vX/DXgr326733zC2Cai2egaPXFikGN4qL41ty5p3Rz0B53Sr+RJYj7LKp5bEMvOLVVN4kPHu86yMAYPO/ZIhQRasXxnibIMHA0JpK4EkHwcWN1NIIYkuHCuQ2XTo4YxoHj8wOXbrnIGNecPzrP+aMT1sNAzBHJjmMen1xijOf54f/pXzFfm7Ayod2JO+QEaMctl0J5swg+c/fIU/9OjMhJ4PXf97t45e9/DY+fXuvhZNA63SOHFV/z7a/nHb/0bh774HWKgaSETsUNBoAff0/hbzz/LdwYvtb56aYMMfDaF38Rb/7AzzLN1zCrnO2u8r73v4cXXr+IXiiMecVeIdnGzRJE2M2nlKkSoxti1SYMZKIF5lrIacXR0QZrjXOrNVDJETKREDMpDyjupjTkkVU+IoSBubT+uXfyuBo5ZkLIlDK5hBAj5cSwWjnlx9QPJd/Z+NeFI1QDpbhVXs4LTxai3EYrhbnOpJz6cu0+/AINvTDPGEYM0b+/JHLOlHnvDusKIQ7MrTEOK3cFj+4gFaOrVXbzjAThxC6ieDxq6NlHcCdZnYx0Nk1YdBf32N3oHfB2w5PNpdvclagZ2qo7/dNjHppiii86p1OquaIstYBYY6979s3J4CKfRU4ZabXzIt096JDnhDDERMbIYeVEcgIMkev7Pa3Cmoqg7MpVdtvHaW3LeJrQKmR1V/qdNHatUGplnh3qOEoDm7Ry3HQcmeYJZxvMhJRYrzfEZqw3a++qY2CMkYQxTTtmLQzpiKEecZQvIBLZ28yuTdR5h+52bp6SYCo4hcyuYfNMlJnWnuNWaSZQRT1V0NyiqTQooW+nO8dq0UyHmIjJw4DC4uJpjX0y6CYWU/dblBTdgy51a6WUkUEII6zEyHng6GjFyfkjbr14wvMunmO1TgxHa8ZV5ty5Yy5eOMcwZo7zCRfPnefiuXMYMI4XyPkcIWYqlWJ7Ztuzt8r1eUcVZZuMBz70BP/xlz/Ifr5Bma/T2p4Q3HSilXLTQOM3vi9P2mI/2yMfK1/73d/Il/6BV3LtxjVyOqJ1ha3uXN45MLF63oqv/q7fyU/+pZ9C9z0rPga0+s/+6FXjVz72Dl78oq9EWfdpX7n7XOS3v+jL+U/v+XcunzTj4U98nNwCJ0d3cnSyRo8rWQaGYUAxpnlHrUqOiVUaGdPAJg0EEaewBKfcoIVhGBy/a8pmNSDZnWpKNzHOkkgydOjEDy7MTR2qNoRAkoy2lVusSaK7WjLVGST7e10b1oTYPQlLVcLR6NxKbaQYHDs1QccBs5Xr77WCDARGWtEuMtg4cTl2KwV1f8WcfFGTZcAI5Dqj1aGUkCKtVWJ2v0+L0eMtJKG1knpeTgzJuYUIpRbObZyU7V7IyelG4pZfNcBKfSxOpEOOjDZ3xJ/b7F6mtTKk2wChTs6R1NCYbXYj4zBg1SeLFIJzdK2414Bqz6hx//kcV2hT938NLt2lQcgJnQxJA2e6pU5nbsir5pvt5NjnbrcnpMZUJso896kMytRct52Mad76gs2Mav5aTGf228LqeMW+FfatYvvCbrunBFgd7dk+cZ2mD5OyuwbVubGfGtvdKevVwNE6cbrdInGk1FNymtFySgrrZ7y/nhNFUjCP2SyVuVXPzVCjxUBKA3N34Y5ksEZIEJOHTRnWfRQ9amGMgSF4Qt5qs2IYB3KOnFwa2RwPHJ8cc/78Ebec37AZ11y6dCe3XrrEhXMbzh+vOVr3myZACBlLiVOd3O5KM1uJ7DRQa2WeHme7fQiVAjjXq7QGaUNRZbVOJFb83E9/gMufeAw9vYLVSiB55nFzPBJ+c4F8yvsj0u315dAlZIsQI8fPW/FN3/f1fPk3fzXbeIPjceVgenCnItXi5sVVGTYDr//GL+fDb3o39/+H9xOqc+8saSdEw4//6pa//oJ3sE2vBfzizUH5qhd/Me/4yC8x768jojz+6ENc/fgTfN23fA3kLYYeoA+1nr2sgWSBVcpuW6Wtd/fOYmhWUCveASUn3gdJ7hZNYciBOhf2844k0QtLcasulebYFxk3MGlocB5eaI2YAHW9boxuy2WS0AjQBQJhJuBFWMXlptp9D/21O5E/R3esUatIciMTzwz3ZYSIHaIJYsruXVqN2goinn/kRruJFAJaYaaR1F3lU4jM0t8/VUQac3UViUTv3kIx1AIxZWIPWTPUM5bUyMkXklX9czQLmBmrNoAEZunu+K1yfG6EVtGUUFkjmhhSQLvU1R3eI0WdiJ9w3LeZECSSzDPgu/8YpbXeIQc0ejZ80kAejggKMQTOnQjNPNDt4uoESd4AtC51nFujtUCKIyqGlrn7jwY/pLSxiompzC6xTRHZu+NV60vZxp7tfmJfZprNKJ5Fvp8r293O6YQ2MYrj0GUaEQlU8TynZ3o8N4qkwdhArNvHm9scxRhIodvzh4AlQcdIXEfGzcg4ZDarkaPNiqPjgeOjNXfcfolbb7vE+XHk3LljTi6cZ3204dzxMXk1EMYMYlgK7E0ozZ1E5rrnE2VLvXGDao25FLIFaojcmPZsp1MigSENrtAxYT/t3IU5KqLFMVPJSIBpvwNmprOB+3/+ndTtGdO0xzQ40bdVapt9/pNnHq2XbvLw5wISIykf8fyX3M13//mv43Nf9yLiekDi3URG//td/C8IyYQhJOZmbOLIn/xv/hgPvPMHeexB5/ctri4IfOwa/NrH7uezX/gabHF5Mbjr3MAXvuAVvOtDv8xud50YC//hJ36Wb/n9r+eWz155zo1Asdp9Ep2GFRBqbb5ACg0S7vYiSlElpoyK291JTLTaPO5BlGjqXp0pULT6As4StZSe0hhp6oqiGAJFHbOOTYk9NdID4PBNp3k2uUWPJA6h5520iqk/B8NQW7a7M22eCKLkECF6MNsSduUjkAexpShdFOGYcutWaDH6Z6dWCbgPo5vQJI/8RWiq5JQwgzgMzgmt1QO3SqVVj0cIEj0vWisFI0TpXGJlmv01EH1Dj/mYLAVi9IlFq8e+Wm0EVeZ9JY8DOShldv9FMQUqEWMYMybOAKiuvySFiLZGHl17LmKsVgPTPKGtEmJFYnAXfvVDR3qHnlQ5yokcBlpw+KA1d0hVjOqSKaayR3L2xM6hew2pMrXKuEpIdDVZjmufMHGvWJ0T5y/cyom4emo9OmatptRWu8NRY7s/I+bMPHtOVBDfC/w0P/u09+BzokiaCC172l1aJRKNYZWISTg5XrM6lzi+eMywXrE5WXPrree589Zbuf2Wi9x28SLnj48ZhhXDKjNuRrcf6z6Tu2mmmfKYGmf7M9oc2FfvnMaQcSu6wm53A7XC3Gb2ZfJICQLVIqUWtGx9w7mY8iq+5MnZYx/60mdYr9zyXmakZj70zkd55IHLzKdXsKbkPBKCdszFT9EnJ3n8xsdvLJ5BAucvneNbvuOr+UN/4tu5cO95GrPnt5iQZUCbKy3cWCCScJciDS55/O0vfTnf9T3/OX/rr/xdtC/S/Xn445++6zH+6n2/xj699PBzc4Ave/7LeODhj2IW2O+v8MD7P8z//iP/mD/+P3w7uzwxq1KX1MSq1OrLoar99UpjGDK1eFk+2+69aDWYamFYrxBtzPstQwie350iWgulzAw5HxQjpfq216MFFKmNuc49LM2DxGgNEaU0Zd5PfsBJYxYo1iWbao7DdS9Ot63zQ3meJ9Dmh3VMvmSj67lVgOIFCQ8zg8VQwzv0ZrhxhASgwOQyWJGMBid9Q1/eWS9ewf1PtTWaeZeao9Da5EIHCzTcoCUmP6zFrMtyPZ5VpTGOTsi37j8Qk8fNShCKKUPsEERTtE7dw1T8veixybE4/5EQ3U4tBPaTc1ZFhFZm72T3CZCeE+Wkd8eFo3u91tlpRTjNK4SuYVe3QNPWfKcghgQjxQDNaLV28wznba5G/wzmWhhzhtEjHKK6SfJqXOGWeNWNtVvtJibi0czBI3QrlZQ2/t7QEHCJ5zM8nhNFMq8i973sdlJOjOfWXLxwwu133Mrx8YbbLl3g+Dhx6dYLBBmJJqzWA7qKzplMA5Iyl2tjmvdMV244AX3vKX2tlj7SJFe5RNey7tvMmDx5bT9N7Kc9QX3Js0jY3Ft5xFpliBMhewzEmBMXzp+wXp/QLDIMA0NMDCGS1yvG1cAgtzOdzvzLt7+d+Ykd1BsISozKNO/4dCP28lgWOcsWfLUZ+SPf/3v5w9/3e2G9xmxDlg3FnCTbrCAxUGgs2TdtGQvNureU8bX/xe/hp3/mjbz7l97Ti/TNhdFHrxq//uB/4vnPf+lTnsvzL93CheGIcF6RIOz3p/zLn/wPvOIbv5BLL7lEa24TIATXAxcPYNPgnZGURpCpu7y4m7iqFzSrxqSFLDDaSFRhngutB5upZs6aYq0gFg5cwpCiu+KIeHCZgTQl5t6FE4GCjIGUkpulKIgEVNz0IwbvJoaYCKMXBjXXH8eY/OvwRWCtlRTd7955rUIMA1UdZxVx3Byg9URNMyWk6P/gOeCmHuzWmneIBMHCsnQ0JPro3NRtxWJyrbiqL6tac7OzKO5/auoshtq61rsfJrWfgCY+KZgHybO3QlgSQINhzTFBkYoFJ9NLd1CSmHw3EF0JFgh45nz3bcSt5ZYDXbqpRkyJIEJt/hoqEdTYh4n1eu24ZleTqSq1uItPGlzjHgKU6qobU/8kowhM3kQ1KbTmS7JRnCCPGWl0KKsBfT3vCz+J5BDZjCOSE3v1WGhrytHqOY5JXrrlhO/47q8nd9BeshsaaPMXoVo4GwbOZicAD7Vg1yamqVHbjv1cwGaCGbFvPk/nHfvdDquVMs2oBNQKKUj3XIaYM5vNhjJXai2cO3eOYTNy7fSUVdqwGTPDuGIcBk6OM0ejv5HrzchmNZLSgIjfoMmcVQOOSVkz3v3eD/PRd30c3V9zLXAeqG1Pa7Nji88iql+Klt90ngaY8siXf90r+Po/9nqurTOO7j2CWURCdjxQHVyv3RcxEHvRwvmP5uaqdlT51u/9Ft7/qx+kPL7zZUpvAkUC//QdH+cv3fsx5njf4RmNEV7/kpfzD//Tv+XSpedxeu08u0dv8M43/Tq/+6VfS20NT6iITsnKHng/tZl1XJGHTlomEEOnyASg2aGbjmKeLWRGUc/5sWpIdOzJR0IvrpiPciGIR2eYxwgniT7AmRegopWmrrhSU0Slv09Dt9xypx/BuiEGBwNf6UlWCkjzLi8GD1lz+pRizTPPQwjLG9i/Vyan4GR2AUIgdQjCtDIEL8IePWLUbigxF3dDT2Joi96h2XJN+PdfhATNzAnw5hOJ79qsyyw9NXCJeRVxFoiHd/WwOG3MbYYsrFfRlVA50KpLNVGw5g4+iGBJkaoQAuqfCLF3vhidm9iYa8O2fp17pwatiU88VE5Pt279lpwV0JoLMYwA2+6v2u/VVhpTLgfKX6uNG/sJ0z05ZVJ0nfksUOfafWf9takaIWWffuYtMQg5QNlVN72J/tm38sx34nOiSIaU0NXIPgRaBVpBT68zzw70Cz0aQY3ZZueKhYhYYDdV9rUSk3CUBwaXyTAEI61GRDaMt6wYhkSIjSGZO52Y0AIMmxXrkDnKg2f/Zqc+rIYVo2Tn7om5fx9Qu2VZjm4ErOI39koC2h2QAWYLvOWNv8bZI9co8+OIRBSllBm42SH+xnF6sWazfsF5x2KknLn7pffwh3/wO9ithVa2jkGFBiGTWW58I0sk0m3daLQ6MZfS1URujpqk8vIv+3y+8hu/kp/7P36m8xn94jQzPnLV+NCn3sS999wskgZ83l0v4ihknnjiEW677UWglxjChkvHt2I2eYiTBaRb9nr0Z0N6FGgp1WWXRGp3f3faTr/R2uRYnykBYwig2QUC2nyMevL7ZzMgnn2k6kUyCNDcFSbFRO3sgSWa1o1C+tIsOJham2u2NTqlzFgWZtVH0v55xOBkiYAQg98+oo7/qVUk+GGjHX7x5+r5Kv4amtueWXeAKpOP2ubdoYibOYcQsNqXMK0XOlVMvSiGEAhRUJsd1g7RDwF1OauIEFKgmhIkMoTQhRj49wjiUEKAaP5zJeAYa5uJ0bpPaqAVIw99yVErLRZiDOQcUW3O0++DUYzR/46689LiE57wg8B8GvduP8Sb90EPTJM+9agKc2k+bo8Qo3MiCd7sODQyeJ5R3ZGid57zNHkD1L9fjIHWJhTY7/fUWnyqWoLmzP0sx/QcH7fnMvGxhz7S/eqEcXBFQrTAKifHU2xmvcqcjAPafIM95gHEaUJHq3OshgHVSqUxptFzLAIe69opAZ394drpGBjHkWywCgNC8O10iDSgdDrEIOanpfWsZoKT1c23uUZlCp7CiCU0Fq48XvhPb3wX+9OrWJ0J4vGrn/7hBTKnlY+oAkLmwj3n+N6/+Ae59bPvY+gufw5oV4+q6JnchlupuajRgXWLGcZN1597JzYAlR3f9Sf+AO/+j+/k0Q9f7p577qaCwo+97df4C3c7uXx5DEH4lle8hn/wi/+Gy48+wG33PY97X3Anx6IUT4335yyNYNkXIV4Ce7FwRY3ZRFZjkEDNsNdKk8YoHh9rFvoSxaNqW3ETV216aKq8aGiHMdzkgugjl4kn+hndobo17xB7oXEJJ/19o2e1uJsTSF9+hUMQXAxCiED0sdIVXNILau84pcdoLPxdfyOw6NzKLL6U1L6I0eDPp7VGSokhu9cl5sbBiIcReEE3H/M7xrikL3rQoHffEgIp58PWvYlT5FLKLi9sDS2OwaH+PGqHlQIgrRGqy2TRhomQ00hK3rnP8w6zZRnlBr0hOGyBuPlGOOTAi+OjuCv+XvumXxLWnO4FjgMvzI0YEjnHbjso5DggKqTs01laCSkGhlx6cU3UMlHLnpw9Qjqv1we4I4l/RvtpRhE2m3MOl+TcJb8B0USZ5/58nv7xnCiS7lpyyjCOrFcD504y6/GIdR5ZDZGcxN2FY0/WEKfQRFz0b8GpQjkkx436RZqzv+lNC0NOCI5j0tPTWq3MBsVgDtXlkDhPt6DsbSJEcZfk5jdNM6ev0Hx5owalzn2oDcS4RpPyvvd8hI+872NY3RICnTJSeXpe/s2Hd5CRpkZMgoXK53/hZ/Nn/ur38ZLXvoSijRydwhC6246f4kuUe0RDY3JSjsc2EIh9zPY+tRcaDbzw85/H7/rWr+Cf/NBP+MhmN7uCj1xVPv7wW7j7zq+9+fyA3/ZZL+V4/FnOpse4enniKG4Y8MREn+Q8lMpwzXTrPNem/ebQ1iWiXp1igJVkWnCXdy3VcTxcP68tkMcV2iK1BRY/TbOe5xMawdxNh/75SOZmvIWaZ6L3DsIVOgnpfMulyMUcb46sXqlRvAv0ZUTvJmP0LbEZoUeUWmcUdEdSTN3VKaXkbtl9IWRBCDEQmhchCx7jEKPDNtBd0Ttm2pr2Mdm7I4l+IPpyQvuB1CEBVajmqqUl2MvwPPruZqXVC5sfiF6och6IAbQZjpp6aJeqRxtb50TluGje+/a/j8h++Hox93HFA2UXD1aLjo3729phpujREAv3WfFQvzZNnTAfkO4KP08zpVZUehfv2ALaZlqtHcIImHWNfvNDsAWPIh7X7htqCjEqipIjSBDqPLM+yn1qe/rHc6JIbjbHfMkXv5ac8KJk6rhSl3k1C8SYOy3Dt7iSnI5grbs2i1G0eOsP1DbTWsFYoyY3HV46N631CIe5VM52W3cMQshpgBCYtSGlIjES40hOG1ZjJAZfvkg2kiRP0quNHFzQDwMWM+967IPMV69iWmiyaKt/Mw75mxQ2AmZOeD46P/At3/m1fOv3fgO33nULIW4Y4w3Hqqj9dTuvbRnLRQKRSrbSy2bs39d5c96JeNFOcYWw5Zv+4Nfw8//ql/j4Bx4k1HjAscyMH7v/fv78N34VKiuMRmmPUes1vv11v5P/58//DNMTe/7OX/4HrC9d5Iu+5HPRdB3r0sEnvUigh0DF0DtKIcbRhSOlehSpggYhhEwSp4UEU4jJ40AtMVdnGCyKkiWeAfDuxwzUPNclLEFwnmESo78X1snRcihKbh4RQy8R/Xpa/rw1pZUer9o5vEPvKAnOrzRC//M+FgcfixeiNCKda9uIIv1z8k5xNQ4Haaqq5+4InYbY1WS1unfBcp24xt8J3TH6dbgsnCK+wCF45nkYRsAP+STe7fkB063JMIqVHow3ekSCOz/TGp4Dr0qtntmt/esJ0R29ezrh4qQfgws4Ar2TDuJUG7pfawi0ArVvlhGhLXBriI6jm3WbRH+s1gOzNs/awZzO1N+z1vwztdgjpmvzaTEamiAHJ9mDOxBhvqxSawx51dkSz/FOMufMpXMXvJNJsdtaubNjM8Oan4RTMw4BRs27ulJ8vEsWKGZMpRKjc7FKbZRdA3wUFdxs1cchIUtEaJw/PurjlYei+kYzgAbSkLGmDBKdp0ZFXXNGIIE2NtndfoIAUhEyZ488gelZ71SA3l182odBCEYc4Nv/9LfxbX/yG8g5MiOEcOoQmroppncsLsNzfMzpL0J2VxbcX7v3QB1Ed1PjHBSsQBi584WfxTf84W/gR/7SP8IazLI7PJcHrsw8dPlt3H7bFzPVhzH1G/Xznnc7q2Fgu9/xwK89wH//R/8Kf/T7/xhf/198Cauj5DhhSEhQlMnH3mWLHjsG18fblNzkJLTFYNbvzqAKKVB0Zjd73pF366ErcYTC3DNMAoRuFDs4B0+0k+/FXNMrQmuVGhQNrjGn9aIVO4eyqTvf19bzqfGRt/9e8NHcEh2Pqx2ecExRW4cAuhLMKWZ62C5nC/3alt6suiLK1UfqBUMMkda38z5a+/LDuyszc4ux5kNjPGBswUUYqiTroz+w8F3RPg3Vikfn+nLKOiVK1JCeYOPQhnMYg+TDEogDZq5+vQeHnRDv1JwnCohfe6rqGGp/J0PqmUuLC5P1RiEGUgieiIhzGx2/FGeViNwMBVShxkjMN31WRQRRCDm7W7oq2ulnEeeiSlAIEMyLKmo9LkKf0qz8xsdzokiqKrO620/ZFYp4W+4AuCfWJXPOn6igBhIFsn/8w+CJcAnf0KU0+EVqjiV6Tq/TRkIQhIZKdas1dVJxlEjUiJB9DBOl4jZeTY0aMljxG8SEYJEYendCOMRHqCmJ5sRxHy76aXnz9f5mu7Mn/VmfkV762s/jG/7Q76GOirXocjtCx8GcsrJsrkfp0IM0lnAC9zwHWMJDK32GdPxJvMs0Swwx8I1/4PX8wr/9BX79/g9Cib078Of2Cw8/yjec//hTX4QW/ujX/C7+zr/9l9CMRz7yMf7Xv/a/cfttd/O6b3whNbmGeVkIaJO+POm3rnghtNZoVg5ql9g7G23O1TPrxOHgW1QvrNHjUcHHfPFgtKU7cmzQrxMTpyAtC5sFxzQx5tmjPxD14l8mv3mqR4PEnuktQErpsNRaOrFm2rsZL5xR3Jos9O5d+7bdLB7+vvSu1sxzhnqz5Rh3SH2i6Y3A4tvXP68Q+jSypANGvw6sNxLuj+rdbejb+aoNCf0aj+5mZbV6iJjRyeiO25oZc3X3rNCpTAL+Nf06rbV68ewBc4TOllCXE4eYvONkgQH0cL2bqQeD9YnigAuLj9W+3Gqe2Gje7YfockiHTWrnxjrfIIQeyXFY/hhai+O0AhKSf/hqBHpOuPbrsF/fwboU9VlQsOdEkTRV5n3pp2tkaEpQNw9I4+AXQ4yMw4oc0s3REfyGMKWa9vFBMHMzjNwdhbS5iURrk58s0U+pSuipbDg3DHesjhYJUSg2OPk3BULKBC2YuvNLkC7Bw097CckhAlOyCdGWvuOZT6ineygOun/TN389L77t+dRYPPRMlk5M2MvOEVBLvjXvmJjZcqr7Rt53yH6CezC8d5SOTTp+CU4JufPOS/yJP/1f8mf+6F9gfuypC6aff8ev8Ls/9/MZeKoJwH3Ha+669z4e+vhHMVGuPfYIf+9v/i88/8V/lhe+7I4D7Uo6tqdP/tzoS4fYM9FDwGxZRyk1NFpfPkQRxpSRqhhumIEprbp1nhcdL1iNSgrm8r+mzFUPKX8xxj5lBKp5XLHz/VrnHQopdMmoNGcw9E5nKRrWR4NMRDo1p6mbQetyAOG4ovSCuuB12vzIYqF/9QbPuFl8hT7mmxJyZsFnpI/oC3XMc508kmRRZdVSaRSadS/VmPwAN9yybu4FXv2qjdEVLQuWaAZ1UQKpeafcZ4+UHY/MMfrhFzxgbYmfJXo7YIoH5cUF3pGbG3+1pwgyllvDrHVSuW/evRNRX05p6R1xJ36LQ3JBPCY6BD+MlpjZcTUcDg0fMQMh4JJXIIV00/RE3V82PAl6ebrHc6JIppi4sD5y4rN55xG0A82Yk6HFHXP2bUfrnCyR0C88CMk13CJ+7SVVQlsuRvcQjEsnIA1obrabV4iJj3C4vta7OXfAIShRjAFFwwipb3B7JyA4pUakd6r9pl6lfOgUfivOPgHl+GTNq1792wkyMjIS5IxG6T1pYiR3rqc/F9/iRRBP84En3Vx0nEwa7qcohxvn5pPyLugrv+K1fM3rv4J/+WM/4xd773hUG//+3e/hm1/2cp5c9GeD3/lFr+SffPIhT6XUygd/7R380H/39/hrP/znuPP5F4k5IVLQoO7haX2U6vhos+aRvvhCRpoPZhG/GbIpNca+yAApjkn5iNhD4MxhmaVT0wZV/eeFIZFaj4VdOpM6E6y6k5SCyIikwX1IzTsai+oLG12cmaS/f45Rls7LtE6Etn7j187ftO4PGvoS4jD0hq6UCeHwGTVtvthTZzY0vNH2iSYcriHrHqNmXuSsF8LDxj4Eoq28K1wWOjr5vaJerIMEYqJv0d1tP4p3e4uRhCiYGDEFdyxqfpHEYSDFSMW7fFEfn5t4dpB2XNkITM231qkXKdNuThOyF/XOu9R+yIjRN+3uhGRa+xZzwWW9CIv6dRwCnUpl1OrS1DFmf+1qEMUXekGo1ZuuHAdCl4tKn1at1W56/BwvkoK7m5S+qZZmzHV2GV0cMQJaKln72Kl4HrJEtJuwRgldCeE3dwreJYaumrAQMOkjpJlzH8NTtSbN+zj/8DqwDrljmYFky+5TAcdNl81il7JgvYCmFA8Y1m/1zfiC3/Yi7nv+Pf0mqQyMCPnwXplF3+6JuSO7xW7w6t1Lkz2F0iV0jgcZ2qN2I9FApRtrdDwJhNUm8r3f/0d46y++k4c+/kmECObZ0L/wnnfztS99FaPs2dvMIxW2Jqxz4lWv/DLe8uY3EAy0JP7vN/4Sf/ZPnvGX/uf/ls/9bfegYXLHmOifgeHGFn3WIgQhazxsQM1cuaMd1si9W6ghILkvlTDWIYF4AmaqSrFGASKD9x4BhpxAFbGGaEOsYikxhOA3tIxEy4g6bmX4e+OhVe3wnvfKcXi/RJzUbNbzi8zHQknJieed4L5o4oV4GK3dOKOPeyF2wjaIDP31dJMk9FAAUkq+tcc/a6/uHcvEI01CiB1ndLw6hkhj6EW2IKJuRK1KXXBTdfK/U3W8410I+N4Ru5mIqft6FsX/TNV9WntXhhmlKSmPrtU2QPwehKXbcwGM9U5XJLg7P34/l9A7cIy8HvpSrDgUFiMWEq04RCMIQ/Qxf8ix81Z92SspHrpYlzx2doxAsEbT4vEqAtJd4Z/tTn1OFMkQAqvVimTq+EcoDKNni8QwEKPHk0YJnYCqT1qIACy8NjloWEEZhsH9DA2qq+e99e8jRFi2lX1cCRYPRdIOb1zoo2lYrnCE5ksbIu4vaEhvGwU/yWqx/y8qpN9cr/sdr2RzLDRp/RZofYxbwPidsyDNsZsm0fWpfdPrqRb951voFz9wGAbBAylq/713O0rjxV9wL9/1J76Vv/EX/y51v3Q7zrf8R2/417zuNa8j5+Epz/lld93OR+68j0c/9VE//DXw5v/4Dv6b/+oH+R//9p/jxS+9A5L2kT8g6kIAUy/0oCQJpOzHkpoTibU0ZBGboDhjSPuI7VODdvcd6znZWEPrjiW/XJn7+Nq7h5D6e+NdlCEEvTn+BRHokr6brkuCNj9OpT9fbdJ14oEg3gEutCy/dMKhILbmnLyYhgOzwKy5MUofH4eYITwVjjCLHQvtROugfVz2f1dVt1ozw0wopTFmX4b57qR7qaZECIPntrdlqw3SF2BivkhZzKS1v78Y/X6KnQoXewSyP5eEd5+YeXcszs4N6gq0xVZPwBegWCfAO8V8gS7cCcgXr60pZepmHeZeobETvzHxTlYXswFfuGnr0Im6d2azBSpw5ZTTsDrMEKFFSApjMWrwn/l0VoXL4zlRJL0oeQFMaaDV0ek1y6JiAaf7OLSML3Z4s/pY2flliGMQrXkmyDImHZxxRA4AugPsneiM31iwWE/EpfHsP1j6j1v+5yNuQP1i6IW1zcIvv/Wd/oW/xUI5jokvec3LibGiKv0kbk/9qTLSUJDZO5xOLTfxLWr03vugo5Z+IBix/y/RGL1ISsdUSf7vwfiWb/s6fu5nfoG3/OKvESQSemf1gUcf4Yn738o3vfZ1hCe9LhH4ild8Cf/8px/yrWUDUeHdb30fP/C9P8j/+L/8d3zRqz/HR2sghIGIK1ACDQ0e9FbK3Bch3rHlKDSbD0A+OH5p2g8kAaxQqbRWKOa0F9EuRAp+QLTmXeAS1SBdSaK9m0O8o3PaUQf9u6vPos7B/OcdtNV284ClXx9ivdvEF3jN3ANSelfYrOAGy9a5il54D3hkz19fttJiXbHSoQ/v7Grf5ZhbiGHkwY0uco6k8KTrFbCqhGCk6JJQQuuiA6ALIMTsgDk29QgU8UnXuabixWnZtGdTpLpNWbbWr0VBglOcUkyEmLuZdekLteidnWpXXUVMlZgcZmlWqP3NWtgloRtqL9eEE47agdA/ldKf1+HW7Lhtx6T7a0wp9c6/INnv+VgrKwkUc0L7wgV9usdnknGzAv5vYOx//5+b2Q+KyAuAHwduAd4OfIeZzSIyAv8Y+GLgceAPmNlHP/3PcSeUKOKefCq4vXfnp6njk0qXl0kn5bKMJtJT8aovasQQDX2Z0UtM8E5yEeOnKN3FZWm0lpvBu4fQL/il8DZqPyl9W2h9bbN0m8H8tP3Upx7j13/1g30L+qzJFb/pcd8L7+AlL/0cMiNZnAjccPeb0DtBMaFKRfAllSAMkhCgdrSy9WVJ/4pOH3dD2kjyl0of24BozX0erXHH7Rf5ru/+/fzqO/4qu+sVMTl0OJcf/gTvfugRXn7PHU953hfGyCu/5Ct4y1vegNNLBJrxgfc8xl//H36UH/6RP8fdLzjBDg25sgDxshyAgMR+6Lg1BuieGIWFrrKvCZJ3D05/6Tk99GVfHGBMJJWb1I+8HIx+45HANPnWWxpRcn++XaETbnZq2kf12Jd6qt5Vxq7qMO0LFVNKrX5AB0BcVnjgPfblkkdc+PXqURZ+9UnvYJ88Ismy0W+td6P+WbXmcruUOoGfm5LU0ripYImRnP01R3HCdMAD8NpBTmhdZusaZq1e9FKIbjYRnSYXRamldpy9Ty7N+qHSzWNCoJqHpwXDfVlbx1arF8BSF1jBJwOvcEawTBZBgqdIJqVvoPtnKAGjYcHNQrTDAmpO5RpSRov1Ed7vOR+1w6H4I9CKNxApZ0pQmIUQM8Qng/RPfXwmneQEfJWZnfbUxF8SkZ8BfgD4YTP7cRH5fwB/BPj7/dcnzOxzROTbgL8B/IFn+wGCMIrTH5aT2V2Q931juOgsF8B/OVUN1aWN7KesuRwvYmDB6QUhEHLPIDl0ICBihxPIT/SChqUTdbGWd279166uANfmOgqoNHPaRyQhKrzv3e/lkU8+9pTR6Rlfuywdine6v+PLfzsXzp/zkZ2py74WGV1/sj03OplvhN1luriLtgFkIPWO8ubr6/M3RiM/aRlgdK2v+Nhq0vjq/+xVfPnv/GJ++l+92XEwvbnxfuv9v8B9t/4+Lq6eevm87M7b+PAd93L54Y93mo1A2/LO+9/NP/nRn+K/+vPfzpgcLzZz6eAi7fNq7mqRKBGx6DjY4riDj0kaXO/tizZ/RVqNQQbiMOKKo+wUFzVSd69fukI1g67a8WE7Hvh8zW6GsR2UVea4r4TcTTXcOTxEORDAJQbU5ObUoOY+owgR7/IIQoiesdM6haZ10+WcvFg263vcfg8U9cxob1sXazVncEinOTXrix0HHv3XPiEtrNhaG7XuupmGU8Hm5sob7yACpfkVnZL7qwZxbA8z1r2DBB/RZ1Na9G5bq9PsrD+HMQ6+GQePsUijk7X7+3/QTWvX2psfIk1BVdy4OGQCrWvWxfmvh+nP3+KMsM5Q+jW/SDa1wwZgPlqDQxuhU6/UXZK0dsmr+tL12SjMz6zFWW4tfyxRYrn/Y8BXAf+8//cfBb6p//4b+7/T//x3yqdZ6TqOJl2zuXSMjaozpUzs5jO283X25ZRie1SKc+uY0TghqZBiYxwCY44crdYcrTaMw0COkTElViEympCrMVQYRAmh0HRL0y2Yp8hhSjAjC6xF2CBsDI4wVgijCGMIZIRMIJuD9glxXC1k3v0r76F0i3xsKYRPv0HzUcuB5pQSL3vZF7BeJ7DWZWpdNdEvEv9PA1gmSCaHgRxGomQimSSZURIrAmsL/qsEjiRyJIG1weCcJ1/qhEwMAyYZcPceEzh/csz3/vHv4tItx12tcPO5qzZ+/m1v7qmUT/ocBb7yFV/SL1KHUMxmStnyb37iDbz/nQ8ycESyyBgHcsjkkBhwm7kkCWKgBaFFsCwUgVmNuXWDZEnk4FCMqLjEUZQYjdC1yhEvkLX6trQUY54brQm1Gm1utLnQpkLZF6b9xDRN1FJotaK1QK3+feka8Fq9VAejUN1j1JwE1lp1bC44vijikruqpUM5bvo6l70b/JpHwZY2EYLR2uz/2NzlnBWT6kXI1B3Oe4frBbIX/KauSunczwVzDxEvdMHQYLSgyNAdfJI7pY/j6I71S20Xl1ummEh9HHc3n4oSaBKpBHa1TwkIpXbqlIi7iTuWwmLQkXM+YJtw00IuiJCzizYcI/b0zCFFop96hOhf73ZrC43KJ84Uk+caafdLlYAVf/0xRsZxIKVE6rLkcUisxoHVkFgPI+vVqnfXgZCEcUwcrVfPWJ8+09ztiI/UnwP8XeBDwFUzW5D/B4G7++/vBj7RC0AVkWv4SP7YM/8EI4h2/MFJLG4gEXGagmNnQYSYncdmjW6Pr3RM10+k2vlhCjkCsdtwxdAli338CU5KzolDZ4rdHJ6DhZtFCe/iMkv34hs4MUFx3lVEEI3QEu98x3v6iN+r/rMAkwuQv3Dg3v++D0HJjCmjVAfNO1ZmvQO2vqBYYNLQ3y/t/a2JdLNVf28XowgOz6Qvo6xzRJFDDIEzNf0Ge+WrX8p3fOc387/9nX9MNy86PC4/8iDv/uQjvPzu3zh2J175JV/OW970Ru+oJGBauPyJa/zv/+u/4GV/9y8wnus3C6l3Mko0x7yi+SjuixiI1ilLGpgrhME9I4P5QiLF2DGuTloWnL+qxjB0FRLJC4Z6qqaoddizRwhgBxdt+nVg6q41Yn6AI75gqCjNlGQur9P+dyWlgyTWMTJ31l8WQtJJ1SkIqkI1p8ccyNb9+yAc5JPgI3AQV9uY8VTVlrhOHlys49tt/16EbgGnPolZ8cWWGZRaMPGmhN7RqymldnVb77hDckx+rkZtSlm4pOJ/b4jJ4bCuKV8koYsQZIFVQvDts5sLu27erDHmgRADZS7UPgX6O2i+/Bcvnjn59VJLj/pQx9tbc+gsxuj54wil/5qSX09BfHlk3RhFq/8aQ/JdbBdpxKdpYJbHZ1QkeyTsy0XkAvAvgc/7TL7u2R4i8j3A9wDcee/tuJuN8wxTD0HqOnb3iVxaegNab6H7KCMa0WhdhuY0mByHrh/2kbLhG2sLfuG5YUXqmJZ0DbD56dJ/rvZCuFCvOZhE+M8JErumZrm5Itcev8GDH3uYLp043DTP+N7S8VICwzByemOHVXcviqF2fpgXZccZ+wVM6D8/9D3hYluxOABpN021J3ULvSCagtXDWLaQpAORwAi9MITVnu/53t/Pm9/0y7z1ze+5ucjwa4K33f+LPP/1v5cL41Mvoy+86w4+cte9PPrIJzAdiKGg9Qa/+LNv5g0/+xZ+z+9/la+VxF29pb8TvlQDOyQGAmEmBc86iUFpKTDPghLdkEQDOSbCELpJbSFRXcYmwjTNnSfr3zKl2FUwh43ck4w9lo5M0H4wHZx+QpeDmh+gBKNaL84OSGDW/QsdaPWFgdGxM385SdwtHHPZo7bWVTPau9Cb/xx2RmYdH6U/97457pOG8zVBkuNry3Y69FjlIO4A5G+ueoCZeKyHOFTtP3M5MGUBOPyaac05iyk6ZpiHgbqbnPIly3a6v5fdULkdTHnpMkzvKMXEg/1kue4jqpUoyZ25ukGGiTFbcaXMstRdaIL9kNOUfPnToOmSejn098RHat+Kqyu6/MKlmd8pJiAxdXL9M+8OPu24/ZQb2uwq8PPAa4AL4gxvgHuAh/rvHwLuBeh/fh5f4PzG7/UjZvYKM3vFpVvPu4FpEyKZ0Bcu1VzW5edwAHOydDMvcCGNpLQixYGoftMkif0i9QplfbudzHmOme6IYwZaQAvSGtEawRxZjJIIFsg2kCUzSCbL2ItydyghLbc1TqHxwvnoo4/zxJXrPjItF9qzPLx4+bHbVLn3s+4m5IqEmRxd6O+FvoLNiBUnw4v7FxadUat9pdWc8oISwSEAHLsM/dChY5AmLl70LazLsw5kJ3FSPwHuufdO/sIP/gB33XurU3SkY4jiY/cb3/aWZxi7X91pOk4wRipXrz7B/+sf/jOeuHyDphNmBbOKqetn1Qz1MAaa0T/7SEFoUSD7zw4xdkPWnmXdg8FMnKrkE0GX70XACrXuaToz9zhfVc8YKloQgZgSw+DXk4Tc2RaZkAesd2gSHL8KIXb/RvHRcvmcrMsqJZBCcmyVjr+qoXVxFHeOpvbn6R1sL/rNTWZbcS6itWXB0l2mUkKSb73dLMInK5fiJlS7IUdTSmtMtbKvhYKxK4XtfneQFtbmSxp3ZvLi5LdOVxiZeQRGN1OOeEDXtN3SCZbQTSpih51cgt4viEDvUrs+Gl/iLNfY8r44zScxZDeyDiERYyb2iIlDGyFCDu4uHvvSVsxVPp5n1Dfl6p3oTUPmzmoIiTgMrFZrhjwyxoHUOZjxyXSN3/D4tEVSRG7rHSQisga+BngfXiy/pf+17wT+df/9v+n/Tv/zN9qn3WAIKWVyyEQSWZ0wbt3p5OD4Utuh69Lq0qlWZqb9jloa2oxSlFqM/TRTi4J6QUPkMEYQOl6GjzitKFrc3Vzo/wQ3i7WOOymOfQXpkaJ0O1EzwkJWpvL4tcfZ7XY4NQc+XZ1c3hnroP3zX3AvQ+4cOwaUASVjuNVb6OsAx/zcbaaKBzypGE28VDacLKsCTZz0W1GKNKr0cQWliReYJoqjvDMTEzUUpjZTqHzxa1/G9//pP8LqOIP481guqssPf4J3f/KR3/S6LoyJV77qK7wQYm7DL4V3vu1XecO/f1Mf9faIVlcphW5iK+LUFvOUwhRwTa40V6vRkGhIov/jNJ++Y6GpMtfmI+JCaTEn96cYCT0TxlkRvqyqWihWaYI7yaR4MLZdbp1labZ0IE0FzA9NrX4YR3GcWEiIJVoRaoFalsMe5lqZa+kjtmNs4IXVseV0OKx9WpCerxMPHSXBuybBuBlSpJhVRBohGia1U44KWAGdCVSGIbvcsndjElzh1EqjzsWz7Ztf16h2KGe53nscr3msRGnNhRzByawHj8jW+bt9xpGwZKjpcmV2k+LGXPZUnf2QXzrPzotMKZOGoQeb2eFzS8FhgIywTgOrlBliJKfkUSrDwLgaSWPAQvXDMwuSxbt3xz/c4MQULTNlv3vGe/QzGbfvBH6045IB+Akz+3ci8l7gx0XkrwK/Avyj/vf/EfBjIvIAcAX4tk/3A0yVMs0O4pp79TVxgFyA1CCZUxJarZRWnAsV44FHCQnTvoUT8RMoBHc5sYaKHqgBIYS+BeyYmUQHu8PC2epcvFD8zw3HSiUeQOSl9knvFqSPwFevXGWeywKtfEYP68udYUjcc89dlNIgBWYr/S2v3byiF24WM9t+iMhBod1/1SdBBP5/2l1fxBZepPMvHYe0XnxDBz474Teov29J+Zbv+D188IEP8aM/8u/8QHqSjdWzjt13fhaPfurjywfNfrvjx/7hv+arf9erufXuwcPt4fC8jeDLG2vs1d/HECOlVbRUJHkXGTvnbhmB3dnbb75qduiGFsNbbeqUnO4kJSEub43H0VofrkWcEdGx0eX67LuHjvvBwr2N3ajBZYjSr4dO+zf3WvSC69CPL5Po3bhAs6f4pIpEpzHhmnI3tpADXnegs/ka3g/jhbiOod3c9qY9ohf3UrsGWjuO179n6xZhC2Hbn7l3mb0N7wTwHrdrRtNCCImcsi/CamGhJ/lDWSSwbsQbiRiztq5685+v5pLD5dCv9aaRxnIgLPxQf//7a+nvC51BsWjdF9YAwX+2dftEUZeCaoclUvI9gnV6Vs65h5g9/ePTFkkzezfwRU/z3z8MvOpp/vse+NZP931/09epYyWCcxxDdCFeEO+YWusUiJhcXG/NDT+lu6OYHojA0MFvW8ZUB14Wj8Sm6lkvqXde9aYJrcnNnqG14vb2YXH9ln4peLZ0xekGTnz3Xm/aT4cM6wNl59M8pI/taYALt5x3T0VZUFF/Ln4GN6rVjjp6afPxovQbeDE00MOi5vAz+pV2kFKa40hLkXRMJrCchWaVilLVu/xxY/ypP/PdPPiJh/m5n34TWuOhUC5j9ze/9nVPolQtY/eX8JP//qGDWQLWeN97HuAN/+F+ft93fpljybKUdI93Lf315Ogyu32daLWR6OFgenPT6zcWB+aAj6Cuz22qPVLDjQwMH8UsBpaEwaU7cnsu/yxCB3GX77s46yAcsmIW13KnlSx4pNeVEFK/LuPhebVWb16XIn1RpC6zleShWE1BrC+EfAHp5aF1IwkvZEseUVjoUb1IuEGH9GKwaM6XQ3DZQkpfFnr3nlLGene92Lz5Bl67rZkdDpblWoyhP18mRDr5vx+9ag7wOpF/+a9C1cX/UXokL53Z4a4+izP4co/KMv5aVwDhENtTfRBuGlXYovsOh/bA/Ti7Z4MXYqNJ8/hiu3ndfbpB97mhuEH6aOOnQtUKKh6wFQJNApp8pGlanOPWN48moQO5/aLL2S/wVpirpyUiRpOASehbXKdIOEVMDvb9JvPBjFUQH3PNZXILK9LdtruVV+jLJtwcdkWmdMLtkm746Uqlk2Qddb399gtcuu0iBc93yZI7ThccxzJBrRPIO80m4PhMNdfXaJ8HvXGxw8YmLEsSc6Gw9mgDYaGUlH4CL9ivZwsF3KMxxsztd1zgL//VH+DyJy/zK7/8QRaAXAQuP/xx3vUs2+773/xG+rvONM382P/xU3zF61/F+dtXgB5cXAJeONQatZW+QDFSTm4HV70D1k5jiiFg6KHoOLbZ33UzQg8Ed/9KaIG++PLiGOXm4Yk531WbOZRhNwvwskjxSI1lqWheFW0pYMvk4jes9QUF+HIjBo/XqKUdhoyqlRyXzsfTGFvvHr2z9Gs0peD4G37ASaeO6U3Ty5uAQHdGQm52w8iiDrKD1Zrg7vym0sucd1k5O2+wqBtE9OWyY8Ct+bWUYPG8NAmUuriks/Db3dvSzDmkihfjjr2jEFN2FRB+AIUF7zYOMo3UFyuqStVymAbdsV1ZTI5rnXwpVPt1HJb7SrDu3u9NVDezaYtlnhzqzzM9niNF0kcARNFWiMG7ybbY5C+jbgy+RcTxJoz+YQvgROBWp17KOl0n9g2g9o6g0y3aUlSk+ljZbafUerg7nk8c8dFuKTyK88FicjeeIKmPjI1IPHQMh8enoQB5rooSYuDVr301JxePIDZMIqWTvFnwIHE3o9ZPRVtoL/29sE6W96bBLXeDLNZawlKkRMy7sI73Bu1dKQvPEBKeLxLEuYnBAhKMF3/O8/mbf/Mv88e/58/y4Q8/6A4qAOgzjt0vu+sOPvy8e3n04U8cRt/3vOsBfuEN7+D13/qlSHLX6+BxUd1Hoi+P+j1eW3WyS8sszgy+iXYOYml+GAaJxJCc8qHeSTgJYlHIOBd2zAMBQ4uPp5JSH1t73IRWv0aEfiD1G6zH0i6HoIgQsi9pvLNePpOOd+NLOb9mJ0S9WxfzqISY3HXd+uickn9OMXaqkgmmizkLXpB1oXWpY6DLyOmX00FUYWadYymHQ9W9KJQYb7ox1e7dqNb7xT4SW3DxxE16znJdeSOhKoSeDiq42fViyLHAEQcYqLtjhdAVSeA2aOod98Fjs3esS+dbS8GAWou7DeHUpjz4ZBd6pz/kVX9eNzX9rsmmf0e5eQ9UgwPzIyIp3Fw2Pc3jt7Td/v/XQ8QL0ZAyOblVmZvKegGQhpvmmjg9sFovDI7blDozt0qx5r9qo2phN23Zz3uqFkJQ0IKqb3+lj16lVWorPd/4poFoaxWr1bERg6LK3IpHtUokSGaQFYNlVmRWkomWOL2xO4QbfWYv3jvVS7ee8B1/+PcRs4/ejq8V31xbBW39xoKs7sQeJSMyeBELXWPNfLNomh8mRQtTm3wRo42pNua5Mc2NuShzU0oxymzUaqgGzDyKQhgQi07EVsGC8oWveBF/8a//AHfcfevBwsq3qpWf/+X7D8uo5REEvuqVr+7BbIZRqVPj3/3UT7M7M7CMhgQpYyH7bj64asg6YdhjKJzvKNIgNCS0XhCsh0iNDHkkWleoxwwhUnAddUI4SgObPJIAaY1VSmyGgfWQWA+JhLHJiVVOrIc1R6sj1sNAIhAVBolk6fxF5PCrancP78YaKUZyzqyGkSHnfm1nz13qMaopdbNXUX9vOld2ofd4LEMmWCbYGtVM00jThKqbViwuVK31hdU8U2vrBcKIYUAk9T2M670VZS6V7XbLfp6ZtTKpwyuzNvZzZS6V0JTY9e2L0cbi4n1Qz8jNLbubIecDfAQcfq7hv9ZmmD2p7IizLQKNHIwchBRcGLBMltJrRJJEDtnxc3Ml3EFBh4/fZq7jx/z7jdGjkIfgyZs5BFeWGSA92fFJpsJP93hudJIdd1g2vGC00rW5EhyLwLoJp6sKYseHwLsi6x3K8qGJBEJelMt+evoHndyAAejkOEzVXbBDIiV/48xAJZHSTSdqzFUQOSlBCjsWr0An9UbJfOxjn+BQHz8DSNIoCIFLt2y4887z/cMKfZSgb9K7gYDvZG8uAVpxQD20jlraTSPZ6tiedFmbhJvE8RRH91K0dsBgxaDRuXuSmXq3kEW667l3oBWlhcKX/e7X8F8/9j385f/ub3P9ypm/XIFHP/Vx3v3JF/GFd9/+lNd5YUy88pVfwf1vfQNIw1rhbb/0Tt779k/wii/7ApTtYYGi1uMwDjia42fOSQyHz0MQYoQ0OChfau0GxL5wovuHDmlYdsU+lgZz49gecytPzqNBCMGIJMx6fo24oXOt9dDZHLbe0rfM3fzZO/5w+H7LHXwIRLObfgFqi6ORB1Itq7BFLhr6vbFcKQHt2LPrlXOKaHX3cRajYe1ZNGLMczngoq31LqwXY8XzqGOM/drQDi3AouP0LG03qJ7n+aam3ZQUEjfdlfy5WXcUuomJP6WX7JpC6Tk2vl1uzfHnhbK1sFlMYYkPjiE4rNV12LU1WmnE4HCGdlhJ9UnNVfPrSDpNy7pX503DX58Oo/hn/Gw363OiSCre8pt2yzJZwHQH4lUUC4JEJ6KiHgSkBiH30cRc4zzk3FP5HBReiqaKeWB6oDvbuHmEqpN4U8zOZSvtoKWtPYxM+4e+YCZG6XB6506q9lUKfPSjH2cpcp8JT9LxwjWPfOoa73//R7jtrjt7gXQT/2ZOmVhIGIZQccmcSQFKJys3VMWNMMwOLjSBJYxel+abODjXVHHQv+8BqB3EbqrUrr4ZxGVfMfSiakBygsq3/cFv4LFHr/HD/9PfZ9r2vGxc2/1Zr/+9XPyNY/fdd/DhO+7l0YcfxKxydmXP3/uhH+P78nfyxV/6QoQGyQ1XF6yzdlfrGFP3y0zdXDmR8Buymd9IOa9oWqk6eZypOHUs1J6X3juaJkoMdHVI5wSmdgj0MrRzE3vh1EpM0QO5ehe1ZDAt+HXj5iJAFsz64FIl0E1prXMGAd+wtr54aP46FqUNT5Lw+f3rTA/Mu1ZC7KFY0SlSvTiZ9YJvHlPrBat13H1ZUjglSrUvqfrWOnY394VAX0IjxIRWx1MXrqN1qWTKrlDWVg7bdImhh7Zpb346ebwf8P7SHXLw98MhKjcruWksYgdc37XW1vRwiPhyzZAOhwQRiG7AvayKHOLwjBvV1lU/oK2ysBha0+7g/+z9zHOiSEJf1eNMwGrLNs4Op5K6fUiXGSkaGs0irZlfuLWRUqQoiCSU6bDhbU39TVQhtJlqXmTG1A112037fMVdrRGhUjqZu2+OJbg7CtYxrkCz4liSZfanjQ9/1HE3AkSVwyn3jA8VGjvmckyxHbOc4dghrlowx0zpm2k1o1pBmx4C7+u0xaCPVkJUxX0uA7V2EFyNJWVwKpN/7+g4Taj+Z2LLJl+R5kVeQ2Wr1XmsXebmF3BmGDLf831/kMcvP86P/oOfoFYlSqS2Pb/w9rfxTa95zVO23UHgK1/xGn7y3/8Lv/hb41ff8TF+6If+PT8wfB2vetVnIyY0m4iSqTZ3d/KBKImaIsEiU+9OoiQnhndFRaO7lvduRZr279e6htgLbu5u1ZLcRKNa8GsAJ3aLxL6J9RArt8PrvMpuu6WlPmlZo9AzxgHPTlrULNLNeQN48TNaq26eEfteOIibQ7vTW4crAirBnaesQcV74SC0aK4AwgjuS4e23OvqkvntTv7gC9DWjWqxgmqltBkL9I7XnGsaOnew+XUW09gPhF6wD+kdNyWgGCRxN6JF1OvKoHpYci3bHI9RcR5s7ZJuN8bwnUTTDl3giqYlceTJRjRmbsKhGrHk6Yn+U4WY4vIFHZPuLIR57nXE30PpBxwCFiIhcKBmPd3jOVIk6TkYTnNptkjou4TQnNQdxInR9AvJtHVw222+1JS5lL6b8fFiCWryBVDPUA4+MkxlZsgLDurWVoh19+bqi8vugShBDrQTzDqO4h1kELfQf+Thyzzx2DXAOPhffrqZu18Am6OR5911G42Z1sfO5cuDOWVksYgrtXc9qr1b6M60IZHi0DeIdEmcHKCFZXMYot98wcxjMswY+w2yhCtV7TJHM3J3bgHpAVIuyWsosgl8/5/7Xj764Cd4w799UzenhUc++RHe/ckX/qax++KYeNWrvoL73/JGEOPq1Yd4/OMv4V/82Nt50QsvcOHWo76MyIhNSPPNu/bo0omZ1hchc9khEij1pkONLZ6i6lZeWRISPBphGPq0YEaKudtndUpYL0BBvJNJh4LQDjEPQL9Bby46FnccO1DM1Ing3fDBsH7z4qN+J843MSwtSYiCtSW6rV873UnHEzz/P+29eZRtyVXe+dsRce7N96pUqpJUmgUCDQgh0IAkJJCMUGOWEDS4BRgBbVg0bdoYunHTeFC73Z7di17YGDzTCzB4YTMaM4MxSGCDBlQghACV5qEG1SDV+F7mPScidv/x7Tj3vlLVq5LB1CtWxlKqXt68efOcOBE79vB931ZhKXmhtqjSuwRVFo6jhWrRs8yjwh4l7zBoHrJjZmA5M+VRxNv37bFgqynPrGKZu5AFve3B3u4ygipciTI40glEUTAFM0khehRjVnhOoDAsqMKooGZNoY67+GoC7Lc4ONrIjtGavMA6LxBG3PSkdIBHqqYTqbKQhlOIH47GUgP+tE9v3Ne4JIyke2epc+QVOkQeZXQY6FGwSBaIeVNuIaW05h+nNbG8bxFpKRphRaW0ZCmNLL1TezzMYXGNgGg0Uol+HS06rCUxtKFzsjuPRY4sCuc0a7hP3HTTzRzffcLK5jYtkPu9f+CKKy7ncY98LIUzAo77HlJh3rCsvjbNGzlNlO0maHcS6tgXihRGk1jnRiBgia222qi9qdro6klMhoW+B0bTacVINuGBp5Q6kgUMxZmbqpgd2FxpfMO3/I/8/u9cy00fuJM+q0Dzpjf9Kh//yldx5fbCBmKf9gRVu2/50A2438VHbv5t3vqbd/JzP3Ulr/7qz8XshN53WMnsurAK2gKR0wK8NpZlYbM5w3azUT6ySUyhho6jerz4WjxQYl/X0Gcp/pBHNdvXaEIR6ACSe+ToYnZtr91YpkLvIWQxVPFbR7z4AU1Sy4ShtK1rCNokIkTQA6VqQ1RFAPEipAp33F65686FZbeh98T5ecd22jLvzuHldi6/3Hn01Y/kaOuYbfbr34wh5DswrR4EhLX27E1SfG6kQY+NlEKL+Zj7ImOXwiO1WNuBFhFEzbTc00ARDHC9PO2RR+7eouAaXl5EimbKE3tr4ZNKmhDXXlOaqcdBr717lKY9fjQLqTycB0adA5Q+M4mEpHFoHI30R0jqlQvX6OG4JIykPJRJdC+ikht5Gcl5CSYxkWgJQWNcGKcWHk7qlXzQytO9r4KfowVmazPHtdFdmMkeVXXJQyXojebabFNOpHwUSf6OuWAntc7qm4LjXS5+CwLWdTd8gN35HWMN0Ubi+mJDZ97xufPcefs5rrj6Ubg1kikpLUCshZlQ8cjTbq3G9Ra0yTCSQ6JflccsjzDonaMIUoJhEFEhPYWQLDmomz0gVHnF1DkH7AeHaTAU3MnFee5zn8bX/M+v4h/+ne+jVeEse6u89jffyJ/5rM/86LD7BS/mx37ux+kOx3fexW3TLfzg9/4sL3jxc3naJ52VOLJvmdzxImxncWEYzRItZaazZ1gLegDhNaQpBS4v0ghMCr3DMEwZms9stoWFTkGGNephobkYkcMa/ipPVmsNFanEbpY00lKHxwc0h9boFkUoFCnU1iOoGLAuGeDeO3VZGN3/lBXwsF/qBnjZwyYuv/KMVKbccduyKQnrG5Y2kScDO8Kp8prjMAGo9aBKbMpBC20Uhtr2MLpsI31QV/5M7VX43B5GLvKFoxovMQ2lWbChiqQAGhf/vta98PA4fAivUyrz4+RCaYr4nBquY28q4iytkpNYScRcZ7NVo1I6pKb4rjY2KXr3dJFRPB6wiltqEZEi13rJ4ySTJbZlQ23OZnsmNroqTiKnG15FN5xKIfsUDytyTThMwlsJO5YDE7UX9Zyi103JKgrJI5V7b+j15IWWJqrvmEqcZBahbiTEp6MjLSYbCYEpgm7jve+8kdriu2bhAd3PkIPB+XM7bv3IzTyJx4JXAddd1dAF6f61wWX3PU4OItkfIc5khVKUsCZFk7Aq/uzSlgBdV+adTltMRRF3SVH16C2+SWcg9/AUBJ9qNkDtwaG3iVwyuRuWK1/x517J637pN3jTf/496qKK6U03vo+33vDUewm7M89/wZ/ijW/4FebdeebjO3nHW97ND/7zH+ZvfNs3kM/MWOqRm2yr59JDsMC6WmYQc9I88KuG8pBdLUlTyvRloQfMwzCOQ2Yup1Cx9iU0FIWQSCbNxY5Tg/2TLQfMSiIXS1tQ3/JhXEXplH2L7oymVsA9CpIhQxXxamCDgYLUqJaq9EKyRLPA+PXOlDpmd2NJjCN3Z+nh3ZpRl46nc7He5Nn2MD7WFV5jQ507KZdrWve9DrywUa2LneRSdK21KuQuG5J3pbZyNNxzZ553uv5cIKvYVb2zzPNadC1ZqYeUlcuNljhUC5hPUnRiLvykh/eZLcLg8NxzyiraoVDZLFE90gjzgkL688zzEqIfZU9rTAkrCcv7pnCl2GocM9EV8j7GJWEkAem8BY4rJwmqOpBcp5SHR9hnVzhOVKnXqp4quBakfA/YuaFEb85Gr1UTXAppU6gdaJ1NylhVj9+epEHYmoOdYFkn1zZtqW30DA6Ato0WuAae+eAHblyN+/D07kdvGNgDgWtT4aGHcVWuJaTSfOQWM1M+o78ReE/pSB5mP+XdNhapyJREyRN92tICGgEyIKoOqgDU+oLZlpScEmF1ZzAh5OlLCd6jBiGOLiZQ9KMeezXf/K3fwF/8vddw20130xFf+I1vfB0f/wVf8lFh97Of8Fje+9gncevNt4A3aJ2f/JGf5LM/99l87he9EFjA1Od5pGLkBagqPCiBNQQZ3DvzHBEFrKo6A/q0pog9qftga8L1ZXmNasuqOZEeheTjlLdSHk3tQ2T0atOHpxL5yYAP5JyitCSj1LyuzzINUdA0oCt6rilnprSRuK8lUonPcBnZEVbkHCdbstAh1QGYclAme5ZkYB90waB4ExpPsdYGisSieGcpqW+5q8KPGaUEeN42bLNyo927xHVdCuKtCX6mtKZH2sugRgsJC7Wfgy+Gg2HhqYe8XA5efOttfV8b6ZI2WFXOmlsNmJy6JDpmhc1mj9McWFFBinTgeVX6yMMRG2iA9lAo3CRXBzci/G1eV9J598CpaS+owpxEz5JBHIwCVZ17d5qpR0r3kTGZKFMhod68zT2KOCUMm1OKkVKhtq6JSSfC3HVTSN1zPJADhkDg5FqDG667KZgT9kBSkRpxYqaUOHPmjIpznqLgkla0v4o2UoIxV6jjId2fSMrnxNxIgivwlb2RSUEtS2rL2TvGchD+KO+TwkN2nBKy+A7YqNIjvUIj0b2u8BlDcmgN5/kvfTZf8lWv5Hu/60eIPlX3G3b/6M/+B3azOhzecdvd/Ivv+F6e9/xP4lFPOsPU5dn0Lq+x1hP9TcvibY/tH8VWyb75mqcCaHm0GNWE13mhFKnGKJUxCKfKyyWTh9i6jMVQt9HzjgN53ENS0aUSIgq1qYOhXKkoSCrtY2HUPTb80vZrfF5mNrlQNhuREVwK49aJUDBEkS06K5lBVi8oqZQ7vUXnxt7X+x24Q8wicFhXlAx/suiLFN0oQ7DaTOlFYZAnJsuCurnWVevqH2OqdK0FMHSJMrpteLZZtMzgrffe2W7UG763wY2LfLGx4khTSngRcsGAJarlA1FQ2wlAtPLQPEzTkEyLg6PthVgM8DxYcWqc1kNg5FCw5Z7jkjCSRmJKkzqhhR5gLiK+11oVEpfMVCS+MCS1VEuRMIDWcwr3Xe0uMcRYacKRzYsEK0pMlEJxYcKaOcvcSaUp9PKO+xnkMlWa2woDGqdy8oGV69x553luuv7muK69hRyG9D5HvDWlxNntGRmwqAKOv9QO3te609O8JqbH4ieqeg31FFdfa3lGvTq73U5pg2yrYca1sJMZaZLHtMRpP/scKYkSSX1tGDV5cGiz+pIUpTysS+rMtju++hu+jNf/2jW87Zq3r1Nx32F34QUvfCm/dc015KlgLfG7b3k3P/D9P8E3/dWvorGj4SxtIUV8kMLDyGE8VC11rLkkxDyoedEUa8zvyIttzkwyLFUbVyGFRdMt8H4C1jV3SaInuYMO3eGalii6KCxWUUCCESlSOeoz7szVg22Ug6oIyZxNCtGFqvxldfCkENRN67WHAQJ5/B4RlnQa9eCHUIcBFRXmxr2WSA80Dz63uLV7/rKFk4FKYkMARZTGSl8aPVUWS6uRTEOz0/ZRkLnSWJazWvRiFAmXk0tmIqrWQVsc9MF9t3WiY9R+v7Tw1Me/8+gZXkVBFh4UkhXEC0eqcTYUjSId5R5rQiD70aExJdU4dEDc9x69JIyke2dp8zjoWdqsapOpqpyS9PlyaPxKIKCHnWw0byvOaejuWQgKtC4vJE85DIrCi42p4jUqaYMH3GqVWGcpmG+w7iyoijvF4lF4m6Qy3TLWKzff8BFuu/luEgUPY/9AGoGpG6SxOVt42BWXkbpaGhgwwMk5FCJb5N7oI8WgucGD8J8yS5M0hdNx0wHTWg04hu3zmdkxH5qJ0hUqOauNgqOKpRG6myETYAiU7lWHS8kqrIUvMHnC08TjnvAo/uK3fBX/51/6dm6/9W41k0/Om35TDcQ+Oux+DO993yO587ZbwRPLMfzwD/w0n/t5L+Vpz/449d52Y6nOJh9Fs3qTQcfZlIy6Fap5l9fgAHsHov9MTywdhbez+N3KdRXUA3xRmJjAYx5TMEA6YnmMEHEQDwxWaa6aHW+zMhHRyqAuwXIBui+0fiLvKSrdOZX1oM42xSw3kk3Qunr+lAg/CQZyPEPhPiu97aAJ24nHIRFUHbMuwHwoPek0nXSPHlTBVklWZUx9lBEjv482ZOoLnhKYlJQsKeLIBt4beVMOgPJVRe+0L/S0JoHnnDJpiGIEFnMc/mOreOzJ2iu9C9Hg7nJwQpxXiVsVxEpWdwL1Xw/ECdIf9WDVjFpRSkW9eHyw9NBBOML7+xiXhpFEWnMpTrLuLlFdI5gEC2aVVFXA6MPbigkBj86Bjrc6Dkuaq7Q/SPwrob+rmk4ucr175EhyQAlcXqnHQyrBMFFIF/Af1NGvlAl65vfe+g7O3XmeocdIGPH7G2MzP+njHssjHvEwpjzRGa0YCM9UYd/Aujl1n3ROKXJO+/ynmaq82hcC0ruPntLKYtp8LB/Mo5KYneqNEg25eoRMKdRUEqMoAkJBJynEu7wCcM5zQvNEKpnP/fyX8Bu/+lb+7ff9mFSULNFq5XXXvIkvvheQ+cue/3x+8j/+bOQfOx/6wC186zf+Pf7Ct7yaV/z3n02ZJtLmMqYUniyGWtcKDdEFgpX4MAmP3gKWC1M3lhZFqO60ZYelSrJMOzmOdMtI5jtE4a9E43u8r7m7AawWw7ELG4hTW2OKQgUmUkSOFh69iaGilKDosoMm2uMQX3OEZkBikwY9doi/EHlXHVnLvLDZTiSTp7niD7sgYgJxx89M3vWobntEOy0wm4NVg6O+NtGuIQ/ID/JCl+UYUqLW0NvM2iNqpZvI2da8+lBEWsX+3Fnm3ciMYlbC61NIvj6bJm55jyJUD1KDDp4W8z3k3GAzjXREOBRZgrzdqwxnMvKUI4UBFqkUVeI73XdaO5e6keyOcHcpB4tEYfWQESNp4yxtkVdYQhY/KFRiDfTVwKWc1SoyIS3K3qTxx/DHnV0XbGSoHSuB28luURUdrRwESrWR0CZOLCJPSKU3eMNvvIXdvEPm5IAH+wCGGWw3RerNQWdcE84uKA4UndAkGgnLgkW0wWc3E00rGd3nCMGGwvM2DpvBQ2/SMVz7+yhFYUigITns5o6RpQKN8oKZ4aWoWJNCqED+vpSaytgG24k//01fwX/5z7/O+6+9SYbcEjfdMMLuqy+Yg0ccZZ77vBfxhje8Vrlm3/CBd93B//Oa7+P97/wQX/tNf5bLHt5pdaa58l3NJQCSNTEskVekduo8QxySdW7kzSQ7QydP0YcGwUtIOkAWb+vB0OZANJRo3ZDjgHAYwra5qF2CihiF7OiAgYC29PiZvLCBP4SRVdKc5zQgOprPZVHObISz0iw4gHlF1bY1GVjvoVaVJQKi5nn7IPYQNylEZvysyxgttdKWqrXugfhIwawyzelS1dFxSpnume5GHbTGoHJ2VwEwmdFrZ9SbdLCnMFDDaJbIY+6UGoriWOSv1lWVQvZMFR5bw+ruocPZVQ8QhGrsh1GwCR2AEF62lCIF5fShb6nq2EX35yVhJM1Mp98aSmo1quq3ZzKYZUo0wOveomlXSB8VgWCBEA1Qgt0gcFTKIZqp/aX1Tk5OMeX9vI4keUAGAG81NChlLMy1GNJYwJ4wmzm5u/I71/xBAIbvOwF8b0PN7eHc3eeYdztSOaM2AhFeuTU6C2IiJG2AKNaorh04OMKzNsdtYMkCMIuKEaQA2Hbx0odDRgKvObxSQau02ZKwpuEZaGsFxpRwwIMZlAy2bKAbuzaTSubJT3ssr/qzX8B3/oPvXYsLZvCmN72OJ7/yVTz8o0Dmj+bdj30CH/7QB+mtsTs+Dz3xz//Rv+PGm27mr/yN/4VHPfqsaKg5Gl016RIaARWJudiUiV5riCarMZV3ZyoTVibAqLVScqJW0TjlnWvN5KwGY6S0phckhDKzFhmqx8YXX741PY0envVQ9dF67mzztDcSWvn7A7HrWe7DvlCkMhnZIUM2IohhQC2p/bCEZV2GasWISs5seHbDS+3hweaUgrLoQUmUinqLFIB3kTgqwKImatmMZo08TZAS81Kx5LRaqW0YeuUDM4TnCkt3SlHbFXnuu4gKWxgvG1VC9TwPkZMRLgvhkeJ+UuAbK7VKLLpbI9loGNGZTL2SovxNbQ3rIUUnMVBygrb4qrp0X+O+EZTjUZkdmdmbzOx3zOz3zOxvx+v/2szea2Zvia/nxOtmZt9lZu8ys7ea2fPu72+AVESkduOU5JSkllDJG9lCIDXyZ2oIpKqaIWCzuvc6GxuK5g4u4zI8AKIyNk0T203hTMmSytpOXHb2iMvPXMaZzTbk3RXlDuGN7qo1F3QaNpfmpeFcf91NfPADN9zb7LE/0e9rfhMpFz7w/ht47a+8WYbJld+x1DGr8dX0RSWaquC90ZeK10avC8u8o80zbVdxvUVc6/h5PzmmnRyTeqM4WG20eYfXJZ6ChULSJBmupNBRKkyJpTcWX+hUWgDvlz5TfWaxhfP9Lu7qt7PkE87b3bS08Kov+wIe/+SrGfROiGr3NW/6qAN8SKoNYHZvJ5w/fxsn53b86A/8PK/5X7+Nd779es6zY7GZTsNKAKSRCo6ZUTOq2E6ZHj1riIOy90btztI73Q1vag63tSIKo6cIzTony47j3QnzsnBycsLJyY7dvFCrvPdWG94kErxiJE2anJacTlXhcAiWxHq1UWxjFBsDMZEj15elbbl00WznViMn6iQbLSOckpNwv5G7Fze6B+ussVf2yaEGFJqSwygHQyjVHmukSRMgGnqNKjFu0aBri/uGZBO9wW637EU8wusbrSpSyljeG/OSLSrtwTX3hbmeMNc5PGcZzFobg/deW5V027Iwz5V5Xqi1sszzygsvUwnRouhnFAfYHB0hpzKxKRu204ZNtLBVq49FEUHa0f0883LHfe7RB+JJ7oCXu/vdZjYB/8XMfj5+9pfd/cfu8f7PB54WX58B/Iv470WGs7QThYOe2KRCIochMOaqMHJflBGNCcYp1VYPYGmRrM5S4xb2TRmL1oXxSqFH6WZQxEBIKVGS+j73WeR/qQ9p89ALtXdKUS+SkQt1h3e9/b2cu+s4Fv0DjLFjGPLs7rhtxz/5x/+Gz/zsz+DyKy6T7p+rWZKlTF26+okbeK+QYlFuNuCaA2+DYaKwammNafTl6ZIno1Zqb+StPNISHN7ejxUCZW3O3iWsoetT3JRMBTF50FNATRqdROoKM5Ur7kwGxYwnfsLVfOXX/A98+9/6burcGBzZm298P2+78al86uMvDLuv2hY+/QUv5U1veG3k4hTq1pOZX/rp/8I8d/7u9/wVHnHVEZu0YVcXAa8j5dAdagWvjZQEAfESxRmQ59uiOBepheSi1pW8FWOEmZSMZWnkXJhSkZFKztH2SPi6LgRGi7nqrakpWdLBrlxzKMh7cKGjkOEQzJTg48d95jwqu8aQKyMQFB5GcsoD4gV1mYVVZRjeKAqxh9H0LqB1i0Zko/1EyvvGYrlkMc4sjvQuj2yA9+mz4rr4PesiH5SSoiikpLiQBaE2FemdFdQexSL5tcN7y0xlg8hg+1x/C7zzJgtkHwlyOnt6o2jHMNpGTxt59E0qGWr8ZRaRVWCPHbzqMMNEaW51pMf+ENVtl/9/d3w7xdfFgvgvBn4gfu8NZnalmT3O3W+87z8iI5XjwQnmEBftxlQ2DAmSAYnQAkwYqhB6YOekkyjBK8EUoq9IyMCD3P2BT2sBQsedxQVZaK1jHaZNZjvpIdZ6oqQ8id4TrRpG5ajAtde+c9/862OzkXQkZ1arc8dtt9N3O7yLwSBojRZHmYrAu7UzlcHyURjdPPiuQRUj5k9QmS6POzmelX/s3jjZ1fWUB913z04qRSpMBt4XzFo8F6nSjBDS1nxaSGOZ0XoBqzjqgFiYaNl49au/lJ/78dfxtrdce7B5Oq9/w2v5uC/4kgi7x8Q5z3niY3nPY57ErTd9MHJyEdK1xq//ylt4/c/9Dl/85S9VysWLvH1XmsWHhFZS+JuywmURC7RucoK5qzWEmRrM9SavKrtwud6dZZmZ55nNZssoxC6904MtstRZugKRE18WSYYJJeDh7Sg3rH2pwK228KqdtWhkZiyziogpZRkn7yufW1Rb1r4xul95k0utkhJMCZogbRapk3SAOeyx/vWng36afVWDylFUSZYEVE9GyYLnyRMGSCTPKtCYFP4bjVSC7NA9cMh9/YycEktdDkL+Ri4uppBLsSiFNiSMg7Zo38Y1eZfDss9p7p2foeOw8vXXvSXGTh137VKFGiInQqkI/K5+3fc+7jfcBjCzbGZvAW4Gfsnd3xg/+vsRUn+HmW3jtScAHzz49evitYt9PqWISqSWkKLWlZLZbDPTxki5YWkhl04pME2ZUlRR22wmSg7F51KYchZM5ECt2pLakZQpsT1SuL2Zsr42RYo/1lhSg6MEkwVgVT2t1fhcxaCU1NlwM01Qjfe++/33l/u9z6EezuIm3/iBO/nxH/kFTpbKSV+Y6VRE4Vp6Y+6V2Tu71tm1xtw6u944XmZhzEzFB8yodWE3zwphWuX87jznlvMc95lmof7ShSIolknlCKdQK+ChIpQKbpl5kQDJvByzLJVlWTiej9m1mbnNojs2eb29i6tbOyzN6alz5eMu4+u++avYXlbWXBmA98avrGH3hbm4l7/wM0lpC4SB7zIKu/OVf/fPfobr3nOOzebyAITDdipsN4UpGyV3NptMKhbc44XWdP3dF6wUmhkLKJw7OWHZzYF5HNlC5eCmSety2mzYTBNWO6WplCb8XVfKoje8S+V6Pjnh5ORECuEhxKECi4oTCeFKlVtL4VXBZtqwmbK0Lr1R6xKGODRPi7ye3sW0ER2zkyeJu9Q6VPn1pZTQHumxAi+CpZNLGJdIH1WcnowF6bcOimDzQvOJpWfmpkijNsHu5t2OZTfTqrpZ9q42tm6VspEosoprov6ad5LpwLOUtIeLimjKoav4MrfKSaucrztO2swuFOgHS0YNwBaJCbu6YPbgwq9iL1Lkpc2BlQ5wuyBMJfL0UrlPF3EXH5CRdPfm7s8Bngi80MyeBbwGeAbwAuARwF99IJ81hpl9vZm92czefNuH7wCP5O8ys7SZ2mZq31HbLhrZ73Bmup9Q2zFOSJlZBSq0GfoMbVGuDmdpmvDdMrNEc/pWZ3pbOH/uTo7j69xdtzOfv5t659308+dYzt+FLzv18Z5nvFdSEmWy1lnVY9uBVc7vTrjxxlux4Hl/rMNXimNn2WV+5qd/nbvOLSxAdVh6FUWuyLvwbGpmlRI9G80glYFTU/F+r2Ep1zbnopxX2TBtt+SsQlQKrGdfGrt6TO3HtHYer8csy3lqn6ltR+0zIGOaI3zPOUMp5GnCShZnxVwiE0y4b2hk5r7QysznfMGLePnnvUSMJSI8dLjp+vfyuzfcMmZjrA4ecVR44Ys+R4a6F1ReNkiVt7/1/fyr7/phzh0rbyu2kENfoDu9bZnnhHGGZGehbUn9iMxZjqarOMpnuCyf4eHTZVw5XcaV01keNm05yhObXFSwiWpxibaqrUt5e2OJTXhdyaOdRhY99ihvyI7axIZ3rU2rXkOtNtq8YF0euNmQE4s8nomRknO0f9hM5IClierYsNxUnc+daas10bry06OHjNvAiHrA2hQ9OCGXl4KPr3+SQvFKlENfK8TLsrA7OeHc7g7Oz3dyUu/iZLmTcyd3sas7qu+LLr1VWl+kNI4iOI90UUqq4HvfG0IPEkBddnjbrQVAedxGdiMtTj+e8V0VOcQjOoSAC6pOkWJNjqgx5ykiqcQmb5hSYZMKZQhjjLRHB7zQquH9DxFuX7ih/XYzey3wCnf/9nh5Z2bfB3xrfH898KSDX3tivHbPz/pu4LsBnvnsp/gmZ4b0vDQjg0EQOnAWFeUU+CZC+UUIA1XG6qwQvHfHS1bvGjJ4FUUs2r/2piZAnY6FfH2eJgqZTYBUU5qY2LJJEnSYqVRz3DqV2IwpcVydW265ba3If6yG0ntl1DtnO+amW+7kxps+zCc+8jFx0rngIyhvY8mokRIQoL5Dz6S8pXedwJWFlByssatOyhtqT0w9rVz31sXmsJxJJXPWAwVQ8r5KnBKOPjcxBFoJEZGCkfGgLKZkIVCsBeueWUxQ6uydKx5+lq/7xq/k9b/2W9z9kXMsI8/lzhve+Fo+fg27163Cpz3hEbznMZ/IbR++DWyhzXfgNM4vt/MLP/paPuPFn8YXvfqFpJIpFNKUKAZeqwDuHY5swlsRRs+2JCbaPEunMkmHdMpSqh8hf4tmXUP+34YaUO9kIbHliaehgl9Xqqx3w6cB1WmCEPm+cVjelHWJpCjSjVx7d4Gu5TWHNmYJZZvuobIdLUqSwt/UpR/QrQV8RuGw0iE9mFcWkDFx7VNK9NqwLCZKLsr7pQTZOj3p78hzdeiNtQVxCihUyjAaxFkmFXHaW0vr6x4kCAfRHT1RcmGT1I8Hd+kEIFbZQheaYBQau+aNFJqhXffi0X625CSmTPdAIKgEHI0uIrIhoExKOTQfGpijmBatQPy+/cX7NZJmdjWwhIE8A/xp4NtGntEUO/0Z4G3xKz8FfJOZ/RAq2Nxx0XxkGIjWKskKOW1JWfCXqURvmy7YTbFEdvVicfa4NUvG3Aa2LIzArPap3oPPHO56zxb5j2A3B0G50vDsLMuiNpbm1HbCZioyzKOvb5zsFpvq+Pgc586d4+Jp2ovOb4SgUGvj5utu4rq338AnPe1JtNIZslDjpE8kFlcIZyP5bFrItdXI7YYMf6hO176jbAqYIBmtKgeWSxYcpDV6UkWx7ZbIZYmC6QFp8hQMiZFXihPdXM8mdeHUxC/WsSZQv9yVBeeTn/8UXv5Fn8WPf/8vqnLeaizUxmuveRNf/JkvPkjpytd42fM+lR//xZ9VTqoLqmO2cO6O2/i3/+oneMUrXkp++LHIi+543ynkK1FxJrE0o/nMZCFm4qMNrIxNKnt4Te8hF5L20l8qnkjEt8Yzq22J3JlycFgN0Lw2cE4byHs4mZ6VGDGqwA5jty9ECKqVxP3uFh0qbW2jmvOGxFBCN1RraRGGSpxC6YciJ6Av4Evk7FlxxMtSg40m4yD2kdbUNBVFb60xTRPTNJGbPOu10DPlwKIE9Cxa+8oDliiuxwGsvLcinNbU79trI3eByVNOLE3eZgoCxnZzRNqqW0GURwNJEF0rI7freWFuUv1pvZPEmwiIT/QU9U6ZclASCx7KUB64Xe27vSDNvY0H4kk+Dvh+G13r4Ufc/WfM7FfCgBrwFuAvxPt/Dngl8C7gPPC19/cH3GUgVKkK6XxT5TcFo6QFjkxUyz2fVdVuW+lF8zxTSlmxfXTBGlQNjkpu/Mw77HYnKzRosy1sosmwu3QHh5RabuoBriJZFI+ycXJ8zLnz59br+a8dsj/GyfnG7s6znE1Xc46bJDIRtDR5EQAhEhpslxJeNsHS6EHRnHcLrS/qTR0e60hs+zI46i6xBa+x0FWswoYKTUDNTILGuHKftVaByaOiMTCWmEUlUid9CYUcs8LmTOIrv/aLeN0vvp5brr/9gvu/6Yb38bs3PJVPu0e1+/w8UzLsluO4mIYbVBJXXfloHvWwj+NOfy9eKngmF1hqpjblqQqDcuh0qyz9GHcVu4plQafqDtHtLJSeIpIJDj0Dt5sijI2fubm8SPTshNMNFEYYkCGOoeJMGAkCfjOeG8G8YY5DKfBnJjRs6wMIXtfrSyZ85xQC1Smps6Q3WFrVM8mG2VYevoMlYWEp2hMl5fWwy0lQIcOY8pZsag/izRjYXxV1VJASkiHwjeFs1Kp+S4Twita1tBW8dUrZkpGxhBNyEUi8TAlviaPpSHCu0Gsomw2td5bW2BxNAcCP6qh3UoIaB/IUUmcDTVBQcaY1CXJYiip8HFDdAwLvPQpA9z0eSHX7rcBz7+X1l9/H+x34xvv73MMh93cK1WNnNBZfBU4jt1NjgSYbOR1bN661EQ4okG4s0TND1MERxLWAreQwFjmXqHQ7vS6ktNGCr52TPOOW2OSJKWXqMK4pcHi9sSwzy7JcbAa52CMYXuQ4yDZHV3LHnQXzy6Cr+i15t33/DlVpCbGACUKJZol+H5a0MS2lYDHp9N5sxLzJuZCD2TNoXDOBO4ucoYQMQnkG8LrQWzR+N0GltqHmLPxfF/DeWGW+yIaZWrlmxB56zrOfzhd/2efyff/sx2mzrXMA7MPuTWZuzm+84128/W3XgA0WcSjDWGFz5tFw9DDe+Y4PcfmjZ8qVqqaSj9l1Sctlh+QK52wqNDpzmzGbIHV284mKNTgnux2b7XZfuIn1kcIQ6BCKwkGPOQwWiEWPb8F6MoT+J0lGlFinI8pRzk5e7gi3exfOYaz1UrarlzkiAnpnGuF75BqJXGQugz6q/Nr6TGjU1lSFD+EM3NluJlX/LYdYyJZiyLkgM1BuS63rc/UwPBIZiRSxh9J5IgxXXj1jIi/pHnnj1EOvs0OJ9BEe0Uih1Tm8aYvOjyrGFDiQQBxzB9blIMgz9KBJyoBapOtGmiEXC9Wo4HSbKKspsKDDW7+3cUkwbhzoJcjr3Vmix0tJWd3kAuukKlanp6TFjumBmppXyVMMUQuOoq+FiZxPJ0/q0VK7B/zD2G63UjfpFVKmodylp860uZwAdlHNpGiS1IluJIZv+/B56oygBZaUQwTwAl7vx0SG6vhYUClTtlfyG2/4dZ71nCM+5YVPJm2ITnUORO+bPpNTYXO0kZcdZH4j4X2m9MaZ7Rl6nlj6RqrseQmOLfTmuAlcXKtLdDcKCX3AsUoPEYUjhZ+9UkqNcFvvK2TMKsEKjxRGD/A0QI7X1MCr2ETZVr76a76Un//3r+X6938Y2C/OHtzu5z3z2fzqG36Vc3feHnNp8tyB7hKy9XYHb3z9r/Kav3nMl33l5/LCz3o0l10OdcnkqYb3JDFkTxtYZsFkAjPah0cYilCepA85kv8eFVJ50iErFgUYWYwKNXC1WWmg7XZDdek5kmSgch6sm8SyzGSTgK+RWFZMjxSNLDQrcxZWE5vWim7vIkXI+wNvCmd9NR3RVmGE7t5XKl/OSTCwKHxMSZz0Eh0Es3d8rvRk7HqTVxZprJwSeUm4dTw5c5/DeBPca1T8q9FoLHJ9iUTxREqFZvu5zDmBbxhK4KNabWbq0ROQHrc9kF03LDRBVkc0KibxJoJjb9EGIiVgEkYa5TYNUyM1l06nvHPhZRdX90T/w+Qk/7jGblmCMTFOC50CHsotZdpIZqoL8rBUdQws00YiBBYS7oELm1vj6OhIbn4WrCIlIfFLyLrL6wwCoIm2OLegAQ5VlZRD7LOHGKhIvEMooi8OfRIlyueIuk05TJNxvtgYVEoA+sKdt72X//jz72fxG/iHn/q36emcik29B61weNcw1GlqVyFFUnITfTHO7SqboyP19umJ4tMatllOKoiZqGiWE1PS6zLFTo6eLzkrN9bLhs4GQZ81V82i0mhQly6mTHgj1glNTx0ezZSb6+Z8/Mc9gac//anc8P6PfNR8fOj69/Fz179P38SmB9aUr3KYTq0zx+fv4t3v+SC/8PO/xdWPezlPfcYZNtsJ+hk2U8FSD6SDqrBaSoWaFV72JohOSoXLzqpnkCI5Zy2EEpmU7hLMsD21VRoiJg+tOa3KKzUK2VN4l8EPNmPKGx2cQX+coo/02pcp8twSyUhS0DZTG4MiUdpahT2cpoIrF8Mo/MlAxu/HPvDwTlM0SyM8v+Sqatcu7rtNMhLbXCK1EikGOrvtENoYWEwP7n/0o+8KcyXiLHZ474IcteZr9KECYCLlHBAe3+ds3UK7VVGiRzFWuuGawoqapalkCVNgdLsLqteCOKLKV40Ht+fE53BXHIHQPWesGoOJdF/jkjCSDhDg22maNIm9RZMfW/M7ecBASOSyYSoCvk6lxEnfV6zU0J4zCFWhigcGSw2sJJ/WQsxVdLBM2hZ5VkCPooqoVom8qq0o3C2+IeUteZuxY1UVvefIae0w7t9IHk6C4/R2nmWeuPadt3Ltuz7MM5/3SOUdi95kCVrfBc4sk7eFqSuMUy8eo+dJOV5XPqshKEZFuZjizmS2JvJ3846UHaqKLC28LE+G1YrVrqR6hPWJKPpE4aDkEhvhQM0mGa2n4Jgr0V9dfPnKToUP9vS8BzJG7k3PfwLLLOfPceUVj+Stb3knT3nGp8uDq3PQWKNg0HO0dIDOhLlEd8mFnhp1mRW1jDx2Zi0UOfJ2pjKxtpB1iepmiMgGvKTwvGUgVL8qayrFUb/v3tXKoDXHXMaGwCpWr5FDS8FyUvGtZN8DwSOErVVGcSh/DwjYQH+MijrBPLNgpPW2YCmvWo05jEia1Md7tFAuJasYFNqU63s90VO0zGgtPO0c0C9dk9KUwnBKxSeKRl0UiL4sq5TaEMw1Hwc4wbOHwYKx+CpmNBK0SjaYu1AFQwBEIfiA9rTo/hmet3c4SGfUOJQsvE5Ll7iRTITLPs5ER5th5Gtaoy8irVsqzK2Hrp+tmMi5L9EtLwoIVUWWkgvNgi/aG5tJdDoitJpKNKBvjdaMOiG+OImlK8TbbKIDnQ0hiRwbPPP0Zz2J7/zev87NH7yd3/mtd/NLv/hW7rj1Jtput7ePF4m3LWbACQiJd8r2Ss7PW37tV9/KJ3/KK7Gzi+amd3zpeJcKSweW1vDdCbhUJPFEno7Uo6XOkTsyppLYbrZasClFBVRhR2EDtsjDAdxTGLWgfnkXiHozkaaJ0Wit9K5qKipUsOisbzmTyiRVoKj3qQ1qx6l4qhwdbda81QMdykXt6A1SaXz8xz+eV736S3jDG1/PY574FLabTycnY3MmkVOVqCzRJXKZGbS1nEz0zGWJzZfV5qH7WtV1FI1475RpknfkI5uS5M90RSkNl6c86omRHsKjy5EBLt5/j6q5x+G8CmD0HpX0TMoTrRvdK7uRc0852iejTc1opWBD9UCj+1pwMld/8eEkaI+NvdD3nTbdWJrRPTGlELYuIjmk7pS8RfFu6AWEgVT7COhJaRXJDhItaXVo5I2tIiyeRk9w9WAaxUjGcTmYU+NrGE8GZ8lZonXtlCGlTdBI45kk3xvWwJ9KRT/EYXC8uoDyQVNNETJc8i1lAXJSfwzR20K3zxAdL3s0mtd7i41uhQNlXzHvcSrJ6HoX9dCSQlKPDb3ZKDwfzBmS2kZ0T5SprDnIhHiqKedVJb035YlwJf57W8hXGJ/+imexPXkEj7r6A/zCL/8WnbuVu7SiYseBu2TRHGq0jCVJ+Vt/tFPSxLTZcvlVD+f666/nA+/5IE985pVixRCLJ0+UlGhNDazsSPhCMynbpJLXPFoLAG+y6OpchSXdDfHT8G6mHFATB+/GhLFNCafS5kULrokzn9Zlmcg2KTQzoGjz1hobMc9kL1gl+uM4bidYapw9e4SlwSWOuUlG6plmGbcdqRulHNFTjWZsWXCUozNc+dQns1x2xL//Dz/Msz710Xzpl79M2FBQ2GtJWp8+CZaTJ5xGST1AyJnRv8aSwPjFJhUjUmFpFeuKbCyk2Abrx1D+srVGivW19/6iGKbidMjbCcfXQ5lJlNlGcqkRWYSpWwRlUfMso3uOHi8dLER/U0jcGXQWqocMYFR54xRcCxEW0K5ik1Sw0HU5xN8qYsu0FjoIUu+ZZ0molWmiVtEzS86UHBJtmNSmAkKnPmgpsJZJxcOu5mEFNRlTOiOatvVKThO9Syey4yHKK686BW7aD46A7sqtTpbIGC3e6wgqlbPT6kLKtkaSa7M8Qgi5z9CIohtYDiN9kcP6kjCSZkYq0wpWpi+M3iu1Nmqc3gm15jQkcWZFidjsE94TZOU76m4mWV8Xt/QnFarXJuxVhzUJ35VRxmNxGkBztmUKgHDAhrwwWYW2Y+pnWVLn4f4wzvbH8/brjvl/v/PfcMdt52mLTj7n5F7udi+H5Q6kpvyLwfaKh/GIxz+OZ336C3nn+64lp1t59FUTR5EnGsZUIgAC3VtK2DSplzZgObO4qFoJoorv0JyGpL2W3lhQtbPu1AJ3blolOYcCUkksEXb3Tex4c9yrkgiuNgQ9BTwrUiPqQ61llVvGvEpdmkzKXf+druATnvZJmP3nUELvWD4L26u54kmfSD65lVuufxtumcZM6lDShnzmStg52SvLrddxxeVX8ewXPYU//01/loc9ogSEBgkwJGjLEpXorM2IMIGWEkvrVIZaTdahF2GZ9WjtEaiHuS7hGQJhaDrRP8kF6UkmFZ82hFPCAxRHPOT12h5Y7t7pdoIjHYCUJeoyTTnWqAyFONhS0OldPPAWBtp1hMlQjbA5YG/DQ/VFUJ5sScYp0gFaiabcp20pAwdrUfDqnTxJALrWncQnIo8rkKEOgDL6CAGBJg1JwnTA/AlOxIDgVX1GW/vK9Kg3KHIcqkDTNIgJ4fzkTgkRkNbrmg+3ot5TMFpaBD43ujrqmRnJNhTOjqyFwOUHNui+xiVhJN2hB89SJ/l+UdRapYCTCqkUjgIjFsrseCS+zaF1iYda60wlFqLvPSwVEjNWMqkkWpVIQc6Z1J1UnWmzUXiDRXjT11xLcSc5bNIVlP5I+rkzvO26hd9+x7u57h3v57pr30c7vh3zTVTldhxWbzX66uWBGBOGQckcbc9yfNft/P41r+XFf+o5fMM3vorHPPEyZmcNNzBncXGiuwtDZsseu5ZK5mTZCXbhSmPkUJpp3iGboEJJQePGkuYOeXV1XgIWMoRda3ivTkuCu0TLNdJmkiEicqI+GiopvFmoLM24zC7nTLqMk34Zx7sNLBsuP3omR0eP4vj4VuyKqzjz2OdSN49n8/CFc+9+r3JLFrIUzUhp4uzDr+Lkjlt53GMu4yu/9vP5vC99KZdfdTlmVepPZFJW18dexYpZaqNFLtFSgnkmh8iBcqcdj0M5YcHGYsU3avOIkho3umYI1ioyaia25rIT0jjtVSILHgXHJIPRlihmBFXPokNnj46R0pbsCPqktFGP8HREDKUUgceThE9qHRXkwZYpsZfkNtYuIoJbXlNHOWfB6kZrZh+9yff31z3YV2ahMiVdBQnaRuHOg4Me15ixkF8JtAMeYXhmyMWpL40OXnnHAtDnXJjKkYxgUv1B3S0nVBBX1NJ6E2bZlcO18LBb6WtVvCX9zSlPQYeN1nqRK7WUou7A6rjc27gkjGRHxipZhHNJ1aYcvXozncF+yB7VVBPEwdBiH137AEoqkQgmEt3OtJGAau1NCzjFSR1iqyNx25YATHfhIMfUObA1qMsn8J9+7cP85lt+nXdfdwvvuvZGbnj3b+PH11HP3Ym1mdE/xHtiMDDG2B8CIx3dyVPiqked5eOefhUv+ezP4FnPegovedkLKZcZ5+qsDeuCefTe2XWPJlQtik5qSNV7o1dCziwyB+ZUBBR372QK2zhoCMgF1jEPIVO06GqvawP6gBxgTV5wKgrRUqipiLljkW9Ssaq1Ru6Z5E/i3R+ceNd7buJdH/oAv/7GN3PXh2/hjhtv4eiqxzJbo1z2aNpmYmm3cevv/zb9rg8gZGUjW6acKeTSeMLVC5/357+QF77k2TzzuU+n5wrNIqTN0sJUJ/s4cC1YVxX3jCElKDFCGs1Cubx5VJxVoNDBC5vtkQRpMbJtZLSGZ2QljFyA/AcTaQD0U8JsQzHnLddcQ86JT37Ws7SZC4DpOnBSJyTxIiUBa3907YV9qX2lSkZFqNXGEq1Wp2kIdOkrpZBmboHgSApXS0rRKd5XtZ7cU4jcImPpkhuccgmPDOVLTXtyFEVSoCCaGVnVFvHURQzc568tB8nDIg+tCroYWvIc3QVPsyCQDGaNjaIqOQ4Pp/am+zqADWGmDgJecaQsL6ZPlcMDLDRprLrji1pYrLjO+xiXhJE0IFsRsyQZuHKDYph0PBMir42GMbnyL4Vo8RAPByK0VglYabKU6EbAVYzUO9vNdm3g1GpjXuYQOs0s4Xk2d+n1WaZEZbuXh/NTP309f+8f/DDn7z6G/BHwE+rJDfidH1LeNCe677Doeiegq9SDHvXoh/GKL/wsHvuYx/HmN/8WN9xwE8967ifxaS/4ZJ7xqU/hac/4ODbbjYyewbwYtXVahDuYvL3JnCm5coKl4KF9SFT3symsabUpZ1XUICm7X0AFdB8LcWgR9vA6FsE3cCiZKbzNvAKrZTcHCB8TJbH2JcQvjN2uc1l/PD/yY2/jn/zLn+W22+7Aj3csx7fhy+1kPwFvkArznbdQzn8Eaws230VvhVQmnvLUR/HZn/dcPuU5z2B71njOsz+JKx93NSch/LuNZvUdNZvCFQ4m26xeVzHEDQ6VGoBumZKin1JdcBdVLYVXsdLefHTvywGSFhi5NTV6G55njwNs5M6UnhHGcJ5nbrj+Rj71Uz9Fz6m3UARXXtRMTBUl3FUAU1En4yaxXYtmccpzh3p861gpFNRTqI/fw0gB1Jb6eECCPKnaHnjiFrTVWhEUxiyIFRnzRuqLJORCk3WImww675Bg6yFQXMxFQICAW408YlTaUQXZA2Cp/PQQyd33VlexBhW3RgdEl2wdLtYdxt5IDugApjk0B2pENo1e5VnWpPpCi+sZjlB/AEy5S8RICkPmyfE0coWsoZvgP4hPTOQTiQIP8iJar/HgMiRlwbxKtJeSZWSIz0/yKMQESGynDctS9ffjdE7J0K9mMEFXbrz+Fv7t9/wwd97wZlhOwCXl3+sJ9GOgB/netf8jlz6d2fDkpz+cv/vtX8fzXvAZ5LJld/zF3HX3Oa64/Aw2weyLQowAKlcf/Fgll7NNWCqBFFN/jsVD4r6ZAPIgfF/kIbsHyDyPzncE48GiAmlhUIk8rTyOFiGk4BRahJnEaN8+xDxacMWXWTm7nS+i+vUZy5fxg9/7o/x///QnuOPDd0A/pi0Vr4vuyiREQDK6n0QfdAHSy9Z4yX/3LP6vv/O/8ehPfCSWOnM7wZJay2ZLtF7ZNQkd195wH7qXzjSpUIILEqP6WHScjhxfxijJ8GJYF7Deux1QPxutLnqACWpVJVxNtzoplcjTJSzBMlKWrjm01iHku176OS9ju9mCF4lGOEHhVMi4cpwJbc5ggYzifwpPLpuUn7wpovKpUKwICWKF1iFnFaqcjnul+L4anqIK7c7aQbM2gbNHmJ2Cqpj6CQ4sIcJROmHcKp6H6pSHxztk8iKVFF9jrWi9BOOIzuj0OfLzQjlI5V2QIh1S3cfKjM9pg/Zq1K7UxGEuUdRDfd6IBPGDv9FqrO2Y//jc+xPKviSMJAae1FK2uyTOlAbUaTJiXguMGsh4pRFgu5NM8kjK2CcqlZE98t6jh47muLZ42GE6BtBVjeeh+iLXvhu7ZcZSZ0mN97//Rt7zttdRzt/CUkPcAHWMc2trV0JDJ7kh0dInP+UM3/yXX8UTnnQVH7jxHQEhSpSy4ZbbbpWy+jQxehdLckxCwSryC6ZjtsGjQqrQTAo0UynkvMGBOu/CGzoQW0UCCIqAXOK5HtzWWNhLhJtDXxD3FTNXPQxnQGTWamBUxmutwh1Grsu9c8f52/nFX34dd912HWU5H8KnRsqqeLZxgLcwz2Z0m7AET3v2I/mf/vdXMj3ymA9/+Dqp1JgzLzuyHQmA753tJGGG5m2llzpQWwjI5kRzdK995NDk7c+1UU0HYQ16Xhp9f1z0TFKOAMVIJa+IBCsWYgvRmykF2mvky3Gyq9DmZywOhChrRBrIkvLqvfVo4KX8WwpGkyrB8nazJXprq5HsrZGa05IYOMkK2CRDH8aqe8OY1M43IodaF1qP6KQv6oZIVcsJAtFBCijPgntn6fLuSk6hPCShiVHk8lEpOTBOq0AIeyM5uNP7A3afq3f2P9PBoEiuMdJM7A8820c96SCTNf6GxXPQc9OzGG1WDt97OC4WasMlYiQdNUL33qkof6GTT3k780DmJ4FJFVWMBZdWbwGIjR3FHGBttF6FI0xJebqUTY3oY4JSEnhWiilJzaZaZ+5QvXFyco4b7ryZxz/rMZzc/TCmzVXkfLKqjtgmkbcTyTubKXHmaOJoU7j6kYWnPeMK/OxHuPbdme32cjabjUDzkQrI2w25wbYU5qVRpqEvKO8ukWg4yTqeApS7VFqvUmKvO+ZZ4Gyp3RteRXVzoPaDxRrtAFr0Q1H/HC2h5Eleaa2kopzl2vTMAt+XbV3olnIcIlm9vrson7fffSd33N14+mc8Ed/uaOd2WL6MzsSUIFmD0sklsUnG0WRspsyZyy7jyqvO8EnPejz5bOL6m27iijNHTJP67ZRpG/hBKJPU6nuFaXPEpmyEY8zSydyakvInTVRMM9SeI8Q3UnI2ZYOXQX8LlfWkHtiJwlKb+q8HI0NOjIdi9kbIichlL1pEOjRRge8wPFwC+JwJcgNAtPMFeYy2hpchfWZD51F5Vk+dpYv+ZyAiRK247bABh4kc4Co2Eu8fIakHMkLqA+FpNR1aPTyqIU47vsyymr6h11tfDv7WYJ8dFGnw1ZlZvcY2ilwKifuAwPm+KDU0RqVWrujFD4znKKAS0dBHGTe3NQe6VynXHxktanVN+znPF5jPex+XhJGEfR6oBId1KG4ZI1kuoU4fLroVCZH2hV2t8tosK8/YHLcW4PKMJ3kUakQkqlpwePR5kcurTadXN2OpC602TpbGSeDIHvP4K/jmv/l1LLXhS6fnHblMdJ9p1tQ3xRNmjWzOZiq0Ctk2nN0ekXwmB6/Zi7hxR5szdCwwnSLs50EPbKruWp4CviExAIUR8siGeME4KLTA1biLHOFzD34sEj8omTX5r0UpwK8WbNP7mwytecOKcqryFlSRbe6hNuNBCWsct4VWO0vvHBf4/C96MS//vBepp4zB7AJmZytRXS1ss7FNUDIcnTkiZ/WsLsH1pshLzHlDmsTBDneBTZ6wLhZOHkK5pUTPaxmjsyEIYciDy2aanw65bMKrVvrFwuipGJiCxikvcADpug8WV4SN4TlDhk7gGlnhNlPOtJD8Op5nJteWXaJwYmhdyjGXocGGFqSMWwpHoZmxmIRcshuNjHfhP7FFCkGM5lvR8TO8st4j7LYoTmH0KgGO3lytP+IA1v6y9XDJcY+1OzTluYdRQ8uC0cY1Vgm+GknC8/N1zg6j2zU0XsPeBDSic7nWZpxia5+aiHoGa2d8LgdG012GX6/oUMAHY26YzoMUyUUs5SVjJJfaUNdTY2jtdW8xIay3tj76CCtaq4K0WKJblUg5rkJLb/RZv4eJazxCHLU3DfBqcMJHrxzHJQbhwr6dzRNQcD9C02orTq1MhSGWmiyJa1oyS63kkplKwnJWor6GsY+i0d4DVj4KIrxKIzkfjajyhtpPFNpUMR0ASgkmkMszwqvSDj0L7pQSNYxFchVdundqb2o7gKrs0i1UCkANv0Q/I6T3YwfTPLjrWBR1oqpYhY27jBT85stDbEAesUV7gtFqI7nYKSVtKOVI2EVLUcEU7bFYiQMzRw+dTDPVN7WyM8kk6dbDO2FAhjBSiJD0MApmI+uqvibyqlJ4K6YDJQozHWcxaFkHaDHDAnzfB0A5mF7eiOKOrVTGcB6BwJ+ankPtHesNpwdFcRhKj6vZKlQ15R89hF7q8NiQkK08TQkFK8cWlFSiRYGxenfVfO+tWhWqKFgzUuhhj+vskeZiwK/kF2aW1SC6C28ricJxnwrvY6ftDV+MyGCsXqXyjge5xLhW/DDs7mLKYWvvm3XOY28nJs1FKA0dXqOuSl/m4WitRR726I8oJl3y1e3eO8fzseAxJnyiiieZqRRBpdxxlhVqYeFNtCYpKCvQe+AhkzymFLkdS4nmel25Iw/pMYFJe0Qjeq5aGnkqZORtJMlSK8x3XxVMTM1IMDsSjCJH7+dScES7y1GpzpbIG+jWlCdLElC1UGgWL3m0/NS9STJqg9rZFnkYpnBEVeRCTs5uUYoAJoVMacBIYgPYJhRuMilvtJgs2iN5hy4lb92W+N7KdBgDaZBLpnTHk0mtCYMe/O+N7vMobRgtCcwSZPUZynmSt+cbSpp00PlwzpzR4dEIrw7lL7WZBF4H9foZubMRUYwqqodKEMgXUaqi4UiqzGPL6Onu4nflTbfIK9MaOaBlzaMLp+vD0vh7faQt5O0rdHYkuhveVA+uu7msg3xBJsHw6ah5lntb7w1g7ufVc91lvFO8Z7+B9zk9s063JYLF4cEJoymPP37j0LuqSrfIkxxVXgguVnxGB6+6Lx99rEPsdnjTsUushyeMjNZYx4cGEsJoxr+HvbvAEz342ZrhHB0O9yUJoAZfPJyo2hlYaCEU9uG1jP/oHBq5TXelLUa+3WPvPxSMJIjvqaSvR4OiAm7MkTMR+sTwXhnTZuRYhCH0yaB4BYMhqSDj3mM2gi2h4io5GCIK7dPKwEmR/xxtPA3lLFNAFxSWpX1FMic8T8oThfLN8C7EC5bhTCXrxHVde+rGlCeEK6zaSjlRawtJt8ZSd8KLUlBVFVVEzRgrr2R1nAviBSDcXnKlHpJJfTuN/ssQupihN4lhnkP8wyhTJnMmqqZRcXYjB9hXOblMtjPh8Y+ufhKfgAjt1vAmvlaLIPgHjMKcR+Wz0u122pCyS6qAJ5dpqeEN6HyMkC6NTwzY5+h8ZVWmyOMtsQOVXlGer3kPip6JBdIr2VxiF3EgYsGRJ+5F/0Nw72hI5c7g86fV/wraZ+BhR85xmGnr4alFukMtEYZr5gdh5OHmHUWMHBs/lODjiCHCYr1nHJR7XOWa2xth8frvvaq/7m94dRrNh4IQ8byVGxyGBjsItw9ylRcMi0A3rqPbPbzJ1Tr6+rfNOAjT47n1cWgYlkaB9/BeDv5ub+v3a5ournMUJffUgPsel4SRHO75uMnqCKrRgphuOuvS8DHCi9RTUx4wmcxIyUngWlfSG1wca4w2i59aLJH7IFEh8U1LKh6ZPEThDYUDTLFwuqnX8mjXSQusYBeGrbfGJk+kklcYzYSgIhYUKPF2K3TnqEykbCx1ZrMtuHeWugyUAyCpMqjBUJAXlksh5XFqwgblIVs3UpHXm8hgAstP5Yict+IyhyCsIYxStkJGOcLuQy/RyV0eoUdIbquFk5UYCx1CaIEwRuFxj8ZV8gnZe3KRvPch5hvg4ICg63cCbC9xVAn/Dv9rPHvtk5Gk0Pfd5SvCrAjDoJNI7QCADViTfmjvgUF0h2ha1WkSeyDSBKQAIqdx9+sYXQabdzKVHMkgwrv08CR9NewjHNyHpaOmHJaGNUiMdMEFwwgzHC0f6OtBaTas9/DHhgs2ikNhPMIoj2d4sAvX69qrbYUfNvQ3+97Y4B489vE8Dl4fH3QwYzYOcB8HwCj4jLlcf6yjwFnXjhTE0YE55NnwiBLWI2h/j+Ne1lse5STWKHCQd4bS1wXG9R7jkjCSwgaqxC8IRImTfOQmZVTkRuU1pImAiZQNi8ZJvVd6r7QBxUiJkidJquH4SApbXhPIvWvxmUk6q+OiQQWTYcWQ2cCvZZxM2WgxqfkYYFkA97WBsPB6ltSd8CggPd1H9V6d3qayZZUYw4nogL5RbtSys92eJdlETlvgYMNjXKiHJ2jSIbxphLLKJ5YwLguqyUYPm/F7Q7w3BWvCL9xMTW7wqn2oPjIVrK6yWyjYXL0uYPWMsHG6R4gdjCTluXrscUUHZlneJSNQFk8EPzCOoXqjexBfvblgQcpayAjLu4rqsXmIT2jeUpLEHF3Abt1vxnuo5ihGuGDNpoC+CFUVO7Krqu0YNUVlezwVF3+ZQBIMI+dxPz2KRMNwOEOvcqQVRli4D7/NRWuVLRwus2A5w/tqPkwEFxglh5VhU/v+3pJFOWmIXHunJchNx5g3pSOEhdR1pSGKbejZH3ivw8NNPYpZ6H05xEAsXMEGDEUQwXucFPPabVANCQ+UKFzJfO0r6WO+hwMVUaCp8EVSrl2eJAcG9o/ISEaPmzcD17v7F5rZJwA/BDwSuAb4c+4+m/pv/wDw6cCHgS939/dd9LMxStqu/9bCjZyiu0QQ7DDcSSEquq+UmTlTThgTtSe6T2FXJc7gIRGlkz3TzaL9JRGW12C67D0mhz39yvb80GICtXtg3UqeFN47TFiwd2QskqOiRFIBoljI20Mot+Q46Yfh25/OKrIseOoU2yhRjdHWbQQRQ15gNF2AlDW8wirOEmrPCom1hRtrWMjEoHbFemK1VyHuMBgoOhDiefjI+SgATcGCSqD8WlzjCt9wMSsEcA66HQfV0CYqp6UaHuIIWTtuLbQVbJ0l9WmW4R65stYWKT0RMKoDr2lvJjR1vY+Kta96nN4tjIuwtrZ6L/vRBpB5hPGmefF4gr2z95YdUeTCSEIYfR+bfxQzFDWNKGKEyg6hzfjRG3kI4dMM66zQnIELba4Wr1rnSV4iptyljwN0PIMRIdi+cBMeYw+qZ4/vD0Nqt4O1Rniqsf5S0v0106HbAu4jzQKXI4QfeHS6lhWHyTD4gtT28eTdICcOUwkD7kc86QuH7VMocW1a6Cnu/Y/Gk/xm4A+AK+L7bwO+w91/yMz+JfB1wL+I/97m7k81s1fH+778Yh9sZmymzQUXbxgkaDX0RcbJFIvGELRlNZKeQ5zASDZh1vaufHd69OmWwVO1OqcjGd8UUmLZFNaGRzTlQrLpwEjm4MNqsjMbzEoUHkJAzILXi6GU2RDh1VWng2dhSBhhyGDF1dKIUDByqz1C2CFr1tMS7+zhgYOtnxehyBr+yF5b6AbKjPRYyFGAUfeX8IBThK5tNWwDnjXyb3Hxh09Q641OMvmIHWW61hCTkbaQKVNtPXoLHcA3nMTgpIe8OR54QrcWnU1XS4J5cNZxmgU0p0t5e/TrqfQ1lGQ8Ctinv9ZQTwb5IDKMw27gF/e/OMRVVuO7cvSlqi2Pd7zd138zvMK1insQDHpUxkelvoXQMWEkZXkjHRPGNnK6RPjqKY6kYeSiS6it+UoXjnY8Rt8/SIsQu3sYSbswtPbeGX/uEPIz7lFzqb1z6I2OCW4DRYKr9QdxeKwzsDdWNubZ+/rABqxpXPzwWCFy7M46p0PBHnxFrIz4ZfUkx9++iIGEB2gkzeyJwBcAfx/4FtOVvRz4ynjL9wN/CxnJL45/A/wY8E/NzPwiVzKS6et2ij1TSglLL6M4KmfukMuW1jMlbdTilbb21FgpECmR8iZ0HVV9VqV1QwqmhNm+n3CmkGyLqsedQiOnCfehrq3FW6nDj8FlUuM8TiurIzpsgJeoJYSyywVuva25tv0QQV+V7GE4orroaf0s2G/adJBfFYh+5LWQUWi20tEGXUxQnb3X5m1U74lFvt8gawP69QADLNFXFkUCL9H/2QeoRrzYNRcooVUVvQaHd5HQRItKe3jP+lnMbQMJpCqsTx6tbuOwJFowNPMVvbCqGq15i7HJdC0dQWV6d3m0ae9djLYF8Qt6LXQ0V6M2DLrc0HAVBV3SvCiKGCeJu8fhESAkHwymgJ2t/WkSh2GiRx5wGJihZbnmV8fXsPZ9LxUWf5jRNnWMgSlcOzsimJX7CJcjl5I8jtPh4YdRz3bhEvY1mI+1amsag4Argdgx5gqhI8qXsVpjguGJDu9UhnosysNUxAWHzwXXEQd8FFfHvHj8kkeRsTWhCiyYTBxc/72NB+pJ/mPgrwAPi+8fCdzu7oPOex3whPj3E4APxk1UM7sj3n/r4Qea2dcDXw/w2CdcLQUTHwtZkJmUCmZFecoR/kYer3cDT0zTkYQCXNzaNWSMsG9s8EFJXMN5UL6DJJffO9062Lx6ED1yW6CHpmZMOmHNIqh1SC4s15poDxUS5UwnRmGB9ZQLtRwHt7rq6pkFLtHVs8Y8JLRsCA5HqwAWfR/YJY8DobkEYBngZA7CCtNy7/GD3GKuQ5Zu6dL3G7nSibKngXX15R59R3SPwziGl9dnzCvRe0oXtRqW+JX41XpQRBmu3PCoBqg9mRZ7ilB75J1aFxPFbQDg5aU4tkK0FLK6gN1RyFgNhQuQP4xdC8TC8DLGkKSWrjoyoevvNdvDZ4YflOjRXE55Q3M16do7kIHAjN8Za0Gbe4SLbTUC41b21xyH14ERGIfoPoQnDO/esyQEYNz12Wkcdn0UQ0aeGPYeMwd0Q+gWWggmLQTbO4eaq5FnNccTdF9IHvRZ12xCtINOprYgY4WONex9zYnv10Pck4+UQKdaOPdNqQYPLVNLSYZ9RQQYjMhneLc9cu5W9mtn/4S4r3G/RtLMvhC42d2vMbOX3d/7H+hw9+8GvhvgU573dL/88oetRsz8DFPakNMGS6q87tfDcOPDAwxXeu866z2JKOLEhB0mrdfPwcUeaA28qQUqKTaNAMxrhnJETONUCi8gITFTnbKDviZVGrXIrYiMNkDyaU2ODzjD8AxawFCUR+uQ9uD21FWF9eZrKcEQBKLXRsuj9n8AaD7Mv0QItsqcDk8qkPrL2lNoyOB7gLjjnA/Bj0OZLm8HoOEIP0ec2r2tG26NdQO3BkghyYMcYOPYcpxQ8zHDm7N0IQ4GzS6FhyaudxgzC7xil2eSndhw0S7UIt8W15oG7c6RgUkRAEdIqQuS0EM30xrpbfWC2soFXi1vVGf3h4itIeR+bgRfO/AEGQZdv5MuWKH7kHqtvpoH534U1PThdmCMexiN8fuWLaKdgxRC0P5G2L73jj3mdn+wAdK4tBGdBPLg8DqR0V3v1UfuUH9keMUDNkVgly+A5LDPp97TYx93SXcViSI3OhynOGYY/a1WI3kPA2jIWRherK9G/OLjgXiSnwV8kZm9EjhCOcnvBK40sxLe5BOB6+P91wNPAq4zAecejgo49zmSFc5MVwKs4VZKYpG4V50A8d4eHFCLxlNaEA4lFqI+RKFNfG8hi3XoUnskkVuENIbLawx8tdqsTlEcjYcYvzmMdApdxzbEE5rCwCEa7JEvG2yc8fB6N+HzvMkTCzvjwcjo6FTuKTw4nNxc/Z0Bt034XFq45oPCqGqmeYQyqwcyduJ+O6kOV/dqKEC4w7ir4lkDEmSOPNhh9Ig5cT+oZEZ3QHrAYtQnaEz5YU5sfC/5rQgxx+GffWVD9B6esbE2J8sHh+Gopg4hg+4BcB45va58Zgsywt7At4N8otOzZmDNUzmIGhge3SgQ+giPtVH38zquY2/YGNjCYXxddFi9aUQ0h0tSSZoLj/L4hNUV1yYfqQhdvsLaEd5fAHU6LIas1xXQpnUuYF2A435HQSr+dh/54chld9+zYLoR/c33H+Dew/tOsc4CxkPMA0hgZni8HvCtCIXvOSxCb3MXQ6L3qIbrvtZrjOs9NPrDaRL1s7NqkY+i2UFa5L7G/RpJd38N8Jq42JcB3+ruX2VmPwp8Kapwfw3wk/ErPxXfvz5+/isXy0fGH2GZ5/V0aZynN7nFyvOxhicjV6ZU5RDuTFKbPgjtaj+cRMN6x/ZrgY7oeVpe0Ys3taBaRYYvusGtNKwxnUFxSyGt1cKTMRe1srXhAeg3eiNC9MgLBv3NLNSiD69rBeVWeTMpPOeQQusGxefVKHR3NrE5WhiufXLd1yWwenQH41CSSko0B9Qui9O/SsC3Gxdq78kOrR56JEPkIaNtu+obptGzaPx+XC+CSPnBZ6r4HV5Ci4OL0Uwq/tX3m8lDGo81/A5jZB08M5Sk1vxtSoKU2IGhidAyHUZfq/EbGed9yG646Jbsjclha2D3ARsLYx7GbBiMvWcTG1wn1AEQ/cKxGl6zCD0PNFStKwQ2XxWExjWs17Ia5XFdoQ0QxvvQSA7DuS8MuVrarj7b3qQ0G+eq1mjiMOIa966/2cUOPfAa+xr2j1s+BM8fMncGiiCtoQkRst/TE94bySF55wf3YitGl/W5HPj79zn+MDjJvwr8kJn9PeC3ge+J178H+Ddm9i7gI8Cr7++D3J2+7NawqXUJnaXUgouswk4fD0WzDF35QByWZX9qaFIGPzdCz1HIAC0sCwxZeD9mGXOiQVQEPn14PiOMHEZBC01ANRheiDIBtoa78dgYa2xsje4hEmAekJkwTIRPFAsnmYdgRhQUIofYo8rdJO9DT3slpOTQ0ggdw7ANZwJWL81cOLnRcK0RUvaIlqgR4qmm/OqImvdrap9bqhEwdzfExlG/oeFlYkbtC7hYLWvI5uH1HzzX2J4Mytm6MQy62j+uwhLuNSrhA7Yizy9F6O1r+D9ogr6v3DJc1kifEO1X495DYYVEVWhmoodKWHwUJ8YGVfrHOTg4ogBicZ9jDaze9PosRnFhbObwsGBfoLJxxkQf7aQDhgDfJ5MYhBkhqrtP5RCG2OLhubcopAekZz2AxpzG743vVwO3LxitUGAb2NNYD86qAi4wvQydjJazplWSDkGP1EGK+05+MD9mF3w5BNd6bzhXEzeiplif2Yz9lvdQ6491AkHjHUb1wEu5l/ExGUl3fx3wuvj3e4AX3st7ToAv+xg/l90yyxy58lnglOyhYRceQrKAwsSkh5QX7itwV8WIhHtdfYC1uZelWMT7DbLCZ8YidS2ifhBWrJ/u4yxOF+RdhokbBrJHI/hKj7yZwLRD6NfxMAoRRhgHCzNOY2eFYPTeL1j0Hp3epMKt1q/J9r/fWg2Yx/7a1v8Pg1MYrJVRSY2Tn+HtjiLDyoNc36dhrEraMkdRu9fmyqCDJzaVeNLya7NpwzUsDgJWH8pioj2KNRfmpaDVUBcfm1nf7dMA6PmnyLe6mmijHLP6rxyCvD3mzsOYpzT6J4m26a7y20iVrCD2dT7G4bY3ZhBr1EeezjA3GY/x84PnPKJbX1k9fb3fES34OtNBxV0xmLEW3Ff84iHdb0RgwysbjJMLxoo28PWAbwOCltKou7D6o7Fhxl/xdR7C3B54dYfzPG7eHcnxxUG6Vs4tIEwjzX2Qk1V/HdvP5/p3x2YZXjIX/P94PgwvMtbn/ufto+BM9xyXBOPGEWx38Fp9PaEV/o6KFyMX0mUgdAKn9aFAGBv39ZhOpOjeFsddJOQZXoTtr2EUB0YYeYGRlFMgAYkISVpIlg1J+DKq8K1Re9c9TSnUgcapWg+MkULRw0W991SHYVOvk1oro8sdJa+HAxYaenFs9i5I0Sg82YFxW8UYAEbF0ve+TV8Xt8DS63LbX45+Hid48gye40Rvkdwf0zq8DvbG2HTA2IAGReg4wtd96DP+7oHXcLheDkKyxPBqfN00Hh6JvO/Y/N4DsmTc4+OAvVJ7lwOyn08XSMtlbhEpUF4QB3+vxGcOj3jNK4eBS0AZ+3kckvuTV5e5hhy63oHpG8pD8qiGZx334mnNefbe6Uu9V0N4OIcXGITVEGlPrQ3SDsLtdZPcxxje2ChnDcM8fnZvIbGOrdW9Vd6YvVHTEXzhtd5zHdzXtQx7YD4O7f2avZ9buddh95cu/OMYZnYXcO2DfR1/xONR3AP29Cdg/Em7pz9p9wOn9/SHGR/v7lff88VLwpMErnX35z/YF/FHOczszaf3dGmPP2n3A6f39N9i3EuC4nScjtNxOk7HGKdG8nScjtNxOi4yLhUj+d0P9gX8Nxin93Tpjz9p9wOn9/RHPi6Jws3pOB2n43RcquNS8SRPx+k4HafjkhwPupE0s1eY2bVm9i4z+2sP9vU80GFm32tmN5vZ2w5ee4SZ/ZKZvTP+e1W8bmb2XXGPbzWz5z14V37vw8yeZGavNbPfN7PfM7Nvjtcfyvd0ZGZvMrPfiXv62/H6J5jZG+Paf9jMNvH6Nr5/V/z8yQ/qDdzHMLNsZr9tZj8T3z/U7+d9Zva7ZvYWM3tzvHbJrLsH1UiayKz/DPh84JnAV5jZMx/Ma/oYxr8GXnGP1/4a8Mvu/jTgl+N70P09Lb6+HuluXmqjAv+Huz8TeBHwjfEsHsr3tANe7u7PBp4DvMLMXsReMPqpwG1IKBoOBKOB74j3XYrjm5EA9hgP9fsB+Bx3f84B1OfSWXf3lCb64/wCXgz84sH3rwFe82Be08d4/U8G3nbw/bXA4+Lfj0P4T4B/BXzFvb3vUv1CgiV/+k/KPQFngd8CPgMBk0u8vq5B4BeBF8e/S7zPHuxrv8d9PBEZjZcDP4M4JA/Z+4lrex/wqHu8dsmsuwc73F4FemMcivc+FMdj3P3G+PeHgMfEvx9S9xlh2XOBN/IQv6cITd8C3Az8EvBuHqBgNHAHEoy+lMY/RgLYQ5XhAQtgc2neD4gx+B/N7BqTGDdcQuvuUmHc/Ikb7u62Skc/dIaZXQ78OPCX3P3Oe3B+H3L35FJnfo6ZXQn8BPCMB/eK/uuH/TcSwL4Exkvc/XozezTwS2b29sMfPtjr7sH2JIdA7xiH4r0PxXGTmT0OIP57c7z+kLhPM5uQgfxBd//38fJD+p7GcPfbgdeicPRKk1gp3LtgNPYABaP/mMcQwH4f0nF9OQcC2PGeh9L9AODu18d/b0YH2Qu5hNbdg20kfxN4WlTnNkh78qce5Gv6w4whOAwfLUT81VGZexFwx0EocUkMk8v4PcAfuPs/OvjRQ/merg4PEjM7g3Ksf4CM5ZfG2+55T+NeH5hg9B/jcPfXuPsT3f3JaK/8irt/FQ/R+wEws8vM7GHj38DnAW/jUlp3l0DS9pXAO1Cu6K8/2NfzMVz3vwNuBBaUF/k6lO/5ZeCdwH8CHhHvNVTFfzfwu8DzH+zrv5f7eQnKDb0VeEt8vfIhfk+fhgSh34o23v8dr38i8CbgXcCPAtt4/Si+f1f8/BMf7Hu4yL29DPiZh/r9xLX/Tnz93rABl9K6O2XcnI7TcTpOx0XGgx1un47TcTpOxyU9To3k6Tgdp+N0XGScGsnTcTpOx+m4yDg1kqfjdJyO03GRcWokT8fpOB2n4yLj1EiejtNxOk7HRcapkTwdp+N0nI6LjFMjeTpOx+k4HRcZ/z9Z24UnRw1BbQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = os.path.join(PROJECT_PATH, 'test_image.jpg')\n",
    "\n",
    "image, keypoints = predict(model, test_image)\n",
    "draw_keypoints_on_image(image, keypoints)\n",
    "draw_skeleton_on_image(image, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647187d",
   "metadata": {},
   "source": [
    "# Simplebaseline 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "61cdd74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 0s 0us/step\n",
      "94781440/94765736 [==============================] - 0s 0us/step\n",
      "Start training...\n",
      "Start epoch 1 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 11.0837221 epoch total loss 11.0837221\n",
      "Trained batch 2 batch loss 10.2619896 epoch total loss 10.6728554\n",
      "Trained batch 3 batch loss 8.03818417 epoch total loss 9.79463196\n",
      "Trained batch 4 batch loss 6.92673635 epoch total loss 9.0776577\n",
      "Trained batch 5 batch loss 7.27583361 epoch total loss 8.71729279\n",
      "Trained batch 6 batch loss 7.65969515 epoch total loss 8.54102612\n",
      "Trained batch 7 batch loss 7.48616 epoch total loss 8.39033127\n",
      "Trained batch 8 batch loss 7.26527309 epoch total loss 8.24969864\n",
      "Trained batch 9 batch loss 6.9141469 epoch total loss 8.10130405\n",
      "Trained batch 10 batch loss 6.7661252 epoch total loss 7.96778631\n",
      "Trained batch 11 batch loss 7.16538477 epoch total loss 7.89484072\n",
      "Trained batch 12 batch loss 6.32687759 epoch total loss 7.76417685\n",
      "Trained batch 13 batch loss 6.45763302 epoch total loss 7.6636734\n",
      "Trained batch 14 batch loss 6.67012787 epoch total loss 7.59270573\n",
      "Trained batch 15 batch loss 6.73187828 epoch total loss 7.53531742\n",
      "Trained batch 16 batch loss 6.59206915 epoch total loss 7.47636461\n",
      "Trained batch 17 batch loss 6.71062613 epoch total loss 7.43132114\n",
      "Trained batch 18 batch loss 6.77716351 epoch total loss 7.394979\n",
      "Trained batch 19 batch loss 6.62572241 epoch total loss 7.35449123\n",
      "Trained batch 20 batch loss 6.65476608 epoch total loss 7.31950521\n",
      "Trained batch 21 batch loss 6.76494551 epoch total loss 7.2930975\n",
      "Trained batch 22 batch loss 6.91454172 epoch total loss 7.27589\n",
      "Trained batch 23 batch loss 6.91718388 epoch total loss 7.26029444\n",
      "Trained batch 24 batch loss 6.98084641 epoch total loss 7.24865103\n",
      "Trained batch 25 batch loss 6.97955751 epoch total loss 7.23788691\n",
      "Trained batch 26 batch loss 6.78417206 epoch total loss 7.22043657\n",
      "Trained batch 27 batch loss 6.62369251 epoch total loss 7.19833469\n",
      "Trained batch 28 batch loss 6.71548843 epoch total loss 7.18109035\n",
      "Trained batch 29 batch loss 6.80754566 epoch total loss 7.16820908\n",
      "Trained batch 30 batch loss 6.77897739 epoch total loss 7.15523481\n",
      "Trained batch 31 batch loss 7.17755365 epoch total loss 7.15595484\n",
      "Trained batch 32 batch loss 6.83460474 epoch total loss 7.14591265\n",
      "Trained batch 33 batch loss 6.90875101 epoch total loss 7.13872576\n",
      "Trained batch 34 batch loss 6.78262138 epoch total loss 7.12825251\n",
      "Trained batch 35 batch loss 6.70578957 epoch total loss 7.11618233\n",
      "Trained batch 36 batch loss 6.50327063 epoch total loss 7.09915686\n",
      "Trained batch 37 batch loss 6.81851673 epoch total loss 7.09157181\n",
      "Trained batch 38 batch loss 6.82090569 epoch total loss 7.08444834\n",
      "Trained batch 39 batch loss 6.47519 epoch total loss 7.06882668\n",
      "Trained batch 40 batch loss 6.65362597 epoch total loss 7.05844641\n",
      "Trained batch 41 batch loss 6.46252632 epoch total loss 7.04391193\n",
      "Trained batch 42 batch loss 6.58618069 epoch total loss 7.03301334\n",
      "Trained batch 43 batch loss 6.55350208 epoch total loss 7.02186203\n",
      "Trained batch 44 batch loss 6.73487139 epoch total loss 7.01533937\n",
      "Trained batch 45 batch loss 6.29161263 epoch total loss 6.99925661\n",
      "Trained batch 46 batch loss 6.62431526 epoch total loss 6.99110603\n",
      "Trained batch 47 batch loss 6.5314393 epoch total loss 6.98132563\n",
      "Trained batch 48 batch loss 6.64207649 epoch total loss 6.97425842\n",
      "Trained batch 49 batch loss 6.51266241 epoch total loss 6.96483803\n",
      "Trained batch 50 batch loss 6.54751492 epoch total loss 6.95649147\n",
      "Trained batch 51 batch loss 6.55272484 epoch total loss 6.94857502\n",
      "Trained batch 52 batch loss 6.29384899 epoch total loss 6.93598413\n",
      "Trained batch 53 batch loss 6.1718688 epoch total loss 6.92156696\n",
      "Trained batch 54 batch loss 6.43181801 epoch total loss 6.91249752\n",
      "Trained batch 55 batch loss 6.33956861 epoch total loss 6.90208054\n",
      "Trained batch 56 batch loss 6.09543037 epoch total loss 6.88767624\n",
      "Trained batch 57 batch loss 5.81491232 epoch total loss 6.86885595\n",
      "Trained batch 58 batch loss 6.60552883 epoch total loss 6.86431551\n",
      "Trained batch 59 batch loss 6.25697231 epoch total loss 6.85402155\n",
      "Trained batch 60 batch loss 6.57223511 epoch total loss 6.84932518\n",
      "Trained batch 61 batch loss 6.68084335 epoch total loss 6.84656334\n",
      "Trained batch 62 batch loss 6.66001511 epoch total loss 6.84355402\n",
      "Trained batch 63 batch loss 6.7056 epoch total loss 6.84136438\n",
      "Trained batch 64 batch loss 5.92455387 epoch total loss 6.82703924\n",
      "Trained batch 65 batch loss 6.30226231 epoch total loss 6.81896591\n",
      "Trained batch 66 batch loss 6.60930252 epoch total loss 6.81578922\n",
      "Trained batch 67 batch loss 6.53062344 epoch total loss 6.81153297\n",
      "Trained batch 68 batch loss 6.0954895 epoch total loss 6.80100298\n",
      "Trained batch 69 batch loss 6.44036341 epoch total loss 6.79577637\n",
      "Trained batch 70 batch loss 5.81670046 epoch total loss 6.78179\n",
      "Trained batch 71 batch loss 6.43907785 epoch total loss 6.77696276\n",
      "Trained batch 72 batch loss 6.11700344 epoch total loss 6.76779699\n",
      "Trained batch 73 batch loss 6.08171225 epoch total loss 6.75839853\n",
      "Trained batch 74 batch loss 6.16174412 epoch total loss 6.75033569\n",
      "Trained batch 75 batch loss 6.26120138 epoch total loss 6.74381399\n",
      "Trained batch 76 batch loss 5.56064939 epoch total loss 6.72824574\n",
      "Trained batch 77 batch loss 5.84943056 epoch total loss 6.71683264\n",
      "Trained batch 78 batch loss 5.79294062 epoch total loss 6.704988\n",
      "Trained batch 79 batch loss 6.4853816 epoch total loss 6.70220804\n",
      "Trained batch 80 batch loss 6.54025459 epoch total loss 6.70018387\n",
      "Trained batch 81 batch loss 6.39921808 epoch total loss 6.69646835\n",
      "Trained batch 82 batch loss 6.4125967 epoch total loss 6.69300652\n",
      "Trained batch 83 batch loss 6.58846521 epoch total loss 6.69174671\n",
      "Trained batch 84 batch loss 6.73865557 epoch total loss 6.69230509\n",
      "Trained batch 85 batch loss 6.8442111 epoch total loss 6.69409275\n",
      "Trained batch 86 batch loss 6.68035507 epoch total loss 6.69393301\n",
      "Trained batch 87 batch loss 7.02910662 epoch total loss 6.69778538\n",
      "Trained batch 88 batch loss 6.75677919 epoch total loss 6.69845581\n",
      "Trained batch 89 batch loss 6.64054823 epoch total loss 6.6978054\n",
      "Trained batch 90 batch loss 6.7514863 epoch total loss 6.69840145\n",
      "Trained batch 91 batch loss 6.67700481 epoch total loss 6.69816637\n",
      "Trained batch 92 batch loss 6.45361185 epoch total loss 6.695508\n",
      "Trained batch 93 batch loss 6.5445857 epoch total loss 6.69388485\n",
      "Trained batch 94 batch loss 6.51544046 epoch total loss 6.69198656\n",
      "Trained batch 95 batch loss 6.80456877 epoch total loss 6.69317198\n",
      "Trained batch 96 batch loss 6.56786537 epoch total loss 6.6918664\n",
      "Trained batch 97 batch loss 6.38480806 epoch total loss 6.68870115\n",
      "Trained batch 98 batch loss 6.41046333 epoch total loss 6.68586206\n",
      "Trained batch 99 batch loss 6.60557365 epoch total loss 6.68505096\n",
      "Trained batch 100 batch loss 6.53038788 epoch total loss 6.68350458\n",
      "Trained batch 101 batch loss 6.70514822 epoch total loss 6.68371868\n",
      "Trained batch 102 batch loss 6.46936798 epoch total loss 6.68161726\n",
      "Trained batch 103 batch loss 6.56277752 epoch total loss 6.68046379\n",
      "Trained batch 104 batch loss 6.35197 epoch total loss 6.67730522\n",
      "Trained batch 105 batch loss 6.36423111 epoch total loss 6.67432404\n",
      "Trained batch 106 batch loss 6.07034683 epoch total loss 6.66862631\n",
      "Trained batch 107 batch loss 6.00704527 epoch total loss 6.66244316\n",
      "Trained batch 108 batch loss 5.93252707 epoch total loss 6.65568495\n",
      "Trained batch 109 batch loss 6.41789865 epoch total loss 6.65350342\n",
      "Trained batch 110 batch loss 6.30915546 epoch total loss 6.65037298\n",
      "Trained batch 111 batch loss 7.03992605 epoch total loss 6.6538825\n",
      "Trained batch 112 batch loss 7.37635326 epoch total loss 6.66033268\n",
      "Trained batch 113 batch loss 7.18969154 epoch total loss 6.6650176\n",
      "Trained batch 114 batch loss 6.62151384 epoch total loss 6.66463614\n",
      "Trained batch 115 batch loss 6.62031317 epoch total loss 6.66425037\n",
      "Trained batch 116 batch loss 6.28435516 epoch total loss 6.66097546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 117 batch loss 6.40609074 epoch total loss 6.65879679\n",
      "Trained batch 118 batch loss 7.08279562 epoch total loss 6.66239\n",
      "Trained batch 119 batch loss 6.87858534 epoch total loss 6.66420698\n",
      "Trained batch 120 batch loss 6.670403 epoch total loss 6.66425896\n",
      "Trained batch 121 batch loss 6.60525274 epoch total loss 6.66377115\n",
      "Trained batch 122 batch loss 6.77004337 epoch total loss 6.66464186\n",
      "Trained batch 123 batch loss 6.66653538 epoch total loss 6.66465759\n",
      "Trained batch 124 batch loss 6.87431479 epoch total loss 6.66634846\n",
      "Trained batch 125 batch loss 7.02480602 epoch total loss 6.66921568\n",
      "Trained batch 126 batch loss 6.92912292 epoch total loss 6.67127848\n",
      "Trained batch 127 batch loss 6.68113613 epoch total loss 6.67135668\n",
      "Trained batch 128 batch loss 6.58580923 epoch total loss 6.67068815\n",
      "Trained batch 129 batch loss 6.90104246 epoch total loss 6.67247391\n",
      "Trained batch 130 batch loss 6.88015413 epoch total loss 6.67407131\n",
      "Trained batch 131 batch loss 6.44571733 epoch total loss 6.67232847\n",
      "Trained batch 132 batch loss 6.62059212 epoch total loss 6.67193651\n",
      "Trained batch 133 batch loss 6.67326689 epoch total loss 6.67194653\n",
      "Trained batch 134 batch loss 6.49257946 epoch total loss 6.67060804\n",
      "Trained batch 135 batch loss 6.51090765 epoch total loss 6.66942501\n",
      "Trained batch 136 batch loss 6.28292608 epoch total loss 6.66658306\n",
      "Trained batch 137 batch loss 6.40728378 epoch total loss 6.66469\n",
      "Trained batch 138 batch loss 5.80316 epoch total loss 6.65844727\n",
      "Trained batch 139 batch loss 5.4757762 epoch total loss 6.64993858\n",
      "Trained batch 140 batch loss 5.59408951 epoch total loss 6.6423974\n",
      "Trained batch 141 batch loss 6.00712872 epoch total loss 6.63789177\n",
      "Trained batch 142 batch loss 6.36427212 epoch total loss 6.63596487\n",
      "Trained batch 143 batch loss 6.71534586 epoch total loss 6.63652\n",
      "Trained batch 144 batch loss 6.29104328 epoch total loss 6.63412046\n",
      "Trained batch 145 batch loss 6.2038064 epoch total loss 6.63115263\n",
      "Trained batch 146 batch loss 6.60400963 epoch total loss 6.63096666\n",
      "Trained batch 147 batch loss 6.17687464 epoch total loss 6.62787771\n",
      "Trained batch 148 batch loss 5.95905828 epoch total loss 6.62335873\n",
      "Trained batch 149 batch loss 6.10488892 epoch total loss 6.61987877\n",
      "Trained batch 150 batch loss 6.08066654 epoch total loss 6.61628437\n",
      "Trained batch 151 batch loss 6.23765898 epoch total loss 6.61377668\n",
      "Trained batch 168 batch loss 6.75320339 epoch total loss 6.59559727\n",
      "Trained batch 169 batch loss 6.59193563 epoch total loss 6.59557533\n",
      "Trained batch 170 batch loss 6.76551771 epoch total loss 6.59657478\n",
      "Trained batch 171 batch loss 6.49369144 epoch total loss 6.59597301\n",
      "Trained batch 172 batch loss 6.12505817 epoch total loss 6.59323454\n",
      "Trained batch 173 batch loss 6.12057972 epoch total loss 6.59050274\n",
      "Trained batch 174 batch loss 6.40660095 epoch total loss 6.58944607\n",
      "Trained batch 175 batch loss 6.5098505 epoch total loss 6.58899117\n",
      "Trained batch 176 batch loss 6.15059042 epoch total loss 6.58650064\n",
      "Trained batch 177 batch loss 6.34046936 epoch total loss 6.58511066\n",
      "Trained batch 178 batch loss 6.58737278 epoch total loss 6.58512354\n",
      "Trained batch 179 batch loss 6.57328463 epoch total loss 6.58505726\n",
      "Trained batch 180 batch loss 6.20588255 epoch total loss 6.58295107\n",
      "Trained batch 181 batch loss 6.62342215 epoch total loss 6.58317423\n",
      "Trained batch 182 batch loss 6.21604967 epoch total loss 6.58115721\n",
      "Trained batch 183 batch loss 6.15296268 epoch total loss 6.57881737\n",
      "Trained batch 184 batch loss 6.38032722 epoch total loss 6.57773876\n",
      "Trained batch 185 batch loss 6.67820454 epoch total loss 6.57828188\n",
      "Trained batch 186 batch loss 6.72770214 epoch total loss 6.57908535\n",
      "Trained batch 187 batch loss 6.95755148 epoch total loss 6.58110905\n",
      "Trained batch 188 batch loss 6.91886663 epoch total loss 6.58290529\n",
      "Trained batch 189 batch loss 7.00787544 epoch total loss 6.58515406\n",
      "Trained batch 190 batch loss 7.09785223 epoch total loss 6.58785295\n",
      "Trained batch 191 batch loss 6.15160894 epoch total loss 6.5855689\n",
      "Trained batch 192 batch loss 5.66930723 epoch total loss 6.58079672\n",
      "Trained batch 193 batch loss 5.48139429 epoch total loss 6.57510042\n",
      "Trained batch 194 batch loss 5.49595499 epoch total loss 6.56953812\n",
      "Trained batch 195 batch loss 5.62482548 epoch total loss 6.56469345\n",
      "Trained batch 196 batch loss 6.27081966 epoch total loss 6.56319427\n",
      "Trained batch 197 batch loss 6.02907658 epoch total loss 6.56048298\n",
      "Trained batch 198 batch loss 6.55060387 epoch total loss 6.56043339\n",
      "Trained batch 199 batch loss 6.27817631 epoch total loss 6.55901527\n",
      "Trained batch 200 batch loss 6.20154476 epoch total loss 6.55722761\n",
      "Trained batch 201 batch loss 6.15898371 epoch total loss 6.55524635\n",
      "Trained batch 202 batch loss 6.38280869 epoch total loss 6.55439281\n",
      "Trained batch 203 batch loss 5.82177639 epoch total loss 6.55078363\n",
      "Trained batch 204 batch loss 6.09077835 epoch total loss 6.54852915\n",
      "Trained batch 205 batch loss 5.90005 epoch total loss 6.54536533\n",
      "Trained batch 206 batch loss 6.28733921 epoch total loss 6.54411316\n",
      "Trained batch 207 batch loss 6.39861441 epoch total loss 6.54341\n",
      "Trained batch 208 batch loss 6.54046392 epoch total loss 6.54339552\n",
      "Trained batch 209 batch loss 6.41583252 epoch total loss 6.54278517\n",
      "Trained batch 210 batch loss 6.28274632 epoch total loss 6.54154682\n",
      "Trained batch 211 batch loss 6.22985315 epoch total loss 6.54006958\n",
      "Trained batch 212 batch loss 6.48237514 epoch total loss 6.53979778\n",
      "Trained batch 213 batch loss 6.68720293 epoch total loss 6.54049\n",
      "Trained batch 214 batch loss 6.12164593 epoch total loss 6.53853321\n",
      "Trained batch 215 batch loss 6.26753521 epoch total loss 6.53727293\n",
      "Trained batch 216 batch loss 6.45746946 epoch total loss 6.53690386\n",
      "Trained batch 217 batch loss 6.20214939 epoch total loss 6.53536081\n",
      "Trained batch 218 batch loss 6.31786346 epoch total loss 6.53436327\n",
      "Trained batch 219 batch loss 6.72201157 epoch total loss 6.53522\n",
      "Trained batch 220 batch loss 6.56367064 epoch total loss 6.53535\n",
      "Trained batch 221 batch loss 6.755198 epoch total loss 6.53634501\n",
      "Trained batch 222 batch loss 6.80212927 epoch total loss 6.53754234\n",
      "Trained batch 223 batch loss 6.74938583 epoch total loss 6.5384922\n",
      "Trained batch 224 batch loss 6.53520679 epoch total loss 6.53847742\n",
      "Trained batch 225 batch loss 6.67669 epoch total loss 6.53909111\n",
      "Trained batch 226 batch loss 6.62965822 epoch total loss 6.53949213\n",
      "Trained batch 227 batch loss 6.72967672 epoch total loss 6.54033\n",
      "Trained batch 228 batch loss 6.78113604 epoch total loss 6.54138613\n",
      "Trained batch 229 batch loss 6.51627398 epoch total loss 6.54127645\n",
      "Trained batch 230 batch loss 6.82962704 epoch total loss 6.54253\n",
      "Trained batch 231 batch loss 6.78537512 epoch total loss 6.54358101\n",
      "Trained batch 232 batch loss 6.54537058 epoch total loss 6.54358912\n",
      "Trained batch 233 batch loss 6.80162191 epoch total loss 6.54469681\n",
      "Trained batch 234 batch loss 6.11553669 epoch total loss 6.54286242\n",
      "Trained batch 235 batch loss 6.69910431 epoch total loss 6.54352713\n",
      "Trained batch 236 batch loss 6.85667849 epoch total loss 6.54485416\n",
      "Trained batch 237 batch loss 5.77351427 epoch total loss 6.54159975\n",
      "Trained batch 238 batch loss 5.67362452 epoch total loss 6.53795242\n",
      "Trained batch 239 batch loss 5.57674885 epoch total loss 6.53393078\n",
      "Trained batch 240 batch loss 5.59970236 epoch total loss 6.53003836\n",
      "Trained batch 241 batch loss 5.97779703 epoch total loss 6.52774715\n",
      "Trained batch 242 batch loss 6.71154308 epoch total loss 6.52850628\n",
      "Trained batch 243 batch loss 6.55724621 epoch total loss 6.52862453\n",
      "Trained batch 244 batch loss 6.78407812 epoch total loss 6.52967167\n",
      "Trained batch 245 batch loss 6.36735916 epoch total loss 6.52900887\n",
      "Trained batch 246 batch loss 5.87147236 epoch total loss 6.52633572\n",
      "Trained batch 247 batch loss 6.03613043 epoch total loss 6.52435112\n",
      "Trained batch 248 batch loss 6.55512953 epoch total loss 6.52447557\n",
      "Trained batch 249 batch loss 6.70709753 epoch total loss 6.52520943\n",
      "Trained batch 250 batch loss 6.53558064 epoch total loss 6.52525043\n",
      "Trained batch 251 batch loss 6.19170761 epoch total loss 6.52392149\n",
      "Trained batch 252 batch loss 6.33422 epoch total loss 6.52316856\n",
      "Trained batch 253 batch loss 6.6171174 epoch total loss 6.52354\n",
      "Trained batch 254 batch loss 6.55625534 epoch total loss 6.52366877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 255 batch loss 6.70253563 epoch total loss 6.52437\n",
      "Trained batch 256 batch loss 6.60681534 epoch total loss 6.52469206\n",
      "Trained batch 257 batch loss 6.53730822 epoch total loss 6.52474117\n",
      "Trained batch 258 batch loss 6.4028 epoch total loss 6.52426863\n",
      "Trained batch 259 batch loss 6.30128336 epoch total loss 6.52340794\n",
      "Trained batch 260 batch loss 6.22302723 epoch total loss 6.52225256\n",
      "Trained batch 261 batch loss 6.48902 epoch total loss 6.52212524\n",
      "Trained batch 262 batch loss 6.44436884 epoch total loss 6.52182817\n",
      "Trained batch 263 batch loss 5.55496073 epoch total loss 6.51815176\n",
      "Trained batch 264 batch loss 5.77549601 epoch total loss 6.5153389\n",
      "Trained batch 265 batch loss 5.95062304 epoch total loss 6.51320791\n",
      "Trained batch 266 batch loss 6.27185774 epoch total loss 6.51230049\n",
      "Trained batch 267 batch loss 6.01748133 epoch total loss 6.5104475\n",
      "Trained batch 268 batch loss 6.80475473 epoch total loss 6.51154566\n",
      "Trained batch 269 batch loss 6.11484909 epoch total loss 6.5100708\n",
      "Trained batch 270 batch loss 6.08797741 epoch total loss 6.50850773\n",
      "Trained batch 271 batch loss 6.28022623 epoch total loss 6.50766563\n",
      "Trained batch 272 batch loss 6.49874163 epoch total loss 6.50763321\n",
      "Trained batch 273 batch loss 6.59372282 epoch total loss 6.5079484\n",
      "Trained batch 274 batch loss 6.76161528 epoch total loss 6.50887394\n",
      "Trained batch 275 batch loss 6.18715715 epoch total loss 6.50770426\n",
      "Trained batch 276 batch loss 4.91728067 epoch total loss 6.50194168\n",
      "Trained batch 277 batch loss 4.77428961 epoch total loss 6.49570465\n",
      "Trained batch 278 batch loss 6.43846655 epoch total loss 6.49549866\n",
      "Trained batch 279 batch loss 6.85669041 epoch total loss 6.49679327\n",
      "Trained batch 280 batch loss 7.18258047 epoch total loss 6.49924278\n",
      "Trained batch 281 batch loss 7.15309858 epoch total loss 6.50156975\n",
      "Trained batch 282 batch loss 6.5382328 epoch total loss 6.50169945\n",
      "Trained batch 283 batch loss 6.61092329 epoch total loss 6.50208569\n",
      "Trained batch 284 batch loss 6.40232754 epoch total loss 6.50173426\n",
      "Trained batch 285 batch loss 6.83462715 epoch total loss 6.50290251\n",
      "Trained batch 286 batch loss 7.39982414 epoch total loss 6.50603819\n",
      "Trained batch 287 batch loss 7.20156 epoch total loss 6.50846148\n",
      "Trained batch 288 batch loss 7.23988485 epoch total loss 6.51100111\n",
      "Trained batch 289 batch loss 6.70099401 epoch total loss 6.51165867\n",
      "Trained batch 290 batch loss 6.86185551 epoch total loss 6.51286602\n",
      "Trained batch 291 batch loss 5.98363066 epoch total loss 6.51104736\n",
      "Trained batch 292 batch loss 6.12354803 epoch total loss 6.50972033\n",
      "Trained batch 293 batch loss 6.49788094 epoch total loss 6.50968027\n",
      "Trained batch 294 batch loss 6.9849782 epoch total loss 6.51129675\n",
      "Trained batch 295 batch loss 6.29532862 epoch total loss 6.5105648\n",
      "Trained batch 296 batch loss 6.50800753 epoch total loss 6.51055622\n",
      "Trained batch 297 batch loss 6.12517357 epoch total loss 6.50925827\n",
      "Trained batch 298 batch loss 6.51078129 epoch total loss 6.50926352\n",
      "Trained batch 299 batch loss 6.37214947 epoch total loss 6.5088048\n",
      "Trained batch 300 batch loss 6.14993 epoch total loss 6.50760841\n",
      "Trained batch 301 batch loss 6.35952663 epoch total loss 6.50711679\n",
      "Trained batch 302 batch loss 6.09948444 epoch total loss 6.50576687\n",
      "Trained batch 303 batch loss 6.67997503 epoch total loss 6.50634146\n",
      "Trained batch 304 batch loss 6.44275045 epoch total loss 6.5061326\n",
      "Trained batch 305 batch loss 6.50032091 epoch total loss 6.50611353\n",
      "Trained batch 306 batch loss 5.97666168 epoch total loss 6.50438356\n",
      "Trained batch 307 batch loss 6.59205627 epoch total loss 6.50466871\n",
      "Trained batch 308 batch loss 6.38974094 epoch total loss 6.50429583\n",
      "Trained batch 309 batch loss 5.83469677 epoch total loss 6.50212908\n",
      "Trained batch 310 batch loss 6.33692408 epoch total loss 6.50159597\n",
      "Trained batch 311 batch loss 6.1297946 epoch total loss 6.50040054\n",
      "Trained batch 312 batch loss 6.60597706 epoch total loss 6.50073862\n",
      "Trained batch 313 batch loss 6.73940182 epoch total loss 6.50150108\n",
      "Trained batch 314 batch loss 6.63556194 epoch total loss 6.50192833\n",
      "Trained batch 315 batch loss 6.40338898 epoch total loss 6.50161505\n",
      "Trained batch 316 batch loss 6.4778986 epoch total loss 6.50153971\n",
      "Trained batch 317 batch loss 6.46071291 epoch total loss 6.50141096\n",
      "Trained batch 318 batch loss 6.04989624 epoch total loss 6.49999094\n",
      "Trained batch 319 batch loss 6.42617798 epoch total loss 6.49975967\n",
      "Trained batch 320 batch loss 6.28113461 epoch total loss 6.49907684\n",
      "Trained batch 321 batch loss 6.278687 epoch total loss 6.49839067\n",
      "Trained batch 322 batch loss 6.31439447 epoch total loss 6.49781942\n",
      "Trained batch 323 batch loss 6.48964453 epoch total loss 6.49779463\n",
      "Trained batch 324 batch loss 6.31647158 epoch total loss 6.49723434\n",
      "Trained batch 325 batch loss 6.03504372 epoch total loss 6.49581289\n",
      "Trained batch 326 batch loss 6.00748444 epoch total loss 6.49431515\n",
      "Trained batch 327 batch loss 6.36710548 epoch total loss 6.49392653\n",
      "Trained batch 328 batch loss 6.48574066 epoch total loss 6.49390173\n",
      "Trained batch 329 batch loss 6.62568474 epoch total loss 6.49430227\n",
      "Trained batch 330 batch loss 6.90604782 epoch total loss 6.49555\n",
      "Trained batch 331 batch loss 6.59463358 epoch total loss 6.49584961\n",
      "Trained batch 332 batch loss 6.52196598 epoch total loss 6.49592829\n",
      "Trained batch 333 batch loss 6.12554407 epoch total loss 6.49481583\n",
      "Trained batch 334 batch loss 6.2464 epoch total loss 6.49407196\n",
      "Trained batch 335 batch loss 6.28698587 epoch total loss 6.4934535\n",
      "Trained batch 336 batch loss 6.49219084 epoch total loss 6.49344969\n",
      "Trained batch 337 batch loss 6.74703455 epoch total loss 6.49420214\n",
      "Trained batch 338 batch loss 6.61687756 epoch total loss 6.49456549\n",
      "Trained batch 339 batch loss 7.05768 epoch total loss 6.49622631\n",
      "Trained batch 340 batch loss 6.83162785 epoch total loss 6.49721241\n",
      "Trained batch 341 batch loss 7.08234787 epoch total loss 6.49892807\n",
      "Trained batch 342 batch loss 6.99588346 epoch total loss 6.50038099\n",
      "Trained batch 343 batch loss 7.18990135 epoch total loss 6.50239182\n",
      "Trained batch 344 batch loss 6.92105055 epoch total loss 6.5036087\n",
      "Trained batch 345 batch loss 7.00042534 epoch total loss 6.50504923\n",
      "Trained batch 346 batch loss 6.41624641 epoch total loss 6.50479269\n",
      "Trained batch 347 batch loss 6.21434546 epoch total loss 6.50395536\n",
      "Trained batch 348 batch loss 6.54445648 epoch total loss 6.50407171\n",
      "Trained batch 349 batch loss 6.08333731 epoch total loss 6.50286579\n",
      "Trained batch 350 batch loss 6.16603422 epoch total loss 6.50190353\n",
      "Trained batch 351 batch loss 5.86452436 epoch total loss 6.50008774\n",
      "Trained batch 352 batch loss 5.90448952 epoch total loss 6.49839592\n",
      "Trained batch 353 batch loss 6.07199526 epoch total loss 6.49718809\n",
      "Trained batch 354 batch loss 5.70050335 epoch total loss 6.49493742\n",
      "Trained batch 355 batch loss 6.29254103 epoch total loss 6.49436712\n",
      "Trained batch 356 batch loss 6.49757767 epoch total loss 6.49437571\n",
      "Trained batch 357 batch loss 6.86526 epoch total loss 6.49541473\n",
      "Trained batch 358 batch loss 6.61122131 epoch total loss 6.49573851\n",
      "Trained batch 359 batch loss 6.46214485 epoch total loss 6.49564505\n",
      "Trained batch 360 batch loss 6.43039608 epoch total loss 6.49546385\n",
      "Trained batch 361 batch loss 6.36104965 epoch total loss 6.49509144\n",
      "Trained batch 362 batch loss 5.67791796 epoch total loss 6.49283409\n",
      "Trained batch 363 batch loss 5.80260468 epoch total loss 6.49093246\n",
      "Trained batch 364 batch loss 6.62117 epoch total loss 6.49129\n",
      "Trained batch 365 batch loss 6.63821554 epoch total loss 6.49169254\n",
      "Trained batch 366 batch loss 6.44836092 epoch total loss 6.49157381\n",
      "Trained batch 367 batch loss 6.61373806 epoch total loss 6.49190664\n",
      "Trained batch 368 batch loss 6.42229033 epoch total loss 6.49171782\n",
      "Trained batch 369 batch loss 6.66201735 epoch total loss 6.49217939\n",
      "Trained batch 370 batch loss 6.74913359 epoch total loss 6.49287367\n",
      "Trained batch 371 batch loss 6.7496357 epoch total loss 6.49356604\n",
      "Trained batch 372 batch loss 6.46320677 epoch total loss 6.4934845\n",
      "Trained batch 373 batch loss 6.93479824 epoch total loss 6.49466753\n",
      "Trained batch 374 batch loss 6.88064861 epoch total loss 6.49569941\n",
      "Trained batch 375 batch loss 6.6427145 epoch total loss 6.49609184\n",
      "Trained batch 376 batch loss 6.12641573 epoch total loss 6.4951086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 377 batch loss 6.15356112 epoch total loss 6.49420261\n",
      "Trained batch 378 batch loss 5.84569597 epoch total loss 6.49248695\n",
      "Trained batch 379 batch loss 5.74683142 epoch total loss 6.49051952\n",
      "Trained batch 380 batch loss 6.22907877 epoch total loss 6.48983145\n",
      "Trained batch 381 batch loss 5.44489431 epoch total loss 6.48708868\n",
      "Trained batch 382 batch loss 5.52482 epoch total loss 6.48457\n",
      "Trained batch 383 batch loss 5.28752279 epoch total loss 6.48144484\n",
      "Trained batch 384 batch loss 5.37592077 epoch total loss 6.47856569\n",
      "Trained batch 385 batch loss 5.93960285 epoch total loss 6.47716618\n",
      "Trained batch 386 batch loss 6.32498312 epoch total loss 6.47677183\n",
      "Trained batch 387 batch loss 6.53242064 epoch total loss 6.47691584\n",
      "Trained batch 388 batch loss 6.53237915 epoch total loss 6.47705889\n",
      "Trained batch 389 batch loss 7.07929039 epoch total loss 6.47860718\n",
      "Trained batch 390 batch loss 6.81141329 epoch total loss 6.47946072\n",
      "Trained batch 391 batch loss 6.5287571 epoch total loss 6.47958708\n",
      "Trained batch 392 batch loss 6.37154865 epoch total loss 6.47931147\n",
      "Trained batch 393 batch loss 5.735 epoch total loss 6.47741795\n",
      "Trained batch 394 batch loss 6.24457169 epoch total loss 6.47682714\n",
      "Trained batch 395 batch loss 6.43930197 epoch total loss 6.47673178\n",
      "Trained batch 396 batch loss 5.71904802 epoch total loss 6.47481823\n",
      "Trained batch 397 batch loss 5.75093222 epoch total loss 6.47299528\n",
      "Trained batch 398 batch loss 5.87261581 epoch total loss 6.47148657\n",
      "Trained batch 399 batch loss 5.86005783 epoch total loss 6.46995401\n",
      "Trained batch 400 batch loss 6.38691235 epoch total loss 6.46974659\n",
      "Trained batch 401 batch loss 6.60061502 epoch total loss 6.47007322\n",
      "Trained batch 402 batch loss 6.54586172 epoch total loss 6.47026157\n",
      "Trained batch 403 batch loss 6.2864666 epoch total loss 6.46980524\n",
      "Trained batch 404 batch loss 6.06501961 epoch total loss 6.46880341\n",
      "Trained batch 405 batch loss 6.15272522 epoch total loss 6.46802282\n",
      "Trained batch 406 batch loss 6.46720648 epoch total loss 6.46802139\n",
      "Trained batch 407 batch loss 6.29766464 epoch total loss 6.46760225\n",
      "Trained batch 408 batch loss 6.26956701 epoch total loss 6.46711683\n",
      "Trained batch 409 batch loss 6.29595757 epoch total loss 6.46669817\n",
      "Trained batch 410 batch loss 6.44470453 epoch total loss 6.46664524\n",
      "Trained batch 411 batch loss 6.33616686 epoch total loss 6.46632767\n",
      "Trained batch 412 batch loss 6.57006454 epoch total loss 6.46657944\n",
      "Trained batch 413 batch loss 6.62500429 epoch total loss 6.46696281\n",
      "Trained batch 414 batch loss 6.04307 epoch total loss 6.46593904\n",
      "Trained batch 415 batch loss 6.55293798 epoch total loss 6.46614838\n",
      "Trained batch 416 batch loss 6.03923 epoch total loss 6.4651227\n",
      "Trained batch 417 batch loss 5.97169256 epoch total loss 6.46393919\n",
      "Trained batch 418 batch loss 6.30382729 epoch total loss 6.46355581\n",
      "Trained batch 419 batch loss 6.72970152 epoch total loss 6.46419096\n",
      "Trained batch 420 batch loss 6.50572109 epoch total loss 6.46428967\n",
      "Trained batch 421 batch loss 6.61167526 epoch total loss 6.46463966\n",
      "Trained batch 422 batch loss 6.27515554 epoch total loss 6.46419048\n",
      "Trained batch 423 batch loss 6.07823133 epoch total loss 6.46327782\n",
      "Trained batch 424 batch loss 6.55439 epoch total loss 6.46349287\n",
      "Trained batch 425 batch loss 6.13750792 epoch total loss 6.46272564\n",
      "Trained batch 426 batch loss 6.15377617 epoch total loss 6.46200037\n",
      "Trained batch 427 batch loss 6.24673843 epoch total loss 6.46149683\n",
      "Trained batch 428 batch loss 6.54484844 epoch total loss 6.46169138\n",
      "Trained batch 429 batch loss 6.82463 epoch total loss 6.46253777\n",
      "Trained batch 430 batch loss 6.99750376 epoch total loss 6.46378183\n",
      "Trained batch 431 batch loss 7.12232494 epoch total loss 6.46531\n",
      "Trained batch 432 batch loss 6.90313673 epoch total loss 6.46632338\n",
      "Trained batch 433 batch loss 6.42551 epoch total loss 6.46622896\n",
      "Trained batch 434 batch loss 6.11562204 epoch total loss 6.46542168\n",
      "Trained batch 435 batch loss 6.25575256 epoch total loss 6.46493959\n",
      "Trained batch 436 batch loss 6.33927822 epoch total loss 6.46465158\n",
      "Trained batch 437 batch loss 6.43524 epoch total loss 6.46458435\n",
      "Trained batch 438 batch loss 6.64681911 epoch total loss 6.465\n",
      "Trained batch 439 batch loss 6.67947817 epoch total loss 6.46548891\n",
      "Trained batch 440 batch loss 6.5378747 epoch total loss 6.46565342\n",
      "Trained batch 441 batch loss 6.54202795 epoch total loss 6.46582651\n",
      "Trained batch 442 batch loss 6.36699295 epoch total loss 6.46560287\n",
      "Trained batch 443 batch loss 6.48029232 epoch total loss 6.46563578\n",
      "Trained batch 444 batch loss 6.77312183 epoch total loss 6.46632862\n",
      "Trained batch 445 batch loss 6.46254539 epoch total loss 6.46632\n",
      "Trained batch 446 batch loss 6.41700697 epoch total loss 6.46620941\n",
      "Trained batch 447 batch loss 6.42405081 epoch total loss 6.46611547\n",
      "Trained batch 448 batch loss 6.36643887 epoch total loss 6.46589279\n",
      "Trained batch 449 batch loss 5.96938 epoch total loss 6.46478701\n",
      "Trained batch 450 batch loss 5.90231085 epoch total loss 6.46353722\n",
      "Trained batch 451 batch loss 6.36292934 epoch total loss 6.46331453\n",
      "Trained batch 452 batch loss 6.499259 epoch total loss 6.46339417\n",
      "Trained batch 453 batch loss 6.66890621 epoch total loss 6.46384764\n",
      "Trained batch 454 batch loss 6.19408798 epoch total loss 6.4632535\n",
      "Trained batch 455 batch loss 6.33380318 epoch total loss 6.46296883\n",
      "Trained batch 456 batch loss 7.00495911 epoch total loss 6.46415758\n",
      "Trained batch 457 batch loss 6.85985184 epoch total loss 6.46502304\n",
      "Trained batch 458 batch loss 6.6017313 epoch total loss 6.46532202\n",
      "Trained batch 459 batch loss 6.68930387 epoch total loss 6.46581\n",
      "Trained batch 460 batch loss 6.79421759 epoch total loss 6.46652365\n",
      "Trained batch 461 batch loss 6.24961233 epoch total loss 6.46605301\n",
      "Trained batch 462 batch loss 6.43639374 epoch total loss 6.46598816\n",
      "Trained batch 463 batch loss 6.45978737 epoch total loss 6.46597481\n",
      "Trained batch 464 batch loss 6.62544 epoch total loss 6.46631861\n",
      "Trained batch 465 batch loss 6.36944294 epoch total loss 6.46611\n",
      "Trained batch 466 batch loss 6.36718464 epoch total loss 6.46589804\n",
      "Trained batch 467 batch loss 6.46849489 epoch total loss 6.46590328\n",
      "Trained batch 468 batch loss 6.56773567 epoch total loss 6.46612072\n",
      "Trained batch 469 batch loss 6.488585 epoch total loss 6.4661684\n",
      "Trained batch 470 batch loss 6.73180342 epoch total loss 6.46673346\n",
      "Trained batch 471 batch loss 6.62829494 epoch total loss 6.4670763\n",
      "Trained batch 472 batch loss 6.42741346 epoch total loss 6.46699238\n",
      "Trained batch 473 batch loss 6.416924 epoch total loss 6.46688652\n",
      "Trained batch 474 batch loss 6.29932833 epoch total loss 6.46653318\n",
      "Trained batch 475 batch loss 6.06672478 epoch total loss 6.46569109\n",
      "Trained batch 476 batch loss 6.24446917 epoch total loss 6.46522617\n",
      "Trained batch 477 batch loss 6.06564045 epoch total loss 6.46438885\n",
      "Trained batch 478 batch loss 5.61189365 epoch total loss 6.462605\n",
      "Trained batch 479 batch loss 5.87317228 epoch total loss 6.46137476\n",
      "Trained batch 480 batch loss 6.26338768 epoch total loss 6.4609623\n",
      "Trained batch 481 batch loss 6.39821243 epoch total loss 6.46083212\n",
      "Trained batch 482 batch loss 6.76301479 epoch total loss 6.46145868\n",
      "Trained batch 483 batch loss 6.46811247 epoch total loss 6.46147251\n",
      "Trained batch 484 batch loss 6.92085409 epoch total loss 6.46242142\n",
      "Trained batch 485 batch loss 6.75143528 epoch total loss 6.46301746\n",
      "Trained batch 486 batch loss 6.69515657 epoch total loss 6.46349478\n",
      "Trained batch 487 batch loss 6.74233198 epoch total loss 6.46406794\n",
      "Trained batch 488 batch loss 6.84309673 epoch total loss 6.46484423\n",
      "Trained batch 489 batch loss 6.85370827 epoch total loss 6.46563959\n",
      "Trained batch 490 batch loss 6.48750448 epoch total loss 6.46568441\n",
      "Trained batch 491 batch loss 6.39177847 epoch total loss 6.46553373\n",
      "Trained batch 492 batch loss 5.67390728 epoch total loss 6.46392488\n",
      "Trained batch 493 batch loss 5.98075294 epoch total loss 6.46294451\n",
      "Trained batch 494 batch loss 6.38559628 epoch total loss 6.46278763\n",
      "Trained batch 495 batch loss 6.65144062 epoch total loss 6.46316862\n",
      "Trained batch 496 batch loss 6.21369743 epoch total loss 6.46266556\n",
      "Trained batch 497 batch loss 6.58956432 epoch total loss 6.46292114\n",
      "Trained batch 498 batch loss 6.25392675 epoch total loss 6.46250153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 499 batch loss 5.91659164 epoch total loss 6.46140718\n",
      "Trained batch 500 batch loss 6.50949955 epoch total loss 6.46150351\n",
      "Trained batch 501 batch loss 6.75690937 epoch total loss 6.46209288\n",
      "Trained batch 502 batch loss 6.67477083 epoch total loss 6.46251678\n",
      "Trained batch 503 batch loss 6.48184633 epoch total loss 6.46255541\n",
      "Trained batch 504 batch loss 6.5958724 epoch total loss 6.46282\n",
      "Trained batch 505 batch loss 6.63534546 epoch total loss 6.46316147\n",
      "Trained batch 506 batch loss 6.68211842 epoch total loss 6.46359396\n",
      "Trained batch 507 batch loss 6.835989 epoch total loss 6.46432829\n",
      "Trained batch 508 batch loss 6.70372725 epoch total loss 6.4647994\n",
      "Trained batch 509 batch loss 6.42549562 epoch total loss 6.46472263\n",
      "Trained batch 510 batch loss 6.59543371 epoch total loss 6.46497869\n",
      "Trained batch 511 batch loss 6.56795263 epoch total loss 6.46518\n",
      "Trained batch 512 batch loss 6.49838 epoch total loss 6.46524477\n",
      "Trained batch 513 batch loss 6.35088682 epoch total loss 6.46502161\n",
      "Trained batch 514 batch loss 6.56874609 epoch total loss 6.46522379\n",
      "Trained batch 515 batch loss 6.20071888 epoch total loss 6.46471\n",
      "Trained batch 516 batch loss 6.38052416 epoch total loss 6.46454716\n",
      "Trained batch 517 batch loss 6.44292641 epoch total loss 6.4645052\n",
      "Trained batch 518 batch loss 6.45572329 epoch total loss 6.46448851\n",
      "Trained batch 519 batch loss 6.61612082 epoch total loss 6.46478081\n",
      "Trained batch 520 batch loss 6.39105797 epoch total loss 6.46463919\n",
      "Trained batch 521 batch loss 6.10536337 epoch total loss 6.46394968\n",
      "Trained batch 522 batch loss 6.45207834 epoch total loss 6.46392727\n",
      "Trained batch 523 batch loss 6.42731762 epoch total loss 6.4638567\n",
      "Trained batch 524 batch loss 6.40637159 epoch total loss 6.46374702\n",
      "Trained batch 525 batch loss 6.44770813 epoch total loss 6.46371651\n",
      "Trained batch 526 batch loss 6.35814381 epoch total loss 6.46351576\n",
      "Trained batch 527 batch loss 6.27913618 epoch total loss 6.46316576\n",
      "Trained batch 528 batch loss 6.59149408 epoch total loss 6.46340895\n",
      "Trained batch 529 batch loss 6.64452 epoch total loss 6.46375132\n",
      "Trained batch 530 batch loss 6.59294128 epoch total loss 6.46399546\n",
      "Trained batch 531 batch loss 6.5955658 epoch total loss 6.46424294\n",
      "Trained batch 532 batch loss 6.03224277 epoch total loss 6.46343088\n",
      "Trained batch 533 batch loss 5.72951698 epoch total loss 6.46205378\n",
      "Trained batch 534 batch loss 5.83986187 epoch total loss 6.46088839\n",
      "Trained batch 535 batch loss 5.9074 epoch total loss 6.45985413\n",
      "Trained batch 536 batch loss 6.4323926 epoch total loss 6.4598031\n",
      "Trained batch 537 batch loss 6.01308393 epoch total loss 6.45897102\n",
      "Trained batch 538 batch loss 5.75482845 epoch total loss 6.45766258\n",
      "Trained batch 539 batch loss 5.77182245 epoch total loss 6.45639\n",
      "Trained batch 540 batch loss 6.35085917 epoch total loss 6.4561944\n",
      "Trained batch 541 batch loss 6.10558701 epoch total loss 6.4555459\n",
      "Trained batch 542 batch loss 6.1205 epoch total loss 6.45492792\n",
      "Trained batch 543 batch loss 7.29108334 epoch total loss 6.45646811\n",
      "Trained batch 544 batch loss 7.06965351 epoch total loss 6.45759487\n",
      "Trained batch 545 batch loss 6.21334267 epoch total loss 6.45714664\n",
      "Trained batch 546 batch loss 6.65516615 epoch total loss 6.45750952\n",
      "Trained batch 547 batch loss 6.660501 epoch total loss 6.4578805\n",
      "Trained batch 548 batch loss 6.12655973 epoch total loss 6.45727587\n",
      "Trained batch 549 batch loss 6.24119425 epoch total loss 6.45688248\n",
      "Trained batch 550 batch loss 6.24957323 epoch total loss 6.4565053\n",
      "Trained batch 551 batch loss 6.03458261 epoch total loss 6.4557395\n",
      "Trained batch 552 batch loss 6.52622938 epoch total loss 6.45586729\n",
      "Trained batch 553 batch loss 6.84118891 epoch total loss 6.45656395\n",
      "Trained batch 554 batch loss 6.64916468 epoch total loss 6.45691204\n",
      "Trained batch 555 batch loss 6.47155142 epoch total loss 6.45693779\n",
      "Trained batch 556 batch loss 6.39802551 epoch total loss 6.45683193\n",
      "Trained batch 557 batch loss 6.51155186 epoch total loss 6.45693\n",
      "Trained batch 558 batch loss 6.41268969 epoch total loss 6.45685053\n",
      "Trained batch 559 batch loss 6.43391228 epoch total loss 6.45680952\n",
      "Trained batch 560 batch loss 6.53724575 epoch total loss 6.45695305\n",
      "Trained batch 561 batch loss 6.45376968 epoch total loss 6.4569478\n",
      "Trained batch 562 batch loss 6.31851578 epoch total loss 6.45670176\n",
      "Trained batch 563 batch loss 6.15835 epoch total loss 6.45617199\n",
      "Trained batch 564 batch loss 6.24326563 epoch total loss 6.45579433\n",
      "Trained batch 565 batch loss 6.29750443 epoch total loss 6.45551395\n",
      "Trained batch 566 batch loss 6.42711926 epoch total loss 6.45546389\n",
      "Trained batch 567 batch loss 6.11819601 epoch total loss 6.45486879\n",
      "Trained batch 568 batch loss 5.72808 epoch total loss 6.45358944\n",
      "Trained batch 569 batch loss 6.10136366 epoch total loss 6.45297\n",
      "Trained batch 570 batch loss 6.1481657 epoch total loss 6.45243549\n",
      "Trained batch 571 batch loss 5.87127876 epoch total loss 6.45141792\n",
      "Trained batch 572 batch loss 5.35851955 epoch total loss 6.44950676\n",
      "Trained batch 573 batch loss 5.63217306 epoch total loss 6.44808\n",
      "Trained batch 574 batch loss 5.72757483 epoch total loss 6.44682503\n",
      "Trained batch 575 batch loss 5.64252472 epoch total loss 6.44542646\n",
      "Trained batch 576 batch loss 5.50712061 epoch total loss 6.44379711\n",
      "Trained batch 577 batch loss 6.31817341 epoch total loss 6.4435792\n",
      "Trained batch 578 batch loss 6.14049149 epoch total loss 6.44305468\n",
      "Trained batch 579 batch loss 6.02544165 epoch total loss 6.4423337\n",
      "Trained batch 580 batch loss 5.86230946 epoch total loss 6.44133329\n",
      "Trained batch 581 batch loss 6.11327791 epoch total loss 6.44076872\n",
      "Trained batch 582 batch loss 6.11462259 epoch total loss 6.44020844\n",
      "Trained batch 583 batch loss 6.32403469 epoch total loss 6.44000864\n",
      "Trained batch 584 batch loss 6.5509367 epoch total loss 6.4401989\n",
      "Trained batch 585 batch loss 7.14076757 epoch total loss 6.44139671\n",
      "Trained batch 586 batch loss 5.28069305 epoch total loss 6.43941593\n",
      "Trained batch 587 batch loss 5.62730646 epoch total loss 6.43803215\n",
      "Trained batch 588 batch loss 5.88458872 epoch total loss 6.43709087\n",
      "Trained batch 589 batch loss 5.99653625 epoch total loss 6.43634319\n",
      "Trained batch 590 batch loss 6.15202713 epoch total loss 6.43586159\n",
      "Trained batch 591 batch loss 6.58499622 epoch total loss 6.43611383\n",
      "Trained batch 592 batch loss 6.4809742 epoch total loss 6.43618917\n",
      "Trained batch 593 batch loss 6.35279894 epoch total loss 6.43604851\n",
      "Trained batch 594 batch loss 6.48310947 epoch total loss 6.43612814\n",
      "Trained batch 595 batch loss 6.1770134 epoch total loss 6.43569231\n",
      "Trained batch 596 batch loss 6.37435484 epoch total loss 6.43558931\n",
      "Trained batch 597 batch loss 6.34138775 epoch total loss 6.43543148\n",
      "Trained batch 598 batch loss 5.85992 epoch total loss 6.43446922\n",
      "Trained batch 599 batch loss 6.45588064 epoch total loss 6.43450451\n",
      "Trained batch 600 batch loss 6.29080391 epoch total loss 6.43426514\n",
      "Trained batch 601 batch loss 6.56122541 epoch total loss 6.43447638\n",
      "Trained batch 602 batch loss 6.33265 epoch total loss 6.43430758\n",
      "Trained batch 603 batch loss 6.99781132 epoch total loss 6.43524218\n",
      "Trained batch 604 batch loss 6.73352385 epoch total loss 6.43573618\n",
      "Trained batch 605 batch loss 5.98836803 epoch total loss 6.4349966\n",
      "Trained batch 606 batch loss 5.69489384 epoch total loss 6.43377495\n",
      "Trained batch 607 batch loss 6.10081339 epoch total loss 6.43322659\n",
      "Trained batch 608 batch loss 6.64114904 epoch total loss 6.43356848\n",
      "Trained batch 609 batch loss 6.433568 epoch total loss 6.43356848\n",
      "Trained batch 610 batch loss 6.43467283 epoch total loss 6.43357\n",
      "Trained batch 611 batch loss 6.09818029 epoch total loss 6.43302107\n",
      "Trained batch 612 batch loss 6.33857775 epoch total loss 6.43286705\n",
      "Trained batch 613 batch loss 6.59980249 epoch total loss 6.43313932\n",
      "Trained batch 614 batch loss 6.28785944 epoch total loss 6.43290281\n",
      "Trained batch 615 batch loss 6.24485254 epoch total loss 6.43259716\n",
      "Trained batch 616 batch loss 6.42832327 epoch total loss 6.43259\n",
      "Trained batch 617 batch loss 6.77131271 epoch total loss 6.43313885\n",
      "Trained batch 618 batch loss 6.10904551 epoch total loss 6.43261433\n",
      "Trained batch 619 batch loss 6.36282301 epoch total loss 6.43250179\n",
      "Trained batch 620 batch loss 6.78728819 epoch total loss 6.433074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 621 batch loss 6.90483713 epoch total loss 6.4338336\n",
      "Trained batch 622 batch loss 6.59351873 epoch total loss 6.43409\n",
      "Trained batch 623 batch loss 6.90047312 epoch total loss 6.43483877\n",
      "Trained batch 624 batch loss 5.67076206 epoch total loss 6.43361425\n",
      "Trained batch 625 batch loss 5.6572094 epoch total loss 6.43237209\n",
      "Trained batch 626 batch loss 6.09421635 epoch total loss 6.43183184\n",
      "Trained batch 627 batch loss 6.71129 epoch total loss 6.4322772\n",
      "Trained batch 628 batch loss 6.58253431 epoch total loss 6.43251657\n",
      "Trained batch 629 batch loss 6.56515312 epoch total loss 6.43272734\n",
      "Trained batch 630 batch loss 6.21247196 epoch total loss 6.43237782\n",
      "Trained batch 631 batch loss 6.40013742 epoch total loss 6.43232679\n",
      "Trained batch 632 batch loss 6.42147493 epoch total loss 6.43230915\n",
      "Trained batch 633 batch loss 6.50486088 epoch total loss 6.43242407\n",
      "Trained batch 634 batch loss 6.50152254 epoch total loss 6.43253279\n",
      "Trained batch 635 batch loss 6.3180337 epoch total loss 6.43235254\n",
      "Trained batch 636 batch loss 6.4365325 epoch total loss 6.43235922\n",
      "Trained batch 637 batch loss 6.20669746 epoch total loss 6.43200493\n",
      "Trained batch 638 batch loss 6.05864239 epoch total loss 6.43141937\n",
      "Trained batch 639 batch loss 6.35621548 epoch total loss 6.43130207\n",
      "Trained batch 640 batch loss 6.498878 epoch total loss 6.43140793\n",
      "Trained batch 641 batch loss 6.58381271 epoch total loss 6.43164587\n",
      "Trained batch 642 batch loss 6.53822374 epoch total loss 6.43181181\n",
      "Trained batch 643 batch loss 7.01041651 epoch total loss 6.43271112\n",
      "Trained batch 644 batch loss 6.32423401 epoch total loss 6.4325428\n",
      "Trained batch 645 batch loss 6.16647291 epoch total loss 6.43213034\n",
      "Trained batch 646 batch loss 6.35183144 epoch total loss 6.43200636\n",
      "Trained batch 647 batch loss 6.44952 epoch total loss 6.43203402\n",
      "Trained batch 648 batch loss 6.23848772 epoch total loss 6.43173504\n",
      "Trained batch 649 batch loss 6.15239191 epoch total loss 6.43130445\n",
      "Trained batch 650 batch loss 6.43700075 epoch total loss 6.43131304\n",
      "Trained batch 651 batch loss 6.48387384 epoch total loss 6.43139362\n",
      "Trained batch 652 batch loss 6.97414303 epoch total loss 6.43222618\n",
      "Trained batch 653 batch loss 6.71034241 epoch total loss 6.43265247\n",
      "Trained batch 654 batch loss 6.4591465 epoch total loss 6.43269253\n",
      "Trained batch 655 batch loss 6.12042046 epoch total loss 6.43221617\n",
      "Trained batch 656 batch loss 6.17572784 epoch total loss 6.43182516\n",
      "Trained batch 657 batch loss 6.64645 epoch total loss 6.43215179\n",
      "Trained batch 658 batch loss 6.76649189 epoch total loss 6.43266\n",
      "Trained batch 659 batch loss 6.31058884 epoch total loss 6.43247509\n",
      "Trained batch 660 batch loss 6.38828707 epoch total loss 6.43240786\n",
      "Trained batch 661 batch loss 6.39554834 epoch total loss 6.43235207\n",
      "Trained batch 662 batch loss 6.19132471 epoch total loss 6.43198824\n",
      "Trained batch 663 batch loss 6.55600166 epoch total loss 6.43217516\n",
      "Trained batch 664 batch loss 6.57134676 epoch total loss 6.43238497\n",
      "Trained batch 665 batch loss 6.67868185 epoch total loss 6.43275499\n",
      "Trained batch 666 batch loss 6.71184444 epoch total loss 6.43317461\n",
      "Trained batch 667 batch loss 6.54225826 epoch total loss 6.43333817\n",
      "Trained batch 668 batch loss 6.48394 epoch total loss 6.43341398\n",
      "Trained batch 669 batch loss 6.3579464 epoch total loss 6.43330097\n",
      "Trained batch 670 batch loss 6.28353357 epoch total loss 6.43307781\n",
      "Trained batch 671 batch loss 6.56619215 epoch total loss 6.43327665\n",
      "Trained batch 672 batch loss 6.67814159 epoch total loss 6.43364096\n",
      "Trained batch 673 batch loss 6.66122818 epoch total loss 6.43397903\n",
      "Trained batch 674 batch loss 5.7658267 epoch total loss 6.43298721\n",
      "Trained batch 675 batch loss 6.17904329 epoch total loss 6.43261147\n",
      "Trained batch 676 batch loss 6.57115078 epoch total loss 6.43281651\n",
      "Trained batch 677 batch loss 6.05768681 epoch total loss 6.43226242\n",
      "Trained batch 678 batch loss 6.00981522 epoch total loss 6.43163919\n",
      "Trained batch 679 batch loss 6.50895929 epoch total loss 6.43175268\n",
      "Trained batch 680 batch loss 6.26573801 epoch total loss 6.43150854\n",
      "Trained batch 681 batch loss 6.464571 epoch total loss 6.4315567\n",
      "Trained batch 682 batch loss 6.41622448 epoch total loss 6.43153381\n",
      "Trained batch 683 batch loss 6.48313618 epoch total loss 6.43160915\n",
      "Trained batch 684 batch loss 6.56426096 epoch total loss 6.43180323\n",
      "Trained batch 685 batch loss 6.17071152 epoch total loss 6.43142271\n",
      "Trained batch 686 batch loss 6.42394733 epoch total loss 6.43141127\n",
      "Trained batch 687 batch loss 6.45021677 epoch total loss 6.43143892\n",
      "Trained batch 688 batch loss 6.72012091 epoch total loss 6.43185854\n",
      "Trained batch 689 batch loss 6.35999346 epoch total loss 6.43175411\n",
      "Trained batch 690 batch loss 6.6456666 epoch total loss 6.43206358\n",
      "Trained batch 691 batch loss 6.34137726 epoch total loss 6.43193245\n",
      "Trained batch 692 batch loss 6.09391117 epoch total loss 6.43144369\n",
      "Trained batch 693 batch loss 6.49324 epoch total loss 6.43153286\n",
      "Trained batch 694 batch loss 6.25422239 epoch total loss 6.43127775\n",
      "Trained batch 695 batch loss 6.45622873 epoch total loss 6.43131304\n",
      "Trained batch 696 batch loss 6.44977951 epoch total loss 6.43133974\n",
      "Trained batch 697 batch loss 6.53317785 epoch total loss 6.43148565\n",
      "Trained batch 698 batch loss 6.21050406 epoch total loss 6.43116903\n",
      "Trained batch 699 batch loss 6.36790276 epoch total loss 6.43107843\n",
      "Trained batch 700 batch loss 6.67295837 epoch total loss 6.43142366\n",
      "Trained batch 701 batch loss 6.30800533 epoch total loss 6.43124771\n",
      "Trained batch 702 batch loss 6.15638 epoch total loss 6.43085623\n",
      "Trained batch 703 batch loss 5.84753704 epoch total loss 6.43002653\n",
      "Trained batch 704 batch loss 6.06532 epoch total loss 6.42950869\n",
      "Trained batch 705 batch loss 6.33592176 epoch total loss 6.42937565\n",
      "Trained batch 706 batch loss 6.25706768 epoch total loss 6.42913151\n",
      "Trained batch 707 batch loss 6.54548931 epoch total loss 6.42929602\n",
      "Trained batch 708 batch loss 6.27342176 epoch total loss 6.42907572\n",
      "Trained batch 709 batch loss 6.4149766 epoch total loss 6.42905617\n",
      "Trained batch 710 batch loss 6.71706486 epoch total loss 6.42946196\n",
      "Trained batch 711 batch loss 6.36641169 epoch total loss 6.42937279\n",
      "Trained batch 712 batch loss 6.06536198 epoch total loss 6.42886162\n",
      "Trained batch 713 batch loss 6.2755909 epoch total loss 6.42864656\n",
      "Trained batch 714 batch loss 6.45449305 epoch total loss 6.4286828\n",
      "Trained batch 715 batch loss 6.67702293 epoch total loss 6.42903042\n",
      "Trained batch 716 batch loss 6.31426668 epoch total loss 6.42887068\n",
      "Trained batch 717 batch loss 6.31821203 epoch total loss 6.42871618\n",
      "Trained batch 718 batch loss 6.40014887 epoch total loss 6.42867708\n",
      "Trained batch 719 batch loss 6.58010197 epoch total loss 6.42888737\n",
      "Trained batch 720 batch loss 6.46345711 epoch total loss 6.42893553\n",
      "Trained batch 721 batch loss 6.80420351 epoch total loss 6.42945576\n",
      "Trained batch 722 batch loss 6.96960163 epoch total loss 6.43020439\n",
      "Trained batch 723 batch loss 6.66486406 epoch total loss 6.43052912\n",
      "Trained batch 724 batch loss 5.56386137 epoch total loss 6.42933226\n",
      "Trained batch 725 batch loss 6.23464966 epoch total loss 6.4290638\n",
      "Trained batch 726 batch loss 6.44490719 epoch total loss 6.42908573\n",
      "Trained batch 727 batch loss 6.45788 epoch total loss 6.42912531\n",
      "Trained batch 728 batch loss 6.51586199 epoch total loss 6.42924404\n",
      "Trained batch 729 batch loss 6.50675488 epoch total loss 6.42935038\n",
      "Trained batch 730 batch loss 6.54253864 epoch total loss 6.42950535\n",
      "Trained batch 731 batch loss 6.43463373 epoch total loss 6.4295125\n",
      "Trained batch 732 batch loss 6.40653 epoch total loss 6.42948151\n",
      "Trained batch 733 batch loss 6.36004877 epoch total loss 6.42938662\n",
      "Trained batch 734 batch loss 6.46026754 epoch total loss 6.42942858\n",
      "Trained batch 735 batch loss 6.35390759 epoch total loss 6.42932606\n",
      "Trained batch 736 batch loss 6.35728645 epoch total loss 6.42922831\n",
      "Trained batch 737 batch loss 6.02795362 epoch total loss 6.42868376\n",
      "Trained batch 738 batch loss 6.09961224 epoch total loss 6.42823792\n",
      "Trained batch 739 batch loss 6.15399218 epoch total loss 6.42786646\n",
      "Trained batch 740 batch loss 6.35946703 epoch total loss 6.42777395\n",
      "Trained batch 741 batch loss 6.52614927 epoch total loss 6.42790699\n",
      "Trained batch 742 batch loss 6.59701967 epoch total loss 6.42813492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 743 batch loss 6.55607033 epoch total loss 6.42830753\n",
      "Trained batch 744 batch loss 6.24687529 epoch total loss 6.42806387\n",
      "Trained batch 745 batch loss 6.1476655 epoch total loss 6.42768717\n",
      "Trained batch 746 batch loss 6.57391 epoch total loss 6.42788315\n",
      "Trained batch 747 batch loss 6.42394 epoch total loss 6.42787743\n",
      "Trained batch 748 batch loss 6.48901272 epoch total loss 6.42795897\n",
      "Trained batch 749 batch loss 6.67395973 epoch total loss 6.42828703\n",
      "Trained batch 750 batch loss 6.57624722 epoch total loss 6.42848444\n",
      "Trained batch 751 batch loss 5.96911907 epoch total loss 6.42787266\n",
      "Trained batch 752 batch loss 5.88606405 epoch total loss 6.42715263\n",
      "Trained batch 753 batch loss 6.03440189 epoch total loss 6.4266305\n",
      "Trained batch 754 batch loss 5.61440659 epoch total loss 6.42555332\n",
      "Trained batch 755 batch loss 6.08349895 epoch total loss 6.42510033\n",
      "Trained batch 756 batch loss 6.43004131 epoch total loss 6.425107\n",
      "Trained batch 757 batch loss 7.01648331 epoch total loss 6.42588854\n",
      "Trained batch 758 batch loss 6.95940447 epoch total loss 6.42659235\n",
      "Trained batch 759 batch loss 6.65036 epoch total loss 6.42688704\n",
      "Trained batch 760 batch loss 6.661304 epoch total loss 6.42719555\n",
      "Trained batch 761 batch loss 6.49022388 epoch total loss 6.42727804\n",
      "Trained batch 762 batch loss 6.45525694 epoch total loss 6.42731476\n",
      "Trained batch 763 batch loss 6.30804253 epoch total loss 6.42715836\n",
      "Trained batch 764 batch loss 6.54367876 epoch total loss 6.42731047\n",
      "Trained batch 765 batch loss 6.45946121 epoch total loss 6.42735291\n",
      "Trained batch 766 batch loss 6.08358145 epoch total loss 6.42690372\n",
      "Trained batch 767 batch loss 5.93223953 epoch total loss 6.42625856\n",
      "Trained batch 768 batch loss 6.37125969 epoch total loss 6.42618704\n",
      "Trained batch 769 batch loss 6.77012205 epoch total loss 6.42663383\n",
      "Trained batch 770 batch loss 6.89845753 epoch total loss 6.42724657\n",
      "Trained batch 771 batch loss 6.7748313 epoch total loss 6.42769766\n",
      "Trained batch 772 batch loss 6.66897964 epoch total loss 6.42801\n",
      "Trained batch 773 batch loss 6.75188637 epoch total loss 6.42842913\n",
      "Trained batch 774 batch loss 6.67521286 epoch total loss 6.42874813\n",
      "Trained batch 775 batch loss 6.4733305 epoch total loss 6.42880535\n",
      "Trained batch 776 batch loss 6.74887371 epoch total loss 6.42921829\n",
      "Trained batch 777 batch loss 6.75982857 epoch total loss 6.42964363\n",
      "Trained batch 778 batch loss 6.85304689 epoch total loss 6.4301877\n",
      "Trained batch 779 batch loss 6.62116861 epoch total loss 6.4304328\n",
      "Trained batch 780 batch loss 6.49163675 epoch total loss 6.43051147\n",
      "Trained batch 781 batch loss 6.58186913 epoch total loss 6.43070555\n",
      "Trained batch 782 batch loss 6.43978405 epoch total loss 6.43071699\n",
      "Trained batch 783 batch loss 6.5380168 epoch total loss 6.43085432\n",
      "Trained batch 784 batch loss 6.48809338 epoch total loss 6.43092728\n",
      "Trained batch 785 batch loss 6.41468048 epoch total loss 6.43090677\n",
      "Trained batch 786 batch loss 6.97062588 epoch total loss 6.43159342\n",
      "Trained batch 787 batch loss 6.337286 epoch total loss 6.43147373\n",
      "Trained batch 788 batch loss 6.09340525 epoch total loss 6.43104458\n",
      "Trained batch 789 batch loss 6.69505024 epoch total loss 6.43137884\n",
      "Trained batch 790 batch loss 6.5769763 epoch total loss 6.43156338\n",
      "Trained batch 791 batch loss 6.25240898 epoch total loss 6.43133688\n",
      "Trained batch 792 batch loss 6.57435 epoch total loss 6.43151712\n",
      "Trained batch 793 batch loss 6.01133919 epoch total loss 6.43098736\n",
      "Trained batch 794 batch loss 6.34947968 epoch total loss 6.43088484\n",
      "Trained batch 795 batch loss 6.56531096 epoch total loss 6.43105412\n",
      "Trained batch 796 batch loss 6.15884 epoch total loss 6.43071175\n",
      "Trained batch 797 batch loss 6.24974442 epoch total loss 6.43048477\n",
      "Trained batch 798 batch loss 6.51719522 epoch total loss 6.43059301\n",
      "Trained batch 799 batch loss 6.3356843 epoch total loss 6.4304738\n",
      "Trained batch 800 batch loss 6.31045675 epoch total loss 6.43032408\n",
      "Trained batch 801 batch loss 6.41644144 epoch total loss 6.43030691\n",
      "Trained batch 802 batch loss 6.13142729 epoch total loss 6.42993402\n",
      "Trained batch 803 batch loss 6.7939 epoch total loss 6.4303875\n",
      "Trained batch 804 batch loss 6.75745821 epoch total loss 6.43079424\n",
      "Trained batch 805 batch loss 6.64101 epoch total loss 6.43105507\n",
      "Trained batch 806 batch loss 6.80240822 epoch total loss 6.43151569\n",
      "Trained batch 807 batch loss 6.74050617 epoch total loss 6.43189907\n",
      "Trained batch 808 batch loss 6.55827522 epoch total loss 6.432055\n",
      "Trained batch 809 batch loss 6.39531279 epoch total loss 6.43201\n",
      "Trained batch 810 batch loss 6.38981104 epoch total loss 6.43195772\n",
      "Trained batch 811 batch loss 6.28231955 epoch total loss 6.43177319\n",
      "Trained batch 812 batch loss 6.12957239 epoch total loss 6.43140078\n",
      "Trained batch 813 batch loss 6.57750416 epoch total loss 6.43158054\n",
      "Trained batch 814 batch loss 6.18420029 epoch total loss 6.43127632\n",
      "Trained batch 815 batch loss 6.27526474 epoch total loss 6.43108511\n",
      "Trained batch 816 batch loss 6.32860661 epoch total loss 6.4309597\n",
      "Trained batch 817 batch loss 6.04094648 epoch total loss 6.43048239\n",
      "Trained batch 818 batch loss 6.20603561 epoch total loss 6.43020821\n",
      "Trained batch 819 batch loss 6.18800735 epoch total loss 6.42991209\n",
      "Trained batch 820 batch loss 6.28907776 epoch total loss 6.42974043\n",
      "Trained batch 821 batch loss 6.20704269 epoch total loss 6.42946911\n",
      "Trained batch 822 batch loss 5.765 epoch total loss 6.42866087\n",
      "Trained batch 823 batch loss 5.90370417 epoch total loss 6.42802334\n",
      "Trained batch 824 batch loss 6.10370493 epoch total loss 6.42762947\n",
      "Trained batch 825 batch loss 6.50733852 epoch total loss 6.42772627\n",
      "Trained batch 826 batch loss 5.93996525 epoch total loss 6.42713547\n",
      "Trained batch 827 batch loss 6.13211489 epoch total loss 6.42677927\n",
      "Trained batch 828 batch loss 5.62822 epoch total loss 6.42581463\n",
      "Trained batch 829 batch loss 5.73247576 epoch total loss 6.42497826\n",
      "Trained batch 830 batch loss 6.45695591 epoch total loss 6.42501688\n",
      "Trained batch 831 batch loss 7.31982231 epoch total loss 6.42609406\n",
      "Trained batch 832 batch loss 7.16032171 epoch total loss 6.4269762\n",
      "Trained batch 833 batch loss 6.81862354 epoch total loss 6.42744637\n",
      "Trained batch 834 batch loss 6.62929916 epoch total loss 6.4276886\n",
      "Trained batch 835 batch loss 7.02411699 epoch total loss 6.4284029\n",
      "Trained batch 836 batch loss 6.83047485 epoch total loss 6.42888403\n",
      "Trained batch 837 batch loss 6.56342459 epoch total loss 6.42904472\n",
      "Trained batch 838 batch loss 6.49856853 epoch total loss 6.42912769\n",
      "Trained batch 839 batch loss 6.26230097 epoch total loss 6.42892838\n",
      "Trained batch 840 batch loss 6.55358458 epoch total loss 6.42907715\n",
      "Trained batch 841 batch loss 6.39569187 epoch total loss 6.42903709\n",
      "Trained batch 842 batch loss 6.49768972 epoch total loss 6.42911863\n",
      "Trained batch 843 batch loss 6.77426815 epoch total loss 6.42952824\n",
      "Trained batch 844 batch loss 6.30652809 epoch total loss 6.4293828\n",
      "Trained batch 845 batch loss 6.55040359 epoch total loss 6.42952585\n",
      "Trained batch 846 batch loss 6.52771854 epoch total loss 6.42964172\n",
      "Trained batch 847 batch loss 6.19323 epoch total loss 6.42936277\n",
      "Trained batch 848 batch loss 6.24003744 epoch total loss 6.42914\n",
      "Trained batch 849 batch loss 6.32817078 epoch total loss 6.42902088\n",
      "Trained batch 850 batch loss 6.17655277 epoch total loss 6.42872429\n",
      "Trained batch 851 batch loss 6.26603651 epoch total loss 6.42853308\n",
      "Trained batch 852 batch loss 6.19711494 epoch total loss 6.42826176\n",
      "Trained batch 853 batch loss 6.05882454 epoch total loss 6.42782831\n",
      "Trained batch 854 batch loss 6.39335442 epoch total loss 6.42778826\n",
      "Trained batch 855 batch loss 6.10851097 epoch total loss 6.42741442\n",
      "Trained batch 856 batch loss 6.50153303 epoch total loss 6.4275012\n",
      "Trained batch 857 batch loss 6.63293123 epoch total loss 6.42774057\n",
      "Trained batch 858 batch loss 6.26508236 epoch total loss 6.42755127\n",
      "Trained batch 859 batch loss 6.3594017 epoch total loss 6.42747164\n",
      "Trained batch 860 batch loss 6.73807144 epoch total loss 6.42783308\n",
      "Trained batch 861 batch loss 6.44159317 epoch total loss 6.42784882\n",
      "Trained batch 862 batch loss 6.51441717 epoch total loss 6.42794943\n",
      "Trained batch 863 batch loss 6.41746855 epoch total loss 6.42793751\n",
      "Trained batch 864 batch loss 6.14699268 epoch total loss 6.4276123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 865 batch loss 6.07891846 epoch total loss 6.42720938\n",
      "Trained batch 866 batch loss 6.31177044 epoch total loss 6.42707634\n",
      "Trained batch 867 batch loss 6.301229 epoch total loss 6.42693138\n",
      "Trained batch 868 batch loss 6.08008575 epoch total loss 6.42653179\n",
      "Trained batch 869 batch loss 6.06871128 epoch total loss 6.42612028\n",
      "Trained batch 870 batch loss 5.79916573 epoch total loss 6.4254\n",
      "Trained batch 871 batch loss 6.56176472 epoch total loss 6.42555571\n",
      "Trained batch 872 batch loss 6.66124821 epoch total loss 6.42582607\n",
      "Trained batch 873 batch loss 6.80044127 epoch total loss 6.42625523\n",
      "Trained batch 874 batch loss 6.66584921 epoch total loss 6.42652941\n",
      "Trained batch 875 batch loss 6.48613834 epoch total loss 6.4265976\n",
      "Trained batch 876 batch loss 6.46944189 epoch total loss 6.42664623\n",
      "Trained batch 877 batch loss 6.45465088 epoch total loss 6.42667818\n",
      "Trained batch 878 batch loss 6.40501928 epoch total loss 6.42665339\n",
      "Trained batch 879 batch loss 6.15100431 epoch total loss 6.42633963\n",
      "Trained batch 880 batch loss 5.92186 epoch total loss 6.42576647\n",
      "Trained batch 881 batch loss 5.66664028 epoch total loss 6.42490435\n",
      "Trained batch 882 batch loss 6.18038654 epoch total loss 6.42462683\n",
      "Trained batch 883 batch loss 6.30237436 epoch total loss 6.42448854\n",
      "Trained batch 884 batch loss 6.34494209 epoch total loss 6.42439795\n",
      "Trained batch 885 batch loss 6.43062592 epoch total loss 6.4244051\n",
      "Trained batch 886 batch loss 6.37562 epoch total loss 6.42435026\n",
      "Trained batch 887 batch loss 5.88540697 epoch total loss 6.42374229\n",
      "Trained batch 888 batch loss 6.43430662 epoch total loss 6.42375374\n",
      "Trained batch 889 batch loss 6.26971 epoch total loss 6.42358065\n",
      "Trained batch 890 batch loss 6.20874929 epoch total loss 6.42333937\n",
      "Trained batch 891 batch loss 6.35992527 epoch total loss 6.42326784\n",
      "Trained batch 892 batch loss 6.74022388 epoch total loss 6.42362356\n",
      "Trained batch 893 batch loss 6.25409079 epoch total loss 6.4234333\n",
      "Trained batch 894 batch loss 6.49672794 epoch total loss 6.42351532\n",
      "Trained batch 895 batch loss 6.46458626 epoch total loss 6.42356062\n",
      "Trained batch 896 batch loss 6.5049696 epoch total loss 6.4236517\n",
      "Trained batch 897 batch loss 6.56205463 epoch total loss 6.42380571\n",
      "Trained batch 898 batch loss 6.43032551 epoch total loss 6.42381287\n",
      "Trained batch 899 batch loss 6.47449827 epoch total loss 6.42386961\n",
      "Trained batch 900 batch loss 6.02559 epoch total loss 6.42342663\n",
      "Trained batch 901 batch loss 6.04164505 epoch total loss 6.42300272\n",
      "Trained batch 902 batch loss 6.48357105 epoch total loss 6.42307\n",
      "Trained batch 903 batch loss 6.49408817 epoch total loss 6.42314863\n",
      "Trained batch 904 batch loss 6.33455563 epoch total loss 6.4230504\n",
      "Trained batch 905 batch loss 6.43482733 epoch total loss 6.42306376\n",
      "Trained batch 906 batch loss 6.43490505 epoch total loss 6.42307663\n",
      "Trained batch 907 batch loss 6.641891 epoch total loss 6.42331839\n",
      "Trained batch 908 batch loss 6.48000765 epoch total loss 6.42338085\n",
      "Trained batch 909 batch loss 6.46915197 epoch total loss 6.4234314\n",
      "Trained batch 910 batch loss 6.4364624 epoch total loss 6.4234457\n",
      "Trained batch 911 batch loss 6.45134068 epoch total loss 6.42347622\n",
      "Trained batch 912 batch loss 6.51545477 epoch total loss 6.42357683\n",
      "Trained batch 913 batch loss 6.18856382 epoch total loss 6.42331934\n",
      "Trained batch 914 batch loss 6.27038574 epoch total loss 6.42315245\n",
      "Trained batch 915 batch loss 6.23073912 epoch total loss 6.42294216\n",
      "Trained batch 916 batch loss 6.5928545 epoch total loss 6.42312765\n",
      "Trained batch 917 batch loss 6.07615089 epoch total loss 6.42274952\n",
      "Trained batch 918 batch loss 6.45827103 epoch total loss 6.42278814\n",
      "Trained batch 919 batch loss 6.309093 epoch total loss 6.42266464\n",
      "Trained batch 920 batch loss 6.84147024 epoch total loss 6.42311954\n",
      "Trained batch 921 batch loss 6.86069679 epoch total loss 6.42359495\n",
      "Trained batch 922 batch loss 6.57270384 epoch total loss 6.4237566\n",
      "Trained batch 923 batch loss 6.47726154 epoch total loss 6.4238143\n",
      "Trained batch 924 batch loss 6.35832119 epoch total loss 6.42374372\n",
      "Trained batch 925 batch loss 6.23316717 epoch total loss 6.42353773\n",
      "Trained batch 926 batch loss 6.07166958 epoch total loss 6.42315769\n",
      "Trained batch 927 batch loss 6.10168839 epoch total loss 6.42281103\n",
      "Trained batch 928 batch loss 6.00727558 epoch total loss 6.42236328\n",
      "Trained batch 929 batch loss 6.11502361 epoch total loss 6.42203283\n",
      "Trained batch 930 batch loss 6.45192385 epoch total loss 6.42206526\n",
      "Trained batch 931 batch loss 6.26677799 epoch total loss 6.42189789\n",
      "Trained batch 932 batch loss 6.20940304 epoch total loss 6.42167\n",
      "Trained batch 933 batch loss 6.82187748 epoch total loss 6.42209911\n",
      "Trained batch 934 batch loss 6.57045 epoch total loss 6.4222579\n",
      "Trained batch 935 batch loss 6.36798143 epoch total loss 6.42219973\n",
      "Trained batch 936 batch loss 6.51388264 epoch total loss 6.42229748\n",
      "Trained batch 937 batch loss 6.37922907 epoch total loss 6.4222517\n",
      "Trained batch 938 batch loss 6.69479656 epoch total loss 6.42254257\n",
      "Trained batch 939 batch loss 6.43321466 epoch total loss 6.42255354\n",
      "Trained batch 940 batch loss 6.38276958 epoch total loss 6.4225111\n",
      "Trained batch 941 batch loss 5.98548603 epoch total loss 6.42204666\n",
      "Trained batch 942 batch loss 5.91618156 epoch total loss 6.42150974\n",
      "Trained batch 943 batch loss 5.71810484 epoch total loss 6.42076397\n",
      "Trained batch 944 batch loss 5.70216846 epoch total loss 6.42000246\n",
      "Trained batch 945 batch loss 5.62402534 epoch total loss 6.41916037\n",
      "Trained batch 946 batch loss 5.36913443 epoch total loss 6.41805029\n",
      "Trained batch 947 batch loss 5.2309227 epoch total loss 6.41679668\n",
      "Trained batch 948 batch loss 5.1560297 epoch total loss 6.41546726\n",
      "Trained batch 949 batch loss 5.69655228 epoch total loss 6.41470957\n",
      "Trained batch 950 batch loss 6.51186085 epoch total loss 6.41481209\n",
      "Trained batch 951 batch loss 6.59259415 epoch total loss 6.41499901\n",
      "Trained batch 952 batch loss 6.25812483 epoch total loss 6.4148345\n",
      "Trained batch 953 batch loss 6.25340843 epoch total loss 6.41466522\n",
      "Trained batch 954 batch loss 6.60731173 epoch total loss 6.41486692\n",
      "Trained batch 955 batch loss 6.27530861 epoch total loss 6.41472101\n",
      "Trained batch 956 batch loss 6.25301886 epoch total loss 6.41455173\n",
      "Trained batch 957 batch loss 6.14229488 epoch total loss 6.41426706\n",
      "Trained batch 958 batch loss 6.31095123 epoch total loss 6.4141593\n",
      "Trained batch 959 batch loss 6.25163364 epoch total loss 6.41398954\n",
      "Trained batch 960 batch loss 6.57619381 epoch total loss 6.41415882\n",
      "Trained batch 961 batch loss 6.33298254 epoch total loss 6.41407442\n",
      "Trained batch 962 batch loss 6.20458555 epoch total loss 6.41385651\n",
      "Trained batch 963 batch loss 6.6841135 epoch total loss 6.41413689\n",
      "Trained batch 964 batch loss 6.07352543 epoch total loss 6.41378403\n",
      "Trained batch 965 batch loss 6.22348928 epoch total loss 6.41358709\n",
      "Trained batch 966 batch loss 6.50757408 epoch total loss 6.41368437\n",
      "Trained batch 967 batch loss 6.19382 epoch total loss 6.41345692\n",
      "Trained batch 968 batch loss 5.85181952 epoch total loss 6.41287708\n",
      "Trained batch 969 batch loss 6.46518707 epoch total loss 6.41293144\n",
      "Trained batch 970 batch loss 6.13470173 epoch total loss 6.41264439\n",
      "Trained batch 971 batch loss 6.35200834 epoch total loss 6.41258192\n",
      "Trained batch 972 batch loss 6.45969343 epoch total loss 6.41263\n",
      "Trained batch 973 batch loss 6.41635 epoch total loss 6.41263437\n",
      "Trained batch 974 batch loss 6.31083918 epoch total loss 6.41253\n",
      "Trained batch 975 batch loss 6.13072062 epoch total loss 6.41224098\n",
      "Trained batch 976 batch loss 6.32509232 epoch total loss 6.41215181\n",
      "Trained batch 977 batch loss 6.35200357 epoch total loss 6.4120903\n",
      "Trained batch 978 batch loss 6.41254377 epoch total loss 6.41209078\n",
      "Trained batch 979 batch loss 6.24836254 epoch total loss 6.41192389\n",
      "Trained batch 980 batch loss 5.49787617 epoch total loss 6.41099119\n",
      "Trained batch 981 batch loss 5.58796453 epoch total loss 6.41015244\n",
      "Trained batch 982 batch loss 6.04025888 epoch total loss 6.40977526\n",
      "Trained batch 983 batch loss 6.36919928 epoch total loss 6.40973425\n",
      "Trained batch 984 batch loss 6.16627598 epoch total loss 6.40948677\n",
      "Trained batch 985 batch loss 6.57496309 epoch total loss 6.40965509\n",
      "Trained batch 986 batch loss 6.58001471 epoch total loss 6.40982771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 987 batch loss 6.36885643 epoch total loss 6.40978622\n",
      "Trained batch 988 batch loss 6.6926918 epoch total loss 6.4100728\n",
      "Trained batch 989 batch loss 6.63844776 epoch total loss 6.41030407\n",
      "Trained batch 990 batch loss 6.43228436 epoch total loss 6.410326\n",
      "Trained batch 991 batch loss 6.10484219 epoch total loss 6.41001797\n",
      "Trained batch 992 batch loss 6.44670391 epoch total loss 6.41005468\n",
      "Trained batch 993 batch loss 5.99495459 epoch total loss 6.40963697\n",
      "Trained batch 994 batch loss 6.04779577 epoch total loss 6.40927315\n",
      "Trained batch 995 batch loss 6.37545204 epoch total loss 6.40923929\n",
      "Trained batch 996 batch loss 6.00824785 epoch total loss 6.40883636\n",
      "Trained batch 997 batch loss 6.19061041 epoch total loss 6.4086175\n",
      "Trained batch 998 batch loss 6.62747288 epoch total loss 6.40883684\n",
      "Trained batch 999 batch loss 6.11396599 epoch total loss 6.4085412\n",
      "Trained batch 1000 batch loss 6.25948477 epoch total loss 6.40839195\n",
      "Trained batch 1001 batch loss 6.3674 epoch total loss 6.40835094\n",
      "Trained batch 1002 batch loss 6.27439308 epoch total loss 6.40821743\n",
      "Trained batch 1003 batch loss 6.34978437 epoch total loss 6.40815878\n",
      "Trained batch 1004 batch loss 6.24362373 epoch total loss 6.40799475\n",
      "Trained batch 1005 batch loss 6.11180973 epoch total loss 6.4077\n",
      "Trained batch 1006 batch loss 6.21356535 epoch total loss 6.40750694\n",
      "Trained batch 1007 batch loss 6.14388609 epoch total loss 6.40724564\n",
      "Trained batch 1008 batch loss 6.02464104 epoch total loss 6.4068656\n",
      "Trained batch 1009 batch loss 6.71953106 epoch total loss 6.40717554\n",
      "Trained batch 1010 batch loss 6.23265171 epoch total loss 6.40700293\n",
      "Trained batch 1011 batch loss 6.65375853 epoch total loss 6.40724707\n",
      "Trained batch 1012 batch loss 6.45279741 epoch total loss 6.40729189\n",
      "Trained batch 1013 batch loss 6.8623457 epoch total loss 6.40774107\n",
      "Trained batch 1014 batch loss 6.60993814 epoch total loss 6.40794039\n",
      "Trained batch 1015 batch loss 6.63802767 epoch total loss 6.40816689\n",
      "Trained batch 1016 batch loss 6.2722578 epoch total loss 6.40803337\n",
      "Trained batch 1017 batch loss 6.38488436 epoch total loss 6.40801048\n",
      "Trained batch 1018 batch loss 5.65222216 epoch total loss 6.40726852\n",
      "Trained batch 1019 batch loss 6.01328516 epoch total loss 6.40688133\n",
      "Trained batch 1020 batch loss 6.51822376 epoch total loss 6.40699053\n",
      "Trained batch 1021 batch loss 6.35396338 epoch total loss 6.40693855\n",
      "Trained batch 1022 batch loss 6.47159386 epoch total loss 6.40700197\n",
      "Trained batch 1023 batch loss 6.33856 epoch total loss 6.40693474\n",
      "Trained batch 1024 batch loss 5.84295177 epoch total loss 6.40638399\n",
      "Trained batch 1025 batch loss 5.66499329 epoch total loss 6.40566063\n",
      "Trained batch 1026 batch loss 6.0217061 epoch total loss 6.40528631\n",
      "Trained batch 1027 batch loss 6.61899757 epoch total loss 6.40549469\n",
      "Trained batch 1028 batch loss 6.74605322 epoch total loss 6.40582561\n",
      "Trained batch 1029 batch loss 6.25955677 epoch total loss 6.40568399\n",
      "Trained batch 1030 batch loss 7.12783575 epoch total loss 6.40638494\n",
      "Trained batch 1031 batch loss 6.85173512 epoch total loss 6.40681696\n",
      "Trained batch 1032 batch loss 6.56788206 epoch total loss 6.40697289\n",
      "Trained batch 1033 batch loss 6.78974104 epoch total loss 6.40734339\n",
      "Trained batch 1034 batch loss 6.45883942 epoch total loss 6.40739346\n",
      "Trained batch 1035 batch loss 6.43454647 epoch total loss 6.40741968\n",
      "Trained batch 1036 batch loss 6.50234032 epoch total loss 6.40751123\n",
      "Trained batch 1037 batch loss 6.54004288 epoch total loss 6.40763903\n",
      "Trained batch 1038 batch loss 6.50900459 epoch total loss 6.4077363\n",
      "Trained batch 1039 batch loss 6.63424826 epoch total loss 6.40795469\n",
      "Trained batch 1040 batch loss 6.36410141 epoch total loss 6.40791273\n",
      "Trained batch 1041 batch loss 5.87738419 epoch total loss 6.40740299\n",
      "Trained batch 1042 batch loss 6.29306078 epoch total loss 6.40729332\n",
      "Trained batch 1043 batch loss 6.64884567 epoch total loss 6.40752459\n",
      "Trained batch 1044 batch loss 7.24165726 epoch total loss 6.40832376\n",
      "Trained batch 1045 batch loss 7.19028091 epoch total loss 6.4090724\n",
      "Trained batch 1046 batch loss 7.07230043 epoch total loss 6.40970612\n",
      "Trained batch 1047 batch loss 7.29836512 epoch total loss 6.41055489\n",
      "Trained batch 1048 batch loss 7.01125813 epoch total loss 6.41112804\n",
      "Trained batch 1049 batch loss 6.17429066 epoch total loss 6.4109025\n",
      "Trained batch 1050 batch loss 6.31253576 epoch total loss 6.41080856\n",
      "Trained batch 1051 batch loss 6.68369484 epoch total loss 6.41106844\n",
      "Trained batch 1052 batch loss 6.27540827 epoch total loss 6.41093922\n",
      "Trained batch 1053 batch loss 6.29582 epoch total loss 6.41083\n",
      "Trained batch 1054 batch loss 6.56329298 epoch total loss 6.41097498\n",
      "Trained batch 1055 batch loss 6.37417412 epoch total loss 6.41093969\n",
      "Trained batch 1056 batch loss 6.37023783 epoch total loss 6.41090107\n",
      "Trained batch 1057 batch loss 6.30143785 epoch total loss 6.4107976\n",
      "Trained batch 1058 batch loss 6.70835876 epoch total loss 6.41107893\n",
      "Trained batch 1059 batch loss 6.56033134 epoch total loss 6.41122\n",
      "Trained batch 1060 batch loss 6.82367754 epoch total loss 6.41160917\n",
      "Trained batch 1061 batch loss 6.83542585 epoch total loss 6.41200876\n",
      "Trained batch 1062 batch loss 6.63632917 epoch total loss 6.41221952\n",
      "Trained batch 1063 batch loss 6.11200142 epoch total loss 6.41193724\n",
      "Trained batch 1064 batch loss 6.07439947 epoch total loss 6.41161966\n",
      "Trained batch 1065 batch loss 6.47262144 epoch total loss 6.41167688\n",
      "Trained batch 1066 batch loss 6.39903975 epoch total loss 6.41166496\n",
      "Trained batch 1067 batch loss 6.14134884 epoch total loss 6.41141129\n",
      "Trained batch 1068 batch loss 6.40641117 epoch total loss 6.41140652\n",
      "Trained batch 1069 batch loss 6.44869804 epoch total loss 6.4114418\n",
      "Trained batch 1070 batch loss 6.55786133 epoch total loss 6.41157818\n",
      "Trained batch 1071 batch loss 6.73530245 epoch total loss 6.41188049\n",
      "Trained batch 1072 batch loss 6.95337296 epoch total loss 6.41238594\n",
      "Trained batch 1073 batch loss 6.56955385 epoch total loss 6.41253233\n",
      "Trained batch 1074 batch loss 6.33864784 epoch total loss 6.41246367\n",
      "Trained batch 1075 batch loss 6.54639959 epoch total loss 6.41258812\n",
      "Trained batch 1076 batch loss 6.41666889 epoch total loss 6.41259193\n",
      "Trained batch 1077 batch loss 6.24126482 epoch total loss 6.41243267\n",
      "Trained batch 1078 batch loss 6.42033863 epoch total loss 6.41244\n",
      "Trained batch 1079 batch loss 6.89008951 epoch total loss 6.4128828\n",
      "Trained batch 1080 batch loss 6.68984556 epoch total loss 6.41313934\n",
      "Trained batch 1081 batch loss 6.26217794 epoch total loss 6.41299963\n",
      "Trained batch 1082 batch loss 5.83065319 epoch total loss 6.41246128\n",
      "Trained batch 1083 batch loss 6.21739483 epoch total loss 6.41228104\n",
      "Trained batch 1084 batch loss 6.24222708 epoch total loss 6.41212416\n",
      "Trained batch 1085 batch loss 6.06081295 epoch total loss 6.41180086\n",
      "Trained batch 1086 batch loss 5.86400604 epoch total loss 6.41129589\n",
      "Trained batch 1087 batch loss 6.13868 epoch total loss 6.41104507\n",
      "Trained batch 1088 batch loss 6.59255171 epoch total loss 6.41121244\n",
      "Trained batch 1089 batch loss 6.40793 epoch total loss 6.41120911\n",
      "Trained batch 1090 batch loss 6.63949728 epoch total loss 6.41141844\n",
      "Trained batch 1091 batch loss 6.36135197 epoch total loss 6.41137266\n",
      "Trained batch 1092 batch loss 6.34514427 epoch total loss 6.4113121\n",
      "Trained batch 1093 batch loss 6.61424494 epoch total loss 6.41149759\n",
      "Trained batch 1094 batch loss 6.70392513 epoch total loss 6.4117651\n",
      "Trained batch 1095 batch loss 6.54807568 epoch total loss 6.41188955\n",
      "Trained batch 1096 batch loss 6.4594841 epoch total loss 6.41193295\n",
      "Trained batch 1097 batch loss 6.29790115 epoch total loss 6.41182899\n",
      "Trained batch 1098 batch loss 6.74938536 epoch total loss 6.41213655\n",
      "Trained batch 1099 batch loss 6.7696538 epoch total loss 6.41246176\n",
      "Trained batch 1100 batch loss 6.51175261 epoch total loss 6.41255188\n",
      "Trained batch 1101 batch loss 6.48519 epoch total loss 6.41261816\n",
      "Trained batch 1102 batch loss 6.33386326 epoch total loss 6.41254663\n",
      "Trained batch 1103 batch loss 6.44702482 epoch total loss 6.41257811\n",
      "Trained batch 1104 batch loss 6.41972 epoch total loss 6.41258478\n",
      "Trained batch 1105 batch loss 6.70978117 epoch total loss 6.41285372\n",
      "Trained batch 1106 batch loss 6.35440111 epoch total loss 6.41280127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1107 batch loss 6.12224293 epoch total loss 6.41253853\n",
      "Trained batch 1108 batch loss 6.47908306 epoch total loss 6.41259861\n",
      "Trained batch 1109 batch loss 6.44612312 epoch total loss 6.41262913\n",
      "Trained batch 1110 batch loss 6.2793026 epoch total loss 6.41250896\n",
      "Trained batch 1111 batch loss 6.57862 epoch total loss 6.41265821\n",
      "Trained batch 1112 batch loss 6.16217422 epoch total loss 6.41243315\n",
      "Trained batch 1113 batch loss 5.95087 epoch total loss 6.4120183\n",
      "Trained batch 1114 batch loss 6.09923792 epoch total loss 6.41173744\n",
      "Trained batch 1115 batch loss 6.16290426 epoch total loss 6.41151428\n",
      "Trained batch 1116 batch loss 6.01552343 epoch total loss 6.41115952\n",
      "Trained batch 1117 batch loss 6.23590755 epoch total loss 6.41100264\n",
      "Trained batch 1118 batch loss 5.80642939 epoch total loss 6.4104619\n",
      "Trained batch 1119 batch loss 6.00064611 epoch total loss 6.41009569\n",
      "Trained batch 1120 batch loss 5.97823048 epoch total loss 6.40971\n",
      "Trained batch 1121 batch loss 5.75806379 epoch total loss 6.40912867\n",
      "Trained batch 1122 batch loss 6.56921053 epoch total loss 6.40927172\n",
      "Trained batch 1123 batch loss 6.15466642 epoch total loss 6.40904474\n",
      "Trained batch 1124 batch loss 6.55102968 epoch total loss 6.40917158\n",
      "Trained batch 1125 batch loss 6.44804287 epoch total loss 6.40920639\n",
      "Trained batch 1126 batch loss 6.58290291 epoch total loss 6.40936041\n",
      "Trained batch 1127 batch loss 6.53850889 epoch total loss 6.40947533\n",
      "Trained batch 1128 batch loss 6.42314672 epoch total loss 6.40948725\n",
      "Trained batch 1129 batch loss 6.55031443 epoch total loss 6.40961218\n",
      "Trained batch 1130 batch loss 6.51463842 epoch total loss 6.40970516\n",
      "Trained batch 1131 batch loss 6.56067753 epoch total loss 6.40983868\n",
      "Trained batch 1132 batch loss 6.41635847 epoch total loss 6.4098444\n",
      "Trained batch 1133 batch loss 6.41683149 epoch total loss 6.4098506\n",
      "Trained batch 1134 batch loss 6.5002737 epoch total loss 6.40993071\n",
      "Trained batch 1135 batch loss 6.49673653 epoch total loss 6.410007\n",
      "Trained batch 1136 batch loss 6.46513557 epoch total loss 6.41005564\n",
      "Trained batch 1137 batch loss 6.68953 epoch total loss 6.41030121\n",
      "Trained batch 1138 batch loss 6.63212109 epoch total loss 6.41049671\n",
      "Trained batch 1139 batch loss 6.68635273 epoch total loss 6.41073895\n",
      "Trained batch 1140 batch loss 6.9993186 epoch total loss 6.41125536\n",
      "Trained batch 1141 batch loss 6.84912872 epoch total loss 6.41163921\n",
      "Trained batch 1142 batch loss 6.8202095 epoch total loss 6.41199684\n",
      "Trained batch 1143 batch loss 6.84246254 epoch total loss 6.41237354\n",
      "Trained batch 1144 batch loss 6.70344543 epoch total loss 6.41262817\n",
      "Trained batch 1145 batch loss 6.69545078 epoch total loss 6.4128747\n",
      "Trained batch 1146 batch loss 6.6650095 epoch total loss 6.413095\n",
      "Trained batch 1147 batch loss 6.36241817 epoch total loss 6.41305065\n",
      "Trained batch 1148 batch loss 6.79064322 epoch total loss 6.41337919\n",
      "Trained batch 1149 batch loss 6.37846565 epoch total loss 6.41334915\n",
      "Trained batch 1150 batch loss 6.54733181 epoch total loss 6.4134655\n",
      "Trained batch 1151 batch loss 6.30172157 epoch total loss 6.4133687\n",
      "Trained batch 1152 batch loss 6.33318281 epoch total loss 6.41329861\n",
      "Trained batch 1153 batch loss 6.25839853 epoch total loss 6.41316414\n",
      "Trained batch 1154 batch loss 6.0577755 epoch total loss 6.4128561\n",
      "Trained batch 1155 batch loss 6.65750456 epoch total loss 6.41306829\n",
      "Trained batch 1156 batch loss 6.98263454 epoch total loss 6.41356087\n",
      "Trained batch 1157 batch loss 6.79397202 epoch total loss 6.41388941\n",
      "Trained batch 1158 batch loss 7.21043825 epoch total loss 6.41457748\n",
      "Trained batch 1159 batch loss 6.48229885 epoch total loss 6.41463566\n",
      "Trained batch 1160 batch loss 6.46160746 epoch total loss 6.41467619\n",
      "Trained batch 1161 batch loss 6.44029713 epoch total loss 6.4146986\n",
      "Trained batch 1162 batch loss 6.39067698 epoch total loss 6.41467762\n",
      "Trained batch 1163 batch loss 6.71069193 epoch total loss 6.41493177\n",
      "Trained batch 1164 batch loss 6.33008957 epoch total loss 6.41485929\n",
      "Trained batch 1165 batch loss 6.5999794 epoch total loss 6.41501808\n",
      "Trained batch 1166 batch loss 6.73713493 epoch total loss 6.41529465\n",
      "Trained batch 1167 batch loss 6.85837936 epoch total loss 6.41567421\n",
      "Trained batch 1168 batch loss 6.41684103 epoch total loss 6.41567516\n",
      "Trained batch 1169 batch loss 6.15084362 epoch total loss 6.41544867\n",
      "Trained batch 1170 batch loss 6.36337566 epoch total loss 6.41540432\n",
      "Trained batch 1171 batch loss 6.01822758 epoch total loss 6.41506481\n",
      "Trained batch 1172 batch loss 6.16711617 epoch total loss 6.4148531\n",
      "Trained batch 1173 batch loss 6.02710438 epoch total loss 6.41452312\n",
      "Trained batch 1174 batch loss 6.2728529 epoch total loss 6.41440248\n",
      "Trained batch 1175 batch loss 6.34478855 epoch total loss 6.41434288\n",
      "Trained batch 1176 batch loss 6.08839607 epoch total loss 6.41406584\n",
      "Trained batch 1177 batch loss 6.19808865 epoch total loss 6.41388226\n",
      "Trained batch 1178 batch loss 6.17645264 epoch total loss 6.41368055\n",
      "Trained batch 1179 batch loss 6.49658585 epoch total loss 6.41375113\n",
      "Trained batch 1180 batch loss 6.21310616 epoch total loss 6.41358089\n",
      "Trained batch 1181 batch loss 5.80251694 epoch total loss 6.41306353\n",
      "Trained batch 1182 batch loss 5.26753712 epoch total loss 6.41209459\n",
      "Trained batch 1183 batch loss 5.91432 epoch total loss 6.41167402\n",
      "Trained batch 1184 batch loss 6.05342054 epoch total loss 6.41137123\n",
      "Trained batch 1185 batch loss 6.28280258 epoch total loss 6.41126251\n",
      "Trained batch 1186 batch loss 6.21634293 epoch total loss 6.411098\n",
      "Trained batch 1187 batch loss 6.3507123 epoch total loss 6.41104746\n",
      "Trained batch 1188 batch loss 6.2131834 epoch total loss 6.41088104\n",
      "Trained batch 1189 batch loss 6.23015594 epoch total loss 6.41072893\n",
      "Trained batch 1190 batch loss 6.53748 epoch total loss 6.41083527\n",
      "Trained batch 1191 batch loss 6.91082191 epoch total loss 6.41125488\n",
      "Trained batch 1192 batch loss 7.09562826 epoch total loss 6.41182899\n",
      "Trained batch 1193 batch loss 6.9053278 epoch total loss 6.41224289\n",
      "Trained batch 1194 batch loss 6.61841822 epoch total loss 6.4124155\n",
      "Trained batch 1195 batch loss 6.62909412 epoch total loss 6.4125967\n",
      "Trained batch 1196 batch loss 6.3324852 epoch total loss 6.41253\n",
      "Trained batch 1197 batch loss 6.43292046 epoch total loss 6.41254711\n",
      "Trained batch 1198 batch loss 6.46714592 epoch total loss 6.41259289\n",
      "Trained batch 1199 batch loss 6.54177713 epoch total loss 6.41270065\n",
      "Trained batch 1200 batch loss 6.74813 epoch total loss 6.41298\n",
      "Trained batch 1201 batch loss 6.73718309 epoch total loss 6.41325\n",
      "Trained batch 1202 batch loss 6.54247093 epoch total loss 6.41335773\n",
      "Trained batch 1203 batch loss 6.52783394 epoch total loss 6.41345263\n",
      "Trained batch 1204 batch loss 6.60964203 epoch total loss 6.41361618\n",
      "Trained batch 1205 batch loss 6.39339256 epoch total loss 6.41359949\n",
      "Trained batch 1206 batch loss 6.71923447 epoch total loss 6.41385269\n",
      "Trained batch 1207 batch loss 6.40916967 epoch total loss 6.41384888\n",
      "Trained batch 1208 batch loss 6.39001322 epoch total loss 6.41382933\n",
      "Trained batch 1209 batch loss 6.69512463 epoch total loss 6.41406202\n",
      "Trained batch 1210 batch loss 6.40862703 epoch total loss 6.41405773\n",
      "Trained batch 1211 batch loss 6.48824453 epoch total loss 6.41411877\n",
      "Trained batch 1212 batch loss 6.50481462 epoch total loss 6.41419363\n",
      "Trained batch 1213 batch loss 6.52781868 epoch total loss 6.41428757\n",
      "Trained batch 1214 batch loss 6.73297262 epoch total loss 6.41455\n",
      "Trained batch 1215 batch loss 6.68198776 epoch total loss 6.41477\n",
      "Trained batch 1216 batch loss 6.45118761 epoch total loss 6.4148\n",
      "Trained batch 1217 batch loss 6.34918261 epoch total loss 6.41474628\n",
      "Trained batch 1218 batch loss 6.5574522 epoch total loss 6.41486359\n",
      "Trained batch 1219 batch loss 6.42961216 epoch total loss 6.41487551\n",
      "Trained batch 1220 batch loss 6.30755901 epoch total loss 6.41478777\n",
      "Trained batch 1221 batch loss 6.26214361 epoch total loss 6.41466284\n",
      "Trained batch 1222 batch loss 6.33153772 epoch total loss 6.41459465\n",
      "Trained batch 1223 batch loss 6.23358059 epoch total loss 6.41444635\n",
      "Trained batch 1224 batch loss 6.49367 epoch total loss 6.4145112\n",
      "Trained batch 1225 batch loss 6.69451284 epoch total loss 6.41473961\n",
      "Trained batch 1226 batch loss 6.41841364 epoch total loss 6.41474295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1227 batch loss 6.09329605 epoch total loss 6.41448069\n",
      "Trained batch 1228 batch loss 6.50848961 epoch total loss 6.41455698\n",
      "Trained batch 1229 batch loss 6.67279577 epoch total loss 6.41476727\n",
      "Trained batch 1230 batch loss 6.52101278 epoch total loss 6.41485357\n",
      "Trained batch 1231 batch loss 6.83257341 epoch total loss 6.41519308\n",
      "Trained batch 1232 batch loss 6.5999279 epoch total loss 6.41534328\n",
      "Trained batch 1233 batch loss 6.34718037 epoch total loss 6.41528797\n",
      "Trained batch 1234 batch loss 6.54766178 epoch total loss 6.41539526\n",
      "Trained batch 1235 batch loss 6.63719177 epoch total loss 6.41557455\n",
      "Trained batch 1236 batch loss 6.47251081 epoch total loss 6.4156208\n",
      "Trained batch 1237 batch loss 5.41455507 epoch total loss 6.41481161\n",
      "Trained batch 1238 batch loss 5.3177371 epoch total loss 6.41392565\n",
      "Trained batch 1239 batch loss 5.73080444 epoch total loss 6.41337442\n",
      "Trained batch 1240 batch loss 5.88575411 epoch total loss 6.41294909\n",
      "Trained batch 1241 batch loss 6.92928839 epoch total loss 6.41336489\n",
      "Trained batch 1242 batch loss 6.77166224 epoch total loss 6.41365337\n",
      "Trained batch 1243 batch loss 6.62845469 epoch total loss 6.41382599\n",
      "Trained batch 1244 batch loss 6.13907 epoch total loss 6.41360521\n",
      "Trained batch 1245 batch loss 6.25199461 epoch total loss 6.41347551\n",
      "Trained batch 1246 batch loss 6.49564028 epoch total loss 6.41354132\n",
      "Trained batch 1247 batch loss 6.54589272 epoch total loss 6.41364765\n",
      "Trained batch 1248 batch loss 6.46667099 epoch total loss 6.41369\n",
      "Trained batch 1249 batch loss 6.405828 epoch total loss 6.41368389\n",
      "Trained batch 1250 batch loss 6.67014885 epoch total loss 6.41388845\n",
      "Trained batch 1251 batch loss 6.39725542 epoch total loss 6.41387558\n",
      "Trained batch 1252 batch loss 6.69044256 epoch total loss 6.41409636\n",
      "Trained batch 1253 batch loss 6.37397861 epoch total loss 6.41406441\n",
      "Trained batch 1254 batch loss 6.38862514 epoch total loss 6.41404438\n",
      "Trained batch 1255 batch loss 6.76209259 epoch total loss 6.41432142\n",
      "Trained batch 1256 batch loss 6.31378794 epoch total loss 6.41424179\n",
      "Trained batch 1257 batch loss 5.67583132 epoch total loss 6.41365433\n",
      "Trained batch 1258 batch loss 6.26481247 epoch total loss 6.41353559\n",
      "Trained batch 1259 batch loss 6.51043653 epoch total loss 6.41361284\n",
      "Trained batch 1260 batch loss 6.38529491 epoch total loss 6.41359\n",
      "Trained batch 1261 batch loss 6.22984171 epoch total loss 6.41344452\n",
      "Trained batch 1262 batch loss 6.38401651 epoch total loss 6.41342115\n",
      "Trained batch 1263 batch loss 6.6247673 epoch total loss 6.41358852\n",
      "Trained batch 1264 batch loss 6.72853041 epoch total loss 6.41383791\n",
      "Trained batch 1265 batch loss 6.45570374 epoch total loss 6.41387081\n",
      "Trained batch 1266 batch loss 6.34245634 epoch total loss 6.41381407\n",
      "Trained batch 1267 batch loss 5.90085173 epoch total loss 6.41340923\n",
      "Trained batch 1268 batch loss 6.00817728 epoch total loss 6.41308975\n",
      "Trained batch 1269 batch loss 6.23161364 epoch total loss 6.4129467\n",
      "Trained batch 1270 batch loss 6.68432283 epoch total loss 6.41316032\n",
      "Trained batch 1271 batch loss 6.22094774 epoch total loss 6.41300917\n",
      "Trained batch 1272 batch loss 6.4525094 epoch total loss 6.41304\n",
      "Trained batch 1273 batch loss 6.43744659 epoch total loss 6.41305923\n",
      "Trained batch 1274 batch loss 6.56144428 epoch total loss 6.41317606\n",
      "Trained batch 1275 batch loss 6.13047457 epoch total loss 6.41295433\n",
      "Trained batch 1276 batch loss 5.87420559 epoch total loss 6.41253185\n",
      "Trained batch 1277 batch loss 6.45851326 epoch total loss 6.41256762\n",
      "Trained batch 1278 batch loss 6.62676144 epoch total loss 6.41273499\n",
      "Trained batch 1279 batch loss 6.5939455 epoch total loss 6.41287661\n",
      "Trained batch 1280 batch loss 6.49223566 epoch total loss 6.41293859\n",
      "Trained batch 1281 batch loss 6.538867 epoch total loss 6.4130373\n",
      "Trained batch 1282 batch loss 6.64428091 epoch total loss 6.41321754\n",
      "Trained batch 1283 batch loss 6.45261335 epoch total loss 6.41324806\n",
      "Trained batch 1284 batch loss 6.48028898 epoch total loss 6.41330051\n",
      "Trained batch 1285 batch loss 6.44153404 epoch total loss 6.41332245\n",
      "Trained batch 1286 batch loss 6.55726242 epoch total loss 6.41343451\n",
      "Trained batch 1287 batch loss 5.99267864 epoch total loss 6.41310787\n",
      "Trained batch 1288 batch loss 6.22920132 epoch total loss 6.4129653\n",
      "Trained batch 1289 batch loss 6.1208806 epoch total loss 6.4127388\n",
      "Trained batch 1290 batch loss 5.99495745 epoch total loss 6.41241503\n",
      "Trained batch 1291 batch loss 6.39264059 epoch total loss 6.4124\n",
      "Trained batch 1292 batch loss 6.40476 epoch total loss 6.41239357\n",
      "Trained batch 1293 batch loss 6.22790194 epoch total loss 6.41225052\n",
      "Trained batch 1294 batch loss 5.98422956 epoch total loss 6.41192\n",
      "Trained batch 1295 batch loss 6.33410549 epoch total loss 6.41186\n",
      "Trained batch 1296 batch loss 6.00752878 epoch total loss 6.41154814\n",
      "Trained batch 1297 batch loss 6.03449297 epoch total loss 6.41125727\n",
      "Trained batch 1298 batch loss 6.32508326 epoch total loss 6.41119051\n",
      "Trained batch 1299 batch loss 6.08127546 epoch total loss 6.41093683\n",
      "Trained batch 1300 batch loss 6.26345062 epoch total loss 6.41082335\n",
      "Trained batch 1301 batch loss 6.55500412 epoch total loss 6.41093397\n",
      "Trained batch 1302 batch loss 6.27607632 epoch total loss 6.4108305\n",
      "Trained batch 1303 batch loss 6.33296967 epoch total loss 6.41077089\n",
      "Trained batch 1304 batch loss 6.40591621 epoch total loss 6.41076756\n",
      "Trained batch 1305 batch loss 6.44013453 epoch total loss 6.41079\n",
      "Trained batch 1306 batch loss 6.64975882 epoch total loss 6.4109726\n",
      "Trained batch 1307 batch loss 6.50296497 epoch total loss 6.41104317\n",
      "Trained batch 1308 batch loss 6.3862977 epoch total loss 6.41102457\n",
      "Trained batch 1309 batch loss 6.52085114 epoch total loss 6.41110802\n",
      "Trained batch 1310 batch loss 6.27784777 epoch total loss 6.41100693\n",
      "Trained batch 1311 batch loss 6.42014456 epoch total loss 6.4110136\n",
      "Trained batch 1312 batch loss 6.43906069 epoch total loss 6.41103554\n",
      "Trained batch 1313 batch loss 6.58963966 epoch total loss 6.41117144\n",
      "Trained batch 1314 batch loss 5.97812319 epoch total loss 6.41084242\n",
      "Trained batch 1315 batch loss 6.70759 epoch total loss 6.41106844\n",
      "Trained batch 1316 batch loss 6.9276638 epoch total loss 6.41146088\n",
      "Trained batch 1317 batch loss 6.85274029 epoch total loss 6.41179562\n",
      "Trained batch 1318 batch loss 7.09220505 epoch total loss 6.41231155\n",
      "Trained batch 1319 batch loss 7.62719631 epoch total loss 6.41323233\n",
      "Trained batch 1320 batch loss 7.30817175 epoch total loss 6.41391087\n",
      "Trained batch 1321 batch loss 7.20949888 epoch total loss 6.41451359\n",
      "Trained batch 1322 batch loss 6.56311893 epoch total loss 6.41462612\n",
      "Trained batch 1323 batch loss 6.64441252 epoch total loss 6.41479969\n",
      "Trained batch 1324 batch loss 6.60180759 epoch total loss 6.41494083\n",
      "Trained batch 1325 batch loss 6.30576229 epoch total loss 6.41485834\n",
      "Trained batch 1326 batch loss 6.34246397 epoch total loss 6.41480398\n",
      "Trained batch 1327 batch loss 6.39932442 epoch total loss 6.41479254\n",
      "Trained batch 1328 batch loss 6.35480213 epoch total loss 6.41474724\n",
      "Trained batch 1329 batch loss 6.14499331 epoch total loss 6.41454363\n",
      "Trained batch 1330 batch loss 6.31186342 epoch total loss 6.41446638\n",
      "Trained batch 1331 batch loss 6.04932594 epoch total loss 6.4141922\n",
      "Trained batch 1332 batch loss 6.38756752 epoch total loss 6.41417265\n",
      "Trained batch 1333 batch loss 6.41155052 epoch total loss 6.41417027\n",
      "Trained batch 1334 batch loss 6.65722466 epoch total loss 6.41435242\n",
      "Trained batch 1335 batch loss 6.43099 epoch total loss 6.41436481\n",
      "Trained batch 1336 batch loss 6.85279 epoch total loss 6.4146924\n",
      "Trained batch 1337 batch loss 6.6634922 epoch total loss 6.41487837\n",
      "Trained batch 1338 batch loss 5.74038696 epoch total loss 6.41437435\n",
      "Trained batch 1339 batch loss 6.13537121 epoch total loss 6.41416597\n",
      "Trained batch 1340 batch loss 6.39238787 epoch total loss 6.41414976\n",
      "Trained batch 1341 batch loss 6.70764685 epoch total loss 6.41436911\n",
      "Trained batch 1342 batch loss 6.64774 epoch total loss 6.41454268\n",
      "Trained batch 1343 batch loss 6.63855076 epoch total loss 6.41470957\n",
      "Trained batch 1344 batch loss 6.8055191 epoch total loss 6.41500044\n",
      "Trained batch 1345 batch loss 6.3291707 epoch total loss 6.41493654\n",
      "Trained batch 1346 batch loss 5.82267 epoch total loss 6.41449642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1347 batch loss 6.41595793 epoch total loss 6.41449738\n",
      "Trained batch 1348 batch loss 6.47288322 epoch total loss 6.41454077\n",
      "Trained batch 1349 batch loss 6.40310478 epoch total loss 6.41453218\n",
      "Trained batch 1350 batch loss 6.6527071 epoch total loss 6.41470861\n",
      "Trained batch 1351 batch loss 6.7243824 epoch total loss 6.41493797\n",
      "Trained batch 1352 batch loss 6.10247564 epoch total loss 6.41470671\n",
      "Trained batch 1353 batch loss 6.35287189 epoch total loss 6.41466093\n",
      "Trained batch 1354 batch loss 6.10554647 epoch total loss 6.41443253\n",
      "Trained batch 1355 batch loss 6.20293951 epoch total loss 6.4142766\n",
      "Trained batch 1356 batch loss 6.37011051 epoch total loss 6.41424417\n",
      "Trained batch 1357 batch loss 6.59939623 epoch total loss 6.41438055\n",
      "Trained batch 1358 batch loss 6.54949236 epoch total loss 6.41448\n",
      "Trained batch 1359 batch loss 6.5549922 epoch total loss 6.41458368\n",
      "Trained batch 1360 batch loss 6.74324036 epoch total loss 6.41482496\n",
      "Trained batch 1361 batch loss 7.07693815 epoch total loss 6.41531181\n",
      "Trained batch 1362 batch loss 6.68848658 epoch total loss 6.41551208\n",
      "Trained batch 1363 batch loss 6.42470837 epoch total loss 6.41551924\n",
      "Trained batch 1364 batch loss 6.584867 epoch total loss 6.41564322\n",
      "Trained batch 1365 batch loss 6.44397116 epoch total loss 6.4156642\n",
      "Trained batch 1366 batch loss 6.61452866 epoch total loss 6.41580963\n",
      "Trained batch 1367 batch loss 6.2717948 epoch total loss 6.41570425\n",
      "Trained batch 1368 batch loss 6.44316196 epoch total loss 6.41572428\n",
      "Trained batch 1369 batch loss 6.62233639 epoch total loss 6.41587496\n",
      "Trained batch 1370 batch loss 6.73568678 epoch total loss 6.41610813\n",
      "Trained batch 1371 batch loss 6.43816185 epoch total loss 6.41612482\n",
      "Trained batch 1372 batch loss 6.45478392 epoch total loss 6.41615295\n",
      "Trained batch 1373 batch loss 6.40927 epoch total loss 6.41614771\n",
      "Trained batch 1374 batch loss 6.52833033 epoch total loss 6.41622972\n",
      "Trained batch 1375 batch loss 6.62906313 epoch total loss 6.41638422\n",
      "Trained batch 1376 batch loss 6.64765787 epoch total loss 6.41655207\n",
      "Trained batch 1377 batch loss 6.77049065 epoch total loss 6.41680908\n",
      "Trained batch 1378 batch loss 6.1404705 epoch total loss 6.41660881\n",
      "Trained batch 1379 batch loss 5.95582676 epoch total loss 6.41627502\n",
      "Trained batch 1380 batch loss 6.6552825 epoch total loss 6.41644812\n",
      "Trained batch 1381 batch loss 6.5115037 epoch total loss 6.41651678\n",
      "Trained batch 1382 batch loss 6.46433306 epoch total loss 6.41655111\n",
      "Trained batch 1383 batch loss 6.28329706 epoch total loss 6.41645479\n",
      "Trained batch 1384 batch loss 6.66353083 epoch total loss 6.41663313\n",
      "Trained batch 1385 batch loss 6.76357794 epoch total loss 6.41688347\n",
      "Trained batch 1386 batch loss 6.50504684 epoch total loss 6.41694689\n",
      "Trained batch 1387 batch loss 6.66247797 epoch total loss 6.41712379\n",
      "Trained batch 1388 batch loss 6.39823818 epoch total loss 6.41711044\n",
      "Epoch 1 train loss 6.417110443115234\n",
      "Validated batch 1 batch loss 6.86072874\n",
      "Validated batch 2 batch loss 6.49673939\n",
      "Validated batch 3 batch loss 6.38995457\n",
      "Validated batch 4 batch loss 6.3734293\n",
      "Validated batch 5 batch loss 6.36784363\n",
      "Validated batch 6 batch loss 6.48397303\n",
      "Validated batch 7 batch loss 6.41471386\n",
      "Validated batch 8 batch loss 5.96507835\n",
      "Validated batch 9 batch loss 6.34506607\n",
      "Validated batch 10 batch loss 6.25932693\n",
      "Validated batch 11 batch loss 6.34743452\n",
      "Validated batch 12 batch loss 6.09743309\n",
      "Validated batch 13 batch loss 6.25235128\n",
      "Validated batch 14 batch loss 6.08910418\n",
      "Validated batch 15 batch loss 6.25113344\n",
      "Validated batch 16 batch loss 6.4227\n",
      "Validated batch 17 batch loss 6.50175428\n",
      "Validated batch 18 batch loss 6.68642044\n",
      "Validated batch 19 batch loss 7.02885294\n",
      "Validated batch 20 batch loss 7.15635204\n",
      "Validated batch 21 batch loss 6.66213131\n",
      "Validated batch 22 batch loss 6.32254934\n",
      "Validated batch 23 batch loss 5.993999\n",
      "Validated batch 24 batch loss 6.17290688\n",
      "Validated batch 25 batch loss 5.88230038\n",
      "Validated batch 26 batch loss 6.32057714\n",
      "Validated batch 27 batch loss 6.26357889\n",
      "Validated batch 28 batch loss 6.25479126\n",
      "Validated batch 29 batch loss 6.53514719\n",
      "Validated batch 30 batch loss 6.35872698\n",
      "Validated batch 31 batch loss 6.60635328\n",
      "Validated batch 32 batch loss 6.36305285\n",
      "Validated batch 33 batch loss 6.4638443\n",
      "Validated batch 34 batch loss 6.13893461\n",
      "Validated batch 35 batch loss 6.30555439\n",
      "Validated batch 36 batch loss 6.29990816\n",
      "Validated batch 37 batch loss 6.62884569\n",
      "Validated batch 38 batch loss 6.45098305\n",
      "Validated batch 39 batch loss 6.2599864\n",
      "Validated batch 40 batch loss 6.50217867\n",
      "Validated batch 41 batch loss 5.89292908\n",
      "Validated batch 42 batch loss 6.39407349\n",
      "Validated batch 43 batch loss 6.46101141\n",
      "Validated batch 44 batch loss 6.34283257\n",
      "Validated batch 45 batch loss 6.48849344\n",
      "Validated batch 46 batch loss 6.16487885\n",
      "Validated batch 47 batch loss 6.50496769\n",
      "Validated batch 48 batch loss 6.7424984\n",
      "Validated batch 49 batch loss 6.27133083\n",
      "Validated batch 50 batch loss 5.75389\n",
      "Validated batch 51 batch loss 6.40926027\n",
      "Validated batch 52 batch loss 6.23654795\n",
      "Validated batch 53 batch loss 5.87705803\n",
      "Validated batch 54 batch loss 6.18243456\n",
      "Validated batch 55 batch loss 5.9675107\n",
      "Validated batch 56 batch loss 6.57229471\n",
      "Validated batch 57 batch loss 6.03508329\n",
      "Validated batch 58 batch loss 5.95076084\n",
      "Validated batch 59 batch loss 6.31775284\n",
      "Validated batch 60 batch loss 6.35860252\n",
      "Validated batch 61 batch loss 6.1505661\n",
      "Validated batch 62 batch loss 6.31774426\n",
      "Validated batch 63 batch loss 6.21990204\n",
      "Validated batch 64 batch loss 6.49351025\n",
      "Validated batch 65 batch loss 6.20899677\n",
      "Validated batch 66 batch loss 6.30552101\n",
      "Validated batch 67 batch loss 6.58204317\n",
      "Validated batch 68 batch loss 5.47672462\n",
      "Validated batch 69 batch loss 6.74230433\n",
      "Validated batch 70 batch loss 6.32720232\n",
      "Validated batch 71 batch loss 6.4567132\n",
      "Validated batch 72 batch loss 6.06484413\n",
      "Validated batch 73 batch loss 5.74425554\n",
      "Validated batch 74 batch loss 6.09533358\n",
      "Validated batch 75 batch loss 6.62655354\n",
      "Validated batch 76 batch loss 6.13731146\n",
      "Validated batch 77 batch loss 6.36932278\n",
      "Validated batch 78 batch loss 6.4265461\n",
      "Validated batch 79 batch loss 6.53616333\n",
      "Validated batch 80 batch loss 6.46798849\n",
      "Validated batch 81 batch loss 6.30311155\n",
      "Validated batch 82 batch loss 6.427\n",
      "Validated batch 83 batch loss 6.31893\n",
      "Validated batch 84 batch loss 6.56900215\n",
      "Validated batch 85 batch loss 6.67638588\n",
      "Validated batch 86 batch loss 6.2262454\n",
      "Validated batch 87 batch loss 6.6580019\n",
      "Validated batch 88 batch loss 6.45861578\n",
      "Validated batch 89 batch loss 6.04244566\n",
      "Validated batch 90 batch loss 6.27508831\n",
      "Validated batch 91 batch loss 6.44027\n",
      "Validated batch 92 batch loss 6.66045475\n",
      "Validated batch 93 batch loss 6.45209789\n",
      "Validated batch 94 batch loss 6.26724625\n",
      "Validated batch 95 batch loss 6.15387487\n",
      "Validated batch 96 batch loss 6.07349253\n",
      "Validated batch 97 batch loss 6.46909571\n",
      "Validated batch 98 batch loss 6.32467461\n",
      "Validated batch 99 batch loss 6.36228752\n",
      "Validated batch 100 batch loss 6.37199688\n",
      "Validated batch 101 batch loss 6.11934042\n",
      "Validated batch 102 batch loss 6.51909351\n",
      "Validated batch 103 batch loss 6.80948782\n",
      "Validated batch 104 batch loss 6.46725893\n",
      "Validated batch 105 batch loss 6.39665556\n",
      "Validated batch 106 batch loss 6.25968742\n",
      "Validated batch 107 batch loss 6.50105953\n",
      "Validated batch 108 batch loss 6.20525503\n",
      "Validated batch 109 batch loss 6.63494444\n",
      "Validated batch 110 batch loss 6.12549877\n",
      "Validated batch 111 batch loss 6.34459829\n",
      "Validated batch 112 batch loss 6.33593225\n",
      "Validated batch 113 batch loss 6.17035818\n",
      "Validated batch 114 batch loss 6.5098896\n",
      "Validated batch 115 batch loss 6.49793\n",
      "Validated batch 116 batch loss 6.64190912\n",
      "Validated batch 117 batch loss 6.40952063\n",
      "Validated batch 118 batch loss 6.18366241\n",
      "Validated batch 119 batch loss 6.05334854\n",
      "Validated batch 120 batch loss 6.17772579\n",
      "Validated batch 121 batch loss 6.41585302\n",
      "Validated batch 122 batch loss 6.10487461\n",
      "Validated batch 123 batch loss 6.33866358\n",
      "Validated batch 124 batch loss 6.42784739\n",
      "Validated batch 125 batch loss 6.4358716\n",
      "Validated batch 126 batch loss 6.19209814\n",
      "Validated batch 127 batch loss 6.02779055\n",
      "Validated batch 128 batch loss 6.23779202\n",
      "Validated batch 129 batch loss 6.72785139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 130 batch loss 6.23661566\n",
      "Validated batch 131 batch loss 6.27454519\n",
      "Validated batch 132 batch loss 6.23928881\n",
      "Validated batch 133 batch loss 5.96093369\n",
      "Validated batch 134 batch loss 5.83229685\n",
      "Validated batch 135 batch loss 6.35960817\n",
      "Validated batch 136 batch loss 6.09443569\n",
      "Validated batch 137 batch loss 6.08004856\n",
      "Validated batch 138 batch loss 6.35905266\n",
      "Validated batch 139 batch loss 6.39104366\n",
      "Validated batch 140 batch loss 6.48023\n",
      "Validated batch 141 batch loss 6.36020803\n",
      "Validated batch 142 batch loss 6.42738152\n",
      "Validated batch 143 batch loss 6.80018902\n",
      "Validated batch 144 batch loss 6.49669886\n",
      "Validated batch 145 batch loss 6.5459466\n",
      "Validated batch 146 batch loss 6.41363811\n",
      "Validated batch 147 batch loss 6.57814884\n",
      "Validated batch 148 batch loss 6.43143845\n",
      "Validated batch 149 batch loss 6.7925725\n",
      "Validated batch 150 batch loss 6.84182787\n",
      "Validated batch 151 batch loss 6.01486349\n",
      "Validated batch 152 batch loss 6.57431602\n",
      "Validated batch 153 batch loss 6.3073349\n",
      "Validated batch 154 batch loss 6.42821455\n",
      "Validated batch 155 batch loss 6.53274202\n",
      "Validated batch 156 batch loss 5.99216938\n",
      "Validated batch 157 batch loss 6.07132673\n",
      "Validated batch 158 batch loss 6.49319267\n",
      "Validated batch 159 batch loss 6.30252314\n",
      "Validated batch 160 batch loss 6.79288435\n",
      "Validated batch 161 batch loss 6.28941107\n",
      "Validated batch 162 batch loss 6.27292\n",
      "Validated batch 163 batch loss 6.46257067\n",
      "Validated batch 164 batch loss 6.44218826\n",
      "Validated batch 165 batch loss 6.55257511\n",
      "Validated batch 166 batch loss 6.36185265\n",
      "Validated batch 167 batch loss 6.58848572\n",
      "Validated batch 168 batch loss 6.19443893\n",
      "Validated batch 169 batch loss 6.73105621\n",
      "Validated batch 170 batch loss 6.27058935\n",
      "Validated batch 171 batch loss 6.3588748\n",
      "Validated batch 172 batch loss 6.40740108\n",
      "Validated batch 173 batch loss 6.15824032\n",
      "Validated batch 174 batch loss 5.40185547\n",
      "Validated batch 175 batch loss 6.51938438\n",
      "Validated batch 176 batch loss 6.51137304\n",
      "Validated batch 177 batch loss 6.40187454\n",
      "Validated batch 178 batch loss 6.27527046\n",
      "Validated batch 179 batch loss 6.46784544\n",
      "Validated batch 180 batch loss 6.54450321\n",
      "Validated batch 181 batch loss 6.51825\n",
      "Validated batch 182 batch loss 6.45194149\n",
      "Validated batch 183 batch loss 6.47362757\n",
      "Validated batch 184 batch loss 5.81878281\n",
      "Validated batch 185 batch loss 3.13813519\n",
      "Epoch 1 val loss 6.33065938949585\n",
      "Model /aiffel/aiffel/mpii/models1/simple_baseline-epoch-1-loss-6.3307.h5 saved.\n",
      "Start epoch 2 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 6.67483377 epoch total loss 6.67483377\n",
      "Trained batch 2 batch loss 6.3461957 epoch total loss 6.51051474\n",
      "Trained batch 3 batch loss 6.39275932 epoch total loss 6.47126245\n",
      "Trained batch 4 batch loss 6.3243928 epoch total loss 6.43454504\n",
      "Trained batch 5 batch loss 6.21220827 epoch total loss 6.39007759\n",
      "Trained batch 6 batch loss 6.64574575 epoch total loss 6.43268919\n",
      "Trained batch 7 batch loss 6.58632803 epoch total loss 6.45463705\n",
      "Trained batch 8 batch loss 6.41441393 epoch total loss 6.44960928\n",
      "Trained batch 9 batch loss 6.53048038 epoch total loss 6.4585948\n",
      "Trained batch 10 batch loss 6.5493536 epoch total loss 6.46767044\n",
      "Trained batch 11 batch loss 6.85793591 epoch total loss 6.50314903\n",
      "Trained batch 12 batch loss 6.83257 epoch total loss 6.53060102\n",
      "Trained batch 13 batch loss 6.96261311 epoch total loss 6.56383276\n",
      "Trained batch 14 batch loss 6.86414957 epoch total loss 6.58528423\n",
      "Trained batch 15 batch loss 6.70642948 epoch total loss 6.59336042\n",
      "Trained batch 16 batch loss 6.64881897 epoch total loss 6.59682655\n",
      "Trained batch 17 batch loss 6.56544399 epoch total loss 6.59498072\n",
      "Trained batch 18 batch loss 6.81024647 epoch total loss 6.60694\n",
      "Trained batch 19 batch loss 6.7495904 epoch total loss 6.61444759\n",
      "Trained batch 20 batch loss 6.42093897 epoch total loss 6.60477209\n",
      "Trained batch 21 batch loss 6.44015169 epoch total loss 6.59693336\n",
      "Trained batch 22 batch loss 6.5603323 epoch total loss 6.59526968\n",
      "Trained batch 23 batch loss 6.12619591 epoch total loss 6.57487488\n",
      "Trained batch 24 batch loss 6.31361628 epoch total loss 6.56398916\n",
      "Trained batch 25 batch loss 5.81380749 epoch total loss 6.5339818\n",
      "Trained batch 26 batch loss 5.59581089 epoch total loss 6.49789858\n",
      "Trained batch 27 batch loss 6.20256186 epoch total loss 6.48696\n",
      "Trained batch 28 batch loss 7.10809565 epoch total loss 6.50914335\n",
      "Trained batch 29 batch loss 7.08985949 epoch total loss 6.52916813\n",
      "Trained batch 30 batch loss 6.78745222 epoch total loss 6.53777742\n",
      "Trained batch 31 batch loss 6.69457531 epoch total loss 6.54283524\n",
      "Trained batch 32 batch loss 6.97954512 epoch total loss 6.55648232\n",
      "Trained batch 33 batch loss 6.3796649 epoch total loss 6.55112457\n",
      "Trained batch 34 batch loss 6.83426857 epoch total loss 6.55945206\n",
      "Trained batch 35 batch loss 6.38767815 epoch total loss 6.55454445\n",
      "Trained batch 36 batch loss 6.59715462 epoch total loss 6.55572796\n",
      "Trained batch 37 batch loss 6.31683636 epoch total loss 6.54927158\n",
      "Trained batch 38 batch loss 6.51113129 epoch total loss 6.54826736\n",
      "Trained batch 39 batch loss 6.58413219 epoch total loss 6.54918718\n",
      "Trained batch 40 batch loss 6.6804924 epoch total loss 6.55246973\n",
      "Trained batch 41 batch loss 6.53641081 epoch total loss 6.55207777\n",
      "Trained batch 42 batch loss 6.41441536 epoch total loss 6.54880047\n",
      "Trained batch 43 batch loss 6.63432217 epoch total loss 6.55078888\n",
      "Trained batch 44 batch loss 6.49995613 epoch total loss 6.54963398\n",
      "Trained batch 45 batch loss 6.52056217 epoch total loss 6.54898834\n",
      "Trained batch 46 batch loss 5.78317642 epoch total loss 6.53234\n",
      "Trained batch 47 batch loss 5.37912512 epoch total loss 6.50780344\n",
      "Trained batch 48 batch loss 6.11066961 epoch total loss 6.49952936\n",
      "Trained batch 49 batch loss 6.37389803 epoch total loss 6.49696589\n",
      "Trained batch 50 batch loss 6.41572714 epoch total loss 6.4953413\n",
      "Trained batch 51 batch loss 6.39103079 epoch total loss 6.49329567\n",
      "Trained batch 52 batch loss 6.45611048 epoch total loss 6.49258089\n",
      "Trained batch 53 batch loss 6.31337738 epoch total loss 6.48919964\n",
      "Trained batch 54 batch loss 6.19303703 epoch total loss 6.48371506\n",
      "Trained batch 55 batch loss 6.72777033 epoch total loss 6.4881525\n",
      "Trained batch 56 batch loss 6.27812529 epoch total loss 6.48440218\n",
      "Trained batch 57 batch loss 5.90329552 epoch total loss 6.4742074\n",
      "Trained batch 58 batch loss 6.07038641 epoch total loss 6.46724463\n",
      "Trained batch 59 batch loss 6.28238106 epoch total loss 6.46411133\n",
      "Trained batch 60 batch loss 6.33453321 epoch total loss 6.46195173\n",
      "Trained batch 61 batch loss 6.34684277 epoch total loss 6.46006441\n",
      "Trained batch 62 batch loss 6.48142815 epoch total loss 6.46040869\n",
      "Trained batch 63 batch loss 6.34037447 epoch total loss 6.45850325\n",
      "Trained batch 64 batch loss 6.364429 epoch total loss 6.45703363\n",
      "Trained batch 65 batch loss 6.55506516 epoch total loss 6.45854187\n",
      "Trained batch 66 batch loss 6.24688816 epoch total loss 6.45533466\n",
      "Trained batch 67 batch loss 6.33305216 epoch total loss 6.45350933\n",
      "Trained batch 68 batch loss 6.39715338 epoch total loss 6.45268059\n",
      "Trained batch 69 batch loss 6.40354252 epoch total loss 6.45196819\n",
      "Trained batch 70 batch loss 6.21700287 epoch total loss 6.44861174\n",
      "Trained batch 71 batch loss 6.69893026 epoch total loss 6.45213747\n",
      "Trained batch 72 batch loss 6.16609192 epoch total loss 6.44816494\n",
      "Trained batch 73 batch loss 5.77051926 epoch total loss 6.43888187\n",
      "Trained batch 74 batch loss 5.43809509 epoch total loss 6.4253583\n",
      "Trained batch 75 batch loss 5.19436502 epoch total loss 6.40894508\n",
      "Trained batch 76 batch loss 5.82646322 epoch total loss 6.40128088\n",
      "Trained batch 77 batch loss 6.49495 epoch total loss 6.40249729\n",
      "Trained batch 78 batch loss 6.54647255 epoch total loss 6.40434361\n",
      "Trained batch 79 batch loss 6.10623646 epoch total loss 6.40057\n",
      "Trained batch 80 batch loss 6.06254339 epoch total loss 6.39634418\n",
      "Trained batch 81 batch loss 6.61749744 epoch total loss 6.39907503\n",
      "Trained batch 82 batch loss 5.84434032 epoch total loss 6.39231\n",
      "Trained batch 83 batch loss 6.16041374 epoch total loss 6.38951588\n",
      "Trained batch 84 batch loss 6.03734636 epoch total loss 6.38532352\n",
      "Trained batch 85 batch loss 5.89419 epoch total loss 6.37954521\n",
      "Trained batch 86 batch loss 6.066401 epoch total loss 6.37590408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 87 batch loss 6.43734169 epoch total loss 6.37661028\n",
      "Trained batch 88 batch loss 6.55123186 epoch total loss 6.37859392\n",
      "Trained batch 89 batch loss 6.6529603 epoch total loss 6.38167667\n",
      "Trained batch 90 batch loss 6.47863674 epoch total loss 6.38275433\n",
      "Trained batch 91 batch loss 5.83064365 epoch total loss 6.37668705\n",
      "Trained batch 92 batch loss 6.40377283 epoch total loss 6.37698078\n",
      "Trained batch 93 batch loss 6.21642733 epoch total loss 6.37525463\n",
      "Trained batch 94 batch loss 6.15722656 epoch total loss 6.3729353\n",
      "Trained batch 95 batch loss 6.31819534 epoch total loss 6.3723588\n",
      "Trained batch 96 batch loss 6.35328388 epoch total loss 6.37216\n",
      "Trained batch 97 batch loss 5.96667 epoch total loss 6.36797953\n",
      "Trained batch 98 batch loss 6.45533657 epoch total loss 6.36887074\n",
      "Trained batch 99 batch loss 6.5159173 epoch total loss 6.37035656\n",
      "Trained batch 100 batch loss 6.49771786 epoch total loss 6.37163\n",
      "Trained batch 101 batch loss 6.28768444 epoch total loss 6.37079906\n",
      "Trained batch 102 batch loss 6.72577429 epoch total loss 6.37427902\n",
      "Trained batch 103 batch loss 6.49359369 epoch total loss 6.37543726\n",
      "Trained batch 104 batch loss 6.75033092 epoch total loss 6.37904167\n",
      "Trained batch 105 batch loss 6.58260441 epoch total loss 6.38098049\n",
      "Trained batch 106 batch loss 6.30683947 epoch total loss 6.38028049\n",
      "Trained batch 107 batch loss 6.12773609 epoch total loss 6.37792063\n",
      "Trained batch 108 batch loss 6.12934685 epoch total loss 6.37561893\n",
      "Trained batch 109 batch loss 6.31207323 epoch total loss 6.37503576\n",
      "Trained batch 110 batch loss 6.15318298 epoch total loss 6.37301922\n",
      "Trained batch 111 batch loss 6.26095152 epoch total loss 6.37200928\n",
      "Trained batch 112 batch loss 6.19805765 epoch total loss 6.37045622\n",
      "Trained batch 113 batch loss 5.8672986 epoch total loss 6.36600351\n",
      "Trained batch 114 batch loss 6.2106986 epoch total loss 6.36464119\n",
      "Trained batch 115 batch loss 6.21387434 epoch total loss 6.36333\n",
      "Trained batch 116 batch loss 5.87147951 epoch total loss 6.35909\n",
      "Trained batch 117 batch loss 6.20253086 epoch total loss 6.35775137\n",
      "Trained batch 118 batch loss 5.53216 epoch total loss 6.35075521\n",
      "Trained batch 119 batch loss 5.75044584 epoch total loss 6.34571028\n",
      "Trained batch 120 batch loss 5.86484718 epoch total loss 6.34170341\n",
      "Trained batch 121 batch loss 5.75174093 epoch total loss 6.33682775\n",
      "Trained batch 122 batch loss 6.05460072 epoch total loss 6.33451462\n",
      "Trained batch 123 batch loss 6.29766 epoch total loss 6.33421516\n",
      "Trained batch 124 batch loss 6.41413832 epoch total loss 6.33485937\n",
      "Trained batch 125 batch loss 6.29345226 epoch total loss 6.33452845\n",
      "Trained batch 126 batch loss 6.48587704 epoch total loss 6.3357296\n",
      "Trained batch 127 batch loss 6.61605358 epoch total loss 6.33793688\n",
      "Trained batch 128 batch loss 6.56912613 epoch total loss 6.33974314\n",
      "Trained batch 129 batch loss 6.61419916 epoch total loss 6.34187078\n",
      "Trained batch 130 batch loss 6.55912638 epoch total loss 6.3435421\n",
      "Trained batch 131 batch loss 6.14524221 epoch total loss 6.34202862\n",
      "Trained batch 132 batch loss 6.170928 epoch total loss 6.3407321\n",
      "Trained batch 133 batch loss 6.1914196 epoch total loss 6.33960915\n",
      "Trained batch 134 batch loss 5.92438316 epoch total loss 6.33651066\n",
      "Trained batch 135 batch loss 5.82240677 epoch total loss 6.33270216\n",
      "Trained batch 136 batch loss 5.77878284 epoch total loss 6.32862949\n",
      "Trained batch 137 batch loss 5.79425573 epoch total loss 6.32472897\n",
      "Trained batch 138 batch loss 6.08350039 epoch total loss 6.32298088\n",
      "Trained batch 139 batch loss 6.32460737 epoch total loss 6.32299232\n",
      "Trained batch 140 batch loss 6.81894493 epoch total loss 6.32653522\n",
      "Trained batch 141 batch loss 6.39623833 epoch total loss 6.32702923\n",
      "Trained batch 142 batch loss 6.41261721 epoch total loss 6.32763195\n",
      "Trained batch 143 batch loss 6.36305761 epoch total loss 6.32787943\n",
      "Trained batch 144 batch loss 6.20391846 epoch total loss 6.32701874\n",
      "Trained batch 145 batch loss 5.82989264 epoch total loss 6.32359028\n",
      "Trained batch 146 batch loss 6.05998611 epoch total loss 6.32178497\n",
      "Trained batch 147 batch loss 6.39629698 epoch total loss 6.32229185\n",
      "Trained batch 148 batch loss 6.41623497 epoch total loss 6.32292652\n",
      "Trained batch 149 batch loss 6.31804323 epoch total loss 6.3228941\n",
      "Trained batch 150 batch loss 6.53428411 epoch total loss 6.32430315\n",
      "Trained batch 151 batch loss 6.43669319 epoch total loss 6.32504797\n",
      "Trained batch 152 batch loss 5.89713144 epoch total loss 6.32223272\n",
      "Trained batch 153 batch loss 6.00465 epoch total loss 6.32015705\n",
      "Trained batch 154 batch loss 6.28788662 epoch total loss 6.31994724\n",
      "Trained batch 155 batch loss 6.33870459 epoch total loss 6.32006836\n",
      "Trained batch 156 batch loss 6.6980691 epoch total loss 6.32249117\n",
      "Trained batch 157 batch loss 6.36201143 epoch total loss 6.32274294\n",
      "Trained batch 158 batch loss 6.46420336 epoch total loss 6.32363844\n",
      "Trained batch 159 batch loss 6.44991064 epoch total loss 6.32443237\n",
      "Trained batch 160 batch loss 6.50685024 epoch total loss 6.32557249\n",
      "Trained batch 161 batch loss 6.42425632 epoch total loss 6.3261857\n",
      "Trained batch 162 batch loss 6.4341836 epoch total loss 6.32685232\n",
      "Trained batch 163 batch loss 6.44068193 epoch total loss 6.32755041\n",
      "Trained batch 164 batch loss 6.61264 epoch total loss 6.32928896\n",
      "Trained batch 165 batch loss 6.18796062 epoch total loss 6.32843256\n",
      "Trained batch 166 batch loss 5.99393 epoch total loss 6.32641745\n",
      "Trained batch 167 batch loss 6.05834 epoch total loss 6.32481241\n",
      "Trained batch 168 batch loss 5.56288242 epoch total loss 6.32027674\n",
      "Trained batch 169 batch loss 5.80001831 epoch total loss 6.31719875\n",
      "Trained batch 170 batch loss 6.30700493 epoch total loss 6.31713867\n",
      "Trained batch 171 batch loss 6.47562504 epoch total loss 6.31806517\n",
      "Trained batch 172 batch loss 6.86098623 epoch total loss 6.32122183\n",
      "Trained batch 173 batch loss 7.25834942 epoch total loss 6.32663822\n",
      "Trained batch 174 batch loss 6.6525445 epoch total loss 6.32851171\n",
      "Trained batch 175 batch loss 6.22643948 epoch total loss 6.32792807\n",
      "Trained batch 176 batch loss 6.2963047 epoch total loss 6.3277483\n",
      "Trained batch 177 batch loss 6.50753593 epoch total loss 6.32876444\n",
      "Trained batch 178 batch loss 6.70530415 epoch total loss 6.33087969\n",
      "Trained batch 179 batch loss 6.91598606 epoch total loss 6.33414888\n",
      "Trained batch 180 batch loss 6.99109602 epoch total loss 6.3377986\n",
      "Trained batch 181 batch loss 6.514112 epoch total loss 6.33877277\n",
      "Trained batch 182 batch loss 5.68188286 epoch total loss 6.33516359\n",
      "Trained batch 183 batch loss 6.20473289 epoch total loss 6.33445072\n",
      "Trained batch 184 batch loss 6.19920683 epoch total loss 6.33371592\n",
      "Trained batch 185 batch loss 6.36670065 epoch total loss 6.33389378\n",
      "Trained batch 186 batch loss 6.49485779 epoch total loss 6.33475924\n",
      "Trained batch 187 batch loss 6.54647875 epoch total loss 6.33589172\n",
      "Trained batch 188 batch loss 6.46590853 epoch total loss 6.33658361\n",
      "Trained batch 189 batch loss 6.42289972 epoch total loss 6.33704\n",
      "Trained batch 190 batch loss 6.46162319 epoch total loss 6.33769608\n",
      "Trained batch 191 batch loss 6.30578423 epoch total loss 6.33752871\n",
      "Trained batch 192 batch loss 6.40444613 epoch total loss 6.33787727\n",
      "Trained batch 193 batch loss 6.41982841 epoch total loss 6.33830166\n",
      "Trained batch 194 batch loss 6.38893509 epoch total loss 6.33856249\n",
      "Trained batch 195 batch loss 6.48008585 epoch total loss 6.33928871\n",
      "Trained batch 196 batch loss 6.71248198 epoch total loss 6.34119272\n",
      "Trained batch 197 batch loss 7.12375 epoch total loss 6.34516525\n",
      "Trained batch 198 batch loss 6.58442068 epoch total loss 6.34637403\n",
      "Trained batch 199 batch loss 6.4890995 epoch total loss 6.3470912\n",
      "Trained batch 200 batch loss 6.46169949 epoch total loss 6.34766436\n",
      "Trained batch 201 batch loss 6.37370968 epoch total loss 6.34779358\n",
      "Trained batch 202 batch loss 6.40535927 epoch total loss 6.34807873\n",
      "Trained batch 203 batch loss 6.51662683 epoch total loss 6.3489089\n",
      "Trained batch 204 batch loss 6.52892637 epoch total loss 6.34979105\n",
      "Trained batch 205 batch loss 6.39720678 epoch total loss 6.35002279\n",
      "Trained batch 206 batch loss 6.39415932 epoch total loss 6.35023689\n",
      "Trained batch 207 batch loss 6.29674911 epoch total loss 6.34997845\n",
      "Trained batch 208 batch loss 6.27138329 epoch total loss 6.34960079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 209 batch loss 6.6638751 epoch total loss 6.35110378\n",
      "Trained batch 210 batch loss 6.45479727 epoch total loss 6.35159779\n",
      "Trained batch 211 batch loss 6.44108915 epoch total loss 6.35202169\n",
      "Trained batch 212 batch loss 6.45664644 epoch total loss 6.35251522\n",
      "Trained batch 213 batch loss 6.55824471 epoch total loss 6.35348129\n",
      "Trained batch 214 batch loss 6.12294579 epoch total loss 6.35240364\n",
      "Trained batch 215 batch loss 5.65803242 epoch total loss 6.3491745\n",
      "Trained batch 216 batch loss 5.95537853 epoch total loss 6.34735107\n",
      "Trained batch 217 batch loss 6.190166 epoch total loss 6.34662676\n",
      "Trained batch 218 batch loss 6.02246618 epoch total loss 6.34514\n",
      "Trained batch 219 batch loss 6.33958054 epoch total loss 6.34511471\n",
      "Trained batch 220 batch loss 6.2996254 epoch total loss 6.34490824\n",
      "Trained batch 221 batch loss 6.44148254 epoch total loss 6.34534502\n",
      "Trained batch 222 batch loss 6.84693384 epoch total loss 6.34760475\n",
      "Trained batch 223 batch loss 6.49621964 epoch total loss 6.34827089\n",
      "Trained batch 224 batch loss 6.13122892 epoch total loss 6.34730196\n",
      "Trained batch 225 batch loss 6.36517572 epoch total loss 6.34738159\n",
      "Trained batch 226 batch loss 6.73945475 epoch total loss 6.3491168\n",
      "Trained batch 227 batch loss 6.29802561 epoch total loss 6.34889126\n",
      "Trained batch 228 batch loss 6.42700624 epoch total loss 6.3492341\n",
      "Trained batch 229 batch loss 5.816535 epoch total loss 6.34690762\n",
      "Trained batch 230 batch loss 6.35584259 epoch total loss 6.34694672\n",
      "Trained batch 231 batch loss 6.27858829 epoch total loss 6.3466506\n",
      "Trained batch 232 batch loss 6.47673368 epoch total loss 6.34721088\n",
      "Trained batch 233 batch loss 6.47799063 epoch total loss 6.3477726\n",
      "Trained batch 234 batch loss 6.43168449 epoch total loss 6.34813118\n",
      "Trained batch 235 batch loss 6.39160633 epoch total loss 6.34831572\n",
      "Trained batch 236 batch loss 6.26037216 epoch total loss 6.34794331\n",
      "Trained batch 237 batch loss 6.31559515 epoch total loss 6.34780645\n",
      "Trained batch 238 batch loss 6.24960327 epoch total loss 6.34739399\n",
      "Trained batch 239 batch loss 6.55890417 epoch total loss 6.34827948\n",
      "Trained batch 240 batch loss 6.43975401 epoch total loss 6.34866047\n",
      "Trained batch 241 batch loss 6.26569462 epoch total loss 6.34831619\n",
      "Trained batch 242 batch loss 6.478302 epoch total loss 6.34885311\n",
      "Trained batch 243 batch loss 5.8304019 epoch total loss 6.34671974\n",
      "Trained batch 244 batch loss 6.15422153 epoch total loss 6.34593058\n",
      "Trained batch 245 batch loss 6.45465851 epoch total loss 6.34637499\n",
      "Trained batch 246 batch loss 6.36844635 epoch total loss 6.34646416\n",
      "Trained batch 247 batch loss 6.55416679 epoch total loss 6.3473053\n",
      "Trained batch 248 batch loss 6.1981163 epoch total loss 6.34670401\n",
      "Trained batch 249 batch loss 6.36722803 epoch total loss 6.34678602\n",
      "Trained batch 250 batch loss 6.29566669 epoch total loss 6.34658146\n",
      "Trained batch 251 batch loss 6.21511936 epoch total loss 6.34605789\n",
      "Trained batch 252 batch loss 6.161695 epoch total loss 6.34532642\n",
      "Trained batch 253 batch loss 6.28143167 epoch total loss 6.3450737\n",
      "Trained batch 254 batch loss 6.14968157 epoch total loss 6.34430408\n",
      "Trained batch 255 batch loss 6.58338499 epoch total loss 6.34524155\n",
      "Trained batch 256 batch loss 7.20999527 epoch total loss 6.34861946\n",
      "Trained batch 257 batch loss 6.89874172 epoch total loss 6.35076\n",
      "Trained batch 258 batch loss 7.07228327 epoch total loss 6.35355616\n",
      "Trained batch 259 batch loss 6.73249865 epoch total loss 6.35501957\n",
      "Trained batch 260 batch loss 6.19171095 epoch total loss 6.3543911\n",
      "Trained batch 261 batch loss 6.28329897 epoch total loss 6.35411882\n",
      "Trained batch 262 batch loss 6.52527285 epoch total loss 6.35477209\n",
      "Trained batch 263 batch loss 6.41766548 epoch total loss 6.35501146\n",
      "Trained batch 264 batch loss 6.30986261 epoch total loss 6.35484028\n",
      "Trained batch 265 batch loss 6.28827429 epoch total loss 6.35458946\n",
      "Trained batch 266 batch loss 6.37285089 epoch total loss 6.35465765\n",
      "Trained batch 267 batch loss 6.81342745 epoch total loss 6.35637617\n",
      "Trained batch 268 batch loss 6.90614 epoch total loss 6.35842752\n",
      "Trained batch 269 batch loss 6.46885061 epoch total loss 6.35883808\n",
      "Trained batch 270 batch loss 6.52666092 epoch total loss 6.3594594\n",
      "Trained batch 271 batch loss 6.77397108 epoch total loss 6.36098909\n",
      "Trained batch 272 batch loss 6.42011166 epoch total loss 6.36120653\n",
      "Trained batch 273 batch loss 6.4253664 epoch total loss 6.36144161\n",
      "Trained batch 274 batch loss 6.46597815 epoch total loss 6.36182308\n",
      "Trained batch 275 batch loss 6.32732153 epoch total loss 6.36169767\n",
      "Trained batch 276 batch loss 6.68528223 epoch total loss 6.36286974\n",
      "Trained batch 277 batch loss 6.8330884 epoch total loss 6.36456776\n",
      "Trained batch 278 batch loss 6.13463831 epoch total loss 6.36374044\n",
      "Trained batch 279 batch loss 6.72816229 epoch total loss 6.3650465\n",
      "Trained batch 280 batch loss 6.32648 epoch total loss 6.36490917\n",
      "Trained batch 281 batch loss 6.53066587 epoch total loss 6.36549902\n",
      "Trained batch 282 batch loss 6.8211441 epoch total loss 6.36711454\n",
      "Trained batch 283 batch loss 6.80851555 epoch total loss 6.36867428\n",
      "Trained batch 284 batch loss 6.28222513 epoch total loss 6.36837\n",
      "Trained batch 285 batch loss 6.78691244 epoch total loss 6.36983824\n",
      "Trained batch 286 batch loss 6.44229364 epoch total loss 6.37009144\n",
      "Trained batch 287 batch loss 6.5381422 epoch total loss 6.37067699\n",
      "Trained batch 288 batch loss 6.60603666 epoch total loss 6.37149429\n",
      "Trained batch 289 batch loss 6.49137926 epoch total loss 6.37190914\n",
      "Trained batch 290 batch loss 6.35523272 epoch total loss 6.37185144\n",
      "Trained batch 291 batch loss 6.50847149 epoch total loss 6.37232065\n",
      "Trained batch 292 batch loss 6.75523043 epoch total loss 6.37363195\n",
      "Trained batch 293 batch loss 6.18874693 epoch total loss 6.3730011\n",
      "Trained batch 294 batch loss 5.98539352 epoch total loss 6.37168264\n",
      "Trained batch 295 batch loss 6.36990261 epoch total loss 6.37167645\n",
      "Trained batch 296 batch loss 6.50833035 epoch total loss 6.37213802\n",
      "Trained batch 297 batch loss 6.64075041 epoch total loss 6.37304258\n",
      "Trained batch 298 batch loss 6.2511692 epoch total loss 6.37263346\n",
      "Trained batch 299 batch loss 6.54701805 epoch total loss 6.37321663\n",
      "Trained batch 300 batch loss 6.73692369 epoch total loss 6.37442923\n",
      "Trained batch 301 batch loss 6.72423601 epoch total loss 6.37559128\n",
      "Trained batch 302 batch loss 6.42923403 epoch total loss 6.37576866\n",
      "Trained batch 303 batch loss 6.50752735 epoch total loss 6.37620401\n",
      "Trained batch 304 batch loss 6.99682236 epoch total loss 6.37824535\n",
      "Trained batch 305 batch loss 6.90457344 epoch total loss 6.37997103\n",
      "Trained batch 306 batch loss 6.77649927 epoch total loss 6.38126659\n",
      "Trained batch 307 batch loss 6.2304821 epoch total loss 6.38077545\n",
      "Trained batch 308 batch loss 6.79730034 epoch total loss 6.38212776\n",
      "Trained batch 309 batch loss 6.52155876 epoch total loss 6.38257885\n",
      "Trained batch 310 batch loss 6.50998497 epoch total loss 6.38299\n",
      "Trained batch 311 batch loss 6.34712601 epoch total loss 6.38287497\n",
      "Trained batch 312 batch loss 6.42285872 epoch total loss 6.38300323\n",
      "Trained batch 313 batch loss 6.23809767 epoch total loss 6.38253975\n",
      "Trained batch 314 batch loss 6.4155097 epoch total loss 6.38264513\n",
      "Trained batch 315 batch loss 6.53071642 epoch total loss 6.38311529\n",
      "Trained batch 316 batch loss 6.62619877 epoch total loss 6.38388443\n",
      "Trained batch 317 batch loss 6.58233452 epoch total loss 6.38451052\n",
      "Trained batch 318 batch loss 6.54240227 epoch total loss 6.3850069\n",
      "Trained batch 319 batch loss 6.64873171 epoch total loss 6.38583326\n",
      "Trained batch 320 batch loss 6.6015811 epoch total loss 6.38650751\n",
      "Trained batch 321 batch loss 6.45542431 epoch total loss 6.38672161\n",
      "Trained batch 322 batch loss 5.90267372 epoch total loss 6.38521814\n",
      "Trained batch 323 batch loss 6.37342453 epoch total loss 6.3851819\n",
      "Trained batch 324 batch loss 5.98436546 epoch total loss 6.38394499\n",
      "Trained batch 325 batch loss 6.41634178 epoch total loss 6.38404465\n",
      "Trained batch 326 batch loss 6.26361036 epoch total loss 6.3836751\n",
      "Trained batch 327 batch loss 6.47415972 epoch total loss 6.38395166\n",
      "Trained batch 328 batch loss 6.38755 epoch total loss 6.38396263\n",
      "Trained batch 329 batch loss 6.50285721 epoch total loss 6.38432407\n",
      "Trained batch 330 batch loss 6.35249186 epoch total loss 6.38422775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 331 batch loss 6.24434805 epoch total loss 6.38380527\n",
      "Trained batch 332 batch loss 6.38947582 epoch total loss 6.38382196\n",
      "Trained batch 333 batch loss 6.49008846 epoch total loss 6.38414097\n",
      "Trained batch 334 batch loss 6.25213814 epoch total loss 6.38374615\n",
      "Trained batch 335 batch loss 6.60407066 epoch total loss 6.38440323\n",
      "Trained batch 336 batch loss 6.32439804 epoch total loss 6.38422489\n",
      "Trained batch 337 batch loss 6.18168068 epoch total loss 6.38362408\n",
      "Trained batch 338 batch loss 6.34744692 epoch total loss 6.38351679\n",
      "Trained batch 339 batch loss 6.69544125 epoch total loss 6.38443708\n",
      "Trained batch 340 batch loss 6.52696133 epoch total loss 6.38485622\n",
      "Trained batch 341 batch loss 6.72113705 epoch total loss 6.38584232\n",
      "Trained batch 342 batch loss 6.73421574 epoch total loss 6.38686085\n",
      "Trained batch 343 batch loss 6.51571274 epoch total loss 6.38723612\n",
      "Trained batch 344 batch loss 6.30685425 epoch total loss 6.38700247\n",
      "Trained batch 345 batch loss 6.68841553 epoch total loss 6.38787651\n",
      "Trained batch 346 batch loss 6.55851221 epoch total loss 6.38837\n",
      "Trained batch 347 batch loss 6.38226461 epoch total loss 6.38835239\n",
      "Trained batch 348 batch loss 5.62042236 epoch total loss 6.38614559\n",
      "Trained batch 349 batch loss 5.99473619 epoch total loss 6.38502359\n",
      "Trained batch 350 batch loss 6.24402428 epoch total loss 6.38462114\n",
      "Trained batch 351 batch loss 6.44625664 epoch total loss 6.3847971\n",
      "Trained batch 352 batch loss 6.57193184 epoch total loss 6.38532877\n",
      "Trained batch 353 batch loss 6.22943068 epoch total loss 6.38488722\n",
      "Trained batch 354 batch loss 6.04379845 epoch total loss 6.38392353\n",
      "Trained batch 355 batch loss 5.98391151 epoch total loss 6.38279676\n",
      "Trained batch 356 batch loss 6.26007032 epoch total loss 6.38245201\n",
      "Trained batch 357 batch loss 6.51981878 epoch total loss 6.38283634\n",
      "Trained batch 358 batch loss 6.37710667 epoch total loss 6.38282061\n",
      "Trained batch 359 batch loss 6.22265482 epoch total loss 6.38237476\n",
      "Trained batch 360 batch loss 6.29776382 epoch total loss 6.38213968\n",
      "Trained batch 361 batch loss 6.60429573 epoch total loss 6.3827548\n",
      "Trained batch 362 batch loss 6.57751608 epoch total loss 6.38329315\n",
      "Trained batch 363 batch loss 6.47799206 epoch total loss 6.38355446\n",
      "Trained batch 364 batch loss 6.70025396 epoch total loss 6.38442421\n",
      "Trained batch 365 batch loss 6.47268391 epoch total loss 6.38466597\n",
      "Trained batch 366 batch loss 6.25659752 epoch total loss 6.38431597\n",
      "Trained batch 367 batch loss 6.37368536 epoch total loss 6.38428736\n",
      "Trained batch 368 batch loss 6.26829863 epoch total loss 6.38397217\n",
      "Trained batch 369 batch loss 6.20393038 epoch total loss 6.38348389\n",
      "Trained batch 370 batch loss 6.43623543 epoch total loss 6.38362694\n",
      "Trained batch 371 batch loss 6.29183 epoch total loss 6.38337898\n",
      "Trained batch 372 batch loss 6.04049 epoch total loss 6.38245726\n",
      "Trained batch 373 batch loss 6.43475962 epoch total loss 6.38259792\n",
      "Trained batch 374 batch loss 5.86983442 epoch total loss 6.38122702\n",
      "Trained batch 375 batch loss 6.2161622 epoch total loss 6.38078642\n",
      "Trained batch 376 batch loss 6.29900503 epoch total loss 6.38056898\n",
      "Trained batch 377 batch loss 6.39292192 epoch total loss 6.38060141\n",
      "Trained batch 378 batch loss 6.55604172 epoch total loss 6.38106585\n",
      "Trained batch 379 batch loss 6.31570816 epoch total loss 6.38089371\n",
      "Trained batch 380 batch loss 6.50488806 epoch total loss 6.38122\n",
      "Trained batch 381 batch loss 6.16129684 epoch total loss 6.38064289\n",
      "Trained batch 382 batch loss 6.24977398 epoch total loss 6.3803\n",
      "Trained batch 383 batch loss 6.34732866 epoch total loss 6.38021421\n",
      "Trained batch 384 batch loss 5.96551132 epoch total loss 6.37913465\n",
      "Trained batch 385 batch loss 5.99923134 epoch total loss 6.3781476\n",
      "Trained batch 386 batch loss 6.304883 epoch total loss 6.3779583\n",
      "Trained batch 387 batch loss 6.48866558 epoch total loss 6.3782444\n",
      "Trained batch 388 batch loss 6.50858116 epoch total loss 6.37858\n",
      "Trained batch 389 batch loss 6.17632627 epoch total loss 6.37806034\n",
      "Trained batch 390 batch loss 6.29033518 epoch total loss 6.37783527\n",
      "Trained batch 391 batch loss 6.16545 epoch total loss 6.37729216\n",
      "Trained batch 392 batch loss 6.60729885 epoch total loss 6.37787867\n",
      "Trained batch 393 batch loss 6.14189911 epoch total loss 6.37727785\n",
      "Trained batch 394 batch loss 6.30999613 epoch total loss 6.37710762\n",
      "Trained batch 395 batch loss 6.6053133 epoch total loss 6.37768507\n",
      "Trained batch 396 batch loss 6.45077896 epoch total loss 6.37786913\n",
      "Trained batch 397 batch loss 6.37659454 epoch total loss 6.37786627\n",
      "Trained batch 398 batch loss 6.26696396 epoch total loss 6.37758732\n",
      "Trained batch 399 batch loss 6.20537 epoch total loss 6.37715578\n",
      "Trained batch 400 batch loss 6.08427286 epoch total loss 6.37642336\n",
      "Trained batch 401 batch loss 6.30142498 epoch total loss 6.37623644\n",
      "Trained batch 402 batch loss 6.59421587 epoch total loss 6.3767786\n",
      "Trained batch 403 batch loss 6.5529356 epoch total loss 6.37721586\n",
      "Trained batch 404 batch loss 6.96635294 epoch total loss 6.37867403\n",
      "Trained batch 405 batch loss 7.39605904 epoch total loss 6.38118601\n",
      "Trained batch 406 batch loss 7.08596182 epoch total loss 6.38292217\n",
      "Trained batch 407 batch loss 6.78352213 epoch total loss 6.38390589\n",
      "Trained batch 408 batch loss 5.88889265 epoch total loss 6.38269281\n",
      "Trained batch 409 batch loss 5.69863844 epoch total loss 6.38102055\n",
      "Trained batch 410 batch loss 5.31497049 epoch total loss 6.37842035\n",
      "Trained batch 411 batch loss 5.27195358 epoch total loss 6.37572813\n",
      "Trained batch 412 batch loss 5.67934322 epoch total loss 6.37403822\n",
      "Trained batch 413 batch loss 6.24862671 epoch total loss 6.37373447\n",
      "Trained batch 414 batch loss 6.26713657 epoch total loss 6.37347698\n",
      "Trained batch 415 batch loss 6.2440505 epoch total loss 6.37316513\n",
      "Trained batch 416 batch loss 6.32717848 epoch total loss 6.3730545\n",
      "Trained batch 417 batch loss 5.80259848 epoch total loss 6.37168646\n",
      "Trained batch 418 batch loss 6.20556974 epoch total loss 6.37128878\n",
      "Trained batch 419 batch loss 6.29457808 epoch total loss 6.37110615\n",
      "Trained batch 420 batch loss 5.93005371 epoch total loss 6.37005568\n",
      "Trained batch 421 batch loss 6.16839314 epoch total loss 6.36957693\n",
      "Trained batch 422 batch loss 5.80162048 epoch total loss 6.36823082\n",
      "Trained batch 423 batch loss 6.08901024 epoch total loss 6.36757088\n",
      "Trained batch 424 batch loss 6.61314106 epoch total loss 6.36814976\n",
      "Trained batch 425 batch loss 6.48046303 epoch total loss 6.36841393\n",
      "Trained batch 426 batch loss 6.26670027 epoch total loss 6.36817503\n",
      "Trained batch 427 batch loss 6.32950163 epoch total loss 6.36808443\n",
      "Trained batch 428 batch loss 5.96857214 epoch total loss 6.36715078\n",
      "Trained batch 429 batch loss 6.3294363 epoch total loss 6.36706305\n",
      "Trained batch 430 batch loss 6.60219479 epoch total loss 6.36761\n",
      "Trained batch 431 batch loss 6.28397894 epoch total loss 6.3674159\n",
      "Trained batch 432 batch loss 6.4024663 epoch total loss 6.36749697\n",
      "Trained batch 433 batch loss 6.20775557 epoch total loss 6.36712837\n",
      "Trained batch 434 batch loss 5.84137058 epoch total loss 6.36591673\n",
      "Trained batch 435 batch loss 6.19109 epoch total loss 6.36551523\n",
      "Trained batch 436 batch loss 6.54754925 epoch total loss 6.36593246\n",
      "Trained batch 437 batch loss 6.24835205 epoch total loss 6.36566353\n",
      "Trained batch 438 batch loss 6.26042271 epoch total loss 6.3654232\n",
      "Trained batch 439 batch loss 5.66704655 epoch total loss 6.36383247\n",
      "Trained batch 440 batch loss 5.75571966 epoch total loss 6.36245\n",
      "Trained batch 441 batch loss 6.51851702 epoch total loss 6.36280394\n",
      "Trained batch 442 batch loss 6.49717 epoch total loss 6.36310768\n",
      "Trained batch 443 batch loss 6.58690929 epoch total loss 6.36361313\n",
      "Trained batch 444 batch loss 6.66272068 epoch total loss 6.3642869\n",
      "Trained batch 445 batch loss 6.79488373 epoch total loss 6.36525488\n",
      "Trained batch 446 batch loss 6.84117317 epoch total loss 6.36632156\n",
      "Trained batch 447 batch loss 6.69428 epoch total loss 6.36705542\n",
      "Trained batch 448 batch loss 6.62678623 epoch total loss 6.36763477\n",
      "Trained batch 449 batch loss 6.22479439 epoch total loss 6.36731672\n",
      "Trained batch 450 batch loss 6.76696873 epoch total loss 6.36820507\n",
      "Trained batch 451 batch loss 6.55624 epoch total loss 6.36862183\n",
      "Trained batch 452 batch loss 6.65704536 epoch total loss 6.36926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 453 batch loss 6.34038687 epoch total loss 6.36919594\n",
      "Trained batch 454 batch loss 6.49412346 epoch total loss 6.36947155\n",
      "Trained batch 455 batch loss 6.23081541 epoch total loss 6.36916637\n",
      "Trained batch 456 batch loss 6.30011034 epoch total loss 6.36901474\n",
      "Trained batch 457 batch loss 6.23221064 epoch total loss 6.36871529\n",
      "Trained batch 458 batch loss 6.32775116 epoch total loss 6.36862564\n",
      "Trained batch 459 batch loss 5.86468077 epoch total loss 6.36752796\n",
      "Trained batch 460 batch loss 6.39562559 epoch total loss 6.36758852\n",
      "Trained batch 461 batch loss 6.61131048 epoch total loss 6.36811733\n",
      "Trained batch 462 batch loss 6.73028374 epoch total loss 6.36890125\n",
      "Trained batch 463 batch loss 6.24871778 epoch total loss 6.36864185\n",
      "Trained batch 464 batch loss 6.21841097 epoch total loss 6.36831808\n",
      "Trained batch 465 batch loss 6.23967028 epoch total loss 6.36804152\n",
      "Trained batch 466 batch loss 6.26266718 epoch total loss 6.36781549\n",
      "Trained batch 467 batch loss 6.38030243 epoch total loss 6.36784267\n",
      "Trained batch 468 batch loss 6.235744 epoch total loss 6.36756039\n",
      "Trained batch 469 batch loss 5.86884785 epoch total loss 6.36649704\n",
      "Trained batch 470 batch loss 6.20222473 epoch total loss 6.36614752\n",
      "Trained batch 471 batch loss 6.39033461 epoch total loss 6.36619902\n",
      "Trained batch 472 batch loss 6.61579847 epoch total loss 6.36672783\n",
      "Trained batch 473 batch loss 5.88784218 epoch total loss 6.3657155\n",
      "Trained batch 474 batch loss 6.4348073 epoch total loss 6.36586142\n",
      "Trained batch 475 batch loss 6.346838 epoch total loss 6.36582136\n",
      "Trained batch 476 batch loss 6.15188026 epoch total loss 6.3653717\n",
      "Trained batch 477 batch loss 5.85643101 epoch total loss 6.36430502\n",
      "Trained batch 478 batch loss 6.19767475 epoch total loss 6.36395645\n",
      "Trained batch 479 batch loss 6.07234 epoch total loss 6.36334753\n",
      "Trained batch 480 batch loss 6.12682104 epoch total loss 6.36285448\n",
      "Trained batch 481 batch loss 6.57516 epoch total loss 6.36329603\n",
      "Trained batch 482 batch loss 6.49646425 epoch total loss 6.3635726\n",
      "Trained batch 483 batch loss 6.01012468 epoch total loss 6.36284065\n",
      "Trained batch 484 batch loss 6.24982071 epoch total loss 6.362607\n",
      "Trained batch 485 batch loss 6.1095233 epoch total loss 6.36208534\n",
      "Trained batch 486 batch loss 5.95092249 epoch total loss 6.36123943\n",
      "Trained batch 487 batch loss 6.05202 epoch total loss 6.36060429\n",
      "Trained batch 488 batch loss 6.29327679 epoch total loss 6.360466\n",
      "Trained batch 489 batch loss 5.91239166 epoch total loss 6.35954952\n",
      "Trained batch 490 batch loss 5.94204903 epoch total loss 6.35869789\n",
      "Trained batch 491 batch loss 5.76099443 epoch total loss 6.35748053\n",
      "Trained batch 492 batch loss 5.76301432 epoch total loss 6.35627222\n",
      "Trained batch 493 batch loss 6.43258238 epoch total loss 6.35642719\n",
      "Trained batch 494 batch loss 6.18798208 epoch total loss 6.35608625\n",
      "Trained batch 495 batch loss 6.26809645 epoch total loss 6.35590839\n",
      "Trained batch 496 batch loss 6.58958817 epoch total loss 6.35637951\n",
      "Trained batch 497 batch loss 6.71980858 epoch total loss 6.3571105\n",
      "Trained batch 498 batch loss 6.3738718 epoch total loss 6.35714388\n",
      "Trained batch 499 batch loss 6.54315901 epoch total loss 6.35751677\n",
      "Trained batch 500 batch loss 6.29806328 epoch total loss 6.35739803\n",
      "Trained batch 501 batch loss 6.08461332 epoch total loss 6.35685349\n",
      "Trained batch 502 batch loss 6.35961914 epoch total loss 6.35685921\n",
      "Trained batch 503 batch loss 6.15770721 epoch total loss 6.35646343\n",
      "Trained batch 504 batch loss 6.72867298 epoch total loss 6.35720205\n",
      "Trained batch 505 batch loss 6.68199348 epoch total loss 6.35784483\n",
      "Trained batch 506 batch loss 6.34707785 epoch total loss 6.35782385\n",
      "Trained batch 507 batch loss 6.41791439 epoch total loss 6.35794258\n",
      "Trained batch 508 batch loss 5.99320936 epoch total loss 6.35722446\n",
      "Trained batch 509 batch loss 6.51380396 epoch total loss 6.35753202\n",
      "Trained batch 510 batch loss 6.29464149 epoch total loss 6.357409\n",
      "Trained batch 511 batch loss 6.19433594 epoch total loss 6.35709\n",
      "Trained batch 512 batch loss 6.14206505 epoch total loss 6.35667\n",
      "Trained batch 513 batch loss 6.64397335 epoch total loss 6.35723\n",
      "Trained batch 514 batch loss 6.38853168 epoch total loss 6.35729074\n",
      "Trained batch 515 batch loss 6.4948864 epoch total loss 6.35755777\n",
      "Trained batch 516 batch loss 6.09900761 epoch total loss 6.35705709\n",
      "Trained batch 517 batch loss 6.06129599 epoch total loss 6.35648489\n",
      "Trained batch 518 batch loss 6.25720119 epoch total loss 6.3562932\n",
      "Trained batch 519 batch loss 6.57307577 epoch total loss 6.35671043\n",
      "Trained batch 520 batch loss 6.5391016 epoch total loss 6.35706139\n",
      "Trained batch 521 batch loss 6.22666216 epoch total loss 6.35681105\n",
      "Trained batch 522 batch loss 6.35156155 epoch total loss 6.35680056\n",
      "Trained batch 523 batch loss 6.24183655 epoch total loss 6.35658121\n",
      "Trained batch 524 batch loss 6.34352541 epoch total loss 6.35655642\n",
      "Trained batch 525 batch loss 6.668221 epoch total loss 6.3571496\n",
      "Trained batch 526 batch loss 6.55685806 epoch total loss 6.35752964\n",
      "Trained batch 527 batch loss 6.48014927 epoch total loss 6.35776234\n",
      "Trained batch 528 batch loss 6.38332558 epoch total loss 6.35781097\n",
      "Trained batch 529 batch loss 6.39147758 epoch total loss 6.35787439\n",
      "Trained batch 530 batch loss 6.60193062 epoch total loss 6.35833502\n",
      "Trained batch 531 batch loss 6.70234632 epoch total loss 6.35898304\n",
      "Trained batch 532 batch loss 6.24729776 epoch total loss 6.35877275\n",
      "Trained batch 533 batch loss 6.40228033 epoch total loss 6.35885477\n",
      "Trained batch 534 batch loss 6.47703743 epoch total loss 6.35907602\n",
      "Trained batch 535 batch loss 6.05319548 epoch total loss 6.3585043\n",
      "Trained batch 536 batch loss 6.17275667 epoch total loss 6.35815811\n",
      "Trained batch 537 batch loss 5.91647434 epoch total loss 6.35733557\n",
      "Trained batch 538 batch loss 6.58609676 epoch total loss 6.35776091\n",
      "Trained batch 539 batch loss 6.37513542 epoch total loss 6.35779333\n",
      "Trained batch 540 batch loss 6.44662333 epoch total loss 6.35795784\n",
      "Trained batch 541 batch loss 6.18608141 epoch total loss 6.35764\n",
      "Trained batch 542 batch loss 6.0810914 epoch total loss 6.35712957\n",
      "Trained batch 543 batch loss 6.33797646 epoch total loss 6.35709429\n",
      "Trained batch 544 batch loss 6.37158251 epoch total loss 6.35712051\n",
      "Trained batch 545 batch loss 6.45006275 epoch total loss 6.35729122\n",
      "Trained batch 546 batch loss 6.27923 epoch total loss 6.35714817\n",
      "Trained batch 547 batch loss 6.51303768 epoch total loss 6.35743284\n",
      "Trained batch 548 batch loss 6.69599152 epoch total loss 6.35805082\n",
      "Trained batch 549 batch loss 6.38151312 epoch total loss 6.35809374\n",
      "Trained batch 550 batch loss 6.42451286 epoch total loss 6.35821486\n",
      "Trained batch 551 batch loss 6.52626181 epoch total loss 6.35852\n",
      "Trained batch 552 batch loss 6.29100323 epoch total loss 6.35839748\n",
      "Trained batch 553 batch loss 6.42239189 epoch total loss 6.35851336\n",
      "Trained batch 554 batch loss 6.22246933 epoch total loss 6.35826778\n",
      "Trained batch 555 batch loss 5.65663528 epoch total loss 6.35700369\n",
      "Trained batch 556 batch loss 5.79400444 epoch total loss 6.35599089\n",
      "Trained batch 557 batch loss 6.20460176 epoch total loss 6.35571909\n",
      "Trained batch 558 batch loss 6.39606476 epoch total loss 6.35579109\n",
      "Trained batch 559 batch loss 6.19239712 epoch total loss 6.35549879\n",
      "Trained batch 560 batch loss 6.45086956 epoch total loss 6.3556695\n",
      "Trained batch 561 batch loss 6.27247 epoch total loss 6.3555212\n",
      "Trained batch 562 batch loss 5.74576521 epoch total loss 6.35443592\n",
      "Trained batch 563 batch loss 6.47308 epoch total loss 6.35464716\n",
      "Trained batch 564 batch loss 6.77479935 epoch total loss 6.35539198\n",
      "Trained batch 565 batch loss 6.29541397 epoch total loss 6.35528612\n",
      "Trained batch 566 batch loss 6.45455408 epoch total loss 6.3554616\n",
      "Trained batch 567 batch loss 6.29297209 epoch total loss 6.35535097\n",
      "Trained batch 568 batch loss 6.61856842 epoch total loss 6.35581493\n",
      "Trained batch 569 batch loss 6.51089764 epoch total loss 6.35608768\n",
      "Trained batch 570 batch loss 6.44572401 epoch total loss 6.35624504\n",
      "Trained batch 571 batch loss 6.29967451 epoch total loss 6.35614538\n",
      "Trained batch 572 batch loss 6.4880929 epoch total loss 6.35637617\n",
      "Trained batch 573 batch loss 6.37153816 epoch total loss 6.35640287\n",
      "Trained batch 574 batch loss 6.45323277 epoch total loss 6.3565712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 575 batch loss 6.6378274 epoch total loss 6.35706043\n",
      "Trained batch 576 batch loss 6.27337122 epoch total loss 6.35691547\n",
      "Trained batch 577 batch loss 6.38832283 epoch total loss 6.35697\n",
      "Trained batch 578 batch loss 6.61024714 epoch total loss 6.35740852\n",
      "Trained batch 579 batch loss 6.83164 epoch total loss 6.35822725\n",
      "Trained batch 580 batch loss 7.03192759 epoch total loss 6.35938883\n",
      "Trained batch 581 batch loss 7.38183 epoch total loss 6.36114883\n",
      "Trained batch 582 batch loss 7.34052229 epoch total loss 6.36283159\n",
      "Trained batch 583 batch loss 7.06942415 epoch total loss 6.36404324\n",
      "Trained batch 584 batch loss 7.40485048 epoch total loss 6.36582565\n",
      "Trained batch 585 batch loss 6.35026455 epoch total loss 6.36579895\n",
      "Trained batch 586 batch loss 6.38146734 epoch total loss 6.36582565\n",
      "Trained batch 587 batch loss 6.50080061 epoch total loss 6.36605549\n",
      "Trained batch 588 batch loss 6.00467682 epoch total loss 6.36544085\n",
      "Trained batch 589 batch loss 6.34784889 epoch total loss 6.3654108\n",
      "Trained batch 590 batch loss 6.19979525 epoch total loss 6.36513\n",
      "Trained batch 591 batch loss 6.05147123 epoch total loss 6.36459923\n",
      "Trained batch 592 batch loss 6.22127628 epoch total loss 6.36435699\n",
      "Trained batch 593 batch loss 6.0791707 epoch total loss 6.36387634\n",
      "Trained batch 594 batch loss 6.69537926 epoch total loss 6.36443424\n",
      "Trained batch 595 batch loss 6.37038946 epoch total loss 6.36444426\n",
      "Trained batch 596 batch loss 6.58621883 epoch total loss 6.36481619\n",
      "Trained batch 597 batch loss 6.63583231 epoch total loss 6.36527\n",
      "Trained batch 598 batch loss 6.09539366 epoch total loss 6.36481857\n",
      "Trained batch 599 batch loss 6.37493 epoch total loss 6.36483574\n",
      "Trained batch 600 batch loss 6.48440504 epoch total loss 6.36503506\n",
      "Trained batch 601 batch loss 6.51503229 epoch total loss 6.36528492\n",
      "Trained batch 602 batch loss 6.52728 epoch total loss 6.36555386\n",
      "Trained batch 603 batch loss 6.45751524 epoch total loss 6.36570644\n",
      "Trained batch 604 batch loss 6.55161905 epoch total loss 6.366014\n",
      "Trained batch 605 batch loss 5.81188679 epoch total loss 6.365098\n",
      "Trained batch 606 batch loss 6.32193136 epoch total loss 6.36502695\n",
      "Trained batch 607 batch loss 6.31379747 epoch total loss 6.36494255\n",
      "Trained batch 608 batch loss 6.57301426 epoch total loss 6.36528444\n",
      "Trained batch 609 batch loss 6.50901842 epoch total loss 6.36552048\n",
      "Trained batch 610 batch loss 6.23513079 epoch total loss 6.36530685\n",
      "Trained batch 611 batch loss 6.4078064 epoch total loss 6.365376\n",
      "Trained batch 612 batch loss 6.07991648 epoch total loss 6.36490965\n",
      "Trained batch 613 batch loss 6.41644096 epoch total loss 6.36499405\n",
      "Trained batch 614 batch loss 6.35511398 epoch total loss 6.36497784\n",
      "Trained batch 615 batch loss 6.10533571 epoch total loss 6.36455536\n",
      "Trained batch 616 batch loss 6.45782614 epoch total loss 6.36470699\n",
      "Trained batch 617 batch loss 5.99472332 epoch total loss 6.36410713\n",
      "Trained batch 618 batch loss 6.56008244 epoch total loss 6.36442423\n",
      "Trained batch 619 batch loss 6.51994514 epoch total loss 6.36467552\n",
      "Trained batch 620 batch loss 6.75415277 epoch total loss 6.36530352\n",
      "Trained batch 621 batch loss 6.81669664 epoch total loss 6.36603069\n",
      "Trained batch 622 batch loss 7.06008 epoch total loss 6.36714649\n",
      "Trained batch 623 batch loss 6.3074975 epoch total loss 6.36705065\n",
      "Trained batch 624 batch loss 6.02543 epoch total loss 6.36650324\n",
      "Trained batch 625 batch loss 5.4824152 epoch total loss 6.36508846\n",
      "Trained batch 626 batch loss 6.16961241 epoch total loss 6.36477661\n",
      "Trained batch 627 batch loss 6.67543554 epoch total loss 6.36527205\n",
      "Trained batch 628 batch loss 6.61553621 epoch total loss 6.36567068\n",
      "Trained batch 629 batch loss 6.34701443 epoch total loss 6.36564064\n",
      "Trained batch 630 batch loss 5.81543112 epoch total loss 6.36476755\n",
      "Trained batch 631 batch loss 5.98608065 epoch total loss 6.36416721\n",
      "Trained batch 632 batch loss 6.15049 epoch total loss 6.36382914\n",
      "Trained batch 633 batch loss 6.59175777 epoch total loss 6.36418915\n",
      "Trained batch 634 batch loss 6.41130638 epoch total loss 6.36426353\n",
      "Trained batch 635 batch loss 6.53658485 epoch total loss 6.36453485\n",
      "Trained batch 636 batch loss 6.45259857 epoch total loss 6.36467361\n",
      "Trained batch 637 batch loss 6.41010571 epoch total loss 6.36474514\n",
      "Trained batch 638 batch loss 6.60410118 epoch total loss 6.36512\n",
      "Trained batch 639 batch loss 6.60623598 epoch total loss 6.36549711\n",
      "Trained batch 640 batch loss 6.30519104 epoch total loss 6.36540318\n",
      "Trained batch 641 batch loss 6.46786976 epoch total loss 6.36556292\n",
      "Trained batch 642 batch loss 6.56875706 epoch total loss 6.36587954\n",
      "Trained batch 643 batch loss 6.51291895 epoch total loss 6.36610794\n",
      "Trained batch 644 batch loss 6.54621077 epoch total loss 6.36638737\n",
      "Trained batch 645 batch loss 6.68381882 epoch total loss 6.36687946\n",
      "Trained batch 646 batch loss 6.35889196 epoch total loss 6.36686707\n",
      "Trained batch 647 batch loss 6.37269497 epoch total loss 6.36687565\n",
      "Trained batch 648 batch loss 6.32238865 epoch total loss 6.36680698\n",
      "Trained batch 649 batch loss 6.64015627 epoch total loss 6.36722803\n",
      "Trained batch 650 batch loss 6.61196518 epoch total loss 6.36760426\n",
      "Trained batch 651 batch loss 5.87282944 epoch total loss 6.36684465\n",
      "Trained batch 652 batch loss 5.67439413 epoch total loss 6.36578274\n",
      "Trained batch 653 batch loss 6.02228832 epoch total loss 6.36525679\n",
      "Trained batch 654 batch loss 6.6566658 epoch total loss 6.36570263\n",
      "Trained batch 655 batch loss 6.55230713 epoch total loss 6.3659873\n",
      "Trained batch 656 batch loss 6.42683029 epoch total loss 6.36608\n",
      "Trained batch 657 batch loss 6.75275 epoch total loss 6.3666687\n",
      "Trained batch 658 batch loss 6.94717884 epoch total loss 6.36755133\n",
      "Trained batch 659 batch loss 6.66357565 epoch total loss 6.36800051\n",
      "Trained batch 660 batch loss 6.86715 epoch total loss 6.36875677\n",
      "Trained batch 661 batch loss 7.06905127 epoch total loss 6.36981583\n",
      "Trained batch 662 batch loss 6.61097097 epoch total loss 6.37017965\n",
      "Trained batch 663 batch loss 6.52847576 epoch total loss 6.37041855\n",
      "Trained batch 664 batch loss 6.42542076 epoch total loss 6.37050104\n",
      "Trained batch 665 batch loss 5.83075905 epoch total loss 6.36968899\n",
      "Trained batch 666 batch loss 5.66426897 epoch total loss 6.36862946\n",
      "Trained batch 667 batch loss 6.62042141 epoch total loss 6.36900759\n",
      "Trained batch 668 batch loss 6.44629145 epoch total loss 6.36912298\n",
      "Trained batch 669 batch loss 6.27735 epoch total loss 6.36898613\n",
      "Trained batch 670 batch loss 6.44586611 epoch total loss 6.36910057\n",
      "Trained batch 671 batch loss 6.51416254 epoch total loss 6.36931658\n",
      "Trained batch 672 batch loss 6.07022667 epoch total loss 6.36887169\n",
      "Trained batch 673 batch loss 6.16314793 epoch total loss 6.36856604\n",
      "Trained batch 674 batch loss 6.05038404 epoch total loss 6.36809397\n",
      "Trained batch 675 batch loss 5.43481 epoch total loss 6.36671066\n",
      "Trained batch 676 batch loss 5.57435226 epoch total loss 6.3655386\n",
      "Trained batch 677 batch loss 5.16031742 epoch total loss 6.36375809\n",
      "Trained batch 678 batch loss 5.77466822 epoch total loss 6.36288929\n",
      "Trained batch 679 batch loss 6.15972471 epoch total loss 6.36259031\n",
      "Trained batch 680 batch loss 6.73087883 epoch total loss 6.363132\n",
      "Trained batch 681 batch loss 7.22385168 epoch total loss 6.36439562\n",
      "Trained batch 682 batch loss 6.75191164 epoch total loss 6.36496353\n",
      "Trained batch 683 batch loss 6.56830835 epoch total loss 6.36526155\n",
      "Trained batch 684 batch loss 6.89098692 epoch total loss 6.36603\n",
      "Trained batch 685 batch loss 6.86925125 epoch total loss 6.36676502\n",
      "Trained batch 686 batch loss 6.84751892 epoch total loss 6.36746597\n",
      "Trained batch 687 batch loss 6.41196346 epoch total loss 6.36753082\n",
      "Trained batch 688 batch loss 6.62027168 epoch total loss 6.36789799\n",
      "Trained batch 689 batch loss 6.91847 epoch total loss 6.36869717\n",
      "Trained batch 690 batch loss 6.65070152 epoch total loss 6.36910582\n",
      "Trained batch 691 batch loss 6.41901922 epoch total loss 6.3691783\n",
      "Trained batch 692 batch loss 6.27095127 epoch total loss 6.3690362\n",
      "Trained batch 693 batch loss 5.89859629 epoch total loss 6.36835718\n",
      "Trained batch 694 batch loss 5.47649717 epoch total loss 6.36707211\n",
      "Trained batch 695 batch loss 5.16872454 epoch total loss 6.36534834\n",
      "Trained batch 696 batch loss 5.42831802 epoch total loss 6.36400175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 697 batch loss 5.89169693 epoch total loss 6.36332417\n",
      "Trained batch 698 batch loss 6.20973778 epoch total loss 6.36310434\n",
      "Trained batch 699 batch loss 6.7755394 epoch total loss 6.36369419\n",
      "Trained batch 700 batch loss 6.71196556 epoch total loss 6.36419153\n",
      "Trained batch 701 batch loss 6.30276728 epoch total loss 6.36410379\n",
      "Trained batch 702 batch loss 6.18526745 epoch total loss 6.36384869\n",
      "Trained batch 703 batch loss 6.35607624 epoch total loss 6.36383772\n",
      "Trained batch 704 batch loss 6.67710876 epoch total loss 6.36428261\n",
      "Trained batch 705 batch loss 6.49746084 epoch total loss 6.36447191\n",
      "Trained batch 706 batch loss 6.48089 epoch total loss 6.3646369\n",
      "Trained batch 707 batch loss 6.60348272 epoch total loss 6.3649745\n",
      "Trained batch 708 batch loss 6.71367 epoch total loss 6.36546755\n",
      "Trained batch 709 batch loss 6.57326031 epoch total loss 6.36576033\n",
      "Trained batch 710 batch loss 6.54192924 epoch total loss 6.36600876\n",
      "Trained batch 711 batch loss 6.446805 epoch total loss 6.36612225\n",
      "Trained batch 712 batch loss 6.5293479 epoch total loss 6.3663516\n",
      "Trained batch 713 batch loss 6.40544128 epoch total loss 6.36640596\n",
      "Trained batch 714 batch loss 6.48286152 epoch total loss 6.36656952\n",
      "Trained batch 715 batch loss 6.08659935 epoch total loss 6.36617756\n",
      "Trained batch 716 batch loss 5.96222258 epoch total loss 6.36561346\n",
      "Trained batch 717 batch loss 6.00858927 epoch total loss 6.36511564\n",
      "Trained batch 718 batch loss 6.58870173 epoch total loss 6.36542749\n",
      "Trained batch 719 batch loss 7.02704048 epoch total loss 6.36634731\n",
      "Trained batch 720 batch loss 7.35826492 epoch total loss 6.36772537\n",
      "Trained batch 721 batch loss 7.31273794 epoch total loss 6.36903572\n",
      "Trained batch 722 batch loss 6.80913925 epoch total loss 6.36964512\n",
      "Trained batch 723 batch loss 6.96442461 epoch total loss 6.37046766\n",
      "Trained batch 724 batch loss 6.47251797 epoch total loss 6.37060881\n",
      "Trained batch 725 batch loss 6.05674934 epoch total loss 6.37017584\n",
      "Trained batch 726 batch loss 6.09339619 epoch total loss 6.36979437\n",
      "Trained batch 727 batch loss 6.50115967 epoch total loss 6.36997461\n",
      "Trained batch 728 batch loss 6.77810812 epoch total loss 6.37053585\n",
      "Trained batch 729 batch loss 6.69548845 epoch total loss 6.37098122\n",
      "Trained batch 730 batch loss 6.14301538 epoch total loss 6.37066889\n",
      "Trained batch 731 batch loss 6.21100569 epoch total loss 6.3704505\n",
      "Trained batch 732 batch loss 6.33411598 epoch total loss 6.37040091\n",
      "Trained batch 733 batch loss 6.18141031 epoch total loss 6.37014294\n",
      "Trained batch 734 batch loss 6.22007847 epoch total loss 6.36993885\n",
      "Trained batch 735 batch loss 5.91582584 epoch total loss 6.36932135\n",
      "Trained batch 736 batch loss 6.42601585 epoch total loss 6.36939812\n",
      "Trained batch 737 batch loss 6.52478838 epoch total loss 6.36960888\n",
      "Trained batch 738 batch loss 6.34252262 epoch total loss 6.36957216\n",
      "Trained batch 739 batch loss 6.65793 epoch total loss 6.36996174\n",
      "Trained batch 740 batch loss 6.59179783 epoch total loss 6.37026167\n",
      "Trained batch 741 batch loss 6.52910376 epoch total loss 6.37047625\n",
      "Trained batch 742 batch loss 6.42237759 epoch total loss 6.37054634\n",
      "Trained batch 743 batch loss 6.62558031 epoch total loss 6.37088919\n",
      "Trained batch 744 batch loss 6.20215178 epoch total loss 6.37066269\n",
      "Trained batch 745 batch loss 6.30554438 epoch total loss 6.37057543\n",
      "Trained batch 746 batch loss 5.82922697 epoch total loss 6.36984968\n",
      "Trained batch 747 batch loss 5.80749273 epoch total loss 6.36909676\n",
      "Trained batch 748 batch loss 6.34307194 epoch total loss 6.36906242\n",
      "Trained batch 749 batch loss 6.24476767 epoch total loss 6.36889601\n",
      "Trained batch 750 batch loss 6.19617844 epoch total loss 6.36866617\n",
      "Trained batch 751 batch loss 6.6087451 epoch total loss 6.36898565\n",
      "Trained batch 752 batch loss 6.55621099 epoch total loss 6.36923456\n",
      "Trained batch 753 batch loss 6.23788834 epoch total loss 6.36906\n",
      "Trained batch 754 batch loss 6.42450762 epoch total loss 6.36913347\n",
      "Trained batch 755 batch loss 6.40458488 epoch total loss 6.36918068\n",
      "Trained batch 756 batch loss 6.1987505 epoch total loss 6.36895514\n",
      "Trained batch 757 batch loss 6.22633791 epoch total loss 6.36876726\n",
      "Trained batch 758 batch loss 6.34574413 epoch total loss 6.36873674\n",
      "Trained batch 759 batch loss 6.15618467 epoch total loss 6.36845684\n",
      "Trained batch 760 batch loss 6.52750254 epoch total loss 6.3686657\n",
      "Trained batch 761 batch loss 6.33276272 epoch total loss 6.36861849\n",
      "Trained batch 762 batch loss 6.48330545 epoch total loss 6.36876917\n",
      "Trained batch 763 batch loss 6.6447525 epoch total loss 6.36913061\n",
      "Trained batch 764 batch loss 6.63326836 epoch total loss 6.36947632\n",
      "Trained batch 765 batch loss 6.48577785 epoch total loss 6.36962843\n",
      "Trained batch 766 batch loss 6.45978642 epoch total loss 6.36974621\n",
      "Trained batch 767 batch loss 6.25265 epoch total loss 6.36959314\n",
      "Trained batch 768 batch loss 6.0832 epoch total loss 6.36922026\n",
      "Trained batch 769 batch loss 6.20810175 epoch total loss 6.36901045\n",
      "Trained batch 770 batch loss 6.42450809 epoch total loss 6.36908245\n",
      "Trained batch 771 batch loss 6.64337444 epoch total loss 6.36943817\n",
      "Trained batch 772 batch loss 6.86471558 epoch total loss 6.37008\n",
      "Trained batch 773 batch loss 7.01953554 epoch total loss 6.37092\n",
      "Trained batch 774 batch loss 6.93537331 epoch total loss 6.37164974\n",
      "Trained batch 775 batch loss 6.9638586 epoch total loss 6.37241364\n",
      "Trained batch 776 batch loss 6.69388962 epoch total loss 6.37282801\n",
      "Trained batch 777 batch loss 7.31591177 epoch total loss 6.37404156\n",
      "Trained batch 778 batch loss 7.02858925 epoch total loss 6.37488317\n",
      "Trained batch 779 batch loss 6.66229534 epoch total loss 6.37525177\n",
      "Trained batch 780 batch loss 6.31326437 epoch total loss 6.37517262\n",
      "Trained batch 781 batch loss 5.96517563 epoch total loss 6.37464809\n",
      "Trained batch 782 batch loss 6.2520237 epoch total loss 6.37449121\n",
      "Trained batch 783 batch loss 6.31938505 epoch total loss 6.37442064\n",
      "Trained batch 784 batch loss 6.4573369 epoch total loss 6.3745265\n",
      "Trained batch 785 batch loss 6.54781628 epoch total loss 6.37474728\n",
      "Trained batch 786 batch loss 6.71158791 epoch total loss 6.37517595\n",
      "Trained batch 787 batch loss 6.72417736 epoch total loss 6.37561941\n",
      "Trained batch 788 batch loss 6.44560957 epoch total loss 6.3757081\n",
      "Trained batch 789 batch loss 6.5108552 epoch total loss 6.37587929\n",
      "Trained batch 790 batch loss 6.3971858 epoch total loss 6.37590599\n",
      "Trained batch 791 batch loss 6.0036521 epoch total loss 6.37543535\n",
      "Trained batch 792 batch loss 5.81331348 epoch total loss 6.37472582\n",
      "Trained batch 793 batch loss 6.66075325 epoch total loss 6.37508631\n",
      "Trained batch 794 batch loss 6.46574688 epoch total loss 6.37520027\n",
      "Trained batch 795 batch loss 6.57510614 epoch total loss 6.37545204\n",
      "Trained batch 796 batch loss 6.56118917 epoch total loss 6.37568521\n",
      "Trained batch 797 batch loss 6.32247543 epoch total loss 6.37561798\n",
      "Trained batch 798 batch loss 6.48891211 epoch total loss 6.37576\n",
      "Trained batch 799 batch loss 6.18325377 epoch total loss 6.3755188\n",
      "Trained batch 800 batch loss 6.56333351 epoch total loss 6.37575388\n",
      "Trained batch 801 batch loss 6.37763119 epoch total loss 6.37575579\n",
      "Trained batch 802 batch loss 6.6975894 epoch total loss 6.37615728\n",
      "Trained batch 803 batch loss 6.04684782 epoch total loss 6.3757472\n",
      "Trained batch 804 batch loss 6.2389307 epoch total loss 6.37557697\n",
      "Trained batch 805 batch loss 6.03049 epoch total loss 6.37514782\n",
      "Trained batch 806 batch loss 6.46981239 epoch total loss 6.37526512\n",
      "Trained batch 807 batch loss 6.18843746 epoch total loss 6.37503386\n",
      "Trained batch 808 batch loss 5.91031408 epoch total loss 6.37445831\n",
      "Trained batch 809 batch loss 6.25949049 epoch total loss 6.37431622\n",
      "Trained batch 810 batch loss 6.1025 epoch total loss 6.37398052\n",
      "Trained batch 811 batch loss 6.10381937 epoch total loss 6.37364769\n",
      "Trained batch 812 batch loss 6.54434 epoch total loss 6.37385798\n",
      "Trained batch 813 batch loss 6.9734 epoch total loss 6.37459564\n",
      "Trained batch 814 batch loss 6.4022131 epoch total loss 6.37463\n",
      "Trained batch 815 batch loss 5.96782732 epoch total loss 6.37413073\n",
      "Trained batch 816 batch loss 6.51447678 epoch total loss 6.37430286\n",
      "Trained batch 817 batch loss 6.53079653 epoch total loss 6.37449455\n",
      "Trained batch 818 batch loss 6.35658264 epoch total loss 6.37447214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 819 batch loss 6.58750582 epoch total loss 6.37473249\n",
      "Trained batch 820 batch loss 6.34544563 epoch total loss 6.37469625\n",
      "Trained batch 821 batch loss 6.17070103 epoch total loss 6.3744483\n",
      "Trained batch 822 batch loss 6.18999624 epoch total loss 6.37422371\n",
      "Trained batch 823 batch loss 6.0236578 epoch total loss 6.37379742\n",
      "Trained batch 824 batch loss 5.83342695 epoch total loss 6.37314177\n",
      "Trained batch 825 batch loss 6.2994175 epoch total loss 6.37305212\n",
      "Trained batch 826 batch loss 6.66834831 epoch total loss 6.37340975\n",
      "Trained batch 827 batch loss 6.51510906 epoch total loss 6.37358141\n",
      "Trained batch 828 batch loss 6.57255888 epoch total loss 6.37382174\n",
      "Trained batch 829 batch loss 6.55147171 epoch total loss 6.37403584\n",
      "Trained batch 830 batch loss 6.5787816 epoch total loss 6.37428236\n",
      "Trained batch 831 batch loss 6.50887632 epoch total loss 6.37444401\n",
      "Trained batch 832 batch loss 6.70808363 epoch total loss 6.37484503\n",
      "Trained batch 833 batch loss 6.504498 epoch total loss 6.37500048\n",
      "Trained batch 834 batch loss 6.58124161 epoch total loss 6.37524748\n",
      "Trained batch 835 batch loss 6.54151773 epoch total loss 6.3754468\n",
      "Trained batch 836 batch loss 6.63084173 epoch total loss 6.37575245\n",
      "Trained batch 837 batch loss 6.59812546 epoch total loss 6.37601805\n",
      "Trained batch 838 batch loss 6.37555313 epoch total loss 6.37601757\n",
      "Trained batch 839 batch loss 6.5031538 epoch total loss 6.37616873\n",
      "Trained batch 840 batch loss 6.16160393 epoch total loss 6.37591314\n",
      "Trained batch 841 batch loss 6.37742853 epoch total loss 6.37591505\n",
      "Trained batch 842 batch loss 6.37078953 epoch total loss 6.37590885\n",
      "Trained batch 843 batch loss 6.32316256 epoch total loss 6.37584639\n",
      "Trained batch 844 batch loss 6.39176416 epoch total loss 6.37586498\n",
      "Trained batch 845 batch loss 6.28815746 epoch total loss 6.37576103\n",
      "Trained batch 846 batch loss 6.81830549 epoch total loss 6.37628412\n",
      "Trained batch 847 batch loss 6.67857695 epoch total loss 6.37664127\n",
      "Trained batch 848 batch loss 6.80646801 epoch total loss 6.37714815\n",
      "Trained batch 849 batch loss 6.70877409 epoch total loss 6.37753916\n",
      "Trained batch 850 batch loss 6.44943333 epoch total loss 6.37762356\n",
      "Trained batch 851 batch loss 6.3030014 epoch total loss 6.3775363\n",
      "Trained batch 852 batch loss 6.33769 epoch total loss 6.37748957\n",
      "Trained batch 853 batch loss 6.70652914 epoch total loss 6.37787533\n",
      "Trained batch 854 batch loss 6.71197748 epoch total loss 6.37826633\n",
      "Trained batch 855 batch loss 6.94221 epoch total loss 6.37892628\n",
      "Trained batch 856 batch loss 7.03987837 epoch total loss 6.37969875\n",
      "Trained batch 857 batch loss 6.79042721 epoch total loss 6.38017797\n",
      "Trained batch 858 batch loss 6.5914197 epoch total loss 6.38042402\n",
      "Trained batch 859 batch loss 6.49418211 epoch total loss 6.38055658\n",
      "Trained batch 860 batch loss 6.30452061 epoch total loss 6.38046837\n",
      "Trained batch 861 batch loss 6.26382446 epoch total loss 6.38033247\n",
      "Trained batch 862 batch loss 6.57718754 epoch total loss 6.38056087\n",
      "Trained batch 863 batch loss 6.69443035 epoch total loss 6.38092422\n",
      "Trained batch 864 batch loss 6.48741531 epoch total loss 6.38104773\n",
      "Trained batch 865 batch loss 6.46769047 epoch total loss 6.38114786\n",
      "Trained batch 866 batch loss 6.41408062 epoch total loss 6.38118601\n",
      "Trained batch 867 batch loss 6.51012325 epoch total loss 6.38133478\n",
      "Trained batch 868 batch loss 6.75040436 epoch total loss 6.38176\n",
      "Trained batch 869 batch loss 6.59942245 epoch total loss 6.38201046\n",
      "Trained batch 870 batch loss 6.36696291 epoch total loss 6.38199377\n",
      "Trained batch 871 batch loss 6.39557457 epoch total loss 6.38200903\n",
      "Trained batch 872 batch loss 6.54165506 epoch total loss 6.38219213\n",
      "Trained batch 873 batch loss 6.50698 epoch total loss 6.38233471\n",
      "Trained batch 874 batch loss 6.54244232 epoch total loss 6.38251829\n",
      "Trained batch 875 batch loss 6.52738667 epoch total loss 6.38268375\n",
      "Trained batch 876 batch loss 6.02441931 epoch total loss 6.38227463\n",
      "Trained batch 877 batch loss 5.82086229 epoch total loss 6.38163424\n",
      "Trained batch 878 batch loss 5.79165125 epoch total loss 6.38096237\n",
      "Trained batch 879 batch loss 5.84886742 epoch total loss 6.38035679\n",
      "Trained batch 880 batch loss 5.66090107 epoch total loss 6.37953949\n",
      "Trained batch 881 batch loss 5.33215809 epoch total loss 6.37835026\n",
      "Trained batch 882 batch loss 5.26031733 epoch total loss 6.37708282\n",
      "Trained batch 883 batch loss 5.09656572 epoch total loss 6.37563276\n",
      "Trained batch 884 batch loss 5.78304577 epoch total loss 6.37496233\n",
      "Trained batch 885 batch loss 6.48110485 epoch total loss 6.37508202\n",
      "Trained batch 886 batch loss 6.54473 epoch total loss 6.3752737\n",
      "Trained batch 887 batch loss 6.55830097 epoch total loss 6.37548\n",
      "Trained batch 888 batch loss 5.91880465 epoch total loss 6.37496614\n",
      "Trained batch 889 batch loss 6.1868515 epoch total loss 6.37475443\n",
      "Trained batch 890 batch loss 5.93562889 epoch total loss 6.3742609\n",
      "Trained batch 891 batch loss 6.00915766 epoch total loss 6.3738513\n",
      "Trained batch 892 batch loss 6.51893759 epoch total loss 6.3740139\n",
      "Trained batch 893 batch loss 6.34752083 epoch total loss 6.37398481\n",
      "Trained batch 894 batch loss 6.31329393 epoch total loss 6.3739171\n",
      "Trained batch 895 batch loss 6.40066147 epoch total loss 6.37394714\n",
      "Trained batch 896 batch loss 6.42669582 epoch total loss 6.37400579\n",
      "Trained batch 897 batch loss 6.63168669 epoch total loss 6.37429333\n",
      "Trained batch 898 batch loss 6.97043943 epoch total loss 6.37495708\n",
      "Trained batch 899 batch loss 6.54964352 epoch total loss 6.37515163\n",
      "Trained batch 900 batch loss 6.64343691 epoch total loss 6.37544966\n",
      "Trained batch 901 batch loss 6.30374908 epoch total loss 6.37537\n",
      "Trained batch 902 batch loss 6.57004499 epoch total loss 6.37558556\n",
      "Trained batch 903 batch loss 6.20233107 epoch total loss 6.37539387\n",
      "Trained batch 904 batch loss 6.34741449 epoch total loss 6.37536287\n",
      "Trained batch 905 batch loss 6.81190586 epoch total loss 6.37584543\n",
      "Trained batch 906 batch loss 6.7147975 epoch total loss 6.37621975\n",
      "Trained batch 907 batch loss 6.3941741 epoch total loss 6.3762393\n",
      "Trained batch 908 batch loss 6.00868273 epoch total loss 6.37583447\n",
      "Trained batch 909 batch loss 6.11661863 epoch total loss 6.37554932\n",
      "Trained batch 910 batch loss 6.27064466 epoch total loss 6.37543392\n",
      "Trained batch 911 batch loss 6.62957287 epoch total loss 6.37571287\n",
      "Trained batch 912 batch loss 6.36088371 epoch total loss 6.37569666\n",
      "Trained batch 913 batch loss 6.20497227 epoch total loss 6.37550974\n",
      "Trained batch 914 batch loss 6.34527969 epoch total loss 6.37547636\n",
      "Trained batch 915 batch loss 6.31500626 epoch total loss 6.37541056\n",
      "Trained batch 916 batch loss 6.48252916 epoch total loss 6.37552738\n",
      "Trained batch 917 batch loss 6.66525 epoch total loss 6.37584305\n",
      "Trained batch 918 batch loss 6.51868677 epoch total loss 6.3759985\n",
      "Trained batch 919 batch loss 6.28456211 epoch total loss 6.37589884\n",
      "Trained batch 920 batch loss 5.76450634 epoch total loss 6.3752346\n",
      "Trained batch 921 batch loss 6.32226 epoch total loss 6.37517691\n",
      "Trained batch 922 batch loss 6.13228416 epoch total loss 6.37491369\n",
      "Trained batch 923 batch loss 6.61002445 epoch total loss 6.37516832\n",
      "Trained batch 924 batch loss 5.84881 epoch total loss 6.3745985\n",
      "Trained batch 925 batch loss 5.86776972 epoch total loss 6.37405\n",
      "Trained batch 926 batch loss 6.12814474 epoch total loss 6.37378454\n",
      "Trained batch 927 batch loss 6.325912 epoch total loss 6.37373257\n",
      "Trained batch 928 batch loss 6.78966761 epoch total loss 6.37418079\n",
      "Trained batch 929 batch loss 6.59186935 epoch total loss 6.37441492\n",
      "Trained batch 930 batch loss 6.70848083 epoch total loss 6.37477446\n",
      "Trained batch 931 batch loss 6.35453701 epoch total loss 6.37475252\n",
      "Trained batch 932 batch loss 5.72942877 epoch total loss 6.37406\n",
      "Trained batch 933 batch loss 6.12122869 epoch total loss 6.37378883\n",
      "Trained batch 934 batch loss 5.70674038 epoch total loss 6.37307453\n",
      "Trained batch 935 batch loss 6.2031846 epoch total loss 6.37289286\n",
      "Trained batch 936 batch loss 6.44520235 epoch total loss 6.37297\n",
      "Trained batch 937 batch loss 5.81262541 epoch total loss 6.37237215\n",
      "Trained batch 938 batch loss 6.28010511 epoch total loss 6.37227392\n",
      "Trained batch 939 batch loss 5.79258 epoch total loss 6.37165642\n",
      "Trained batch 940 batch loss 5.6472435 epoch total loss 6.37088585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 941 batch loss 5.9621954 epoch total loss 6.37045193\n",
      "Trained batch 942 batch loss 6.37734 epoch total loss 6.37045908\n",
      "Trained batch 943 batch loss 6.45415735 epoch total loss 6.37054777\n",
      "Trained batch 944 batch loss 6.47793913 epoch total loss 6.37066174\n",
      "Trained batch 945 batch loss 6.50773668 epoch total loss 6.37080717\n",
      "Trained batch 946 batch loss 5.88881397 epoch total loss 6.37029743\n",
      "Trained batch 947 batch loss 6.27901 epoch total loss 6.37020063\n",
      "Trained batch 948 batch loss 6.23263264 epoch total loss 6.3700552\n",
      "Trained batch 949 batch loss 6.52718973 epoch total loss 6.37022114\n",
      "Trained batch 950 batch loss 6.16898727 epoch total loss 6.37000942\n",
      "Trained batch 951 batch loss 6.08706045 epoch total loss 6.3697114\n",
      "Trained batch 952 batch loss 6.26576233 epoch total loss 6.3696022\n",
      "Trained batch 953 batch loss 6.22932243 epoch total loss 6.36945534\n",
      "Trained batch 954 batch loss 6.12103605 epoch total loss 6.36919498\n",
      "Trained batch 955 batch loss 6.11427975 epoch total loss 6.36892796\n",
      "Trained batch 956 batch loss 6.19920921 epoch total loss 6.36875057\n",
      "Trained batch 957 batch loss 6.193048 epoch total loss 6.36856651\n",
      "Trained batch 958 batch loss 6.22613 epoch total loss 6.36841774\n",
      "Trained batch 959 batch loss 6.08554316 epoch total loss 6.36812305\n",
      "Trained batch 960 batch loss 6.0977087 epoch total loss 6.36784124\n",
      "Trained batch 961 batch loss 6.23710871 epoch total loss 6.36770535\n",
      "Trained batch 962 batch loss 6.68707561 epoch total loss 6.36803722\n",
      "Trained batch 963 batch loss 6.03872728 epoch total loss 6.36769485\n",
      "Trained batch 964 batch loss 6.01684 epoch total loss 6.36733103\n",
      "Trained batch 965 batch loss 5.3339324 epoch total loss 6.36626\n",
      "Trained batch 966 batch loss 5.89268255 epoch total loss 6.36577\n",
      "Trained batch 967 batch loss 5.82622194 epoch total loss 6.36521149\n",
      "Trained batch 968 batch loss 6.083004 epoch total loss 6.36492\n",
      "Trained batch 969 batch loss 6.1572113 epoch total loss 6.36470556\n",
      "Trained batch 970 batch loss 6.19276237 epoch total loss 6.36452866\n",
      "Trained batch 971 batch loss 6.32238913 epoch total loss 6.36448526\n",
      "Trained batch 972 batch loss 6.2386 epoch total loss 6.36435556\n",
      "Trained batch 973 batch loss 6.25653553 epoch total loss 6.36424494\n",
      "Trained batch 974 batch loss 6.85897923 epoch total loss 6.36475277\n",
      "Trained batch 975 batch loss 7.44119501 epoch total loss 6.36585665\n",
      "Trained batch 976 batch loss 7.10325432 epoch total loss 6.36661196\n",
      "Trained batch 977 batch loss 6.58114386 epoch total loss 6.36683178\n",
      "Trained batch 978 batch loss 6.87221575 epoch total loss 6.36734819\n",
      "Trained batch 979 batch loss 7.16618919 epoch total loss 6.36816406\n",
      "Trained batch 980 batch loss 7.16014624 epoch total loss 6.3689723\n",
      "Trained batch 981 batch loss 6.89218235 epoch total loss 6.36950541\n",
      "Trained batch 982 batch loss 6.78346062 epoch total loss 6.36992741\n",
      "Trained batch 983 batch loss 6.26825333 epoch total loss 6.36982346\n",
      "Trained batch 984 batch loss 6.40368843 epoch total loss 6.36985826\n",
      "Trained batch 985 batch loss 6.62376499 epoch total loss 6.37011576\n",
      "Trained batch 986 batch loss 6.5995965 epoch total loss 6.37034845\n",
      "Trained batch 987 batch loss 6.66613722 epoch total loss 6.37064791\n",
      "Trained batch 988 batch loss 6.73380089 epoch total loss 6.37101555\n",
      "Trained batch 989 batch loss 6.62660074 epoch total loss 6.37127399\n",
      "Trained batch 990 batch loss 6.49875116 epoch total loss 6.37140226\n",
      "Trained batch 991 batch loss 6.66047955 epoch total loss 6.37169456\n",
      "Trained batch 992 batch loss 6.99130678 epoch total loss 6.37231874\n",
      "Trained batch 993 batch loss 6.95279789 epoch total loss 6.37290335\n",
      "Trained batch 994 batch loss 7.07955122 epoch total loss 6.37361431\n",
      "Trained batch 995 batch loss 6.40877104 epoch total loss 6.3736496\n",
      "Trained batch 996 batch loss 6.58528709 epoch total loss 6.37386227\n",
      "Trained batch 997 batch loss 6.78380823 epoch total loss 6.3742733\n",
      "Trained batch 998 batch loss 6.40983486 epoch total loss 6.37430859\n",
      "Trained batch 999 batch loss 6.53495455 epoch total loss 6.37446976\n",
      "Trained batch 1000 batch loss 6.50445032 epoch total loss 6.37459946\n",
      "Trained batch 1001 batch loss 6.41661167 epoch total loss 6.37464142\n",
      "Trained batch 1002 batch loss 6.56015253 epoch total loss 6.37482643\n",
      "Trained batch 1003 batch loss 6.36164093 epoch total loss 6.37481356\n",
      "Trained batch 1004 batch loss 6.52094936 epoch total loss 6.37495899\n",
      "Trained batch 1005 batch loss 6.68157291 epoch total loss 6.37526417\n",
      "Trained batch 1006 batch loss 6.23248863 epoch total loss 6.37512255\n",
      "Trained batch 1007 batch loss 6.62962961 epoch total loss 6.37537479\n",
      "Trained batch 1008 batch loss 6.65936232 epoch total loss 6.3756566\n",
      "Trained batch 1009 batch loss 5.93612671 epoch total loss 6.37522078\n",
      "Trained batch 1010 batch loss 6.01262474 epoch total loss 6.37486172\n",
      "Trained batch 1011 batch loss 5.46072483 epoch total loss 6.37395763\n",
      "Trained batch 1012 batch loss 6.00836611 epoch total loss 6.37359667\n",
      "Trained batch 1013 batch loss 5.99063969 epoch total loss 6.37321854\n",
      "Trained batch 1014 batch loss 6.29508591 epoch total loss 6.37314129\n",
      "Trained batch 1015 batch loss 6.27424955 epoch total loss 6.37304401\n",
      "Trained batch 1016 batch loss 5.72681618 epoch total loss 6.37240839\n",
      "Trained batch 1017 batch loss 6.26574183 epoch total loss 6.37230301\n",
      "Trained batch 1018 batch loss 5.87548971 epoch total loss 6.3718152\n",
      "Trained batch 1019 batch loss 6.08124113 epoch total loss 6.37152958\n",
      "Trained batch 1020 batch loss 4.85075426 epoch total loss 6.37003851\n",
      "Trained batch 1021 batch loss 5.20788479 epoch total loss 6.36890078\n",
      "Trained batch 1022 batch loss 6.24676704 epoch total loss 6.36878109\n",
      "Trained batch 1023 batch loss 5.79468727 epoch total loss 6.36822\n",
      "Trained batch 1024 batch loss 6.57306 epoch total loss 6.36842\n",
      "Trained batch 1025 batch loss 6.59738874 epoch total loss 6.36864328\n",
      "Trained batch 1026 batch loss 6.10157251 epoch total loss 6.36838293\n",
      "Trained batch 1027 batch loss 6.34753656 epoch total loss 6.3683629\n",
      "Trained batch 1028 batch loss 6.3590107 epoch total loss 6.36835337\n",
      "Trained batch 1029 batch loss 6.28439331 epoch total loss 6.36827183\n",
      "Trained batch 1030 batch loss 6.54574108 epoch total loss 6.36844444\n",
      "Trained batch 1031 batch loss 6.24492645 epoch total loss 6.36832476\n",
      "Trained batch 1032 batch loss 5.94974947 epoch total loss 6.36791897\n",
      "Trained batch 1033 batch loss 6.36388302 epoch total loss 6.36791515\n",
      "Trained batch 1034 batch loss 6.23673868 epoch total loss 6.36778831\n",
      "Trained batch 1035 batch loss 6.35329628 epoch total loss 6.36777449\n",
      "Trained batch 1036 batch loss 7.07075405 epoch total loss 6.36845303\n",
      "Trained batch 1037 batch loss 6.68117666 epoch total loss 6.36875439\n",
      "Trained batch 1038 batch loss 6.12362 epoch total loss 6.36851835\n",
      "Trained batch 1039 batch loss 6.08691359 epoch total loss 6.36824703\n",
      "Trained batch 1040 batch loss 5.98540068 epoch total loss 6.36787891\n",
      "Trained batch 1041 batch loss 6.11307812 epoch total loss 6.3676343\n",
      "Trained batch 1042 batch loss 6.73541451 epoch total loss 6.36798763\n",
      "Trained batch 1043 batch loss 6.52761745 epoch total loss 6.3681407\n",
      "Trained batch 1044 batch loss 7.04609 epoch total loss 6.36878967\n",
      "Trained batch 1045 batch loss 6.96968079 epoch total loss 6.36936474\n",
      "Trained batch 1046 batch loss 6.54709578 epoch total loss 6.36953449\n",
      "Trained batch 1047 batch loss 6.46787643 epoch total loss 6.36962843\n",
      "Trained batch 1048 batch loss 6.2195859 epoch total loss 6.36948538\n",
      "Trained batch 1049 batch loss 6.64572239 epoch total loss 6.36974859\n",
      "Trained batch 1050 batch loss 6.26937962 epoch total loss 6.36965322\n",
      "Trained batch 1051 batch loss 6.35477638 epoch total loss 6.36963892\n",
      "Trained batch 1052 batch loss 6.4755764 epoch total loss 6.36974\n",
      "Trained batch 1053 batch loss 5.90096188 epoch total loss 6.36929464\n",
      "Trained batch 1054 batch loss 6.36452723 epoch total loss 6.36929035\n",
      "Trained batch 1055 batch loss 6.11536407 epoch total loss 6.36904955\n",
      "Trained batch 1056 batch loss 6.1735816 epoch total loss 6.36886406\n",
      "Trained batch 1057 batch loss 6.21802759 epoch total loss 6.36872149\n",
      "Trained batch 1058 batch loss 6.34570551 epoch total loss 6.3687\n",
      "Trained batch 1059 batch loss 6.10230923 epoch total loss 6.36844873\n",
      "Trained batch 1060 batch loss 6.19696379 epoch total loss 6.36828661\n",
      "Trained batch 1061 batch loss 5.78098059 epoch total loss 6.367733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1062 batch loss 5.95894718 epoch total loss 6.36734819\n",
      "Trained batch 1063 batch loss 6.16589928 epoch total loss 6.36715841\n",
      "Trained batch 1064 batch loss 6.22402763 epoch total loss 6.36702394\n",
      "Trained batch 1065 batch loss 5.99748516 epoch total loss 6.36667728\n",
      "Trained batch 1066 batch loss 5.62560368 epoch total loss 6.36598206\n",
      "Trained batch 1067 batch loss 5.62909412 epoch total loss 6.36529112\n",
      "Trained batch 1068 batch loss 6.05150223 epoch total loss 6.36499691\n",
      "Trained batch 1069 batch loss 6.0924716 epoch total loss 6.3647418\n",
      "Trained batch 1070 batch loss 6.08956718 epoch total loss 6.36448479\n",
      "Trained batch 1071 batch loss 6.27039385 epoch total loss 6.36439705\n",
      "Trained batch 1072 batch loss 6.18539095 epoch total loss 6.36423\n",
      "Trained batch 1073 batch loss 6.30529594 epoch total loss 6.36417484\n",
      "Trained batch 1074 batch loss 6.48987103 epoch total loss 6.36429214\n",
      "Trained batch 1075 batch loss 6.51890945 epoch total loss 6.36443567\n",
      "Trained batch 1076 batch loss 6.56222439 epoch total loss 6.36461926\n",
      "Trained batch 1077 batch loss 6.04748869 epoch total loss 6.36432505\n",
      "Trained batch 1078 batch loss 5.50326443 epoch total loss 6.36352634\n",
      "Trained batch 1079 batch loss 4.81169462 epoch total loss 6.36208773\n",
      "Trained batch 1080 batch loss 5.68295765 epoch total loss 6.36145926\n",
      "Trained batch 1081 batch loss 6.9301 epoch total loss 6.36198521\n",
      "Trained batch 1082 batch loss 6.99910355 epoch total loss 6.3625741\n",
      "Trained batch 1083 batch loss 7.01250553 epoch total loss 6.36317444\n",
      "Trained batch 1084 batch loss 6.79117155 epoch total loss 6.36356926\n",
      "Trained batch 1085 batch loss 6.55021381 epoch total loss 6.3637414\n",
      "Trained batch 1086 batch loss 6.39250708 epoch total loss 6.36376762\n",
      "Trained batch 1087 batch loss 6.28568792 epoch total loss 6.3636961\n",
      "Trained batch 1088 batch loss 5.99522209 epoch total loss 6.36335707\n",
      "Trained batch 1089 batch loss 5.9334712 epoch total loss 6.36296225\n",
      "Trained batch 1090 batch loss 5.94601059 epoch total loss 6.36258\n",
      "Trained batch 1091 batch loss 6.31117725 epoch total loss 6.36253262\n",
      "Trained batch 1092 batch loss 5.30253744 epoch total loss 6.36156178\n",
      "Trained batch 1093 batch loss 5.33431 epoch total loss 6.36062241\n",
      "Trained batch 1094 batch loss 5.68540955 epoch total loss 6.36000538\n",
      "Trained batch 1095 batch loss 5.93505764 epoch total loss 6.35961723\n",
      "Trained batch 1096 batch loss 5.5258441 epoch total loss 6.3588562\n",
      "Trained batch 1097 batch loss 5.68715811 epoch total loss 6.35824394\n",
      "Trained batch 1098 batch loss 6.09792757 epoch total loss 6.35800695\n",
      "Trained batch 1099 batch loss 6.07225418 epoch total loss 6.35774708\n",
      "Trained batch 1100 batch loss 6.19940853 epoch total loss 6.35760307\n",
      "Trained batch 1101 batch loss 5.65518427 epoch total loss 6.35696507\n",
      "Trained batch 1102 batch loss 6.08773279 epoch total loss 6.35672092\n",
      "Trained batch 1103 batch loss 6.22500229 epoch total loss 6.35660172\n",
      "Trained batch 1104 batch loss 6.54159307 epoch total loss 6.35676908\n",
      "Trained batch 1105 batch loss 6.49662685 epoch total loss 6.35689545\n",
      "Trained batch 1106 batch loss 7.03621054 epoch total loss 6.35750961\n",
      "Trained batch 1107 batch loss 6.61773777 epoch total loss 6.35774469\n",
      "Trained batch 1108 batch loss 6.45402 epoch total loss 6.35783148\n",
      "Trained batch 1109 batch loss 6.31055832 epoch total loss 6.35778904\n",
      "Trained batch 1110 batch loss 6.22407341 epoch total loss 6.35766888\n",
      "Trained batch 1111 batch loss 6.18649101 epoch total loss 6.35751438\n",
      "Trained batch 1112 batch loss 6.1320014 epoch total loss 6.35731173\n",
      "Trained batch 1113 batch loss 6.32363272 epoch total loss 6.35728168\n",
      "Trained batch 1114 batch loss 6.08897305 epoch total loss 6.35704041\n",
      "Trained batch 1115 batch loss 6.40022087 epoch total loss 6.35707951\n",
      "Trained batch 1116 batch loss 6.15809393 epoch total loss 6.35690117\n",
      "Trained batch 1117 batch loss 6.50271845 epoch total loss 6.35703182\n",
      "Trained batch 1118 batch loss 6.33207941 epoch total loss 6.35700941\n",
      "Trained batch 1119 batch loss 6.50190735 epoch total loss 6.35713911\n",
      "Trained batch 1120 batch loss 6.98479223 epoch total loss 6.35769939\n",
      "Trained batch 1121 batch loss 6.37781668 epoch total loss 6.35771751\n",
      "Trained batch 1122 batch loss 5.8997159 epoch total loss 6.35731\n",
      "Trained batch 1123 batch loss 6.58139038 epoch total loss 6.35750914\n",
      "Trained batch 1124 batch loss 6.56664276 epoch total loss 6.3576951\n",
      "Trained batch 1125 batch loss 6.40148687 epoch total loss 6.35773373\n",
      "Trained batch 1126 batch loss 6.78377724 epoch total loss 6.35811234\n",
      "Trained batch 1127 batch loss 6.69956398 epoch total loss 6.35841513\n",
      "Trained batch 1128 batch loss 7.03264332 epoch total loss 6.35901308\n",
      "Trained batch 1129 batch loss 6.59370422 epoch total loss 6.35922098\n",
      "Trained batch 1130 batch loss 6.43924665 epoch total loss 6.35929203\n",
      "Trained batch 1131 batch loss 6.50424385 epoch total loss 6.3594203\n",
      "Trained batch 1132 batch loss 6.75571394 epoch total loss 6.35977077\n",
      "Trained batch 1133 batch loss 7.1865344 epoch total loss 6.36050034\n",
      "Trained batch 1134 batch loss 6.39554119 epoch total loss 6.36053133\n",
      "Trained batch 1135 batch loss 6.15127134 epoch total loss 6.36034679\n",
      "Trained batch 1136 batch loss 6.28281116 epoch total loss 6.36027861\n",
      "Trained batch 1137 batch loss 5.62940502 epoch total loss 6.35963583\n",
      "Trained batch 1138 batch loss 5.56817579 epoch total loss 6.35894\n",
      "Trained batch 1139 batch loss 6.17923975 epoch total loss 6.35878277\n",
      "Trained batch 1140 batch loss 5.63123131 epoch total loss 6.35814428\n",
      "Trained batch 1141 batch loss 5.42887449 epoch total loss 6.35733\n",
      "Trained batch 1142 batch loss 5.08501673 epoch total loss 6.35621548\n",
      "Trained batch 1143 batch loss 5.3820591 epoch total loss 6.35536337\n",
      "Trained batch 1144 batch loss 5.72338343 epoch total loss 6.35481071\n",
      "Trained batch 1145 batch loss 6.2278533 epoch total loss 6.3547\n",
      "Trained batch 1146 batch loss 6.49102879 epoch total loss 6.35481882\n",
      "Trained batch 1147 batch loss 6.73943377 epoch total loss 6.35515404\n",
      "Trained batch 1148 batch loss 6.64720488 epoch total loss 6.35540819\n",
      "Trained batch 1149 batch loss 6.95013237 epoch total loss 6.35592604\n",
      "Trained batch 1150 batch loss 7.3652277 epoch total loss 6.35680389\n",
      "Trained batch 1151 batch loss 7.16798544 epoch total loss 6.35750818\n",
      "Trained batch 1152 batch loss 6.55000353 epoch total loss 6.35767555\n",
      "Trained batch 1153 batch loss 6.17440367 epoch total loss 6.35751629\n",
      "Trained batch 1154 batch loss 6.28398561 epoch total loss 6.35745287\n",
      "Trained batch 1155 batch loss 6.70276 epoch total loss 6.35775185\n",
      "Trained batch 1156 batch loss 6.26452923 epoch total loss 6.35767126\n",
      "Trained batch 1157 batch loss 6.18169641 epoch total loss 6.35751915\n",
      "Trained batch 1158 batch loss 6.07343245 epoch total loss 6.35727358\n",
      "Trained batch 1159 batch loss 5.99432039 epoch total loss 6.3569603\n",
      "Trained batch 1160 batch loss 6.8411684 epoch total loss 6.35737753\n",
      "Trained batch 1161 batch loss 6.86411333 epoch total loss 6.35781431\n",
      "Trained batch 1162 batch loss 6.64894247 epoch total loss 6.35806465\n",
      "Trained batch 1163 batch loss 6.41501188 epoch total loss 6.35811377\n",
      "Trained batch 1164 batch loss 6.36891031 epoch total loss 6.3581233\n",
      "Trained batch 1165 batch loss 6.55681419 epoch total loss 6.35829353\n",
      "Trained batch 1166 batch loss 6.40408039 epoch total loss 6.35833311\n",
      "Trained batch 1167 batch loss 6.25795794 epoch total loss 6.3582468\n",
      "Trained batch 1168 batch loss 6.28842306 epoch total loss 6.3581872\n",
      "Trained batch 1169 batch loss 6.33451939 epoch total loss 6.35816717\n",
      "Trained batch 1170 batch loss 6.01756716 epoch total loss 6.35787582\n",
      "Trained batch 1171 batch loss 6.31530046 epoch total loss 6.35783958\n",
      "Trained batch 1172 batch loss 6.29225 epoch total loss 6.35778379\n",
      "Trained batch 1173 batch loss 6.48244858 epoch total loss 6.35789\n",
      "Trained batch 1174 batch loss 6.39194918 epoch total loss 6.35791922\n",
      "Trained batch 1175 batch loss 6.74195814 epoch total loss 6.35824633\n",
      "Trained batch 1176 batch loss 6.40308 epoch total loss 6.35828447\n",
      "Trained batch 1177 batch loss 6.56638098 epoch total loss 6.35846138\n",
      "Trained batch 1178 batch loss 6.36965799 epoch total loss 6.35847092\n",
      "Trained batch 1179 batch loss 6.17021847 epoch total loss 6.35831165\n",
      "Trained batch 1180 batch loss 6.12433434 epoch total loss 6.35811329\n",
      "Trained batch 1181 batch loss 6.2633481 epoch total loss 6.35803318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1182 batch loss 6.02274179 epoch total loss 6.35774946\n",
      "Trained batch 1183 batch loss 6.48206186 epoch total loss 6.35785437\n",
      "Trained batch 1184 batch loss 6.27432 epoch total loss 6.35778379\n",
      "Trained batch 1185 batch loss 6.18273163 epoch total loss 6.35763597\n",
      "Trained batch 1186 batch loss 6.06667614 epoch total loss 6.35739088\n",
      "Trained batch 1187 batch loss 5.82988834 epoch total loss 6.35694695\n",
      "Trained batch 1188 batch loss 6.04558659 epoch total loss 6.35668468\n",
      "Trained batch 1189 batch loss 6.32961464 epoch total loss 6.3566618\n",
      "Trained batch 1190 batch loss 5.88690948 epoch total loss 6.35626698\n",
      "Trained batch 1191 batch loss 6.30702639 epoch total loss 6.35622549\n",
      "Trained batch 1192 batch loss 6.46514416 epoch total loss 6.35631704\n",
      "Trained batch 1193 batch loss 6.69701099 epoch total loss 6.35660267\n",
      "Trained batch 1194 batch loss 6.39658689 epoch total loss 6.35663605\n",
      "Trained batch 1195 batch loss 6.22088718 epoch total loss 6.35652208\n",
      "Trained batch 1196 batch loss 6.14432526 epoch total loss 6.3563447\n",
      "Trained batch 1197 batch loss 6.46667814 epoch total loss 6.35643721\n",
      "Trained batch 1198 batch loss 6.33299398 epoch total loss 6.35641766\n",
      "Trained batch 1199 batch loss 6.26142454 epoch total loss 6.35633802\n",
      "Trained batch 1200 batch loss 6.18054104 epoch total loss 6.35619164\n",
      "Trained batch 1201 batch loss 6.57816 epoch total loss 6.35637665\n",
      "Trained batch 1202 batch loss 6.7828927 epoch total loss 6.35673141\n",
      "Trained batch 1203 batch loss 7.09910297 epoch total loss 6.35734844\n",
      "Trained batch 1204 batch loss 6.42584467 epoch total loss 6.35740519\n",
      "Trained batch 1205 batch loss 6.29165459 epoch total loss 6.35735035\n",
      "Trained batch 1206 batch loss 6.27140665 epoch total loss 6.3572793\n",
      "Trained batch 1207 batch loss 6.22545624 epoch total loss 6.35717\n",
      "Trained batch 1208 batch loss 6.29427385 epoch total loss 6.35711813\n",
      "Trained batch 1209 batch loss 6.14870405 epoch total loss 6.35694599\n",
      "Trained batch 1210 batch loss 6.10643053 epoch total loss 6.35673904\n",
      "Trained batch 1211 batch loss 6.01591825 epoch total loss 6.35645771\n",
      "Trained batch 1212 batch loss 6.3972826 epoch total loss 6.35649157\n",
      "Trained batch 1213 batch loss 6.15562439 epoch total loss 6.3563261\n",
      "Trained batch 1214 batch loss 6.26977301 epoch total loss 6.35625458\n",
      "Trained batch 1215 batch loss 6.38407183 epoch total loss 6.35627794\n",
      "Trained batch 1216 batch loss 5.66356134 epoch total loss 6.35570812\n",
      "Trained batch 1217 batch loss 6.15525627 epoch total loss 6.35554361\n",
      "Trained batch 1218 batch loss 6.29617929 epoch total loss 6.35549498\n",
      "Trained batch 1219 batch loss 6.51511621 epoch total loss 6.35562563\n",
      "Trained batch 1220 batch loss 6.74955034 epoch total loss 6.35594845\n",
      "Trained batch 1221 batch loss 6.50863 epoch total loss 6.35607386\n",
      "Trained batch 1222 batch loss 6.1318779 epoch total loss 6.35589027\n",
      "Trained batch 1223 batch loss 6.11764812 epoch total loss 6.35569572\n",
      "Trained batch 1224 batch loss 5.93078423 epoch total loss 6.35534811\n",
      "Trained batch 1225 batch loss 6.33120966 epoch total loss 6.35532856\n",
      "Trained batch 1226 batch loss 6.5737896 epoch total loss 6.35550642\n",
      "Trained batch 1227 batch loss 6.48170614 epoch total loss 6.35560942\n",
      "Trained batch 1228 batch loss 6.55904102 epoch total loss 6.35577536\n",
      "Trained batch 1229 batch loss 6.74546957 epoch total loss 6.35609245\n",
      "Trained batch 1230 batch loss 6.94293594 epoch total loss 6.35657\n",
      "Trained batch 1231 batch loss 6.89176035 epoch total loss 6.35700417\n",
      "Trained batch 1232 batch loss 6.57800436 epoch total loss 6.35718346\n",
      "Trained batch 1233 batch loss 6.52211714 epoch total loss 6.35731745\n",
      "Trained batch 1234 batch loss 6.37791252 epoch total loss 6.35733414\n",
      "Trained batch 1235 batch loss 6.52380228 epoch total loss 6.35746908\n",
      "Trained batch 1236 batch loss 6.41490459 epoch total loss 6.35751534\n",
      "Trained batch 1237 batch loss 6.3027916 epoch total loss 6.35747099\n",
      "Trained batch 1238 batch loss 6.34394741 epoch total loss 6.35746\n",
      "Trained batch 1239 batch loss 6.55181885 epoch total loss 6.3576169\n",
      "Trained batch 1240 batch loss 6.44118786 epoch total loss 6.35768461\n",
      "Trained batch 1241 batch loss 6.21089697 epoch total loss 6.35756636\n",
      "Trained batch 1242 batch loss 6.46086 epoch total loss 6.35764933\n",
      "Trained batch 1243 batch loss 6.36032963 epoch total loss 6.35765171\n",
      "Trained batch 1244 batch loss 6.30684566 epoch total loss 6.3576107\n",
      "Trained batch 1245 batch loss 5.99903536 epoch total loss 6.35732269\n",
      "Trained batch 1246 batch loss 6.36291552 epoch total loss 6.35732698\n",
      "Trained batch 1247 batch loss 6.41710806 epoch total loss 6.35737467\n",
      "Trained batch 1248 batch loss 6.48874426 epoch total loss 6.35748\n",
      "Trained batch 1249 batch loss 6.51603127 epoch total loss 6.35760736\n",
      "Trained batch 1250 batch loss 6.59442949 epoch total loss 6.35779667\n",
      "Trained batch 1251 batch loss 6.88382196 epoch total loss 6.35821676\n",
      "Trained batch 1252 batch loss 5.88064718 epoch total loss 6.35783577\n",
      "Trained batch 1253 batch loss 6.39942551 epoch total loss 6.35786867\n",
      "Trained batch 1254 batch loss 6.35917854 epoch total loss 6.35787\n",
      "Trained batch 1255 batch loss 6.21880484 epoch total loss 6.357759\n",
      "Trained batch 1256 batch loss 6.07529 epoch total loss 6.35753441\n",
      "Trained batch 1257 batch loss 6.28769636 epoch total loss 6.35747862\n",
      "Trained batch 1258 batch loss 6.48981524 epoch total loss 6.35758352\n",
      "Trained batch 1259 batch loss 6.90934372 epoch total loss 6.35802174\n",
      "Trained batch 1260 batch loss 6.84292936 epoch total loss 6.35840654\n",
      "Trained batch 1261 batch loss 6.70945358 epoch total loss 6.35868502\n",
      "Trained batch 1262 batch loss 6.03439045 epoch total loss 6.358428\n",
      "Trained batch 1263 batch loss 6.21187687 epoch total loss 6.35831165\n",
      "Trained batch 1264 batch loss 6.43779802 epoch total loss 6.35837507\n",
      "Trained batch 1265 batch loss 6.70898438 epoch total loss 6.35865211\n",
      "Trained batch 1266 batch loss 6.40414667 epoch total loss 6.35868788\n",
      "Trained batch 1267 batch loss 6.34582138 epoch total loss 6.35867786\n",
      "Trained batch 1268 batch loss 6.4766469 epoch total loss 6.35877085\n",
      "Trained batch 1269 batch loss 6.23173666 epoch total loss 6.35867071\n",
      "Trained batch 1270 batch loss 6.43570042 epoch total loss 6.35873127\n",
      "Trained batch 1271 batch loss 6.60659122 epoch total loss 6.3589263\n",
      "Trained batch 1272 batch loss 6.61039114 epoch total loss 6.35912418\n",
      "Trained batch 1273 batch loss 6.60622454 epoch total loss 6.35931826\n",
      "Trained batch 1274 batch loss 6.45788956 epoch total loss 6.3593955\n",
      "Trained batch 1275 batch loss 6.57312 epoch total loss 6.35956335\n",
      "Trained batch 1276 batch loss 6.30037212 epoch total loss 6.3595171\n",
      "Trained batch 1277 batch loss 6.3407774 epoch total loss 6.35950232\n",
      "Trained batch 1278 batch loss 6.50990105 epoch total loss 6.35962\n",
      "Trained batch 1279 batch loss 6.6557579 epoch total loss 6.35985136\n",
      "Trained batch 1280 batch loss 6.62246656 epoch total loss 6.36005688\n",
      "Trained batch 1281 batch loss 6.52468252 epoch total loss 6.36018515\n",
      "Trained batch 1282 batch loss 6.32027626 epoch total loss 6.36015415\n",
      "Trained batch 1283 batch loss 5.79107332 epoch total loss 6.35971069\n",
      "Trained batch 1284 batch loss 5.63412523 epoch total loss 6.35914564\n",
      "Trained batch 1285 batch loss 6.13014412 epoch total loss 6.35896778\n",
      "Trained batch 1286 batch loss 6.05352449 epoch total loss 6.35873032\n",
      "Trained batch 1287 batch loss 6.17546654 epoch total loss 6.35858774\n",
      "Trained batch 1288 batch loss 6.39615536 epoch total loss 6.35861683\n",
      "Trained batch 1289 batch loss 6.39780092 epoch total loss 6.35864687\n",
      "Trained batch 1290 batch loss 6.34569216 epoch total loss 6.35863686\n",
      "Trained batch 1291 batch loss 6.48686886 epoch total loss 6.35873652\n",
      "Trained batch 1292 batch loss 6.60846329 epoch total loss 6.35892963\n",
      "Trained batch 1293 batch loss 6.62213898 epoch total loss 6.35913324\n",
      "Trained batch 1294 batch loss 6.44625378 epoch total loss 6.35920048\n",
      "Trained batch 1295 batch loss 6.33799 epoch total loss 6.35918427\n",
      "Trained batch 1296 batch loss 6.15040159 epoch total loss 6.35902309\n",
      "Trained batch 1297 batch loss 6.09169292 epoch total loss 6.3588171\n",
      "Trained batch 1298 batch loss 6.05773973 epoch total loss 6.35858488\n",
      "Trained batch 1299 batch loss 6.21922541 epoch total loss 6.35847759\n",
      "Trained batch 1300 batch loss 5.98753786 epoch total loss 6.35819197\n",
      "Trained batch 1301 batch loss 5.75055695 epoch total loss 6.35772514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1302 batch loss 6.08343124 epoch total loss 6.3575139\n",
      "Trained batch 1303 batch loss 6.46508694 epoch total loss 6.3575964\n",
      "Trained batch 1304 batch loss 7.17326355 epoch total loss 6.35822153\n",
      "Trained batch 1305 batch loss 6.78867722 epoch total loss 6.35855198\n",
      "Trained batch 1306 batch loss 6.7627039 epoch total loss 6.35886145\n",
      "Trained batch 1307 batch loss 7.09555721 epoch total loss 6.35942507\n",
      "Trained batch 1308 batch loss 7.18472719 epoch total loss 6.36005592\n",
      "Trained batch 1309 batch loss 6.61266613 epoch total loss 6.36024857\n",
      "Trained batch 1310 batch loss 6.35684586 epoch total loss 6.3602457\n",
      "Trained batch 1311 batch loss 6.52574587 epoch total loss 6.36037159\n",
      "Trained batch 1312 batch loss 6.35828495 epoch total loss 6.36037\n",
      "Trained batch 1313 batch loss 6.18590879 epoch total loss 6.36023712\n",
      "Trained batch 1314 batch loss 6.72887611 epoch total loss 6.3605175\n",
      "Trained batch 1315 batch loss 6.41345692 epoch total loss 6.36055708\n",
      "Trained batch 1316 batch loss 6.03413 epoch total loss 6.36030912\n",
      "Trained batch 1317 batch loss 6.28583622 epoch total loss 6.36025286\n",
      "Trained batch 1318 batch loss 6.54157972 epoch total loss 6.36039066\n",
      "Trained batch 1319 batch loss 7.02144814 epoch total loss 6.36089182\n",
      "Trained batch 1320 batch loss 6.47824097 epoch total loss 6.36098099\n",
      "Trained batch 1321 batch loss 6.8597517 epoch total loss 6.36135864\n",
      "Trained batch 1322 batch loss 6.77105 epoch total loss 6.36166859\n",
      "Trained batch 1323 batch loss 6.6393714 epoch total loss 6.36187887\n",
      "Trained batch 1324 batch loss 6.50769234 epoch total loss 6.36198902\n",
      "Trained batch 1325 batch loss 6.43525743 epoch total loss 6.36204433\n",
      "Trained batch 1326 batch loss 6.94410229 epoch total loss 6.3624835\n",
      "Trained batch 1327 batch loss 6.65953159 epoch total loss 6.36270714\n",
      "Trained batch 1328 batch loss 6.34777546 epoch total loss 6.36269569\n",
      "Trained batch 1329 batch loss 6.83241081 epoch total loss 6.36304903\n",
      "Trained batch 1330 batch loss 6.66496563 epoch total loss 6.363276\n",
      "Trained batch 1331 batch loss 6.49349976 epoch total loss 6.36337376\n",
      "Trained batch 1332 batch loss 6.74775314 epoch total loss 6.36366272\n",
      "Trained batch 1333 batch loss 6.69450569 epoch total loss 6.36391068\n",
      "Trained batch 1334 batch loss 6.81958055 epoch total loss 6.36425209\n",
      "Trained batch 1335 batch loss 6.73849583 epoch total loss 6.36453199\n",
      "Trained batch 1336 batch loss 6.49331045 epoch total loss 6.36462831\n",
      "Trained batch 1337 batch loss 6.70840597 epoch total loss 6.36488533\n",
      "Trained batch 1338 batch loss 6.36230564 epoch total loss 6.36488342\n",
      "Trained batch 1339 batch loss 6.65282583 epoch total loss 6.365098\n",
      "Trained batch 1340 batch loss 6.57753 epoch total loss 6.36525631\n",
      "Trained batch 1341 batch loss 6.60149908 epoch total loss 6.36543226\n",
      "Trained batch 1342 batch loss 6.21679735 epoch total loss 6.36532164\n",
      "Trained batch 1343 batch loss 6.01087809 epoch total loss 6.36505747\n",
      "Trained batch 1344 batch loss 5.76195621 epoch total loss 6.36460876\n",
      "Trained batch 1345 batch loss 5.99367809 epoch total loss 6.36433315\n",
      "Trained batch 1346 batch loss 6.22367573 epoch total loss 6.36422873\n",
      "Trained batch 1347 batch loss 6.47832918 epoch total loss 6.3643136\n",
      "Trained batch 1348 batch loss 6.33535957 epoch total loss 6.36429167\n",
      "Trained batch 1349 batch loss 6.2652359 epoch total loss 6.36421871\n",
      "Trained batch 1350 batch loss 6.21192169 epoch total loss 6.3641057\n",
      "Trained batch 1351 batch loss 6.53578615 epoch total loss 6.36423302\n",
      "Trained batch 1352 batch loss 6.06620121 epoch total loss 6.36401272\n",
      "Trained batch 1353 batch loss 6.54784536 epoch total loss 6.36414862\n",
      "Trained batch 1354 batch loss 6.47033882 epoch total loss 6.36422729\n",
      "Trained batch 1355 batch loss 6.85412312 epoch total loss 6.36458921\n",
      "Trained batch 1356 batch loss 6.57056236 epoch total loss 6.36474085\n",
      "Trained batch 1357 batch loss 6.61497355 epoch total loss 6.36492586\n",
      "Trained batch 1358 batch loss 6.60116625 epoch total loss 6.3651\n",
      "Trained batch 1359 batch loss 6.88773155 epoch total loss 6.36548424\n",
      "Trained batch 1360 batch loss 6.79975224 epoch total loss 6.36580372\n",
      "Trained batch 1361 batch loss 6.24103832 epoch total loss 6.36571217\n",
      "Trained batch 1362 batch loss 6.70339775 epoch total loss 6.36596\n",
      "Trained batch 1363 batch loss 6.92544222 epoch total loss 6.36637068\n",
      "Trained batch 1364 batch loss 6.57375956 epoch total loss 6.36652327\n",
      "Trained batch 1365 batch loss 6.68792772 epoch total loss 6.36675835\n",
      "Trained batch 1366 batch loss 6.50623608 epoch total loss 6.36686\n",
      "Trained batch 1367 batch loss 6.50287 epoch total loss 6.36695957\n",
      "Trained batch 1368 batch loss 6.33292246 epoch total loss 6.36693478\n",
      "Trained batch 1369 batch loss 6.26766205 epoch total loss 6.3668623\n",
      "Trained batch 1370 batch loss 6.04772902 epoch total loss 6.3666296\n",
      "Trained batch 1371 batch loss 6.33786964 epoch total loss 6.36660862\n",
      "Trained batch 1372 batch loss 6.58788824 epoch total loss 6.36677\n",
      "Trained batch 1373 batch loss 6.86529446 epoch total loss 6.36713266\n",
      "Trained batch 1374 batch loss 6.82436275 epoch total loss 6.3674655\n",
      "Trained batch 1375 batch loss 7.09318638 epoch total loss 6.36799288\n",
      "Trained batch 1376 batch loss 6.65801954 epoch total loss 6.36820364\n",
      "Trained batch 1377 batch loss 6.38623667 epoch total loss 6.36821747\n",
      "Trained batch 1378 batch loss 6.56285524 epoch total loss 6.36835814\n",
      "Trained batch 1379 batch loss 6.4555335 epoch total loss 6.36842108\n",
      "Trained batch 1380 batch loss 6.27206135 epoch total loss 6.36835146\n",
      "Trained batch 1381 batch loss 6.52364874 epoch total loss 6.36846399\n",
      "Trained batch 1382 batch loss 6.67450619 epoch total loss 6.36868572\n",
      "Trained batch 1383 batch loss 6.78134108 epoch total loss 6.36898375\n",
      "Trained batch 1384 batch loss 6.7055254 epoch total loss 6.36922693\n",
      "Trained batch 1385 batch loss 6.08375263 epoch total loss 6.36902094\n",
      "Trained batch 1386 batch loss 6.48322773 epoch total loss 6.36910343\n",
      "Trained batch 1387 batch loss 6.27548409 epoch total loss 6.36903572\n",
      "Trained batch 1388 batch loss 6.18494225 epoch total loss 6.36890268\n",
      "Epoch 2 train loss 6.368902683258057\n",
      "Validated batch 1 batch loss 6.57592344\n",
      "Validated batch 2 batch loss 6.30935621\n",
      "Validated batch 3 batch loss 6.1719408\n",
      "Validated batch 4 batch loss 5.95740461\n",
      "Validated batch 5 batch loss 6.22543764\n",
      "Validated batch 6 batch loss 6.28523159\n",
      "Validated batch 7 batch loss 6.27851057\n",
      "Validated batch 8 batch loss 6.46189642\n",
      "Validated batch 9 batch loss 6.53299189\n",
      "Validated batch 10 batch loss 6.21376562\n",
      "Validated batch 11 batch loss 6.29423761\n",
      "Validated batch 12 batch loss 5.78788948\n",
      "Validated batch 13 batch loss 6.6784153\n",
      "Validated batch 14 batch loss 6.16889524\n",
      "Validated batch 15 batch loss 6.30287886\n",
      "Validated batch 16 batch loss 6.50981665\n",
      "Validated batch 17 batch loss 6.26638508\n",
      "Validated batch 18 batch loss 5.64884281\n",
      "Validated batch 19 batch loss 6.03224182\n",
      "Validated batch 20 batch loss 6.37730217\n",
      "Validated batch 21 batch loss 6.03041697\n",
      "Validated batch 22 batch loss 6.19517803\n",
      "Validated batch 23 batch loss 6.24883127\n",
      "Validated batch 24 batch loss 5.99738646\n",
      "Validated batch 25 batch loss 6.60070133\n",
      "Validated batch 26 batch loss 6.40846157\n",
      "Validated batch 27 batch loss 6.50977755\n",
      "Validated batch 28 batch loss 6.45510387\n",
      "Validated batch 29 batch loss 6.6685586\n",
      "Validated batch 30 batch loss 6.27492\n",
      "Validated batch 31 batch loss 6.65527105\n",
      "Validated batch 32 batch loss 6.12279081\n",
      "Validated batch 33 batch loss 6.42492771\n",
      "Validated batch 34 batch loss 6.4318881\n",
      "Validated batch 35 batch loss 5.76889944\n",
      "Validated batch 36 batch loss 5.78945446\n",
      "Validated batch 37 batch loss 6.58205891\n",
      "Validated batch 38 batch loss 6.51626062\n",
      "Validated batch 39 batch loss 6.08938026\n",
      "Validated batch 40 batch loss 6.5470829\n",
      "Validated batch 41 batch loss 6.55210257\n",
      "Validated batch 42 batch loss 6.50889158\n",
      "Validated batch 43 batch loss 6.64146948\n",
      "Validated batch 44 batch loss 6.5908432\n",
      "Validated batch 45 batch loss 6.22458363\n",
      "Validated batch 46 batch loss 5.9987011\n",
      "Validated batch 47 batch loss 6.04866838\n",
      "Validated batch 48 batch loss 5.96230459\n",
      "Validated batch 49 batch loss 6.31632328\n",
      "Validated batch 50 batch loss 6.27969551\n",
      "Validated batch 51 batch loss 6.22049332\n",
      "Validated batch 52 batch loss 6.54937935\n",
      "Validated batch 53 batch loss 6.48220491\n",
      "Validated batch 54 batch loss 6.40484285\n",
      "Validated batch 55 batch loss 6.34175968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 56 batch loss 6.41238594\n",
      "Validated batch 57 batch loss 6.14021349\n",
      "Validated batch 58 batch loss 6.36065626\n",
      "Validated batch 59 batch loss 6.23265934\n",
      "Validated batch 60 batch loss 6.6309\n",
      "Validated batch 61 batch loss 6.53148842\n",
      "Validated batch 62 batch loss 6.20735931\n",
      "Validated batch 63 batch loss 6.55812454\n",
      "Validated batch 64 batch loss 5.87709236\n",
      "Validated batch 65 batch loss 6.38402414\n",
      "Validated batch 66 batch loss 6.47940826\n",
      "Validated batch 67 batch loss 6.38378811\n",
      "Validated batch 68 batch loss 6.54768038\n",
      "Validated batch 69 batch loss 6.11439323\n",
      "Validated batch 70 batch loss 6.41780329\n",
      "Validated batch 71 batch loss 6.33652735\n",
      "Validated batch 72 batch loss 6.09566927\n",
      "Validated batch 73 batch loss 6.10981607\n",
      "Validated batch 74 batch loss 6.42119837\n",
      "Validated batch 75 batch loss 6.33942652\n",
      "Validated batch 76 batch loss 6.40200281\n",
      "Validated batch 77 batch loss 6.30758\n",
      "Validated batch 78 batch loss 6.17045975\n",
      "Validated batch 79 batch loss 6.62944555\n",
      "Validated batch 80 batch loss 6.69537354\n",
      "Validated batch 81 batch loss 6.42412901\n",
      "Validated batch 82 batch loss 6.43106604\n",
      "Validated batch 83 batch loss 6.24177837\n",
      "Validated batch 84 batch loss 6.42535925\n",
      "Validated batch 85 batch loss 6.27168703\n",
      "Validated batch 86 batch loss 6.62616777\n",
      "Validated batch 87 batch loss 6.16914701\n",
      "Validated batch 88 batch loss 6.24567366\n",
      "Validated batch 89 batch loss 6.41654158\n",
      "Validated batch 90 batch loss 6.10366\n",
      "Validated batch 91 batch loss 6.55656815\n",
      "Validated batch 92 batch loss 6.5284729\n",
      "Validated batch 93 batch loss 6.82951784\n",
      "Validated batch 94 batch loss 6.4368515\n",
      "Validated batch 95 batch loss 6.45377827\n",
      "Validated batch 96 batch loss 6.35837555\n",
      "Validated batch 97 batch loss 6.38435221\n",
      "Validated batch 98 batch loss 6.6411953\n",
      "Validated batch 99 batch loss 6.28826857\n",
      "Validated batch 100 batch loss 6.11620665\n",
      "Validated batch 101 batch loss 6.14224958\n",
      "Validated batch 102 batch loss 6.28496408\n",
      "Validated batch 103 batch loss 6.46561384\n",
      "Validated batch 104 batch loss 6.30664158\n",
      "Validated batch 105 batch loss 6.05897617\n",
      "Validated batch 106 batch loss 6.01453686\n",
      "Validated batch 107 batch loss 6.20324135\n",
      "Validated batch 108 batch loss 6.53671932\n",
      "Validated batch 109 batch loss 6.53614569\n",
      "Validated batch 110 batch loss 6.55858278\n",
      "Validated batch 111 batch loss 6.84608555\n",
      "Validated batch 112 batch loss 7.11330795\n",
      "Validated batch 113 batch loss 6.87028694\n",
      "Validated batch 114 batch loss 6.29411936\n",
      "Validated batch 115 batch loss 6.02682209\n",
      "Validated batch 116 batch loss 6.11438656\n",
      "Validated batch 117 batch loss 6.40471745\n",
      "Validated batch 118 batch loss 6.14096928\n",
      "Validated batch 119 batch loss 6.68450832\n",
      "Validated batch 120 batch loss 6.78337336\n",
      "Validated batch 121 batch loss 6.59033871\n",
      "Validated batch 122 batch loss 6.46335602\n",
      "Validated batch 123 batch loss 6.49426126\n",
      "Validated batch 124 batch loss 6.59570694\n",
      "Validated batch 125 batch loss 6.43568277\n",
      "Validated batch 126 batch loss 6.82317781\n",
      "Validated batch 127 batch loss 6.76210785\n",
      "Validated batch 128 batch loss 6.03435898\n",
      "Validated batch 129 batch loss 6.62273073\n",
      "Validated batch 130 batch loss 6.23958635\n",
      "Validated batch 131 batch loss 6.47021151\n",
      "Validated batch 132 batch loss 6.59633398\n",
      "Validated batch 133 batch loss 5.86122751\n",
      "Validated batch 134 batch loss 6.01605558\n",
      "Validated batch 135 batch loss 6.52722597\n",
      "Validated batch 136 batch loss 6.23374748\n",
      "Validated batch 137 batch loss 6.83947182\n",
      "Validated batch 138 batch loss 6.2404089\n",
      "Validated batch 139 batch loss 6.34191036\n",
      "Validated batch 140 batch loss 6.39831734\n",
      "Validated batch 141 batch loss 6.18780231\n",
      "Validated batch 142 batch loss 5.59145689\n",
      "Validated batch 143 batch loss 6.20623779\n",
      "Validated batch 144 batch loss 6.59643\n",
      "Validated batch 145 batch loss 5.99284697\n",
      "Validated batch 146 batch loss 6.38103294\n",
      "Validated batch 147 batch loss 6.44193649\n",
      "Validated batch 148 batch loss 6.51402092\n",
      "Validated batch 149 batch loss 6.5776124\n",
      "Validated batch 150 batch loss 6.47873831\n",
      "Validated batch 151 batch loss 6.03106737\n",
      "Validated batch 152 batch loss 6.46323538\n",
      "Validated batch 153 batch loss 6.49327135\n",
      "Validated batch 154 batch loss 6.73958349\n",
      "Validated batch 155 batch loss 6.32436132\n",
      "Validated batch 156 batch loss 6.58559895\n",
      "Validated batch 157 batch loss 6.49187\n",
      "Validated batch 158 batch loss 6.12002802\n",
      "Validated batch 159 batch loss 6.33900833\n",
      "Validated batch 160 batch loss 6.39843416\n",
      "Validated batch 161 batch loss 6.62116575\n",
      "Validated batch 162 batch loss 6.50909805\n",
      "Validated batch 163 batch loss 6.79116297\n",
      "Validated batch 164 batch loss 6.31927967\n",
      "Validated batch 165 batch loss 5.79258347\n",
      "Validated batch 166 batch loss 6.29556704\n",
      "Validated batch 167 batch loss 6.1808362\n",
      "Validated batch 168 batch loss 6.06732273\n",
      "Validated batch 169 batch loss 6.04080057\n",
      "Validated batch 170 batch loss 5.83024311\n",
      "Validated batch 171 batch loss 6.60471106\n",
      "Validated batch 172 batch loss 6.28065729\n",
      "Validated batch 173 batch loss 5.98543167\n",
      "Validated batch 174 batch loss 5.85244703\n",
      "Validated batch 175 batch loss 6.57507944\n",
      "Validated batch 176 batch loss 6.01480675\n",
      "Validated batch 177 batch loss 6.30416489\n",
      "Validated batch 178 batch loss 6.24239683\n",
      "Validated batch 179 batch loss 6.6099987\n",
      "Validated batch 180 batch loss 6.16207075\n",
      "Validated batch 181 batch loss 6.37714338\n",
      "Validated batch 182 batch loss 6.57053757\n",
      "Validated batch 183 batch loss 5.63046932\n",
      "Validated batch 184 batch loss 6.1947608\n",
      "Validated batch 185 batch loss 3.52228975\n",
      "Epoch 2 val loss 6.327327251434326\n",
      "Model /aiffel/aiffel/mpii/models1/simple_baseline-epoch-2-loss-6.3273.h5 saved.\n",
      "Start epoch 3 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 6.4697156 epoch total loss 6.4697156\n",
      "Trained batch 2 batch loss 6.27925634 epoch total loss 6.37448597\n",
      "Trained batch 3 batch loss 6.05229235 epoch total loss 6.26708794\n",
      "Trained batch 4 batch loss 6.60876513 epoch total loss 6.35250711\n",
      "Trained batch 5 batch loss 6.47092247 epoch total loss 6.37619\n",
      "Trained batch 6 batch loss 6.62789106 epoch total loss 6.41814041\n",
      "Trained batch 7 batch loss 6.4691186 epoch total loss 6.42542315\n",
      "Trained batch 8 batch loss 6.35504103 epoch total loss 6.4166255\n",
      "Trained batch 9 batch loss 5.88904 epoch total loss 6.35800505\n",
      "Trained batch 10 batch loss 6.29125071 epoch total loss 6.35133\n",
      "Trained batch 11 batch loss 6.42649794 epoch total loss 6.35816336\n",
      "Trained batch 12 batch loss 6.30437279 epoch total loss 6.35368109\n",
      "Trained batch 13 batch loss 6.28789425 epoch total loss 6.34862041\n",
      "Trained batch 14 batch loss 6.46125221 epoch total loss 6.35666561\n",
      "Trained batch 15 batch loss 6.50776482 epoch total loss 6.3667388\n",
      "Trained batch 16 batch loss 6.62780857 epoch total loss 6.38305569\n",
      "Trained batch 17 batch loss 6.05782938 epoch total loss 6.36392498\n",
      "Trained batch 18 batch loss 5.97204733 epoch total loss 6.34215355\n",
      "Trained batch 19 batch loss 6.23206758 epoch total loss 6.33636\n",
      "Trained batch 20 batch loss 6.7459774 epoch total loss 6.35684109\n",
      "Trained batch 21 batch loss 6.46650219 epoch total loss 6.36206293\n",
      "Trained batch 22 batch loss 6.55895567 epoch total loss 6.37101269\n",
      "Trained batch 23 batch loss 6.54903555 epoch total loss 6.37875319\n",
      "Trained batch 24 batch loss 6.49540424 epoch total loss 6.38361359\n",
      "Trained batch 25 batch loss 6.54982 epoch total loss 6.39026165\n",
      "Trained batch 26 batch loss 6.62945557 epoch total loss 6.39946175\n",
      "Trained batch 27 batch loss 6.57455 epoch total loss 6.40594673\n",
      "Trained batch 28 batch loss 6.50009346 epoch total loss 6.40930891\n",
      "Trained batch 29 batch loss 6.58877754 epoch total loss 6.4154973\n",
      "Trained batch 30 batch loss 6.45406437 epoch total loss 6.41678333\n",
      "Trained batch 31 batch loss 6.49146509 epoch total loss 6.41919231\n",
      "Trained batch 32 batch loss 6.41931248 epoch total loss 6.41919613\n",
      "Trained batch 33 batch loss 6.63256598 epoch total loss 6.42566204\n",
      "Trained batch 34 batch loss 6.55507231 epoch total loss 6.42946815\n",
      "Trained batch 35 batch loss 6.3380456 epoch total loss 6.42685604\n",
      "Trained batch 36 batch loss 6.4476161 epoch total loss 6.42743254\n",
      "Trained batch 37 batch loss 6.35051 epoch total loss 6.42535353\n",
      "Trained batch 38 batch loss 6.31784678 epoch total loss 6.42252445\n",
      "Trained batch 39 batch loss 6.38236809 epoch total loss 6.42149448\n",
      "Trained batch 40 batch loss 6.47890615 epoch total loss 6.42293024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 41 batch loss 6.33462715 epoch total loss 6.42077637\n",
      "Trained batch 42 batch loss 6.12265444 epoch total loss 6.41367817\n",
      "Trained batch 43 batch loss 6.41456032 epoch total loss 6.4136982\n",
      "Trained batch 44 batch loss 6.05480909 epoch total loss 6.4055419\n",
      "Trained batch 45 batch loss 6.22106028 epoch total loss 6.40144253\n",
      "Trained batch 46 batch loss 6.35100174 epoch total loss 6.40034628\n",
      "Trained batch 47 batch loss 6.49002171 epoch total loss 6.4022541\n",
      "Trained batch 48 batch loss 6.80720091 epoch total loss 6.41069031\n",
      "Trained batch 49 batch loss 6.09181595 epoch total loss 6.40418291\n",
      "Trained batch 50 batch loss 6.50567 epoch total loss 6.40621281\n",
      "Trained batch 51 batch loss 6.3859849 epoch total loss 6.40581608\n",
      "Trained batch 52 batch loss 6.62956238 epoch total loss 6.41011858\n",
      "Trained batch 53 batch loss 6.45811462 epoch total loss 6.41102457\n",
      "Trained batch 54 batch loss 6.32409668 epoch total loss 6.40941477\n",
      "Trained batch 55 batch loss 6.47515869 epoch total loss 6.41061\n",
      "Trained batch 56 batch loss 6.3006258 epoch total loss 6.40864611\n",
      "Trained batch 57 batch loss 5.94462919 epoch total loss 6.40050554\n",
      "Trained batch 58 batch loss 6.1192522 epoch total loss 6.39565659\n",
      "Trained batch 59 batch loss 5.58392239 epoch total loss 6.3818984\n",
      "Trained batch 60 batch loss 5.70581627 epoch total loss 6.37063026\n",
      "Trained batch 61 batch loss 5.9221797 epoch total loss 6.36327887\n",
      "Trained batch 62 batch loss 6.66672707 epoch total loss 6.36817312\n",
      "Trained batch 63 batch loss 6.62687922 epoch total loss 6.37227964\n",
      "Trained batch 64 batch loss 7.12564707 epoch total loss 6.38405085\n",
      "Trained batch 65 batch loss 6.7382679 epoch total loss 6.38950062\n",
      "Trained batch 66 batch loss 6.95332575 epoch total loss 6.39804363\n",
      "Trained batch 67 batch loss 6.21121264 epoch total loss 6.39525509\n",
      "Trained batch 68 batch loss 6.48069906 epoch total loss 6.39651155\n",
      "Trained batch 69 batch loss 5.98884344 epoch total loss 6.39060354\n",
      "Trained batch 70 batch loss 5.84543324 epoch total loss 6.38281488\n",
      "Trained batch 71 batch loss 6.19870663 epoch total loss 6.38022184\n",
      "Trained batch 72 batch loss 6.31704092 epoch total loss 6.37934446\n",
      "Trained batch 73 batch loss 6.4558382 epoch total loss 6.38039255\n",
      "Trained batch 74 batch loss 6.62918282 epoch total loss 6.38375425\n",
      "Trained batch 75 batch loss 6.44771862 epoch total loss 6.38460732\n",
      "Trained batch 76 batch loss 6.01166296 epoch total loss 6.3797\n",
      "Trained batch 77 batch loss 6.33068752 epoch total loss 6.37906361\n",
      "Trained batch 78 batch loss 6.29427624 epoch total loss 6.37797642\n",
      "Trained batch 79 batch loss 6.21399927 epoch total loss 6.37590075\n",
      "Trained batch 80 batch loss 6.26814699 epoch total loss 6.37455416\n",
      "Trained batch 81 batch loss 6.33568096 epoch total loss 6.37407398\n",
      "Trained batch 82 batch loss 6.97825718 epoch total loss 6.38144207\n",
      "Trained batch 83 batch loss 6.87185049 epoch total loss 6.38735056\n",
      "Trained batch 84 batch loss 7.02574205 epoch total loss 6.39495039\n",
      "Trained batch 85 batch loss 6.42576599 epoch total loss 6.39531326\n",
      "Trained batch 86 batch loss 6.47748184 epoch total loss 6.39626884\n",
      "Trained batch 87 batch loss 5.92122841 epoch total loss 6.39080811\n",
      "Trained batch 88 batch loss 5.95776081 epoch total loss 6.38588715\n",
      "Trained batch 89 batch loss 6.00371075 epoch total loss 6.38159323\n",
      "Trained batch 90 batch loss 6.38496542 epoch total loss 6.38163042\n",
      "Trained batch 91 batch loss 6.49555779 epoch total loss 6.38288212\n",
      "Trained batch 92 batch loss 6.40915966 epoch total loss 6.38316822\n",
      "Trained batch 93 batch loss 6.41501284 epoch total loss 6.38351059\n",
      "Trained batch 94 batch loss 5.7217741 epoch total loss 6.37647152\n",
      "Trained batch 95 batch loss 6.00687885 epoch total loss 6.37258101\n",
      "Trained batch 96 batch loss 6.54079485 epoch total loss 6.3743329\n",
      "Trained batch 97 batch loss 6.60671663 epoch total loss 6.37672853\n",
      "Trained batch 98 batch loss 6.46391201 epoch total loss 6.37761831\n",
      "Trained batch 99 batch loss 6.20052576 epoch total loss 6.37582922\n",
      "Trained batch 100 batch loss 6.15701771 epoch total loss 6.37364149\n",
      "Trained batch 101 batch loss 6.3093338 epoch total loss 6.37300444\n",
      "Trained batch 102 batch loss 6.50084066 epoch total loss 6.37425804\n",
      "Trained batch 103 batch loss 6.93469715 epoch total loss 6.37969923\n",
      "Trained batch 104 batch loss 6.65726566 epoch total loss 6.38236809\n",
      "Trained batch 105 batch loss 6.28224516 epoch total loss 6.38141441\n",
      "Trained batch 106 batch loss 6.32794714 epoch total loss 6.38091\n",
      "Trained batch 107 batch loss 6.3170414 epoch total loss 6.38031292\n",
      "Trained batch 108 batch loss 6.38803768 epoch total loss 6.38038445\n",
      "Trained batch 109 batch loss 6.24775314 epoch total loss 6.37916756\n",
      "Trained batch 110 batch loss 6.19042301 epoch total loss 6.3774519\n",
      "Trained batch 111 batch loss 6.3684516 epoch total loss 6.37737083\n",
      "Trained batch 112 batch loss 6.29070282 epoch total loss 6.3765974\n",
      "Trained batch 113 batch loss 6.79679537 epoch total loss 6.38031578\n",
      "Trained batch 114 batch loss 6.43155909 epoch total loss 6.38076591\n",
      "Trained batch 115 batch loss 6.39327383 epoch total loss 6.38087416\n",
      "Trained batch 116 batch loss 6.47656965 epoch total loss 6.38169909\n",
      "Trained batch 117 batch loss 6.59937525 epoch total loss 6.3835597\n",
      "Trained batch 118 batch loss 6.21049738 epoch total loss 6.38209295\n",
      "Trained batch 119 batch loss 6.62341595 epoch total loss 6.38412094\n",
      "Trained batch 120 batch loss 5.97047234 epoch total loss 6.38067389\n",
      "Trained batch 121 batch loss 5.59943295 epoch total loss 6.37421703\n",
      "Trained batch 122 batch loss 5.5988903 epoch total loss 6.36786175\n",
      "Trained batch 123 batch loss 6.15986156 epoch total loss 6.36617088\n",
      "Trained batch 124 batch loss 6.17663813 epoch total loss 6.36464214\n",
      "Trained batch 125 batch loss 6.7819767 epoch total loss 6.36798096\n",
      "Trained batch 126 batch loss 6.52560091 epoch total loss 6.3692317\n",
      "Trained batch 127 batch loss 6.26151371 epoch total loss 6.36838388\n",
      "Trained batch 128 batch loss 6.02437258 epoch total loss 6.36569595\n",
      "Trained batch 129 batch loss 6.19070148 epoch total loss 6.36433935\n",
      "Trained batch 130 batch loss 6.73167086 epoch total loss 6.36716509\n",
      "Trained batch 131 batch loss 6.48453093 epoch total loss 6.36806107\n",
      "Trained batch 132 batch loss 6.51376152 epoch total loss 6.36916447\n",
      "Trained batch 133 batch loss 6.49853373 epoch total loss 6.37013721\n",
      "Trained batch 134 batch loss 6.07871246 epoch total loss 6.36796284\n",
      "Trained batch 135 batch loss 6.40108728 epoch total loss 6.36820793\n",
      "Trained batch 136 batch loss 6.48048306 epoch total loss 6.36903334\n",
      "Trained batch 137 batch loss 5.80508709 epoch total loss 6.36491728\n",
      "Trained batch 138 batch loss 6.16899729 epoch total loss 6.36349773\n",
      "Trained batch 139 batch loss 6.2851162 epoch total loss 6.36293364\n",
      "Trained batch 140 batch loss 6.25746 epoch total loss 6.36218\n",
      "Trained batch 141 batch loss 6.46125555 epoch total loss 6.36288261\n",
      "Trained batch 142 batch loss 6.35961866 epoch total loss 6.36285973\n",
      "Trained batch 143 batch loss 6.40563869 epoch total loss 6.3631587\n",
      "Trained batch 144 batch loss 6.56233835 epoch total loss 6.36454201\n",
      "Trained batch 145 batch loss 6.59823227 epoch total loss 6.36615324\n",
      "Trained batch 146 batch loss 6.75283813 epoch total loss 6.36880207\n",
      "Trained batch 147 batch loss 6.71227598 epoch total loss 6.37113857\n",
      "Trained batch 148 batch loss 6.32577515 epoch total loss 6.37083244\n",
      "Trained batch 149 batch loss 6.29129601 epoch total loss 6.37029886\n",
      "Trained batch 150 batch loss 6.1362 epoch total loss 6.3687377\n",
      "Trained batch 151 batch loss 5.8296051 epoch total loss 6.36516714\n",
      "Trained batch 152 batch loss 6.31078053 epoch total loss 6.36480951\n",
      "Trained batch 153 batch loss 6.44061041 epoch total loss 6.36530495\n",
      "Trained batch 154 batch loss 6.19484377 epoch total loss 6.36419773\n",
      "Trained batch 155 batch loss 5.52613783 epoch total loss 6.35879087\n",
      "Trained batch 156 batch loss 5.38433075 epoch total loss 6.35254431\n",
      "Trained batch 157 batch loss 6.53189087 epoch total loss 6.35368681\n",
      "Trained batch 158 batch loss 5.76083374 epoch total loss 6.34993458\n",
      "Trained batch 159 batch loss 6.16693592 epoch total loss 6.34878349\n",
      "Trained batch 160 batch loss 6.34347105 epoch total loss 6.34875\n",
      "Trained batch 161 batch loss 6.09036446 epoch total loss 6.34714556\n",
      "Trained batch 162 batch loss 6.19970894 epoch total loss 6.34623575\n",
      "Trained batch 163 batch loss 6.18191 epoch total loss 6.34522772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 164 batch loss 6.44992733 epoch total loss 6.3458662\n",
      "Trained batch 165 batch loss 6.33705044 epoch total loss 6.3458128\n",
      "Trained batch 166 batch loss 6.78733826 epoch total loss 6.3484726\n",
      "Trained batch 167 batch loss 5.0629797 epoch total loss 6.34077501\n",
      "Trained batch 168 batch loss 4.98234749 epoch total loss 6.33268881\n",
      "Trained batch 169 batch loss 5.17221165 epoch total loss 6.32582235\n",
      "Trained batch 170 batch loss 6.94324303 epoch total loss 6.32945395\n",
      "Trained batch 171 batch loss 6.95704174 epoch total loss 6.33312416\n",
      "Trained batch 172 batch loss 7.15868378 epoch total loss 6.337924\n",
      "Trained batch 173 batch loss 6.81958818 epoch total loss 6.34070826\n",
      "Trained batch 174 batch loss 6.64794254 epoch total loss 6.34247398\n",
      "Trained batch 175 batch loss 6.15654898 epoch total loss 6.34141111\n",
      "Trained batch 176 batch loss 6.27589512 epoch total loss 6.3410387\n",
      "Trained batch 177 batch loss 6.10979462 epoch total loss 6.33973217\n",
      "Trained batch 178 batch loss 6.34232092 epoch total loss 6.33974648\n",
      "Trained batch 179 batch loss 5.83570051 epoch total loss 6.33693027\n",
      "Trained batch 180 batch loss 6.13524628 epoch total loss 6.33581\n",
      "Trained batch 181 batch loss 6.05444717 epoch total loss 6.3342557\n",
      "Trained batch 182 batch loss 6.11715794 epoch total loss 6.33306265\n",
      "Trained batch 183 batch loss 5.93051147 epoch total loss 6.33086348\n",
      "Trained batch 184 batch loss 6.04826784 epoch total loss 6.32932711\n",
      "Trained batch 185 batch loss 6.20051479 epoch total loss 6.32863092\n",
      "Trained batch 186 batch loss 6.46864748 epoch total loss 6.32938385\n",
      "Trained batch 187 batch loss 6.58511496 epoch total loss 6.33075094\n",
      "Trained batch 188 batch loss 6.47448158 epoch total loss 6.33151579\n",
      "Trained batch 189 batch loss 5.7778573 epoch total loss 6.3285861\n",
      "Trained batch 190 batch loss 6.55982304 epoch total loss 6.32980299\n",
      "Trained batch 191 batch loss 6.45529079 epoch total loss 6.33046055\n",
      "Trained batch 192 batch loss 6.36082554 epoch total loss 6.33061838\n",
      "Trained batch 193 batch loss 6.16036844 epoch total loss 6.32973671\n",
      "Trained batch 194 batch loss 6.06098127 epoch total loss 6.3283515\n",
      "Trained batch 195 batch loss 6.19942951 epoch total loss 6.3276906\n",
      "Trained batch 196 batch loss 6.79511881 epoch total loss 6.33007574\n",
      "Trained batch 197 batch loss 6.95616245 epoch total loss 6.33325386\n",
      "Trained batch 198 batch loss 6.75792 epoch total loss 6.33539867\n",
      "Trained batch 199 batch loss 6.3735528 epoch total loss 6.33559036\n",
      "Trained batch 200 batch loss 6.28312922 epoch total loss 6.33532763\n",
      "Trained batch 201 batch loss 6.03460836 epoch total loss 6.33383179\n",
      "Trained batch 202 batch loss 6.62114334 epoch total loss 6.33525419\n",
      "Trained batch 203 batch loss 6.59389973 epoch total loss 6.33652782\n",
      "Trained batch 204 batch loss 6.44610071 epoch total loss 6.33706474\n",
      "Trained batch 205 batch loss 6.47451258 epoch total loss 6.33773518\n",
      "Trained batch 206 batch loss 6.19357 epoch total loss 6.33703566\n",
      "Trained batch 207 batch loss 6.36761141 epoch total loss 6.337183\n",
      "Trained batch 208 batch loss 6.61998272 epoch total loss 6.33854246\n",
      "Trained batch 209 batch loss 6.67863607 epoch total loss 6.34016943\n",
      "Trained batch 210 batch loss 6.60743332 epoch total loss 6.34144211\n",
      "Trained batch 211 batch loss 6.54713583 epoch total loss 6.34241724\n",
      "Trained batch 212 batch loss 6.4955039 epoch total loss 6.34313917\n",
      "Trained batch 213 batch loss 6.28065538 epoch total loss 6.34284544\n",
      "Trained batch 214 batch loss 6.47932911 epoch total loss 6.34348345\n",
      "Trained batch 215 batch loss 6.33790636 epoch total loss 6.3434577\n",
      "Trained batch 216 batch loss 6.49271345 epoch total loss 6.34414864\n",
      "Trained batch 217 batch loss 6.93601465 epoch total loss 6.34687614\n",
      "Trained batch 218 batch loss 6.39454317 epoch total loss 6.34709454\n",
      "Trained batch 219 batch loss 6.5237112 epoch total loss 6.34790087\n",
      "Trained batch 220 batch loss 6.33209896 epoch total loss 6.34782934\n",
      "Trained batch 221 batch loss 6.37734175 epoch total loss 6.34796286\n",
      "Trained batch 222 batch loss 5.94749117 epoch total loss 6.34615898\n",
      "Trained batch 223 batch loss 6.16529799 epoch total loss 6.34534788\n",
      "Trained batch 224 batch loss 6.31741858 epoch total loss 6.34522295\n",
      "Trained batch 225 batch loss 6.10467577 epoch total loss 6.34415436\n",
      "Trained batch 226 batch loss 6.4347868 epoch total loss 6.34455538\n",
      "Trained batch 227 batch loss 6.26810598 epoch total loss 6.34421825\n",
      "Trained batch 228 batch loss 6.51493931 epoch total loss 6.34496689\n",
      "Trained batch 229 batch loss 6.107584 epoch total loss 6.34393024\n",
      "Trained batch 230 batch loss 6.33231306 epoch total loss 6.3438797\n",
      "Trained batch 231 batch loss 6.90196228 epoch total loss 6.34629536\n",
      "Trained batch 232 batch loss 6.57455349 epoch total loss 6.34727955\n",
      "Trained batch 233 batch loss 5.96468449 epoch total loss 6.3456378\n",
      "Trained batch 234 batch loss 6.30753279 epoch total loss 6.34547472\n",
      "Trained batch 235 batch loss 6.35820723 epoch total loss 6.3455286\n",
      "Trained batch 236 batch loss 6.75288534 epoch total loss 6.34725475\n",
      "Trained batch 237 batch loss 6.70644855 epoch total loss 6.34877\n",
      "Trained batch 238 batch loss 6.8219943 epoch total loss 6.35075855\n",
      "Trained batch 239 batch loss 7.07637787 epoch total loss 6.35379505\n",
      "Trained batch 240 batch loss 6.6510849 epoch total loss 6.35503387\n",
      "Trained batch 241 batch loss 6.86070538 epoch total loss 6.35713196\n",
      "Trained batch 242 batch loss 6.62474632 epoch total loss 6.35823822\n",
      "Trained batch 243 batch loss 6.49244404 epoch total loss 6.3587904\n",
      "Trained batch 244 batch loss 6.16146946 epoch total loss 6.35798168\n",
      "Trained batch 245 batch loss 6.45163393 epoch total loss 6.35836411\n",
      "Trained batch 246 batch loss 6.48622465 epoch total loss 6.35888386\n",
      "Trained batch 247 batch loss 6.47417688 epoch total loss 6.35935\n",
      "Trained batch 248 batch loss 6.57784557 epoch total loss 6.3602314\n",
      "Trained batch 249 batch loss 6.47398806 epoch total loss 6.36068821\n",
      "Trained batch 250 batch loss 6.25004864 epoch total loss 6.3602457\n",
      "Trained batch 251 batch loss 6.53091526 epoch total loss 6.36092567\n",
      "Trained batch 252 batch loss 6.69360209 epoch total loss 6.36224556\n",
      "Trained batch 253 batch loss 6.33516 epoch total loss 6.36213875\n",
      "Trained batch 254 batch loss 6.41703081 epoch total loss 6.36235476\n",
      "Trained batch 255 batch loss 6.37619925 epoch total loss 6.36240911\n",
      "Trained batch 256 batch loss 6.30140972 epoch total loss 6.3621707\n",
      "Trained batch 257 batch loss 6.30307341 epoch total loss 6.36194086\n",
      "Trained batch 258 batch loss 6.05672169 epoch total loss 6.36075783\n",
      "Trained batch 259 batch loss 5.89795399 epoch total loss 6.35897112\n",
      "Trained batch 260 batch loss 5.6384716 epoch total loss 6.35619974\n",
      "Trained batch 261 batch loss 6.2936039 epoch total loss 6.35596\n",
      "Trained batch 262 batch loss 6.3640461 epoch total loss 6.35599041\n",
      "Trained batch 263 batch loss 6.71441364 epoch total loss 6.35735321\n",
      "Trained batch 264 batch loss 6.54350376 epoch total loss 6.35805798\n",
      "Trained batch 265 batch loss 6.32321215 epoch total loss 6.35792685\n",
      "Trained batch 266 batch loss 6.45433283 epoch total loss 6.35828924\n",
      "Trained batch 267 batch loss 6.2331 epoch total loss 6.35782051\n",
      "Trained batch 268 batch loss 6.18406296 epoch total loss 6.35717249\n",
      "Trained batch 269 batch loss 6.43442488 epoch total loss 6.35745955\n",
      "Trained batch 270 batch loss 6.20193291 epoch total loss 6.35688353\n",
      "Trained batch 271 batch loss 5.88681746 epoch total loss 6.35514879\n",
      "Trained batch 272 batch loss 6.30664349 epoch total loss 6.35497046\n",
      "Trained batch 273 batch loss 6.39407682 epoch total loss 6.35511351\n",
      "Trained batch 274 batch loss 6.13315296 epoch total loss 6.35430384\n",
      "Trained batch 275 batch loss 6.00814199 epoch total loss 6.35304499\n",
      "Trained batch 276 batch loss 6.03416204 epoch total loss 6.35188961\n",
      "Trained batch 277 batch loss 5.90013409 epoch total loss 6.35025883\n",
      "Trained batch 278 batch loss 6.44128466 epoch total loss 6.35058641\n",
      "Trained batch 279 batch loss 6.24723053 epoch total loss 6.35021591\n",
      "Trained batch 280 batch loss 5.81672192 epoch total loss 6.34831047\n",
      "Trained batch 281 batch loss 6.54161739 epoch total loss 6.34899855\n",
      "Trained batch 282 batch loss 6.26699066 epoch total loss 6.34870768\n",
      "Trained batch 283 batch loss 6.08657551 epoch total loss 6.34778118\n",
      "Trained batch 284 batch loss 6.25587273 epoch total loss 6.34745789\n",
      "Trained batch 285 batch loss 6.24596691 epoch total loss 6.34710169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 286 batch loss 5.87850523 epoch total loss 6.34546328\n",
      "Trained batch 287 batch loss 6.19230938 epoch total loss 6.34492922\n",
      "Trained batch 288 batch loss 6.20525265 epoch total loss 6.34444427\n",
      "Trained batch 289 batch loss 6.37874413 epoch total loss 6.34456301\n",
      "Trained batch 290 batch loss 6.41198254 epoch total loss 6.3447957\n",
      "Trained batch 291 batch loss 6.27920437 epoch total loss 6.34457\n",
      "Trained batch 292 batch loss 5.32955837 epoch total loss 6.34109402\n",
      "Trained batch 293 batch loss 5.53309774 epoch total loss 6.33833647\n",
      "Trained batch 294 batch loss 5.6629734 epoch total loss 6.33603907\n",
      "Trained batch 295 batch loss 6.12938118 epoch total loss 6.33533859\n",
      "Trained batch 296 batch loss 5.99258518 epoch total loss 6.33418083\n",
      "Trained batch 297 batch loss 6.48888063 epoch total loss 6.33470154\n",
      "Trained batch 298 batch loss 6.07848215 epoch total loss 6.3338418\n",
      "Trained batch 299 batch loss 6.19601107 epoch total loss 6.33338118\n",
      "Trained batch 300 batch loss 6.1182642 epoch total loss 6.33266401\n",
      "Trained batch 301 batch loss 6.75194454 epoch total loss 6.33405685\n",
      "Trained batch 302 batch loss 7.0164876 epoch total loss 6.33631659\n",
      "Trained batch 303 batch loss 6.92065477 epoch total loss 6.33824492\n",
      "Trained batch 304 batch loss 7.06732512 epoch total loss 6.34064341\n",
      "Trained batch 305 batch loss 6.4700284 epoch total loss 6.34106779\n",
      "Trained batch 306 batch loss 6.40367222 epoch total loss 6.34127235\n",
      "Trained batch 307 batch loss 6.03750372 epoch total loss 6.34028292\n",
      "Trained batch 308 batch loss 6.36942625 epoch total loss 6.34037733\n",
      "Trained batch 309 batch loss 6.4171114 epoch total loss 6.34062576\n",
      "Trained batch 310 batch loss 6.4394989 epoch total loss 6.34094429\n",
      "Trained batch 311 batch loss 6.24157143 epoch total loss 6.34062481\n",
      "Trained batch 312 batch loss 6.34477091 epoch total loss 6.34063816\n",
      "Trained batch 313 batch loss 6.46525 epoch total loss 6.34103584\n",
      "Trained batch 314 batch loss 5.93767548 epoch total loss 6.33975124\n",
      "Trained batch 315 batch loss 6.62995434 epoch total loss 6.34067249\n",
      "Trained batch 316 batch loss 6.49878931 epoch total loss 6.34117317\n",
      "Trained batch 317 batch loss 6.86243105 epoch total loss 6.34281731\n",
      "Trained batch 318 batch loss 6.56498337 epoch total loss 6.34351587\n",
      "Trained batch 319 batch loss 7.00827789 epoch total loss 6.34559965\n",
      "Trained batch 320 batch loss 6.02972126 epoch total loss 6.3446126\n",
      "Trained batch 321 batch loss 5.658144 epoch total loss 6.34247398\n",
      "Trained batch 322 batch loss 5.99947309 epoch total loss 6.34140921\n",
      "Trained batch 323 batch loss 6.61270666 epoch total loss 6.34224892\n",
      "Trained batch 324 batch loss 6.69717503 epoch total loss 6.34334469\n",
      "Trained batch 325 batch loss 6.3068676 epoch total loss 6.34323263\n",
      "Trained batch 326 batch loss 6.35013819 epoch total loss 6.34325361\n",
      "Trained batch 327 batch loss 6.65241671 epoch total loss 6.3441987\n",
      "Trained batch 328 batch loss 6.68341732 epoch total loss 6.34523249\n",
      "Trained batch 329 batch loss 6.47004747 epoch total loss 6.34561205\n",
      "Trained batch 330 batch loss 6.71955 epoch total loss 6.34674501\n",
      "Trained batch 331 batch loss 6.55926085 epoch total loss 6.34738684\n",
      "Trained batch 332 batch loss 6.47773266 epoch total loss 6.34777975\n",
      "Trained batch 333 batch loss 6.60358 epoch total loss 6.34854794\n",
      "Trained batch 334 batch loss 6.50788069 epoch total loss 6.34902477\n",
      "Trained batch 335 batch loss 6.75540876 epoch total loss 6.35023737\n",
      "Trained batch 336 batch loss 6.58997393 epoch total loss 6.35095119\n",
      "Trained batch 337 batch loss 6.05856419 epoch total loss 6.35008383\n",
      "Trained batch 338 batch loss 5.98324585 epoch total loss 6.34899807\n",
      "Trained batch 339 batch loss 6.64844275 epoch total loss 6.34988165\n",
      "Trained batch 340 batch loss 6.48018456 epoch total loss 6.35026503\n",
      "Trained batch 341 batch loss 6.50570059 epoch total loss 6.35072041\n",
      "Trained batch 342 batch loss 6.22108126 epoch total loss 6.3503418\n",
      "Trained batch 343 batch loss 6.65809631 epoch total loss 6.3512392\n",
      "Trained batch 344 batch loss 6.64751816 epoch total loss 6.35210037\n",
      "Trained batch 345 batch loss 6.63594389 epoch total loss 6.35292339\n",
      "Trained batch 346 batch loss 6.40263891 epoch total loss 6.35306692\n",
      "Trained batch 347 batch loss 6.416852 epoch total loss 6.3532505\n",
      "Trained batch 348 batch loss 6.443964 epoch total loss 6.35351086\n",
      "Trained batch 349 batch loss 6.30269718 epoch total loss 6.35336542\n",
      "Trained batch 350 batch loss 6.5802393 epoch total loss 6.35401344\n",
      "Trained batch 351 batch loss 6.22220659 epoch total loss 6.35363817\n",
      "Trained batch 352 batch loss 6.32695961 epoch total loss 6.35356188\n",
      "Trained batch 353 batch loss 6.38733101 epoch total loss 6.3536582\n",
      "Trained batch 354 batch loss 6.29341602 epoch total loss 6.35348797\n",
      "Trained batch 355 batch loss 6.31173325 epoch total loss 6.35337067\n",
      "Trained batch 356 batch loss 6.00948572 epoch total loss 6.35240459\n",
      "Trained batch 357 batch loss 6.44875956 epoch total loss 6.35267448\n",
      "Trained batch 358 batch loss 6.52212238 epoch total loss 6.35314798\n",
      "Trained batch 359 batch loss 6.28112888 epoch total loss 6.35294771\n",
      "Trained batch 360 batch loss 6.56051302 epoch total loss 6.35352421\n",
      "Trained batch 361 batch loss 6.811831 epoch total loss 6.35479403\n",
      "Trained batch 362 batch loss 6.32537889 epoch total loss 6.35471249\n",
      "Trained batch 363 batch loss 6.38023186 epoch total loss 6.35478258\n",
      "Trained batch 364 batch loss 6.21101284 epoch total loss 6.35438776\n",
      "Trained batch 365 batch loss 6.29276657 epoch total loss 6.35421848\n",
      "Trained batch 366 batch loss 5.95167112 epoch total loss 6.3531189\n",
      "Trained batch 367 batch loss 6.34175158 epoch total loss 6.3530879\n",
      "Trained batch 368 batch loss 6.25588512 epoch total loss 6.35282373\n",
      "Trained batch 369 batch loss 6.58088398 epoch total loss 6.35344172\n",
      "Trained batch 370 batch loss 6.60782528 epoch total loss 6.35412931\n",
      "Trained batch 371 batch loss 5.76370573 epoch total loss 6.35253763\n",
      "Trained batch 372 batch loss 5.61089897 epoch total loss 6.35054398\n",
      "Trained batch 373 batch loss 5.43432188 epoch total loss 6.34808779\n",
      "Trained batch 374 batch loss 6.55585146 epoch total loss 6.3486433\n",
      "Trained batch 375 batch loss 6.44914198 epoch total loss 6.34891129\n",
      "Trained batch 376 batch loss 6.25328064 epoch total loss 6.34865665\n",
      "Trained batch 377 batch loss 6.34662151 epoch total loss 6.34865141\n",
      "Trained batch 378 batch loss 6.39689732 epoch total loss 6.3487792\n",
      "Trained batch 379 batch loss 6.2918644 epoch total loss 6.348629\n",
      "Trained batch 380 batch loss 6.25477314 epoch total loss 6.34838247\n",
      "Trained batch 381 batch loss 6.19576645 epoch total loss 6.34798193\n",
      "Trained batch 382 batch loss 5.95563459 epoch total loss 6.34695435\n",
      "Trained batch 383 batch loss 6.48378229 epoch total loss 6.34731197\n",
      "Trained batch 384 batch loss 6.26782417 epoch total loss 6.34710503\n",
      "Trained batch 385 batch loss 6.25774431 epoch total loss 6.34687328\n",
      "Trained batch 386 batch loss 6.43836832 epoch total loss 6.34711027\n",
      "Trained batch 387 batch loss 6.21611118 epoch total loss 6.34677172\n",
      "Trained batch 388 batch loss 6.42163372 epoch total loss 6.34696484\n",
      "Trained batch 389 batch loss 6.37376356 epoch total loss 6.3470335\n",
      "Trained batch 390 batch loss 6.2311492 epoch total loss 6.34673643\n",
      "Trained batch 391 batch loss 5.98417854 epoch total loss 6.34580946\n",
      "Trained batch 392 batch loss 6.26789236 epoch total loss 6.34561\n",
      "Trained batch 393 batch loss 6.77623367 epoch total loss 6.34670591\n",
      "Trained batch 394 batch loss 6.48141861 epoch total loss 6.34704781\n",
      "Trained batch 395 batch loss 6.55248737 epoch total loss 6.34756804\n",
      "Trained batch 396 batch loss 6.42298126 epoch total loss 6.34775877\n",
      "Trained batch 397 batch loss 6.62340641 epoch total loss 6.34845257\n",
      "Trained batch 398 batch loss 6.4375844 epoch total loss 6.3486762\n",
      "Trained batch 399 batch loss 6.34645081 epoch total loss 6.34867096\n",
      "Trained batch 400 batch loss 6.26385832 epoch total loss 6.34845877\n",
      "Trained batch 401 batch loss 6.01790619 epoch total loss 6.34763432\n",
      "Trained batch 402 batch loss 6.27105331 epoch total loss 6.34744358\n",
      "Trained batch 403 batch loss 6.35013199 epoch total loss 6.34745026\n",
      "Trained batch 404 batch loss 6.68839264 epoch total loss 6.34829426\n",
      "Trained batch 405 batch loss 6.5351963 epoch total loss 6.34875584\n",
      "Trained batch 406 batch loss 6.5315609 epoch total loss 6.34920597\n",
      "Trained batch 407 batch loss 6.29401255 epoch total loss 6.34907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 408 batch loss 6.48945618 epoch total loss 6.34941435\n",
      "Trained batch 409 batch loss 6.43682528 epoch total loss 6.34962797\n",
      "Trained batch 410 batch loss 6.50322342 epoch total loss 6.35000229\n",
      "Trained batch 411 batch loss 6.44283152 epoch total loss 6.35022831\n",
      "Trained batch 412 batch loss 6.32592678 epoch total loss 6.35016918\n",
      "Trained batch 413 batch loss 6.12995148 epoch total loss 6.34963608\n",
      "Trained batch 414 batch loss 6.36129761 epoch total loss 6.34966421\n",
      "Trained batch 415 batch loss 6.48728466 epoch total loss 6.34999609\n",
      "Trained batch 416 batch loss 6.40959787 epoch total loss 6.35013914\n",
      "Trained batch 417 batch loss 6.54946709 epoch total loss 6.35061741\n",
      "Trained batch 418 batch loss 6.36857367 epoch total loss 6.3506608\n",
      "Trained batch 419 batch loss 6.36162853 epoch total loss 6.35068655\n",
      "Trained batch 420 batch loss 6.38950157 epoch total loss 6.35077906\n",
      "Trained batch 421 batch loss 6.38469887 epoch total loss 6.35085964\n",
      "Trained batch 422 batch loss 6.52207756 epoch total loss 6.35126495\n",
      "Trained batch 423 batch loss 6.36084557 epoch total loss 6.35128784\n",
      "Trained batch 424 batch loss 6.33021 epoch total loss 6.35123825\n",
      "Trained batch 425 batch loss 6.5053463 epoch total loss 6.35160112\n",
      "Trained batch 426 batch loss 6.56878901 epoch total loss 6.35211086\n",
      "Trained batch 427 batch loss 6.96811104 epoch total loss 6.3535533\n",
      "Trained batch 428 batch loss 6.84030151 epoch total loss 6.35469055\n",
      "Trained batch 429 batch loss 7.31566334 epoch total loss 6.35693073\n",
      "Trained batch 430 batch loss 7.41673183 epoch total loss 6.3593955\n",
      "Trained batch 431 batch loss 7.19149303 epoch total loss 6.36132574\n",
      "Trained batch 432 batch loss 7.11594677 epoch total loss 6.36307287\n",
      "Trained batch 433 batch loss 6.86527634 epoch total loss 6.36423254\n",
      "Trained batch 434 batch loss 6.67732334 epoch total loss 6.36495352\n",
      "Trained batch 435 batch loss 6.72165585 epoch total loss 6.36577368\n",
      "Trained batch 436 batch loss 6.71310043 epoch total loss 6.36657047\n",
      "Trained batch 437 batch loss 6.84013081 epoch total loss 6.36765385\n",
      "Trained batch 438 batch loss 6.73158932 epoch total loss 6.36848497\n",
      "Trained batch 439 batch loss 6.49359655 epoch total loss 6.36877\n",
      "Trained batch 440 batch loss 6.51007891 epoch total loss 6.36909103\n",
      "Trained batch 441 batch loss 6.45224285 epoch total loss 6.36927938\n",
      "Trained batch 442 batch loss 6.42425394 epoch total loss 6.36940432\n",
      "Trained batch 443 batch loss 6.07261276 epoch total loss 6.36873388\n",
      "Trained batch 444 batch loss 6.56240177 epoch total loss 6.36917\n",
      "Trained batch 445 batch loss 6.31376505 epoch total loss 6.36904573\n",
      "Trained batch 446 batch loss 6.45513344 epoch total loss 6.36923838\n",
      "Trained batch 447 batch loss 6.07605648 epoch total loss 6.3685832\n",
      "Trained batch 448 batch loss 6.15694 epoch total loss 6.36811066\n",
      "Trained batch 449 batch loss 6.44154263 epoch total loss 6.36827421\n",
      "Trained batch 450 batch loss 6.12932491 epoch total loss 6.36774349\n",
      "Trained batch 451 batch loss 6.15202284 epoch total loss 6.36726522\n",
      "Trained batch 452 batch loss 6.17202854 epoch total loss 6.36683369\n",
      "Trained batch 453 batch loss 5.9123559 epoch total loss 6.36583042\n",
      "Trained batch 454 batch loss 6.06603861 epoch total loss 6.36517\n",
      "Trained batch 455 batch loss 6.08846617 epoch total loss 6.36456156\n",
      "Trained batch 456 batch loss 6.14918184 epoch total loss 6.36408901\n",
      "Trained batch 457 batch loss 6.51155376 epoch total loss 6.36441183\n",
      "Trained batch 458 batch loss 6.08085251 epoch total loss 6.36379242\n",
      "Trained batch 459 batch loss 6.42654371 epoch total loss 6.36392927\n",
      "Trained batch 460 batch loss 6.68278837 epoch total loss 6.36462259\n",
      "Trained batch 461 batch loss 6.37604475 epoch total loss 6.36464691\n",
      "Trained batch 462 batch loss 6.51763773 epoch total loss 6.36497831\n",
      "Trained batch 463 batch loss 6.3060441 epoch total loss 6.364851\n",
      "Trained batch 464 batch loss 6.11234188 epoch total loss 6.36430693\n",
      "Trained batch 465 batch loss 5.95855665 epoch total loss 6.36343384\n",
      "Trained batch 466 batch loss 6.26809311 epoch total loss 6.36322927\n",
      "Trained batch 467 batch loss 6.57250118 epoch total loss 6.3636775\n",
      "Trained batch 468 batch loss 6.8368845 epoch total loss 6.36468887\n",
      "Trained batch 469 batch loss 6.64997721 epoch total loss 6.36529684\n",
      "Trained batch 470 batch loss 7.18460226 epoch total loss 6.36704\n",
      "Trained batch 471 batch loss 7.21466 epoch total loss 6.36883926\n",
      "Trained batch 472 batch loss 6.60830259 epoch total loss 6.3693471\n",
      "Trained batch 473 batch loss 5.78858423 epoch total loss 6.36811924\n",
      "Trained batch 474 batch loss 5.83855295 epoch total loss 6.36700201\n",
      "Trained batch 475 batch loss 5.50412226 epoch total loss 6.36518574\n",
      "Trained batch 476 batch loss 5.47480965 epoch total loss 6.36331511\n",
      "Trained batch 477 batch loss 5.82435703 epoch total loss 6.36218548\n",
      "Trained batch 478 batch loss 5.98258495 epoch total loss 6.36139154\n",
      "Trained batch 479 batch loss 5.92943907 epoch total loss 6.36049\n",
      "Trained batch 480 batch loss 6.23581409 epoch total loss 6.36023\n",
      "Trained batch 481 batch loss 6.20262957 epoch total loss 6.35990238\n",
      "Trained batch 482 batch loss 6.42416191 epoch total loss 6.36003542\n",
      "Trained batch 483 batch loss 6.05085659 epoch total loss 6.35939503\n",
      "Trained batch 484 batch loss 6.14321661 epoch total loss 6.35894871\n",
      "Trained batch 485 batch loss 5.94513559 epoch total loss 6.35809517\n",
      "Trained batch 486 batch loss 6.54699755 epoch total loss 6.35848427\n",
      "Trained batch 487 batch loss 6.44894028 epoch total loss 6.35867\n",
      "Trained batch 488 batch loss 6.56887293 epoch total loss 6.35910082\n",
      "Trained batch 489 batch loss 6.51234245 epoch total loss 6.35941458\n",
      "Trained batch 490 batch loss 6.23388624 epoch total loss 6.35915804\n",
      "Trained batch 491 batch loss 6.31648636 epoch total loss 6.35907125\n",
      "Trained batch 492 batch loss 6.49128723 epoch total loss 6.35933971\n",
      "Trained batch 493 batch loss 6.33489275 epoch total loss 6.35929\n",
      "Trained batch 494 batch loss 6.64155817 epoch total loss 6.35986185\n",
      "Trained batch 495 batch loss 6.59178114 epoch total loss 6.36033058\n",
      "Trained batch 496 batch loss 6.3418231 epoch total loss 6.36029291\n",
      "Trained batch 497 batch loss 6.01835 epoch total loss 6.35960484\n",
      "Trained batch 498 batch loss 5.87792921 epoch total loss 6.35863781\n",
      "Trained batch 499 batch loss 6.90159655 epoch total loss 6.35972595\n",
      "Trained batch 500 batch loss 6.76787233 epoch total loss 6.36054182\n",
      "Trained batch 501 batch loss 6.73705482 epoch total loss 6.36129332\n",
      "Trained batch 502 batch loss 6.72963428 epoch total loss 6.36202765\n",
      "Trained batch 503 batch loss 6.404037 epoch total loss 6.36211109\n",
      "Trained batch 504 batch loss 6.34683561 epoch total loss 6.36208105\n",
      "Trained batch 505 batch loss 6.49417448 epoch total loss 6.36234236\n",
      "Trained batch 506 batch loss 6.60872412 epoch total loss 6.36282921\n",
      "Trained batch 507 batch loss 6.53665686 epoch total loss 6.36317205\n",
      "Trained batch 508 batch loss 7.0115881 epoch total loss 6.36444807\n",
      "Trained batch 509 batch loss 6.75051689 epoch total loss 6.36520672\n",
      "Trained batch 510 batch loss 6.68456888 epoch total loss 6.36583281\n",
      "Trained batch 511 batch loss 6.61293507 epoch total loss 6.36631632\n",
      "Trained batch 512 batch loss 6.67216635 epoch total loss 6.3669138\n",
      "Trained batch 513 batch loss 6.36528301 epoch total loss 6.36691046\n",
      "Trained batch 514 batch loss 6.35092306 epoch total loss 6.36687946\n",
      "Trained batch 515 batch loss 6.64875555 epoch total loss 6.3674264\n",
      "Trained batch 516 batch loss 6.24025917 epoch total loss 6.36718\n",
      "Trained batch 517 batch loss 6.71322823 epoch total loss 6.36784887\n",
      "Trained batch 518 batch loss 6.6070118 epoch total loss 6.36831045\n",
      "Trained batch 519 batch loss 6.4048233 epoch total loss 6.36838102\n",
      "Trained batch 520 batch loss 6.51546431 epoch total loss 6.36866379\n",
      "Trained batch 521 batch loss 6.37664747 epoch total loss 6.36867905\n",
      "Trained batch 522 batch loss 6.42701674 epoch total loss 6.36879063\n",
      "Trained batch 523 batch loss 6.30421638 epoch total loss 6.36866713\n",
      "Trained batch 524 batch loss 6.33305407 epoch total loss 6.36859941\n",
      "Trained batch 525 batch loss 6.35190058 epoch total loss 6.36856747\n",
      "Trained batch 526 batch loss 6.55875874 epoch total loss 6.36892891\n",
      "Trained batch 527 batch loss 6.5423 epoch total loss 6.36925793\n",
      "Trained batch 528 batch loss 6.10094404 epoch total loss 6.36874962\n",
      "Trained batch 529 batch loss 6.17354393 epoch total loss 6.36838055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 530 batch loss 6.23705292 epoch total loss 6.36813259\n",
      "Trained batch 531 batch loss 6.36810732 epoch total loss 6.36813259\n",
      "Trained batch 532 batch loss 6.40621519 epoch total loss 6.36820459\n",
      "Trained batch 533 batch loss 6.11008072 epoch total loss 6.36772\n",
      "Trained batch 534 batch loss 5.84471941 epoch total loss 6.3667407\n",
      "Trained batch 535 batch loss 6.00219584 epoch total loss 6.3660593\n",
      "Trained batch 536 batch loss 6.4215765 epoch total loss 6.36616325\n",
      "Trained batch 537 batch loss 6.48575258 epoch total loss 6.36638594\n",
      "Trained batch 538 batch loss 6.55818653 epoch total loss 6.36674213\n",
      "Trained batch 539 batch loss 6.59652042 epoch total loss 6.36716843\n",
      "Trained batch 540 batch loss 6.51737213 epoch total loss 6.36744642\n",
      "Trained batch 541 batch loss 6.18940163 epoch total loss 6.3671174\n",
      "Trained batch 542 batch loss 5.77373409 epoch total loss 6.36602259\n",
      "Trained batch 543 batch loss 5.85737 epoch total loss 6.36508608\n",
      "Trained batch 544 batch loss 6.38367653 epoch total loss 6.36512041\n",
      "Trained batch 545 batch loss 6.49820375 epoch total loss 6.36536455\n",
      "Trained batch 546 batch loss 6.56879234 epoch total loss 6.36573744\n",
      "Trained batch 547 batch loss 6.57443523 epoch total loss 6.36611891\n",
      "Trained batch 548 batch loss 6.63641 epoch total loss 6.36661243\n",
      "Trained batch 549 batch loss 6.21854925 epoch total loss 6.36634254\n",
      "Trained batch 550 batch loss 6.3698535 epoch total loss 6.36634922\n",
      "Trained batch 551 batch loss 6.19241619 epoch total loss 6.36603308\n",
      "Trained batch 552 batch loss 6.12537336 epoch total loss 6.36559772\n",
      "Trained batch 553 batch loss 6.47063828 epoch total loss 6.36578751\n",
      "Trained batch 554 batch loss 6.52611828 epoch total loss 6.36607695\n",
      "Trained batch 555 batch loss 6.87115097 epoch total loss 6.36698675\n",
      "Trained batch 556 batch loss 6.88899183 epoch total loss 6.36792564\n",
      "Trained batch 557 batch loss 7.04253721 epoch total loss 6.36913681\n",
      "Trained batch 558 batch loss 6.91561794 epoch total loss 6.37011576\n",
      "Trained batch 559 batch loss 6.78281307 epoch total loss 6.3708539\n",
      "Trained batch 560 batch loss 7.37165117 epoch total loss 6.37264109\n",
      "Trained batch 561 batch loss 7.01025534 epoch total loss 6.37377739\n",
      "Trained batch 562 batch loss 6.89341 epoch total loss 6.37470198\n",
      "Trained batch 563 batch loss 6.33480215 epoch total loss 6.37463093\n",
      "Trained batch 564 batch loss 6.30118704 epoch total loss 6.37450075\n",
      "Trained batch 565 batch loss 5.87793922 epoch total loss 6.37362194\n",
      "Trained batch 566 batch loss 6.3845048 epoch total loss 6.37364149\n",
      "Trained batch 567 batch loss 6.35565901 epoch total loss 6.37360954\n",
      "Trained batch 568 batch loss 6.23985672 epoch total loss 6.37337399\n",
      "Trained batch 569 batch loss 6.61575031 epoch total loss 6.3738\n",
      "Trained batch 570 batch loss 6.74147034 epoch total loss 6.37444496\n",
      "Trained batch 571 batch loss 6.21348143 epoch total loss 6.37416267\n",
      "Trained batch 572 batch loss 6.27728 epoch total loss 6.3739934\n",
      "Trained batch 573 batch loss 6.09297609 epoch total loss 6.37350321\n",
      "Trained batch 574 batch loss 6.28753901 epoch total loss 6.37335348\n",
      "Trained batch 575 batch loss 6.40942526 epoch total loss 6.37341642\n",
      "Trained batch 576 batch loss 6.37460804 epoch total loss 6.37341833\n",
      "Trained batch 577 batch loss 6.52810955 epoch total loss 6.37368631\n",
      "Trained batch 578 batch loss 6.59752226 epoch total loss 6.37407351\n",
      "Trained batch 579 batch loss 6.97667789 epoch total loss 6.37511396\n",
      "Trained batch 580 batch loss 6.87401867 epoch total loss 6.37597418\n",
      "Trained batch 581 batch loss 6.72988653 epoch total loss 6.37658358\n",
      "Trained batch 582 batch loss 6.46309519 epoch total loss 6.37673187\n",
      "Trained batch 583 batch loss 6.3226285 epoch total loss 6.37663889\n",
      "Trained batch 584 batch loss 6.49677 epoch total loss 6.37684488\n",
      "Trained batch 585 batch loss 6.45040703 epoch total loss 6.37697077\n",
      "Trained batch 586 batch loss 6.7969656 epoch total loss 6.37768698\n",
      "Trained batch 587 batch loss 6.34802723 epoch total loss 6.37763691\n",
      "Trained batch 588 batch loss 6.35961199 epoch total loss 6.37760639\n",
      "Trained batch 589 batch loss 6.03616428 epoch total loss 6.37702656\n",
      "Trained batch 590 batch loss 6.38455439 epoch total loss 6.37703943\n",
      "Trained batch 591 batch loss 6.15536547 epoch total loss 6.37666416\n",
      "Trained batch 592 batch loss 6.29256916 epoch total loss 6.37652159\n",
      "Trained batch 593 batch loss 6.1650238 epoch total loss 6.37616491\n",
      "Trained batch 594 batch loss 6.50419092 epoch total loss 6.37638044\n",
      "Trained batch 595 batch loss 6.8462038 epoch total loss 6.37717\n",
      "Trained batch 596 batch loss 6.697258 epoch total loss 6.37770748\n",
      "Trained batch 597 batch loss 6.46489334 epoch total loss 6.37785339\n",
      "Trained batch 598 batch loss 6.52652168 epoch total loss 6.37810183\n",
      "Trained batch 599 batch loss 6.18585205 epoch total loss 6.37778091\n",
      "Trained batch 600 batch loss 6.44963121 epoch total loss 6.3779006\n",
      "Trained batch 601 batch loss 6.00179625 epoch total loss 6.37727499\n",
      "Trained batch 602 batch loss 5.90361738 epoch total loss 6.37648773\n",
      "Trained batch 603 batch loss 6.11423874 epoch total loss 6.37605286\n",
      "Trained batch 604 batch loss 6.35562944 epoch total loss 6.37601948\n",
      "Trained batch 605 batch loss 6.29071426 epoch total loss 6.37587833\n",
      "Trained batch 606 batch loss 6.13078213 epoch total loss 6.37547398\n",
      "Trained batch 607 batch loss 6.32483435 epoch total loss 6.37539101\n",
      "Trained batch 608 batch loss 6.42664051 epoch total loss 6.37547541\n",
      "Trained batch 609 batch loss 6.21209812 epoch total loss 6.37520742\n",
      "Trained batch 610 batch loss 6.40255165 epoch total loss 6.37525225\n",
      "Trained batch 611 batch loss 5.87795639 epoch total loss 6.37443829\n",
      "Trained batch 612 batch loss 6.11243725 epoch total loss 6.37401\n",
      "Trained batch 613 batch loss 7.0025506 epoch total loss 6.37503529\n",
      "Trained batch 614 batch loss 7.12464142 epoch total loss 6.37625647\n",
      "Trained batch 615 batch loss 6.78456497 epoch total loss 6.3769207\n",
      "Trained batch 616 batch loss 6.80716705 epoch total loss 6.37761879\n",
      "Trained batch 617 batch loss 6.53163433 epoch total loss 6.37786865\n",
      "Trained batch 618 batch loss 6.6166029 epoch total loss 6.37825537\n",
      "Trained batch 619 batch loss 6.64143 epoch total loss 6.37868\n",
      "Trained batch 620 batch loss 6.18723345 epoch total loss 6.37837172\n",
      "Trained batch 621 batch loss 6.4993062 epoch total loss 6.37856627\n",
      "Trained batch 622 batch loss 6.35433102 epoch total loss 6.37852716\n",
      "Trained batch 623 batch loss 6.61488342 epoch total loss 6.37890673\n",
      "Trained batch 624 batch loss 6.82275963 epoch total loss 6.37961817\n",
      "Trained batch 625 batch loss 6.71941948 epoch total loss 6.38016176\n",
      "Trained batch 626 batch loss 6.23856544 epoch total loss 6.37993526\n",
      "Trained batch 627 batch loss 6.28789902 epoch total loss 6.3797884\n",
      "Trained batch 628 batch loss 6.26483583 epoch total loss 6.37960577\n",
      "Trained batch 629 batch loss 6.36554909 epoch total loss 6.37958336\n",
      "Trained batch 630 batch loss 6.32422781 epoch total loss 6.37949514\n",
      "Trained batch 631 batch loss 6.27863073 epoch total loss 6.3793354\n",
      "Trained batch 632 batch loss 6.44276762 epoch total loss 6.37943602\n",
      "Trained batch 633 batch loss 6.54016352 epoch total loss 6.37969\n",
      "Trained batch 634 batch loss 6.85776949 epoch total loss 6.38044405\n",
      "Trained batch 635 batch loss 6.61672211 epoch total loss 6.38081598\n",
      "Trained batch 636 batch loss 5.94458199 epoch total loss 6.38013\n",
      "Trained batch 637 batch loss 6.66473389 epoch total loss 6.38057709\n",
      "Trained batch 638 batch loss 6.60215616 epoch total loss 6.38092422\n",
      "Trained batch 639 batch loss 6.54076195 epoch total loss 6.38117409\n",
      "Trained batch 640 batch loss 6.09589434 epoch total loss 6.38072872\n",
      "Trained batch 641 batch loss 6.23393106 epoch total loss 6.38049936\n",
      "Trained batch 642 batch loss 6.24723434 epoch total loss 6.38029194\n",
      "Trained batch 643 batch loss 6.08415174 epoch total loss 6.37983131\n",
      "Trained batch 644 batch loss 6.43165112 epoch total loss 6.37991142\n",
      "Trained batch 645 batch loss 6.56912708 epoch total loss 6.38020515\n",
      "Trained batch 646 batch loss 6.05457592 epoch total loss 6.37970161\n",
      "Trained batch 647 batch loss 6.23308563 epoch total loss 6.37947464\n",
      "Trained batch 648 batch loss 6.49806499 epoch total loss 6.37965775\n",
      "Trained batch 649 batch loss 6.53103495 epoch total loss 6.37989092\n",
      "Trained batch 650 batch loss 6.12132788 epoch total loss 6.37949276\n",
      "Trained batch 651 batch loss 6.49493122 epoch total loss 6.37967062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 652 batch loss 6.49274111 epoch total loss 6.37984371\n",
      "Trained batch 653 batch loss 6.68481064 epoch total loss 6.38031054\n",
      "Trained batch 654 batch loss 6.60924339 epoch total loss 6.38066101\n",
      "Trained batch 655 batch loss 6.83192 epoch total loss 6.38135\n",
      "Trained batch 656 batch loss 6.94814825 epoch total loss 6.38221407\n",
      "Trained batch 657 batch loss 6.50551605 epoch total loss 6.38240147\n",
      "Trained batch 658 batch loss 6.06197834 epoch total loss 6.38191462\n",
      "Trained batch 659 batch loss 6.09449577 epoch total loss 6.38147879\n",
      "Trained batch 660 batch loss 5.87749863 epoch total loss 6.38071489\n",
      "Trained batch 661 batch loss 5.4989543 epoch total loss 6.37938118\n",
      "Trained batch 662 batch loss 6.25842381 epoch total loss 6.37919855\n",
      "Trained batch 663 batch loss 5.62972689 epoch total loss 6.37806797\n",
      "Trained batch 664 batch loss 5.18286371 epoch total loss 6.37626839\n",
      "Trained batch 665 batch loss 4.96287489 epoch total loss 6.37414312\n",
      "Trained batch 666 batch loss 5.37170887 epoch total loss 6.37263775\n",
      "Trained batch 667 batch loss 5.95592499 epoch total loss 6.37201309\n",
      "Trained batch 668 batch loss 6.16616344 epoch total loss 6.37170506\n",
      "Trained batch 669 batch loss 6.47493362 epoch total loss 6.37185955\n",
      "Trained batch 670 batch loss 6.73410892 epoch total loss 6.3724\n",
      "Trained batch 671 batch loss 6.72534227 epoch total loss 6.37292624\n",
      "Trained batch 672 batch loss 6.74913073 epoch total loss 6.37348557\n",
      "Trained batch 673 batch loss 6.50867224 epoch total loss 6.37368679\n",
      "Trained batch 674 batch loss 6.49309635 epoch total loss 6.37386417\n",
      "Trained batch 675 batch loss 6.05195665 epoch total loss 6.37338686\n",
      "Trained batch 676 batch loss 6.5656929 epoch total loss 6.37367153\n",
      "Trained batch 677 batch loss 6.71614361 epoch total loss 6.37417793\n",
      "Trained batch 678 batch loss 7.00200748 epoch total loss 6.37510347\n",
      "Trained batch 679 batch loss 7.16522932 epoch total loss 6.37626696\n",
      "Trained batch 680 batch loss 6.33681297 epoch total loss 6.37620926\n",
      "Trained batch 681 batch loss 5.8922925 epoch total loss 6.37549829\n",
      "Trained batch 682 batch loss 6.21584654 epoch total loss 6.37526417\n",
      "Trained batch 683 batch loss 6.4296689 epoch total loss 6.3753438\n",
      "Trained batch 684 batch loss 6.08000946 epoch total loss 6.37491226\n",
      "Trained batch 685 batch loss 6.55991316 epoch total loss 6.37518263\n",
      "Trained batch 686 batch loss 6.53810215 epoch total loss 6.37542\n",
      "Trained batch 687 batch loss 6.42364788 epoch total loss 6.37549\n",
      "Trained batch 688 batch loss 6.32101822 epoch total loss 6.37541103\n",
      "Trained batch 689 batch loss 6.33598471 epoch total loss 6.37535381\n",
      "Trained batch 690 batch loss 6.4624896 epoch total loss 6.3754797\n",
      "Trained batch 691 batch loss 6.33281326 epoch total loss 6.37541819\n",
      "Trained batch 692 batch loss 6.33411 epoch total loss 6.37535858\n",
      "Trained batch 693 batch loss 6.27264309 epoch total loss 6.37521\n",
      "Trained batch 694 batch loss 6.42067051 epoch total loss 6.37527561\n",
      "Trained batch 695 batch loss 6.00618219 epoch total loss 6.37474489\n",
      "Trained batch 696 batch loss 6.30534554 epoch total loss 6.37464523\n",
      "Trained batch 697 batch loss 6.14385271 epoch total loss 6.37431431\n",
      "Trained batch 698 batch loss 6.54953909 epoch total loss 6.37456465\n",
      "Trained batch 699 batch loss 5.98409224 epoch total loss 6.37400579\n",
      "Trained batch 700 batch loss 6.19746494 epoch total loss 6.37375355\n",
      "Trained batch 701 batch loss 6.2595644 epoch total loss 6.37359095\n",
      "Trained batch 702 batch loss 6.14395571 epoch total loss 6.37326384\n",
      "Trained batch 703 batch loss 5.96827 epoch total loss 6.37268782\n",
      "Trained batch 704 batch loss 6.81869888 epoch total loss 6.37332153\n",
      "Trained batch 705 batch loss 6.88867569 epoch total loss 6.37405252\n",
      "Trained batch 706 batch loss 6.11767769 epoch total loss 6.37368917\n",
      "Trained batch 707 batch loss 6.0301528 epoch total loss 6.37320375\n",
      "Trained batch 708 batch loss 6.46624947 epoch total loss 6.37333536\n",
      "Trained batch 709 batch loss 6.60485077 epoch total loss 6.37366199\n",
      "Trained batch 710 batch loss 6.62966204 epoch total loss 6.37402296\n",
      "Trained batch 711 batch loss 6.57711744 epoch total loss 6.37430859\n",
      "Trained batch 712 batch loss 6.28842402 epoch total loss 6.37418795\n",
      "Trained batch 713 batch loss 6.05933094 epoch total loss 6.37374687\n",
      "Trained batch 714 batch loss 6.12982798 epoch total loss 6.37340546\n",
      "Trained batch 715 batch loss 5.6219449 epoch total loss 6.37235451\n",
      "Trained batch 716 batch loss 5.49546909 epoch total loss 6.37113\n",
      "Trained batch 717 batch loss 5.61391973 epoch total loss 6.3700738\n",
      "Trained batch 718 batch loss 6.20820808 epoch total loss 6.36984777\n",
      "Trained batch 719 batch loss 6.27120113 epoch total loss 6.36971045\n",
      "Trained batch 720 batch loss 6.53375912 epoch total loss 6.36993837\n",
      "Trained batch 721 batch loss 6.51883316 epoch total loss 6.37014484\n",
      "Trained batch 722 batch loss 6.55244684 epoch total loss 6.37039709\n",
      "Trained batch 723 batch loss 6.95751762 epoch total loss 6.37120914\n",
      "Trained batch 724 batch loss 6.68154955 epoch total loss 6.37163782\n",
      "Trained batch 725 batch loss 6.81115294 epoch total loss 6.37224388\n",
      "Trained batch 726 batch loss 6.86848116 epoch total loss 6.37292767\n",
      "Trained batch 727 batch loss 6.66455507 epoch total loss 6.37332916\n",
      "Trained batch 728 batch loss 6.63718891 epoch total loss 6.37369156\n",
      "Trained batch 729 batch loss 6.54343 epoch total loss 6.37392426\n",
      "Trained batch 730 batch loss 6.08183956 epoch total loss 6.37352467\n",
      "Trained batch 731 batch loss 5.77136564 epoch total loss 6.37270069\n",
      "Trained batch 732 batch loss 5.94329643 epoch total loss 6.37211418\n",
      "Trained batch 733 batch loss 6.55626822 epoch total loss 6.37236547\n",
      "Trained batch 734 batch loss 6.04059649 epoch total loss 6.37191343\n",
      "Trained batch 735 batch loss 6.62924194 epoch total loss 6.37226343\n",
      "Trained batch 736 batch loss 6.2210393 epoch total loss 6.37205839\n",
      "Trained batch 737 batch loss 6.41720963 epoch total loss 6.37211943\n",
      "Trained batch 738 batch loss 6.11672 epoch total loss 6.37177324\n",
      "Trained batch 739 batch loss 5.89894772 epoch total loss 6.37113333\n",
      "Trained batch 740 batch loss 6.31864834 epoch total loss 6.37106276\n",
      "Trained batch 741 batch loss 5.83467245 epoch total loss 6.37033844\n",
      "Trained batch 742 batch loss 5.82498312 epoch total loss 6.36960411\n",
      "Trained batch 743 batch loss 5.80368519 epoch total loss 6.36884212\n",
      "Trained batch 744 batch loss 5.77293205 epoch total loss 6.36804152\n",
      "Trained batch 745 batch loss 5.89585352 epoch total loss 6.3674078\n",
      "Trained batch 746 batch loss 6.46587133 epoch total loss 6.36753941\n",
      "Trained batch 747 batch loss 6.72961044 epoch total loss 6.36802435\n",
      "Trained batch 748 batch loss 6.43320513 epoch total loss 6.36811113\n",
      "Trained batch 749 batch loss 6.44148684 epoch total loss 6.36820889\n",
      "Trained batch 750 batch loss 6.27025 epoch total loss 6.36807823\n",
      "Trained batch 751 batch loss 6.20568466 epoch total loss 6.36786175\n",
      "Trained batch 752 batch loss 5.96599579 epoch total loss 6.36732721\n",
      "Trained batch 753 batch loss 5.65028191 epoch total loss 6.36637497\n",
      "Trained batch 754 batch loss 6.45491 epoch total loss 6.36649275\n",
      "Trained batch 755 batch loss 6.55679798 epoch total loss 6.36674452\n",
      "Trained batch 756 batch loss 6.64118052 epoch total loss 6.36710739\n",
      "Trained batch 757 batch loss 6.32156181 epoch total loss 6.36704731\n",
      "Trained batch 758 batch loss 6.43240309 epoch total loss 6.36713409\n",
      "Trained batch 759 batch loss 6.30948782 epoch total loss 6.36705828\n",
      "Trained batch 760 batch loss 6.38891554 epoch total loss 6.36708641\n",
      "Trained batch 761 batch loss 5.79580259 epoch total loss 6.36633587\n",
      "Trained batch 762 batch loss 6.52070951 epoch total loss 6.36653852\n",
      "Trained batch 763 batch loss 6.25761747 epoch total loss 6.36639595\n",
      "Trained batch 764 batch loss 5.82647133 epoch total loss 6.36568928\n",
      "Trained batch 765 batch loss 5.79066229 epoch total loss 6.36493778\n",
      "Trained batch 766 batch loss 5.96 epoch total loss 6.36440897\n",
      "Trained batch 767 batch loss 5.63694143 epoch total loss 6.36346\n",
      "Trained batch 768 batch loss 6.17478228 epoch total loss 6.36321449\n",
      "Trained batch 769 batch loss 6.35503912 epoch total loss 6.363204\n",
      "Trained batch 770 batch loss 6.54518318 epoch total loss 6.36344051\n",
      "Trained batch 771 batch loss 6.31567812 epoch total loss 6.363379\n",
      "Trained batch 772 batch loss 6.01830864 epoch total loss 6.36293125\n",
      "Trained batch 773 batch loss 6.08377314 epoch total loss 6.36257076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 774 batch loss 6.44209766 epoch total loss 6.36267328\n",
      "Trained batch 775 batch loss 6.52686644 epoch total loss 6.362885\n",
      "Trained batch 776 batch loss 6.21857166 epoch total loss 6.36269903\n",
      "Trained batch 777 batch loss 6.16845322 epoch total loss 6.36244917\n",
      "Trained batch 778 batch loss 6.35087872 epoch total loss 6.36243439\n",
      "Trained batch 779 batch loss 6.24665356 epoch total loss 6.36228609\n",
      "Trained batch 780 batch loss 6.19367504 epoch total loss 6.36207\n",
      "Trained batch 781 batch loss 6.23690128 epoch total loss 6.36190939\n",
      "Trained batch 782 batch loss 6.04956198 epoch total loss 6.36151028\n",
      "Trained batch 783 batch loss 6.32012367 epoch total loss 6.36145782\n",
      "Trained batch 784 batch loss 6.27259159 epoch total loss 6.36134434\n",
      "Trained batch 785 batch loss 6.08165503 epoch total loss 6.36098766\n",
      "Trained batch 786 batch loss 6.53064919 epoch total loss 6.36120367\n",
      "Trained batch 787 batch loss 6.51316309 epoch total loss 6.36139679\n",
      "Trained batch 788 batch loss 6.49260378 epoch total loss 6.36156368\n",
      "Trained batch 789 batch loss 6.31179 epoch total loss 6.36150074\n",
      "Trained batch 790 batch loss 6.25792074 epoch total loss 6.36136961\n",
      "Trained batch 791 batch loss 6.10668182 epoch total loss 6.36104727\n",
      "Trained batch 792 batch loss 6.34034204 epoch total loss 6.36102104\n",
      "Trained batch 793 batch loss 6.28439045 epoch total loss 6.36092424\n",
      "Trained batch 794 batch loss 6.10469866 epoch total loss 6.36060143\n",
      "Trained batch 795 batch loss 6.14058256 epoch total loss 6.36032438\n",
      "Trained batch 796 batch loss 6.48159122 epoch total loss 6.36047649\n",
      "Trained batch 797 batch loss 6.04780149 epoch total loss 6.36008453\n",
      "Trained batch 798 batch loss 6.41948891 epoch total loss 6.36015892\n",
      "Trained batch 799 batch loss 6.49736214 epoch total loss 6.36033058\n",
      "Trained batch 800 batch loss 5.9988122 epoch total loss 6.35987902\n",
      "Trained batch 801 batch loss 6.67922974 epoch total loss 6.36027765\n",
      "Trained batch 802 batch loss 5.81273317 epoch total loss 6.35959482\n",
      "Trained batch 803 batch loss 6.28079414 epoch total loss 6.35949659\n",
      "Trained batch 804 batch loss 6.20727968 epoch total loss 6.35930777\n",
      "Trained batch 805 batch loss 6.16311073 epoch total loss 6.35906363\n",
      "Trained batch 806 batch loss 6.35463285 epoch total loss 6.35905838\n",
      "Trained batch 807 batch loss 6.52973938 epoch total loss 6.35926962\n",
      "Trained batch 808 batch loss 6.36167049 epoch total loss 6.35927296\n",
      "Trained batch 809 batch loss 6.44710779 epoch total loss 6.35938168\n",
      "Trained batch 810 batch loss 6.36236191 epoch total loss 6.35938501\n",
      "Trained batch 811 batch loss 6.55157185 epoch total loss 6.35962248\n",
      "Trained batch 812 batch loss 6.31958246 epoch total loss 6.35957336\n",
      "Trained batch 813 batch loss 6.51790524 epoch total loss 6.35976839\n",
      "Trained batch 814 batch loss 6.24924946 epoch total loss 6.35963249\n",
      "Trained batch 815 batch loss 6.28533173 epoch total loss 6.35954094\n",
      "Trained batch 816 batch loss 6.55008411 epoch total loss 6.35977459\n",
      "Trained batch 817 batch loss 6.48377943 epoch total loss 6.3599267\n",
      "Trained batch 818 batch loss 6.86081743 epoch total loss 6.36053896\n",
      "Trained batch 819 batch loss 6.84290457 epoch total loss 6.36112785\n",
      "Trained batch 820 batch loss 6.33106804 epoch total loss 6.36109114\n",
      "Trained batch 821 batch loss 6.3876524 epoch total loss 6.36112356\n",
      "Trained batch 822 batch loss 6.42609692 epoch total loss 6.36120272\n",
      "Trained batch 823 batch loss 6.63276196 epoch total loss 6.36153269\n",
      "Trained batch 824 batch loss 6.68281126 epoch total loss 6.36192226\n",
      "Trained batch 825 batch loss 6.57727957 epoch total loss 6.36218357\n",
      "Trained batch 826 batch loss 6.31145954 epoch total loss 6.36212206\n",
      "Trained batch 827 batch loss 6.12628555 epoch total loss 6.36183691\n",
      "Trained batch 828 batch loss 5.92348814 epoch total loss 6.36130762\n",
      "Trained batch 829 batch loss 5.45925903 epoch total loss 6.36021948\n",
      "Trained batch 830 batch loss 5.97044468 epoch total loss 6.35975\n",
      "Trained batch 831 batch loss 6.05215 epoch total loss 6.35938\n",
      "Trained batch 832 batch loss 6.55393648 epoch total loss 6.35961342\n",
      "Trained batch 833 batch loss 6.32871819 epoch total loss 6.35957623\n",
      "Trained batch 834 batch loss 6.42511272 epoch total loss 6.3596549\n",
      "Trained batch 835 batch loss 6.35701799 epoch total loss 6.35965157\n",
      "Trained batch 836 batch loss 6.74857664 epoch total loss 6.36011696\n",
      "Trained batch 837 batch loss 6.55603409 epoch total loss 6.36035109\n",
      "Trained batch 838 batch loss 6.32147 epoch total loss 6.36030436\n",
      "Trained batch 839 batch loss 6.29093409 epoch total loss 6.36022186\n",
      "Trained batch 840 batch loss 6.18640232 epoch total loss 6.36001492\n",
      "Trained batch 841 batch loss 5.99064 epoch total loss 6.35957575\n",
      "Trained batch 842 batch loss 5.92738056 epoch total loss 6.35906219\n",
      "Trained batch 843 batch loss 6.39057827 epoch total loss 6.3591\n",
      "Trained batch 844 batch loss 6.24074221 epoch total loss 6.35895967\n",
      "Trained batch 845 batch loss 5.64043665 epoch total loss 6.35810947\n",
      "Trained batch 846 batch loss 6.39537382 epoch total loss 6.35815382\n",
      "Trained batch 847 batch loss 6.41940832 epoch total loss 6.3582263\n",
      "Trained batch 848 batch loss 5.65810871 epoch total loss 6.35740042\n",
      "Trained batch 849 batch loss 5.73363113 epoch total loss 6.35666561\n",
      "Trained batch 850 batch loss 5.86338806 epoch total loss 6.3560853\n",
      "Trained batch 851 batch loss 6.03935862 epoch total loss 6.35571337\n",
      "Trained batch 852 batch loss 7.02155542 epoch total loss 6.35649443\n",
      "Trained batch 853 batch loss 6.92131138 epoch total loss 6.35715675\n",
      "Trained batch 854 batch loss 6.7203455 epoch total loss 6.35758209\n",
      "Trained batch 855 batch loss 6.68552637 epoch total loss 6.35796547\n",
      "Trained batch 856 batch loss 6.85321283 epoch total loss 6.35854387\n",
      "Trained batch 857 batch loss 6.6785717 epoch total loss 6.35891771\n",
      "Trained batch 858 batch loss 6.45411539 epoch total loss 6.35902834\n",
      "Trained batch 859 batch loss 6.77045393 epoch total loss 6.35950756\n",
      "Trained batch 860 batch loss 6.50507927 epoch total loss 6.35967636\n",
      "Trained batch 861 batch loss 6.30532551 epoch total loss 6.35961342\n",
      "Trained batch 862 batch loss 6.62503433 epoch total loss 6.35992098\n",
      "Trained batch 863 batch loss 6.54023504 epoch total loss 6.36013\n",
      "Trained batch 864 batch loss 6.58354759 epoch total loss 6.36038828\n",
      "Trained batch 865 batch loss 6.50155544 epoch total loss 6.36055136\n",
      "Trained batch 866 batch loss 6.4642992 epoch total loss 6.36067104\n",
      "Trained batch 867 batch loss 6.41159678 epoch total loss 6.36073\n",
      "Trained batch 868 batch loss 6.47157478 epoch total loss 6.36085796\n",
      "Trained batch 869 batch loss 6.54628658 epoch total loss 6.36107111\n",
      "Trained batch 870 batch loss 6.19121027 epoch total loss 6.36087656\n",
      "Trained batch 871 batch loss 6.18608189 epoch total loss 6.36067581\n",
      "Trained batch 872 batch loss 6.61961555 epoch total loss 6.3609724\n",
      "Trained batch 873 batch loss 6.39647818 epoch total loss 6.36101341\n",
      "Trained batch 874 batch loss 6.39969063 epoch total loss 6.36105776\n",
      "Trained batch 875 batch loss 6.15789557 epoch total loss 6.36082554\n",
      "Trained batch 876 batch loss 6.19606829 epoch total loss 6.36063766\n",
      "Trained batch 877 batch loss 6.76996851 epoch total loss 6.36110449\n",
      "Trained batch 878 batch loss 6.754807 epoch total loss 6.36155272\n",
      "Trained batch 879 batch loss 6.88537 epoch total loss 6.36214876\n",
      "Trained batch 880 batch loss 6.43339968 epoch total loss 6.36223\n",
      "Trained batch 881 batch loss 6.59725046 epoch total loss 6.36249638\n",
      "Trained batch 882 batch loss 6.78922176 epoch total loss 6.36298\n",
      "Trained batch 883 batch loss 6.45702219 epoch total loss 6.3630867\n",
      "Trained batch 884 batch loss 6.55546188 epoch total loss 6.36330462\n",
      "Trained batch 885 batch loss 6.66239166 epoch total loss 6.36364269\n",
      "Trained batch 886 batch loss 6.88061619 epoch total loss 6.36422634\n",
      "Trained batch 887 batch loss 6.84810495 epoch total loss 6.36477184\n",
      "Trained batch 888 batch loss 6.46190119 epoch total loss 6.36488152\n",
      "Trained batch 889 batch loss 6.37831068 epoch total loss 6.36489677\n",
      "Trained batch 890 batch loss 6.49784517 epoch total loss 6.36504602\n",
      "Trained batch 891 batch loss 5.95206976 epoch total loss 6.36458302\n",
      "Trained batch 892 batch loss 5.33775425 epoch total loss 6.36343193\n",
      "Trained batch 893 batch loss 5.44247055 epoch total loss 6.36240053\n",
      "Trained batch 894 batch loss 5.31296444 epoch total loss 6.36122656\n",
      "Trained batch 895 batch loss 6.16372871 epoch total loss 6.36100578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 896 batch loss 5.8756814 epoch total loss 6.36046362\n",
      "Trained batch 897 batch loss 6.92153549 epoch total loss 6.36108923\n",
      "Trained batch 898 batch loss 6.71290541 epoch total loss 6.36148071\n",
      "Trained batch 899 batch loss 6.65967083 epoch total loss 6.36181259\n",
      "Trained batch 900 batch loss 6.74945211 epoch total loss 6.36224318\n",
      "Trained batch 901 batch loss 7.03053951 epoch total loss 6.36298513\n",
      "Trained batch 902 batch loss 6.78728485 epoch total loss 6.36345577\n",
      "Trained batch 903 batch loss 6.75314283 epoch total loss 6.36388683\n",
      "Trained batch 904 batch loss 6.60298538 epoch total loss 6.36415148\n",
      "Trained batch 905 batch loss 6.55728245 epoch total loss 6.36436462\n",
      "Trained batch 906 batch loss 6.9091754 epoch total loss 6.36496592\n",
      "Trained batch 907 batch loss 6.29488087 epoch total loss 6.36488867\n",
      "Trained batch 908 batch loss 6.58046103 epoch total loss 6.36512613\n",
      "Trained batch 909 batch loss 6.13169 epoch total loss 6.36486959\n",
      "Trained batch 910 batch loss 5.76832914 epoch total loss 6.36421442\n",
      "Trained batch 911 batch loss 6.15693045 epoch total loss 6.36398649\n",
      "Trained batch 912 batch loss 6.26592255 epoch total loss 6.3638792\n",
      "Trained batch 913 batch loss 6.28113031 epoch total loss 6.3637886\n",
      "Trained batch 914 batch loss 6.2639122 epoch total loss 6.36367941\n",
      "Trained batch 915 batch loss 6.45154905 epoch total loss 6.36377525\n",
      "Trained batch 916 batch loss 5.51277351 epoch total loss 6.36284637\n",
      "Trained batch 917 batch loss 6.35212326 epoch total loss 6.36283445\n",
      "Trained batch 918 batch loss 6.0450573 epoch total loss 6.36248827\n",
      "Trained batch 919 batch loss 6.02412701 epoch total loss 6.36211967\n",
      "Trained batch 920 batch loss 5.92679453 epoch total loss 6.36164665\n",
      "Trained batch 921 batch loss 5.81524897 epoch total loss 6.36105347\n",
      "Trained batch 922 batch loss 5.88577127 epoch total loss 6.36053801\n",
      "Trained batch 923 batch loss 5.77867222 epoch total loss 6.35990763\n",
      "Trained batch 924 batch loss 5.66403675 epoch total loss 6.3591547\n",
      "Trained batch 925 batch loss 6.04598904 epoch total loss 6.35881615\n",
      "Trained batch 926 batch loss 6.58435535 epoch total loss 6.35906\n",
      "Trained batch 927 batch loss 6.41734505 epoch total loss 6.35912275\n",
      "Trained batch 928 batch loss 6.43638515 epoch total loss 6.3592062\n",
      "Trained batch 929 batch loss 6.42037296 epoch total loss 6.359272\n",
      "Trained batch 930 batch loss 6.68883514 epoch total loss 6.35962629\n",
      "Trained batch 931 batch loss 6.75414848 epoch total loss 6.36005\n",
      "Trained batch 932 batch loss 6.74365044 epoch total loss 6.36046171\n",
      "Trained batch 933 batch loss 6.67204189 epoch total loss 6.3607955\n",
      "Trained batch 934 batch loss 6.4773 epoch total loss 6.36092043\n",
      "Trained batch 935 batch loss 6.79111385 epoch total loss 6.36138058\n",
      "Trained batch 936 batch loss 6.29272842 epoch total loss 6.36130714\n",
      "Trained batch 937 batch loss 6.48235083 epoch total loss 6.36143637\n",
      "Trained batch 938 batch loss 6.42536545 epoch total loss 6.36150455\n",
      "Trained batch 939 batch loss 6.5979681 epoch total loss 6.3617568\n",
      "Trained batch 940 batch loss 6.38443613 epoch total loss 6.36178064\n",
      "Trained batch 941 batch loss 6.25354576 epoch total loss 6.36166525\n",
      "Trained batch 942 batch loss 5.82896328 epoch total loss 6.3611\n",
      "Trained batch 943 batch loss 5.56551838 epoch total loss 6.3602562\n",
      "Trained batch 944 batch loss 5.70221615 epoch total loss 6.35955906\n",
      "Trained batch 945 batch loss 5.60058689 epoch total loss 6.35875607\n",
      "Trained batch 946 batch loss 5.42601109 epoch total loss 6.35777\n",
      "Trained batch 947 batch loss 5.03420162 epoch total loss 6.35637188\n",
      "Trained batch 948 batch loss 5.02835417 epoch total loss 6.35497141\n",
      "Trained batch 949 batch loss 5.69758701 epoch total loss 6.35427856\n",
      "Trained batch 950 batch loss 6.45501232 epoch total loss 6.3543849\n",
      "Trained batch 951 batch loss 6.42336321 epoch total loss 6.35445738\n",
      "Trained batch 952 batch loss 6.42203856 epoch total loss 6.35452795\n",
      "Trained batch 953 batch loss 6.33755398 epoch total loss 6.35451031\n",
      "Trained batch 954 batch loss 6.33191299 epoch total loss 6.35448647\n",
      "Trained batch 955 batch loss 6.21250296 epoch total loss 6.35433769\n",
      "Trained batch 956 batch loss 6.44721413 epoch total loss 6.35443497\n",
      "Trained batch 957 batch loss 6.39037418 epoch total loss 6.35447216\n",
      "Trained batch 958 batch loss 6.36314917 epoch total loss 6.3544817\n",
      "Trained batch 959 batch loss 6.43464 epoch total loss 6.35456514\n",
      "Trained batch 960 batch loss 6.91823626 epoch total loss 6.35515261\n",
      "Trained batch 961 batch loss 6.24963522 epoch total loss 6.35504246\n",
      "Trained batch 962 batch loss 5.793046 epoch total loss 6.35445833\n",
      "Trained batch 963 batch loss 6.2098918 epoch total loss 6.35430813\n",
      "Trained batch 964 batch loss 5.95476866 epoch total loss 6.35389328\n",
      "Trained batch 965 batch loss 6.12151384 epoch total loss 6.35365295\n",
      "Trained batch 966 batch loss 6.18346548 epoch total loss 6.35347652\n",
      "Trained batch 967 batch loss 6.65980101 epoch total loss 6.35379314\n",
      "Trained batch 968 batch loss 6.4133873 epoch total loss 6.35385513\n",
      "Trained batch 969 batch loss 6.44533491 epoch total loss 6.35394955\n",
      "Trained batch 970 batch loss 6.4342947 epoch total loss 6.35403204\n",
      "Trained batch 971 batch loss 6.48784971 epoch total loss 6.35417\n",
      "Trained batch 972 batch loss 6.30397654 epoch total loss 6.35411835\n",
      "Trained batch 973 batch loss 6.25387812 epoch total loss 6.35401535\n",
      "Trained batch 974 batch loss 6.15392303 epoch total loss 6.35381\n",
      "Trained batch 975 batch loss 6.65236664 epoch total loss 6.35411596\n",
      "Trained batch 976 batch loss 7.02938223 epoch total loss 6.35480785\n",
      "Trained batch 977 batch loss 7.27140284 epoch total loss 6.35574627\n",
      "Trained batch 978 batch loss 7.06249332 epoch total loss 6.35646868\n",
      "Trained batch 979 batch loss 6.30374241 epoch total loss 6.35641479\n",
      "Trained batch 980 batch loss 6.45698786 epoch total loss 6.35651779\n",
      "Trained batch 981 batch loss 6.55786896 epoch total loss 6.35672283\n",
      "Trained batch 982 batch loss 6.20193386 epoch total loss 6.35656548\n",
      "Trained batch 983 batch loss 6.09857893 epoch total loss 6.35630322\n",
      "Trained batch 984 batch loss 6.11579084 epoch total loss 6.3560586\n",
      "Trained batch 985 batch loss 6.04993773 epoch total loss 6.3557477\n",
      "Trained batch 986 batch loss 6.59593534 epoch total loss 6.35599136\n",
      "Trained batch 987 batch loss 6.78490257 epoch total loss 6.35642576\n",
      "Trained batch 988 batch loss 6.70044613 epoch total loss 6.35677385\n",
      "Trained batch 989 batch loss 6.51430702 epoch total loss 6.35693312\n",
      "Trained batch 990 batch loss 6.28135777 epoch total loss 6.35685682\n",
      "Trained batch 991 batch loss 6.13405132 epoch total loss 6.35663223\n",
      "Trained batch 992 batch loss 6.55275059 epoch total loss 6.35682964\n",
      "Trained batch 993 batch loss 6.59142303 epoch total loss 6.35706568\n",
      "Trained batch 994 batch loss 6.34831047 epoch total loss 6.35705709\n",
      "Trained batch 995 batch loss 6.3156786 epoch total loss 6.35701561\n",
      "Trained batch 996 batch loss 6.17654276 epoch total loss 6.35683441\n",
      "Trained batch 997 batch loss 6.18488693 epoch total loss 6.35666227\n",
      "Trained batch 998 batch loss 5.67093229 epoch total loss 6.35597515\n",
      "Trained batch 999 batch loss 5.83070803 epoch total loss 6.3554492\n",
      "Trained batch 1000 batch loss 6.44591951 epoch total loss 6.35553932\n",
      "Trained batch 1001 batch loss 6.43211079 epoch total loss 6.35561609\n",
      "Trained batch 1002 batch loss 6.4865365 epoch total loss 6.35574675\n",
      "Trained batch 1003 batch loss 6.18893862 epoch total loss 6.35558033\n",
      "Trained batch 1004 batch loss 6.26417589 epoch total loss 6.35548925\n",
      "Trained batch 1005 batch loss 6.31795645 epoch total loss 6.35545158\n",
      "Trained batch 1006 batch loss 6.69665718 epoch total loss 6.35579109\n",
      "Trained batch 1007 batch loss 6.72392654 epoch total loss 6.35615683\n",
      "Trained batch 1008 batch loss 6.47341537 epoch total loss 6.35627317\n",
      "Trained batch 1009 batch loss 6.41341209 epoch total loss 6.35633\n",
      "Trained batch 1010 batch loss 6.65484762 epoch total loss 6.35662556\n",
      "Trained batch 1011 batch loss 5.85624647 epoch total loss 6.35613108\n",
      "Trained batch 1012 batch loss 6.45175505 epoch total loss 6.35622549\n",
      "Trained batch 1013 batch loss 6.60719681 epoch total loss 6.35647345\n",
      "Trained batch 1014 batch loss 6.81596136 epoch total loss 6.35692644\n",
      "Trained batch 1015 batch loss 6.56937122 epoch total loss 6.35713577\n",
      "Trained batch 1016 batch loss 5.82584143 epoch total loss 6.35661268\n",
      "Trained batch 1017 batch loss 6.55931616 epoch total loss 6.35681152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1018 batch loss 5.86020184 epoch total loss 6.3563242\n",
      "Trained batch 1019 batch loss 6.76075172 epoch total loss 6.35672092\n",
      "Trained batch 1020 batch loss 7.15314865 epoch total loss 6.35750198\n",
      "Trained batch 1021 batch loss 6.62587833 epoch total loss 6.35776472\n",
      "Trained batch 1022 batch loss 6.54637289 epoch total loss 6.35794926\n",
      "Trained batch 1023 batch loss 6.43329048 epoch total loss 6.35802269\n",
      "Trained batch 1024 batch loss 6.78188896 epoch total loss 6.35843658\n",
      "Trained batch 1025 batch loss 6.42559767 epoch total loss 6.35850239\n",
      "Trained batch 1026 batch loss 6.37497044 epoch total loss 6.3585186\n",
      "Trained batch 1027 batch loss 6.52224 epoch total loss 6.35867786\n",
      "Trained batch 1028 batch loss 6.32024288 epoch total loss 6.35864067\n",
      "Trained batch 1029 batch loss 6.24555874 epoch total loss 6.358531\n",
      "Trained batch 1030 batch loss 6.55001831 epoch total loss 6.35871649\n",
      "Trained batch 1031 batch loss 6.76742125 epoch total loss 6.35911322\n",
      "Trained batch 1032 batch loss 6.53654289 epoch total loss 6.35928488\n",
      "Trained batch 1033 batch loss 6.54828596 epoch total loss 6.35946798\n",
      "Trained batch 1034 batch loss 6.67157555 epoch total loss 6.35977\n",
      "Trained batch 1035 batch loss 6.56040907 epoch total loss 6.35996389\n",
      "Trained batch 1036 batch loss 6.60062647 epoch total loss 6.36019611\n",
      "Trained batch 1037 batch loss 6.30612278 epoch total loss 6.36014414\n",
      "Trained batch 1038 batch loss 6.19876337 epoch total loss 6.35998821\n",
      "Trained batch 1039 batch loss 6.33232 epoch total loss 6.35996199\n",
      "Trained batch 1040 batch loss 6.02742386 epoch total loss 6.35964203\n",
      "Trained batch 1041 batch loss 6.07221222 epoch total loss 6.35936594\n",
      "Trained batch 1042 batch loss 6.45641279 epoch total loss 6.3594594\n",
      "Trained batch 1043 batch loss 6.54979229 epoch total loss 6.35964203\n",
      "Trained batch 1044 batch loss 6.59325933 epoch total loss 6.35986567\n",
      "Trained batch 1045 batch loss 6.14346647 epoch total loss 6.35965872\n",
      "Trained batch 1046 batch loss 5.73186588 epoch total loss 6.35905838\n",
      "Trained batch 1047 batch loss 5.70663643 epoch total loss 6.35843515\n",
      "Trained batch 1048 batch loss 6.19819164 epoch total loss 6.35828257\n",
      "Trained batch 1049 batch loss 6.66220284 epoch total loss 6.35857201\n",
      "Trained batch 1050 batch loss 6.59294605 epoch total loss 6.35879517\n",
      "Trained batch 1051 batch loss 6.71598721 epoch total loss 6.35913467\n",
      "Trained batch 1052 batch loss 6.72922421 epoch total loss 6.35948658\n",
      "Trained batch 1053 batch loss 6.72222805 epoch total loss 6.35983086\n",
      "Trained batch 1054 batch loss 6.64859962 epoch total loss 6.36010456\n",
      "Trained batch 1055 batch loss 6.7150116 epoch total loss 6.36044073\n",
      "Trained batch 1056 batch loss 6.41298151 epoch total loss 6.3604908\n",
      "Trained batch 1057 batch loss 6.65631 epoch total loss 6.3607707\n",
      "Trained batch 1058 batch loss 6.36574125 epoch total loss 6.36077499\n",
      "Trained batch 1059 batch loss 6.58541632 epoch total loss 6.36098719\n",
      "Trained batch 1060 batch loss 6.71805859 epoch total loss 6.36132431\n",
      "Trained batch 1061 batch loss 6.22246647 epoch total loss 6.36119366\n",
      "Trained batch 1062 batch loss 6.40603733 epoch total loss 6.3612361\n",
      "Trained batch 1063 batch loss 6.21170044 epoch total loss 6.36109591\n",
      "Trained batch 1064 batch loss 6.11358643 epoch total loss 6.36086321\n",
      "Trained batch 1065 batch loss 6.22313452 epoch total loss 6.36073399\n",
      "Trained batch 1066 batch loss 6.49140453 epoch total loss 6.36085653\n",
      "Trained batch 1067 batch loss 6.42631435 epoch total loss 6.36091757\n",
      "Trained batch 1068 batch loss 6.14457273 epoch total loss 6.36071491\n",
      "Trained batch 1069 batch loss 6.62215281 epoch total loss 6.36095953\n",
      "Trained batch 1070 batch loss 6.28363276 epoch total loss 6.36088753\n",
      "Trained batch 1071 batch loss 6.40875101 epoch total loss 6.36093187\n",
      "Trained batch 1072 batch loss 6.56044388 epoch total loss 6.36111832\n",
      "Trained batch 1073 batch loss 6.56551313 epoch total loss 6.36130857\n",
      "Trained batch 1074 batch loss 6.50707293 epoch total loss 6.361444\n",
      "Trained batch 1075 batch loss 5.58360195 epoch total loss 6.36072\n",
      "Trained batch 1076 batch loss 5.37808228 epoch total loss 6.35980701\n",
      "Trained batch 1077 batch loss 5.90420485 epoch total loss 6.35938406\n",
      "Trained batch 1078 batch loss 5.9450841 epoch total loss 6.35899973\n",
      "Trained batch 1079 batch loss 6.14886141 epoch total loss 6.35880518\n",
      "Trained batch 1080 batch loss 5.99820566 epoch total loss 6.35847139\n",
      "Trained batch 1081 batch loss 5.89784336 epoch total loss 6.3580451\n",
      "Trained batch 1082 batch loss 5.80609035 epoch total loss 6.35753536\n",
      "Trained batch 1083 batch loss 6.0622716 epoch total loss 6.35726261\n",
      "Trained batch 1084 batch loss 6.08720732 epoch total loss 6.3570137\n",
      "Trained batch 1085 batch loss 6.39887285 epoch total loss 6.35705233\n",
      "Trained batch 1086 batch loss 6.48504353 epoch total loss 6.35717\n",
      "Trained batch 1087 batch loss 6.52958393 epoch total loss 6.35732889\n",
      "Trained batch 1088 batch loss 7.19037914 epoch total loss 6.35809469\n",
      "Trained batch 1089 batch loss 7.34166908 epoch total loss 6.35899782\n",
      "Trained batch 1090 batch loss 7.46345854 epoch total loss 6.3600111\n",
      "Trained batch 1091 batch loss 6.82694 epoch total loss 6.3604393\n",
      "Trained batch 1092 batch loss 6.73018837 epoch total loss 6.36077785\n",
      "Trained batch 1093 batch loss 6.42748213 epoch total loss 6.36083841\n",
      "Trained batch 1094 batch loss 5.78411627 epoch total loss 6.36031151\n",
      "Trained batch 1095 batch loss 6.41723156 epoch total loss 6.36036301\n",
      "Trained batch 1096 batch loss 6.74748898 epoch total loss 6.36071634\n",
      "Trained batch 1097 batch loss 6.57404852 epoch total loss 6.36091089\n",
      "Trained batch 1098 batch loss 6.13068819 epoch total loss 6.36070156\n",
      "Trained batch 1099 batch loss 6.20206833 epoch total loss 6.36055708\n",
      "Trained batch 1100 batch loss 6.36340952 epoch total loss 6.36056\n",
      "Trained batch 1101 batch loss 6.56045246 epoch total loss 6.36074162\n",
      "Trained batch 1102 batch loss 5.957901 epoch total loss 6.36037588\n",
      "Trained batch 1103 batch loss 6.35397148 epoch total loss 6.36037\n",
      "Trained batch 1104 batch loss 6.23282576 epoch total loss 6.36025476\n",
      "Trained batch 1105 batch loss 6.46718216 epoch total loss 6.36035156\n",
      "Trained batch 1106 batch loss 6.43441534 epoch total loss 6.3604188\n",
      "Trained batch 1107 batch loss 6.35633183 epoch total loss 6.36041498\n",
      "Trained batch 1108 batch loss 6.4943018 epoch total loss 6.36053562\n",
      "Trained batch 1109 batch loss 6.86555481 epoch total loss 6.36099148\n",
      "Trained batch 1110 batch loss 6.35186195 epoch total loss 6.36098337\n",
      "Trained batch 1111 batch loss 6.85714865 epoch total loss 6.36142969\n",
      "Trained batch 1112 batch loss 6.6937294 epoch total loss 6.36172867\n",
      "Trained batch 1113 batch loss 6.8641119 epoch total loss 6.36218\n",
      "Trained batch 1114 batch loss 6.46289301 epoch total loss 6.36227036\n",
      "Trained batch 1115 batch loss 6.70208 epoch total loss 6.36257553\n",
      "Trained batch 1116 batch loss 6.67149162 epoch total loss 6.3628521\n",
      "Trained batch 1117 batch loss 6.87052488 epoch total loss 6.36330652\n",
      "Trained batch 1118 batch loss 6.53641033 epoch total loss 6.36346149\n",
      "Trained batch 1119 batch loss 6.58950138 epoch total loss 6.36366367\n",
      "Trained batch 1120 batch loss 6.70573044 epoch total loss 6.36396885\n",
      "Trained batch 1121 batch loss 6.32345295 epoch total loss 6.36393261\n",
      "Trained batch 1122 batch loss 6.70555782 epoch total loss 6.36423683\n",
      "Trained batch 1123 batch loss 6.43103361 epoch total loss 6.36429644\n",
      "Trained batch 1124 batch loss 6.44446087 epoch total loss 6.36436749\n",
      "Trained batch 1125 batch loss 6.68804502 epoch total loss 6.36465549\n",
      "Trained batch 1126 batch loss 5.86944151 epoch total loss 6.36421585\n",
      "Trained batch 1127 batch loss 5.89414215 epoch total loss 6.36379862\n",
      "Trained batch 1128 batch loss 5.90262842 epoch total loss 6.36339\n",
      "Trained batch 1129 batch loss 6.21129513 epoch total loss 6.3632555\n",
      "Trained batch 1130 batch loss 6.45694542 epoch total loss 6.36333847\n",
      "Trained batch 1131 batch loss 6.33165884 epoch total loss 6.36331034\n",
      "Trained batch 1132 batch loss 6.73107576 epoch total loss 6.36363506\n",
      "Trained batch 1133 batch loss 6.20083952 epoch total loss 6.36349106\n",
      "Trained batch 1134 batch loss 6.39698792 epoch total loss 6.36352062\n",
      "Trained batch 1135 batch loss 6.4559083 epoch total loss 6.36360216\n",
      "Trained batch 1136 batch loss 6.44487619 epoch total loss 6.36367369\n",
      "Trained batch 1137 batch loss 6.71012831 epoch total loss 6.36397839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1138 batch loss 6.61734629 epoch total loss 6.36420059\n",
      "Trained batch 1139 batch loss 6.79821825 epoch total loss 6.36458206\n",
      "Trained batch 1140 batch loss 6.77009249 epoch total loss 6.36493778\n",
      "Trained batch 1141 batch loss 6.74266577 epoch total loss 6.36526871\n",
      "Trained batch 1142 batch loss 6.7488637 epoch total loss 6.36560488\n",
      "Trained batch 1143 batch loss 6.82748222 epoch total loss 6.36600876\n",
      "Trained batch 1144 batch loss 6.63613844 epoch total loss 6.36624527\n",
      "Trained batch 1145 batch loss 6.81835222 epoch total loss 6.36664\n",
      "Trained batch 1146 batch loss 6.68083 epoch total loss 6.3669138\n",
      "Trained batch 1147 batch loss 6.4344883 epoch total loss 6.36697292\n",
      "Trained batch 1148 batch loss 6.66006041 epoch total loss 6.36722851\n",
      "Trained batch 1149 batch loss 6.27497 epoch total loss 6.36714792\n",
      "Trained batch 1150 batch loss 6.57745934 epoch total loss 6.36733103\n",
      "Trained batch 1151 batch loss 6.67293596 epoch total loss 6.36759663\n",
      "Trained batch 1152 batch loss 7.02215242 epoch total loss 6.36816454\n",
      "Trained batch 1153 batch loss 6.97261333 epoch total loss 6.36868858\n",
      "Trained batch 1154 batch loss 7.02096462 epoch total loss 6.36925411\n",
      "Trained batch 1155 batch loss 6.65871 epoch total loss 6.36950445\n",
      "Trained batch 1156 batch loss 6.59164333 epoch total loss 6.36969709\n",
      "Trained batch 1157 batch loss 6.11932945 epoch total loss 6.36948\n",
      "Trained batch 1158 batch loss 6.77574062 epoch total loss 6.36983109\n",
      "Trained batch 1159 batch loss 6.75657 epoch total loss 6.37016487\n",
      "Trained batch 1160 batch loss 6.71522617 epoch total loss 6.37046242\n",
      "Trained batch 1161 batch loss 6.56468821 epoch total loss 6.37062931\n",
      "Trained batch 1162 batch loss 6.52740049 epoch total loss 6.37076426\n",
      "Trained batch 1163 batch loss 6.63683271 epoch total loss 6.37099314\n",
      "Trained batch 1164 batch loss 6.60260963 epoch total loss 6.37119198\n",
      "Trained batch 1165 batch loss 6.58063793 epoch total loss 6.37137175\n",
      "Trained batch 1166 batch loss 7.0814991 epoch total loss 6.37198067\n",
      "Trained batch 1167 batch loss 6.95044708 epoch total loss 6.37247658\n",
      "Trained batch 1168 batch loss 6.73997116 epoch total loss 6.37279081\n",
      "Trained batch 1169 batch loss 6.60208654 epoch total loss 6.37298727\n",
      "Trained batch 1170 batch loss 6.62978649 epoch total loss 6.37320662\n",
      "Trained batch 1171 batch loss 6.90508699 epoch total loss 6.37366104\n",
      "Trained batch 1172 batch loss 6.79030561 epoch total loss 6.37401676\n",
      "Trained batch 1173 batch loss 6.00099802 epoch total loss 6.37369871\n",
      "Trained batch 1174 batch loss 6.45383835 epoch total loss 6.3737669\n",
      "Trained batch 1175 batch loss 5.77181959 epoch total loss 6.37325478\n",
      "Trained batch 1176 batch loss 6.18176079 epoch total loss 6.3730917\n",
      "Trained batch 1177 batch loss 6.29946804 epoch total loss 6.37302923\n",
      "Trained batch 1178 batch loss 6.03220654 epoch total loss 6.37274\n",
      "Trained batch 1179 batch loss 5.28217888 epoch total loss 6.37181473\n",
      "Trained batch 1180 batch loss 5.25990391 epoch total loss 6.3708725\n",
      "Trained batch 1181 batch loss 5.88807106 epoch total loss 6.37046385\n",
      "Trained batch 1182 batch loss 5.607306 epoch total loss 6.36981821\n",
      "Trained batch 1183 batch loss 5.70241976 epoch total loss 6.36925411\n",
      "Trained batch 1184 batch loss 5.83293152 epoch total loss 6.36880112\n",
      "Trained batch 1185 batch loss 6.27349329 epoch total loss 6.36872053\n",
      "Trained batch 1186 batch loss 6.0610857 epoch total loss 6.36846113\n",
      "Trained batch 1187 batch loss 6.09045458 epoch total loss 6.36822701\n",
      "Trained batch 1188 batch loss 5.66608906 epoch total loss 6.36763573\n",
      "Trained batch 1189 batch loss 6.25255537 epoch total loss 6.36753893\n",
      "Trained batch 1190 batch loss 6.12609291 epoch total loss 6.36733627\n",
      "Trained batch 1191 batch loss 6.65733385 epoch total loss 6.36757946\n",
      "Trained batch 1192 batch loss 6.83263063 epoch total loss 6.36796951\n",
      "Trained batch 1193 batch loss 6.44105 epoch total loss 6.36803055\n",
      "Trained batch 1194 batch loss 6.7500205 epoch total loss 6.36835051\n",
      "Trained batch 1195 batch loss 6.42150354 epoch total loss 6.36839485\n",
      "Trained batch 1196 batch loss 6.34352303 epoch total loss 6.36837435\n",
      "Trained batch 1197 batch loss 6.22713566 epoch total loss 6.36825609\n",
      "Trained batch 1198 batch loss 6.49955845 epoch total loss 6.36836576\n",
      "Trained batch 1199 batch loss 6.4928565 epoch total loss 6.36846972\n",
      "Trained batch 1200 batch loss 6.77937508 epoch total loss 6.36881208\n",
      "Trained batch 1201 batch loss 6.74999475 epoch total loss 6.36912918\n",
      "Trained batch 1202 batch loss 6.37280464 epoch total loss 6.36913252\n",
      "Trained batch 1203 batch loss 6.707757 epoch total loss 6.36941385\n",
      "Trained batch 1204 batch loss 6.80524397 epoch total loss 6.36977577\n",
      "Trained batch 1205 batch loss 6.43860292 epoch total loss 6.36983252\n",
      "Trained batch 1206 batch loss 6.66351 epoch total loss 6.37007618\n",
      "Trained batch 1207 batch loss 6.3767724 epoch total loss 6.3700819\n",
      "Trained batch 1208 batch loss 6.28832626 epoch total loss 6.37001419\n",
      "Trained batch 1209 batch loss 6.67988968 epoch total loss 6.37027025\n",
      "Trained batch 1210 batch loss 6.55492067 epoch total loss 6.37042284\n",
      "Trained batch 1211 batch loss 6.57743073 epoch total loss 6.37059355\n",
      "Trained batch 1212 batch loss 6.14088583 epoch total loss 6.37040424\n",
      "Trained batch 1213 batch loss 6.4279995 epoch total loss 6.37045193\n",
      "Trained batch 1214 batch loss 6.69168758 epoch total loss 6.37071705\n",
      "Trained batch 1215 batch loss 5.69573593 epoch total loss 6.37016153\n",
      "Trained batch 1216 batch loss 5.54212 epoch total loss 6.36948\n",
      "Trained batch 1217 batch loss 5.71126223 epoch total loss 6.3689394\n",
      "Trained batch 1218 batch loss 6.25020647 epoch total loss 6.36884212\n",
      "Trained batch 1219 batch loss 6.22305679 epoch total loss 6.36872244\n",
      "Trained batch 1220 batch loss 6.32689762 epoch total loss 6.36868811\n",
      "Trained batch 1221 batch loss 6.38420105 epoch total loss 6.3687005\n",
      "Trained batch 1222 batch loss 6.32764769 epoch total loss 6.36866713\n",
      "Trained batch 1223 batch loss 6.28133535 epoch total loss 6.3685956\n",
      "Trained batch 1224 batch loss 6.46503735 epoch total loss 6.36867428\n",
      "Trained batch 1225 batch loss 6.49697971 epoch total loss 6.36877918\n",
      "Trained batch 1226 batch loss 6.06182814 epoch total loss 6.36852884\n",
      "Trained batch 1227 batch loss 5.79884863 epoch total loss 6.3680644\n",
      "Trained batch 1228 batch loss 6.41384506 epoch total loss 6.36810207\n",
      "Trained batch 1229 batch loss 6.23643446 epoch total loss 6.36799479\n",
      "Trained batch 1230 batch loss 6.17523289 epoch total loss 6.36783838\n",
      "Trained batch 1231 batch loss 6.74838924 epoch total loss 6.36814737\n",
      "Trained batch 1232 batch loss 6.87590408 epoch total loss 6.36856\n",
      "Trained batch 1233 batch loss 6.40901041 epoch total loss 6.36859274\n",
      "Trained batch 1234 batch loss 5.9550705 epoch total loss 6.36825752\n",
      "Trained batch 1235 batch loss 6.17171097 epoch total loss 6.36809826\n",
      "Trained batch 1236 batch loss 5.59213114 epoch total loss 6.36747074\n",
      "Trained batch 1237 batch loss 5.11716318 epoch total loss 6.36646\n",
      "Trained batch 1238 batch loss 4.93806839 epoch total loss 6.36530638\n",
      "Trained batch 1239 batch loss 5.4081049 epoch total loss 6.3645339\n",
      "Trained batch 1240 batch loss 6.46652555 epoch total loss 6.36461592\n",
      "Trained batch 1241 batch loss 7.01382303 epoch total loss 6.36513853\n",
      "Trained batch 1242 batch loss 6.6282115 epoch total loss 6.36535072\n",
      "Trained batch 1243 batch loss 6.47051048 epoch total loss 6.3654356\n",
      "Trained batch 1244 batch loss 5.90696859 epoch total loss 6.36506701\n",
      "Trained batch 1245 batch loss 6.53810024 epoch total loss 6.36520576\n",
      "Trained batch 1246 batch loss 6.56523418 epoch total loss 6.36536646\n",
      "Trained batch 1247 batch loss 6.5593977 epoch total loss 6.36552238\n",
      "Trained batch 1248 batch loss 6.50820398 epoch total loss 6.36563635\n",
      "Trained batch 1249 batch loss 6.5448308 epoch total loss 6.36578035\n",
      "Trained batch 1250 batch loss 6.83096123 epoch total loss 6.36615229\n",
      "Trained batch 1251 batch loss 6.24273348 epoch total loss 6.36605358\n",
      "Trained batch 1252 batch loss 6.71803188 epoch total loss 6.36633492\n",
      "Trained batch 1253 batch loss 6.01805162 epoch total loss 6.36605692\n",
      "Trained batch 1254 batch loss 6.60038805 epoch total loss 6.36624384\n",
      "Trained batch 1255 batch loss 6.83177423 epoch total loss 6.36661482\n",
      "Trained batch 1256 batch loss 6.39840031 epoch total loss 6.36664\n",
      "Trained batch 1257 batch loss 6.28996849 epoch total loss 6.36657906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1258 batch loss 5.40391541 epoch total loss 6.36581373\n",
      "Trained batch 1259 batch loss 6.16778517 epoch total loss 6.36565685\n",
      "Trained batch 1260 batch loss 6.92941523 epoch total loss 6.36610413\n",
      "Trained batch 1261 batch loss 7.05436373 epoch total loss 6.36664963\n",
      "Trained batch 1262 batch loss 6.68316126 epoch total loss 6.36690044\n",
      "Trained batch 1263 batch loss 7.07969713 epoch total loss 6.36746454\n",
      "Trained batch 1264 batch loss 7.18950891 epoch total loss 6.36811495\n",
      "Trained batch 1265 batch loss 6.66306496 epoch total loss 6.36834812\n",
      "Trained batch 1266 batch loss 5.99865532 epoch total loss 6.3680563\n",
      "Trained batch 1267 batch loss 6.46412659 epoch total loss 6.36813211\n",
      "Trained batch 1268 batch loss 6.67002583 epoch total loss 6.36837\n",
      "Trained batch 1269 batch loss 6.22226238 epoch total loss 6.36825466\n",
      "Trained batch 1270 batch loss 6.41209173 epoch total loss 6.36828947\n",
      "Trained batch 1271 batch loss 6.3838377 epoch total loss 6.36830139\n",
      "Trained batch 1272 batch loss 6.66083765 epoch total loss 6.36853123\n",
      "Trained batch 1273 batch loss 6.02696466 epoch total loss 6.36826324\n",
      "Trained batch 1274 batch loss 6.22391081 epoch total loss 6.36814976\n",
      "Trained batch 1275 batch loss 6.69448423 epoch total loss 6.36840582\n",
      "Trained batch 1276 batch loss 6.65285587 epoch total loss 6.3686285\n",
      "Trained batch 1277 batch loss 6.51132202 epoch total loss 6.36874\n",
      "Trained batch 1278 batch loss 6.91377497 epoch total loss 6.36916637\n",
      "Trained batch 1279 batch loss 6.85093594 epoch total loss 6.36954355\n",
      "Trained batch 1280 batch loss 6.26511 epoch total loss 6.36946201\n",
      "Trained batch 1281 batch loss 6.43451118 epoch total loss 6.36951256\n",
      "Trained batch 1282 batch loss 5.97979784 epoch total loss 6.36920881\n",
      "Trained batch 1283 batch loss 6.42305183 epoch total loss 6.36925077\n",
      "Trained batch 1284 batch loss 6.46466827 epoch total loss 6.36932516\n",
      "Trained batch 1285 batch loss 5.64892769 epoch total loss 6.3687644\n",
      "Trained batch 1286 batch loss 5.92305279 epoch total loss 6.36841774\n",
      "Trained batch 1287 batch loss 6.58277225 epoch total loss 6.36858463\n",
      "Trained batch 1288 batch loss 6.39552069 epoch total loss 6.36860514\n",
      "Trained batch 1289 batch loss 6.57596827 epoch total loss 6.36876631\n",
      "Trained batch 1290 batch loss 6.40095 epoch total loss 6.36879158\n",
      "Trained batch 1291 batch loss 6.36854 epoch total loss 6.3687911\n",
      "Trained batch 1292 batch loss 6.36141634 epoch total loss 6.36878538\n",
      "Trained batch 1293 batch loss 6.28014231 epoch total loss 6.36871672\n",
      "Trained batch 1294 batch loss 6.3287797 epoch total loss 6.3686862\n",
      "Trained batch 1295 batch loss 6.04683 epoch total loss 6.36843777\n",
      "Trained batch 1296 batch loss 6.05329704 epoch total loss 6.36819506\n",
      "Trained batch 1297 batch loss 6.24503136 epoch total loss 6.3681\n",
      "Trained batch 1298 batch loss 6.49454355 epoch total loss 6.36819696\n",
      "Trained batch 1299 batch loss 6.3413353 epoch total loss 6.36817694\n",
      "Trained batch 1300 batch loss 6.40814495 epoch total loss 6.36820745\n",
      "Trained batch 1301 batch loss 6.01403141 epoch total loss 6.36793518\n",
      "Trained batch 1302 batch loss 6.03069782 epoch total loss 6.36767578\n",
      "Trained batch 1303 batch loss 6.46044731 epoch total loss 6.36774683\n",
      "Trained batch 1304 batch loss 6.46343327 epoch total loss 6.36782026\n",
      "Trained batch 1305 batch loss 6.26754522 epoch total loss 6.36774349\n",
      "Trained batch 1306 batch loss 6.23977852 epoch total loss 6.36764574\n",
      "Trained batch 1307 batch loss 6.24064589 epoch total loss 6.36754847\n",
      "Trained batch 1308 batch loss 6.42956924 epoch total loss 6.36759567\n",
      "Trained batch 1309 batch loss 5.79320431 epoch total loss 6.36715698\n",
      "Trained batch 1310 batch loss 5.22744226 epoch total loss 6.36628675\n",
      "Trained batch 1311 batch loss 5.35256672 epoch total loss 6.3655138\n",
      "Trained batch 1312 batch loss 5.72764158 epoch total loss 6.36502743\n",
      "Trained batch 1313 batch loss 6.80142689 epoch total loss 6.36536026\n",
      "Trained batch 1314 batch loss 6.44627666 epoch total loss 6.36542177\n",
      "Trained batch 1315 batch loss 6.43198776 epoch total loss 6.36547184\n",
      "Trained batch 1316 batch loss 6.17977381 epoch total loss 6.3653307\n",
      "Trained batch 1317 batch loss 6.61543226 epoch total loss 6.36552048\n",
      "Trained batch 1318 batch loss 6.09071207 epoch total loss 6.3653121\n",
      "Trained batch 1319 batch loss 5.67541218 epoch total loss 6.36478949\n",
      "Trained batch 1320 batch loss 5.62364 epoch total loss 6.36422825\n",
      "Trained batch 1321 batch loss 5.91409826 epoch total loss 6.36388731\n",
      "Trained batch 1322 batch loss 6.35458803 epoch total loss 6.36388\n",
      "Trained batch 1323 batch loss 5.78358316 epoch total loss 6.36344147\n",
      "Trained batch 1324 batch loss 5.65227604 epoch total loss 6.36290455\n",
      "Trained batch 1325 batch loss 5.54337263 epoch total loss 6.36228561\n",
      "Trained batch 1326 batch loss 6.27680206 epoch total loss 6.36222076\n",
      "Trained batch 1327 batch loss 6.60113144 epoch total loss 6.36240101\n",
      "Trained batch 1328 batch loss 6.3684597 epoch total loss 6.3624053\n",
      "Trained batch 1329 batch loss 6.53559732 epoch total loss 6.36253548\n",
      "Trained batch 1330 batch loss 6.51220083 epoch total loss 6.36264753\n",
      "Trained batch 1331 batch loss 6.4226222 epoch total loss 6.36269283\n",
      "Trained batch 1332 batch loss 6.51283026 epoch total loss 6.36280537\n",
      "Trained batch 1333 batch loss 6.54492617 epoch total loss 6.36294222\n",
      "Trained batch 1334 batch loss 6.32540321 epoch total loss 6.36291361\n",
      "Trained batch 1335 batch loss 6.39992476 epoch total loss 6.36294174\n",
      "Trained batch 1336 batch loss 6.28831244 epoch total loss 6.36288595\n",
      "Trained batch 1337 batch loss 7.00949526 epoch total loss 6.36336946\n",
      "Trained batch 1338 batch loss 6.35454321 epoch total loss 6.36336279\n",
      "Trained batch 1339 batch loss 6.45214558 epoch total loss 6.36342907\n",
      "Trained batch 1340 batch loss 6.32012367 epoch total loss 6.36339712\n",
      "Trained batch 1341 batch loss 6.26065636 epoch total loss 6.36332035\n",
      "Trained batch 1342 batch loss 6.28962898 epoch total loss 6.36326599\n",
      "Trained batch 1343 batch loss 6.34133911 epoch total loss 6.36325\n",
      "Trained batch 1344 batch loss 6.63622904 epoch total loss 6.36345291\n",
      "Trained batch 1345 batch loss 6.51135731 epoch total loss 6.36356306\n",
      "Trained batch 1346 batch loss 6.22584581 epoch total loss 6.36346054\n",
      "Trained batch 1347 batch loss 6.11700535 epoch total loss 6.36327744\n",
      "Trained batch 1348 batch loss 6.2312026 epoch total loss 6.36317968\n",
      "Trained batch 1349 batch loss 6.57236 epoch total loss 6.36333466\n",
      "Trained batch 1350 batch loss 6.58640099 epoch total loss 6.36349964\n",
      "Trained batch 1351 batch loss 6.51900673 epoch total loss 6.36361456\n",
      "Trained batch 1352 batch loss 6.54772568 epoch total loss 6.36375093\n",
      "Trained batch 1353 batch loss 6.42328119 epoch total loss 6.36379433\n",
      "Trained batch 1354 batch loss 6.47703791 epoch total loss 6.36387777\n",
      "Trained batch 1355 batch loss 6.69056511 epoch total loss 6.36411858\n",
      "Trained batch 1356 batch loss 6.36402702 epoch total loss 6.36411905\n",
      "Trained batch 1357 batch loss 6.46547413 epoch total loss 6.36419392\n",
      "Trained batch 1358 batch loss 6.52748394 epoch total loss 6.36431408\n",
      "Trained batch 1359 batch loss 6.12372351 epoch total loss 6.36413717\n",
      "Trained batch 1360 batch loss 5.65971231 epoch total loss 6.36361933\n",
      "Trained batch 1361 batch loss 6.150208 epoch total loss 6.36346292\n",
      "Trained batch 1362 batch loss 6.46497297 epoch total loss 6.36353731\n",
      "Trained batch 1363 batch loss 6.50409508 epoch total loss 6.36364031\n",
      "Trained batch 1364 batch loss 6.56468201 epoch total loss 6.36378765\n",
      "Trained batch 1365 batch loss 6.3251586 epoch total loss 6.36375904\n",
      "Trained batch 1366 batch loss 6.02205038 epoch total loss 6.36350918\n",
      "Trained batch 1367 batch loss 5.92256927 epoch total loss 6.36318684\n",
      "Trained batch 1368 batch loss 5.80899954 epoch total loss 6.36278152\n",
      "Trained batch 1369 batch loss 6.46054745 epoch total loss 6.36285305\n",
      "Trained batch 1370 batch loss 6.56545734 epoch total loss 6.36300135\n",
      "Trained batch 1371 batch loss 6.33117723 epoch total loss 6.36297798\n",
      "Trained batch 1372 batch loss 6.47608757 epoch total loss 6.36306047\n",
      "Trained batch 1373 batch loss 6.20597029 epoch total loss 6.36294603\n",
      "Trained batch 1374 batch loss 5.87078428 epoch total loss 6.36258841\n",
      "Trained batch 1375 batch loss 6.15975714 epoch total loss 6.36244106\n",
      "Trained batch 1376 batch loss 5.93178 epoch total loss 6.36212778\n",
      "Trained batch 1377 batch loss 6.02095413 epoch total loss 6.36188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1378 batch loss 6.01743269 epoch total loss 6.36163\n",
      "Trained batch 1379 batch loss 5.81680393 epoch total loss 6.36123466\n",
      "Trained batch 1380 batch loss 5.67014837 epoch total loss 6.36073351\n",
      "Trained batch 1381 batch loss 6.2247076 epoch total loss 6.36063528\n",
      "Trained batch 1382 batch loss 6.19143963 epoch total loss 6.36051273\n",
      "Trained batch 1383 batch loss 6.04084921 epoch total loss 6.36028147\n",
      "Trained batch 1384 batch loss 6.5112772 epoch total loss 6.36039114\n",
      "Trained batch 1385 batch loss 6.4096 epoch total loss 6.36042643\n",
      "Trained batch 1386 batch loss 6.52097893 epoch total loss 6.36054182\n",
      "Trained batch 1387 batch loss 6.44103622 epoch total loss 6.3606\n",
      "Trained batch 1388 batch loss 6.37864351 epoch total loss 6.36061335\n",
      "Epoch 3 train loss 6.3606133460998535\n",
      "Validated batch 1 batch loss 6.29231405\n",
      "Validated batch 2 batch loss 6.27238512\n",
      "Validated batch 3 batch loss 6.12236\n",
      "Validated batch 4 batch loss 6.98933125\n",
      "Validated batch 5 batch loss 6.48834658\n",
      "Validated batch 6 batch loss 6.51799107\n",
      "Validated batch 7 batch loss 6.45854235\n",
      "Validated batch 8 batch loss 6.38532877\n",
      "Validated batch 9 batch loss 6.48159742\n",
      "Validated batch 10 batch loss 6.66138\n",
      "Validated batch 11 batch loss 6.83377743\n",
      "Validated batch 12 batch loss 6.37848949\n",
      "Validated batch 13 batch loss 6.22778893\n",
      "Validated batch 14 batch loss 6.59912109\n",
      "Validated batch 15 batch loss 6.28559446\n",
      "Validated batch 16 batch loss 6.31017685\n",
      "Validated batch 17 batch loss 6.60826111\n",
      "Validated batch 18 batch loss 5.71523666\n",
      "Validated batch 19 batch loss 6.26996231\n",
      "Validated batch 20 batch loss 6.35041714\n",
      "Validated batch 21 batch loss 6.36466837\n",
      "Validated batch 22 batch loss 6.7807622\n",
      "Validated batch 23 batch loss 6.16657448\n",
      "Validated batch 24 batch loss 6.26978731\n",
      "Validated batch 25 batch loss 5.81726694\n",
      "Validated batch 26 batch loss 6.32093811\n",
      "Validated batch 27 batch loss 6.26751137\n",
      "Validated batch 28 batch loss 6.22633457\n",
      "Validated batch 29 batch loss 6.52953529\n",
      "Validated batch 30 batch loss 6.34458876\n",
      "Validated batch 31 batch loss 6.55966949\n",
      "Validated batch 32 batch loss 6.3489852\n",
      "Validated batch 33 batch loss 6.42019749\n",
      "Validated batch 34 batch loss 6.1255703\n",
      "Validated batch 35 batch loss 6.29412365\n",
      "Validated batch 36 batch loss 6.27205849\n",
      "Validated batch 37 batch loss 6.63031912\n",
      "Validated batch 38 batch loss 6.45391035\n",
      "Validated batch 39 batch loss 6.22902346\n",
      "Validated batch 40 batch loss 6.54996681\n",
      "Validated batch 41 batch loss 5.83971357\n",
      "Validated batch 42 batch loss 6.32597065\n",
      "Validated batch 43 batch loss 6.41808414\n",
      "Validated batch 44 batch loss 6.35727549\n",
      "Validated batch 45 batch loss 6.52332926\n",
      "Validated batch 46 batch loss 6.10351467\n",
      "Validated batch 47 batch loss 6.2330637\n",
      "Validated batch 48 batch loss 6.3731184\n",
      "Validated batch 49 batch loss 6.02437\n",
      "Validated batch 50 batch loss 5.78207731\n",
      "Validated batch 51 batch loss 6.08685207\n",
      "Validated batch 52 batch loss 6.48090219\n",
      "Validated batch 53 batch loss 6.24955034\n",
      "Validated batch 54 batch loss 6.30153561\n",
      "Validated batch 55 batch loss 6.42618322\n",
      "Validated batch 56 batch loss 6.54125309\n",
      "Validated batch 57 batch loss 6.45243263\n",
      "Validated batch 58 batch loss 6.21378183\n",
      "Validated batch 59 batch loss 6.46747971\n",
      "Validated batch 60 batch loss 6.2722826\n",
      "Validated batch 61 batch loss 6.59690714\n",
      "Validated batch 62 batch loss 6.6896739\n",
      "Validated batch 63 batch loss 6.1686554\n",
      "Validated batch 64 batch loss 6.7572403\n",
      "Validated batch 65 batch loss 6.2157917\n",
      "Validated batch 66 batch loss 6.1650095\n",
      "Validated batch 67 batch loss 6.25144911\n",
      "Validated batch 68 batch loss 6.39316416\n",
      "Validated batch 69 batch loss 6.67185974\n",
      "Validated batch 70 batch loss 6.4061904\n",
      "Validated batch 71 batch loss 6.87499332\n",
      "Validated batch 72 batch loss 6.1391592\n",
      "Validated batch 73 batch loss 5.7178669\n",
      "Validated batch 74 batch loss 6.51077127\n",
      "Validated batch 75 batch loss 6.12233257\n",
      "Validated batch 76 batch loss 5.88278103\n",
      "Validated batch 77 batch loss 6.10839081\n",
      "Validated batch 78 batch loss 5.89751148\n",
      "Validated batch 79 batch loss 6.60984278\n",
      "Validated batch 80 batch loss 5.9534955\n",
      "Validated batch 81 batch loss 5.84644699\n",
      "Validated batch 82 batch loss 6.28223181\n",
      "Validated batch 83 batch loss 6.39735174\n",
      "Validated batch 84 batch loss 6.03950644\n",
      "Validated batch 85 batch loss 6.3116951\n",
      "Validated batch 86 batch loss 6.19644833\n",
      "Validated batch 87 batch loss 6.53781\n",
      "Validated batch 88 batch loss 6.14268637\n",
      "Validated batch 89 batch loss 6.30860186\n",
      "Validated batch 90 batch loss 6.56325054\n",
      "Validated batch 91 batch loss 5.37537956\n",
      "Validated batch 92 batch loss 6.65633345\n",
      "Validated batch 93 batch loss 6.90542603\n",
      "Validated batch 94 batch loss 6.39736\n",
      "Validated batch 95 batch loss 6.43858147\n",
      "Validated batch 96 batch loss 6.30608368\n",
      "Validated batch 97 batch loss 6.34801531\n",
      "Validated batch 98 batch loss 6.62593\n",
      "Validated batch 99 batch loss 6.23757696\n",
      "Validated batch 100 batch loss 6.06530523\n",
      "Validated batch 101 batch loss 6.13566113\n",
      "Validated batch 102 batch loss 6.25363302\n",
      "Validated batch 103 batch loss 6.42958736\n",
      "Validated batch 104 batch loss 6.27582359\n",
      "Validated batch 105 batch loss 6.05216169\n",
      "Validated batch 106 batch loss 6.00853157\n",
      "Validated batch 107 batch loss 6.17015743\n",
      "Validated batch 108 batch loss 6.44980669\n",
      "Validated batch 109 batch loss 6.51012516\n",
      "Validated batch 110 batch loss 6.56140566\n",
      "Validated batch 111 batch loss 6.85411\n",
      "Validated batch 112 batch loss 7.17564869\n",
      "Validated batch 113 batch loss 6.89961672\n",
      "Validated batch 114 batch loss 6.28932762\n",
      "Validated batch 115 batch loss 5.98731852\n",
      "Validated batch 116 batch loss 6.27296829\n",
      "Validated batch 117 batch loss 6.23682117\n",
      "Validated batch 118 batch loss 6.13414192\n",
      "Validated batch 119 batch loss 6.11356735\n",
      "Validated batch 120 batch loss 6.34772396\n",
      "Validated batch 121 batch loss 6.33082676\n",
      "Validated batch 122 batch loss 6.33830833\n",
      "Validated batch 123 batch loss 6.39087915\n",
      "Validated batch 124 batch loss 6.14686966\n",
      "Validated batch 125 batch loss 6.40364408\n",
      "Validated batch 126 batch loss 6.78548193\n",
      "Validated batch 127 batch loss 6.54852772\n",
      "Validated batch 128 batch loss 6.25216866\n",
      "Validated batch 129 batch loss 6.25968409\n",
      "Validated batch 130 batch loss 6.39913654\n",
      "Validated batch 131 batch loss 6.25690508\n",
      "Validated batch 132 batch loss 6.62444639\n",
      "Validated batch 133 batch loss 6.09407425\n",
      "Validated batch 134 batch loss 6.45177937\n",
      "Validated batch 135 batch loss 6.25066185\n",
      "Validated batch 136 batch loss 6.1327467\n",
      "Validated batch 137 batch loss 6.53514624\n",
      "Validated batch 138 batch loss 6.4264679\n",
      "Validated batch 139 batch loss 6.2184248\n",
      "Validated batch 140 batch loss 6.54428959\n",
      "Validated batch 141 batch loss 6.36919737\n",
      "Validated batch 142 batch loss 6.52404881\n",
      "Validated batch 143 batch loss 6.48581266\n",
      "Validated batch 144 batch loss 6.60192585\n",
      "Validated batch 145 batch loss 6.11900663\n",
      "Validated batch 146 batch loss 6.69779348\n",
      "Validated batch 147 batch loss 6.13689947\n",
      "Validated batch 148 batch loss 6.33496332\n",
      "Validated batch 149 batch loss 6.50759125\n",
      "Validated batch 150 batch loss 6.02812529\n",
      "Validated batch 151 batch loss 5.42705917\n",
      "Validated batch 152 batch loss 6.52715492\n",
      "Validated batch 153 batch loss 6.51381874\n",
      "Validated batch 154 batch loss 6.3274684\n",
      "Validated batch 155 batch loss 6.31176901\n",
      "Validated batch 156 batch loss 6.47920942\n",
      "Validated batch 157 batch loss 6.50602627\n",
      "Validated batch 158 batch loss 6.5339613\n",
      "Validated batch 159 batch loss 6.43576908\n",
      "Validated batch 160 batch loss 6.37781763\n",
      "Validated batch 161 batch loss 5.85412264\n",
      "Validated batch 162 batch loss 6.3100462\n",
      "Validated batch 163 batch loss 6.3940053\n",
      "Validated batch 164 batch loss 6.24962759\n",
      "Validated batch 165 batch loss 6.09781504\n",
      "Validated batch 166 batch loss 6.1050868\n",
      "Validated batch 167 batch loss 6.40243149\n",
      "Validated batch 168 batch loss 6.1182332\n",
      "Validated batch 169 batch loss 6.19630909\n",
      "Validated batch 170 batch loss 6.36721\n",
      "Validated batch 171 batch loss 6.54472208\n",
      "Validated batch 172 batch loss 6.11714745\n",
      "Validated batch 173 batch loss 6.1486\n",
      "Validated batch 174 batch loss 6.00028\n",
      "Validated batch 175 batch loss 6.72108889\n",
      "Validated batch 176 batch loss 6.198349\n",
      "Validated batch 177 batch loss 6.24273062\n",
      "Validated batch 178 batch loss 6.37259531\n",
      "Validated batch 179 batch loss 5.87394762\n",
      "Validated batch 180 batch loss 5.76753378\n",
      "Validated batch 181 batch loss 6.20798111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 182 batch loss 6.26313162\n",
      "Validated batch 183 batch loss 5.78801489\n",
      "Validated batch 184 batch loss 6.48726702\n",
      "Validated batch 185 batch loss 3.26292753\n",
      "Epoch 3 val loss 6.3064494132995605\n",
      "Model /aiffel/aiffel/mpii/models1/simple_baseline-epoch-3-loss-6.3064.h5 saved.\n",
      "Start epoch 4 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 6.74899578 epoch total loss 6.74899578\n",
      "Trained batch 2 batch loss 6.7241 epoch total loss 6.73654795\n",
      "Trained batch 3 batch loss 6.69171143 epoch total loss 6.72160196\n",
      "Trained batch 4 batch loss 6.61567307 epoch total loss 6.69512\n",
      "Trained batch 5 batch loss 6.39317703 epoch total loss 6.63473129\n",
      "Trained batch 6 batch loss 6.26396036 epoch total loss 6.57293653\n",
      "Trained batch 7 batch loss 6.58757496 epoch total loss 6.57502747\n",
      "Trained batch 8 batch loss 6.75148439 epoch total loss 6.59708452\n",
      "Trained batch 9 batch loss 6.85656118 epoch total loss 6.62591505\n",
      "Trained batch 10 batch loss 6.94004965 epoch total loss 6.65732861\n",
      "Trained batch 11 batch loss 6.62835121 epoch total loss 6.65469408\n",
      "Trained batch 12 batch loss 6.78605175 epoch total loss 6.66564035\n",
      "Trained batch 13 batch loss 6.50060701 epoch total loss 6.652946\n",
      "Trained batch 14 batch loss 6.15621758 epoch total loss 6.6174655\n",
      "Trained batch 15 batch loss 6.19607401 epoch total loss 6.58937263\n",
      "Trained batch 16 batch loss 6.58444262 epoch total loss 6.5890646\n",
      "Trained batch 17 batch loss 6.66727304 epoch total loss 6.59366512\n",
      "Trained batch 18 batch loss 6.54311085 epoch total loss 6.59085655\n",
      "Trained batch 19 batch loss 6.57497168 epoch total loss 6.59002066\n",
      "Trained batch 20 batch loss 6.47218323 epoch total loss 6.58412933\n",
      "Trained batch 21 batch loss 6.31668377 epoch total loss 6.57139349\n",
      "Trained batch 22 batch loss 6.44016504 epoch total loss 6.56542921\n",
      "Trained batch 23 batch loss 5.83158207 epoch total loss 6.53352308\n",
      "Trained batch 24 batch loss 6.15533447 epoch total loss 6.51776505\n",
      "Trained batch 25 batch loss 6.55827522 epoch total loss 6.51938534\n",
      "Trained batch 26 batch loss 6.36742783 epoch total loss 6.51354122\n",
      "Trained batch 27 batch loss 6.32746696 epoch total loss 6.50664949\n",
      "Trained batch 28 batch loss 6.14398336 epoch total loss 6.49369717\n",
      "Trained batch 29 batch loss 5.91776562 epoch total loss 6.47383738\n",
      "Trained batch 30 batch loss 6.20495749 epoch total loss 6.46487474\n",
      "Trained batch 31 batch loss 5.88075256 epoch total loss 6.44603205\n",
      "Trained batch 32 batch loss 6.25684595 epoch total loss 6.44012\n",
      "Trained batch 33 batch loss 6.13524103 epoch total loss 6.4308815\n",
      "Trained batch 34 batch loss 5.74503803 epoch total loss 6.41070938\n",
      "Trained batch 35 batch loss 5.98229837 epoch total loss 6.39846945\n",
      "Trained batch 36 batch loss 5.67622805 epoch total loss 6.378407\n",
      "Trained batch 37 batch loss 6.14648438 epoch total loss 6.37213898\n",
      "Trained batch 38 batch loss 6.48335028 epoch total loss 6.37506533\n",
      "Trained batch 39 batch loss 6.16359043 epoch total loss 6.36964321\n",
      "Trained batch 40 batch loss 6.29713964 epoch total loss 6.36783028\n",
      "Trained batch 41 batch loss 6.63282728 epoch total loss 6.3742938\n",
      "Trained batch 42 batch loss 6.54600096 epoch total loss 6.37838173\n",
      "Trained batch 43 batch loss 6.1967063 epoch total loss 6.37415695\n",
      "Trained batch 44 batch loss 6.44684315 epoch total loss 6.37580872\n",
      "Trained batch 45 batch loss 6.52625084 epoch total loss 6.37915182\n",
      "Trained batch 46 batch loss 6.6270752 epoch total loss 6.38454151\n",
      "Trained batch 47 batch loss 6.61172152 epoch total loss 6.38937521\n",
      "Trained batch 48 batch loss 6.53340387 epoch total loss 6.39237595\n",
      "Trained batch 49 batch loss 6.52759075 epoch total loss 6.3951354\n",
      "Trained batch 50 batch loss 6.48941851 epoch total loss 6.39702082\n",
      "Trained batch 51 batch loss 6.67447948 epoch total loss 6.40246105\n",
      "Trained batch 52 batch loss 6.76451445 epoch total loss 6.40942383\n",
      "Trained batch 53 batch loss 6.44128084 epoch total loss 6.41002512\n",
      "Trained batch 54 batch loss 6.39374781 epoch total loss 6.40972328\n",
      "Trained batch 55 batch loss 6.51854324 epoch total loss 6.41170216\n",
      "Trained batch 56 batch loss 6.43718719 epoch total loss 6.41215754\n",
      "Trained batch 57 batch loss 6.49664116 epoch total loss 6.41363955\n",
      "Trained batch 58 batch loss 6.45447969 epoch total loss 6.41434336\n",
      "Trained batch 59 batch loss 6.36815882 epoch total loss 6.41356087\n",
      "Trained batch 60 batch loss 6.17928171 epoch total loss 6.40965605\n",
      "Trained batch 61 batch loss 6.39609385 epoch total loss 6.40943384\n",
      "Trained batch 62 batch loss 6.43507385 epoch total loss 6.40984726\n",
      "Trained batch 63 batch loss 6.36110258 epoch total loss 6.40907383\n",
      "Trained batch 64 batch loss 6.37961674 epoch total loss 6.4086132\n",
      "Trained batch 65 batch loss 6.42060661 epoch total loss 6.40879774\n",
      "Trained batch 66 batch loss 6.31526518 epoch total loss 6.40738058\n",
      "Trained batch 67 batch loss 6.40584517 epoch total loss 6.40735769\n",
      "Trained batch 68 batch loss 6.17692709 epoch total loss 6.40396929\n",
      "Trained batch 69 batch loss 5.92625427 epoch total loss 6.39704609\n",
      "Trained batch 70 batch loss 6.49758959 epoch total loss 6.39848232\n",
      "Trained batch 71 batch loss 6.74725628 epoch total loss 6.4033947\n",
      "Trained batch 72 batch loss 7.32523489 epoch total loss 6.41619778\n",
      "Trained batch 73 batch loss 6.66612244 epoch total loss 6.41962194\n",
      "Trained batch 74 batch loss 6.81326 epoch total loss 6.42494106\n",
      "Trained batch 75 batch loss 6.4985857 epoch total loss 6.42592335\n",
      "Trained batch 76 batch loss 6.61883068 epoch total loss 6.42846155\n",
      "Trained batch 77 batch loss 6.28918791 epoch total loss 6.42665291\n",
      "Trained batch 78 batch loss 6.43935108 epoch total loss 6.42681551\n",
      "Trained batch 79 batch loss 6.62983 epoch total loss 6.42938519\n",
      "Trained batch 80 batch loss 6.15923595 epoch total loss 6.4260087\n",
      "Trained batch 81 batch loss 6.76822186 epoch total loss 6.43023396\n",
      "Trained batch 82 batch loss 6.8138051 epoch total loss 6.43491125\n",
      "Trained batch 83 batch loss 6.73847389 epoch total loss 6.43856859\n",
      "Trained batch 84 batch loss 5.86357355 epoch total loss 6.43172359\n",
      "Trained batch 85 batch loss 6.15361166 epoch total loss 6.42845154\n",
      "Trained batch 86 batch loss 6.34017658 epoch total loss 6.42742491\n",
      "Trained batch 87 batch loss 6.33070421 epoch total loss 6.42631292\n",
      "Trained batch 88 batch loss 6.61015797 epoch total loss 6.42840242\n",
      "Trained batch 89 batch loss 6.45648 epoch total loss 6.42871761\n",
      "Trained batch 90 batch loss 5.82492304 epoch total loss 6.42200947\n",
      "Trained batch 91 batch loss 5.44532728 epoch total loss 6.41127634\n",
      "Trained batch 92 batch loss 5.66723299 epoch total loss 6.40318918\n",
      "Trained batch 93 batch loss 6.06856489 epoch total loss 6.39959049\n",
      "Trained batch 94 batch loss 6.32571173 epoch total loss 6.39880419\n",
      "Trained batch 95 batch loss 6.53761482 epoch total loss 6.40026522\n",
      "Trained batch 96 batch loss 6.54599476 epoch total loss 6.40178347\n",
      "Trained batch 97 batch loss 6.30146694 epoch total loss 6.40074921\n",
      "Trained batch 98 batch loss 6.63036585 epoch total loss 6.40309238\n",
      "Trained batch 99 batch loss 6.62651587 epoch total loss 6.40534925\n",
      "Trained batch 100 batch loss 6.44797421 epoch total loss 6.40577555\n",
      "Trained batch 101 batch loss 6.21052074 epoch total loss 6.40384245\n",
      "Trained batch 102 batch loss 6.23293543 epoch total loss 6.40216684\n",
      "Trained batch 103 batch loss 6.3132267 epoch total loss 6.40130329\n",
      "Trained batch 104 batch loss 6.20667696 epoch total loss 6.39943171\n",
      "Trained batch 105 batch loss 5.88323259 epoch total loss 6.39451551\n",
      "Trained batch 106 batch loss 6.33672953 epoch total loss 6.39397049\n",
      "Trained batch 107 batch loss 5.98378038 epoch total loss 6.39013672\n",
      "Trained batch 108 batch loss 5.79939032 epoch total loss 6.38466692\n",
      "Trained batch 109 batch loss 6.17469025 epoch total loss 6.3827405\n",
      "Trained batch 110 batch loss 6.28056145 epoch total loss 6.38181162\n",
      "Trained batch 111 batch loss 6.69461489 epoch total loss 6.38462973\n",
      "Trained batch 112 batch loss 6.58325815 epoch total loss 6.38640308\n",
      "Trained batch 113 batch loss 6.65215 epoch total loss 6.38875484\n",
      "Trained batch 114 batch loss 6.45812225 epoch total loss 6.38936377\n",
      "Trained batch 115 batch loss 6.47810698 epoch total loss 6.39013529\n",
      "Trained batch 116 batch loss 6.38798332 epoch total loss 6.39011669\n",
      "Trained batch 117 batch loss 6.46798325 epoch total loss 6.39078188\n",
      "Trained batch 118 batch loss 6.42681122 epoch total loss 6.39108753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 119 batch loss 6.41483784 epoch total loss 6.39128733\n",
      "Trained batch 120 batch loss 6.40213203 epoch total loss 6.39137793\n",
      "Trained batch 121 batch loss 6.20550489 epoch total loss 6.38984156\n",
      "Trained batch 122 batch loss 6.42172384 epoch total loss 6.39010334\n",
      "Trained batch 123 batch loss 6.57260847 epoch total loss 6.39158726\n",
      "Trained batch 124 batch loss 6.36622047 epoch total loss 6.39138269\n",
      "Trained batch 125 batch loss 6.3706708 epoch total loss 6.39121675\n",
      "Trained batch 126 batch loss 6.74796391 epoch total loss 6.39404821\n",
      "Trained batch 127 batch loss 6.5856 epoch total loss 6.39555645\n",
      "Trained batch 128 batch loss 6.57813 epoch total loss 6.39698267\n",
      "Trained batch 129 batch loss 6.43671799 epoch total loss 6.39729071\n",
      "Trained batch 130 batch loss 6.24374294 epoch total loss 6.3961091\n",
      "Trained batch 131 batch loss 5.95826149 epoch total loss 6.39276695\n",
      "Trained batch 132 batch loss 5.93505239 epoch total loss 6.38929939\n",
      "Trained batch 133 batch loss 6.56842136 epoch total loss 6.39064598\n",
      "Trained batch 134 batch loss 6.38312531 epoch total loss 6.39058971\n",
      "Trained batch 135 batch loss 6.19303894 epoch total loss 6.38912678\n",
      "Trained batch 136 batch loss 6.34108162 epoch total loss 6.38877344\n",
      "Trained batch 137 batch loss 6.34402752 epoch total loss 6.38844681\n",
      "Trained batch 138 batch loss 6.40430737 epoch total loss 6.38856173\n",
      "Trained batch 139 batch loss 6.78366804 epoch total loss 6.39140463\n",
      "Trained batch 140 batch loss 6.77483654 epoch total loss 6.3941431\n",
      "Trained batch 141 batch loss 6.4804678 epoch total loss 6.39475536\n",
      "Trained batch 142 batch loss 6.50088787 epoch total loss 6.39550304\n",
      "Trained batch 143 batch loss 6.33127594 epoch total loss 6.39505434\n",
      "Trained batch 144 batch loss 6.10260773 epoch total loss 6.39302301\n",
      "Trained batch 145 batch loss 6.18577337 epoch total loss 6.39159393\n",
      "Trained batch 146 batch loss 7.13321352 epoch total loss 6.39667368\n",
      "Trained batch 147 batch loss 6.79905796 epoch total loss 6.3994112\n",
      "Trained batch 148 batch loss 6.27860117 epoch total loss 6.39859486\n",
      "Trained batch 149 batch loss 5.96310759 epoch total loss 6.39567232\n",
      "Trained batch 150 batch loss 5.95494843 epoch total loss 6.39273453\n",
      "Trained batch 151 batch loss 6.54174662 epoch total loss 6.3937211\n",
      "Trained batch 152 batch loss 6.63823938 epoch total loss 6.39533\n",
      "Trained batch 153 batch loss 6.55732632 epoch total loss 6.39638853\n",
      "Trained batch 154 batch loss 6.63962269 epoch total loss 6.39796829\n",
      "Trained batch 155 batch loss 7.23623133 epoch total loss 6.4033761\n",
      "Trained batch 156 batch loss 7.19043255 epoch total loss 6.40842152\n",
      "Trained batch 157 batch loss 6.79916859 epoch total loss 6.41091061\n",
      "Trained batch 158 batch loss 6.43053484 epoch total loss 6.41103458\n",
      "Trained batch 159 batch loss 6.38438272 epoch total loss 6.41086721\n",
      "Trained batch 160 batch loss 6.38078737 epoch total loss 6.41067886\n",
      "Trained batch 161 batch loss 6.84750748 epoch total loss 6.41339207\n",
      "Trained batch 162 batch loss 6.812 epoch total loss 6.41585302\n",
      "Trained batch 163 batch loss 6.62481308 epoch total loss 6.41713428\n",
      "Trained batch 164 batch loss 6.59435797 epoch total loss 6.41821527\n",
      "Trained batch 165 batch loss 6.63683176 epoch total loss 6.41954\n",
      "Trained batch 166 batch loss 6.46938086 epoch total loss 6.41984034\n",
      "Trained batch 167 batch loss 6.69123077 epoch total loss 6.42146587\n",
      "Trained batch 168 batch loss 6.84568071 epoch total loss 6.42399073\n",
      "Trained batch 169 batch loss 6.98173952 epoch total loss 6.42729092\n",
      "Trained batch 170 batch loss 6.64458656 epoch total loss 6.42856884\n",
      "Trained batch 171 batch loss 6.54374075 epoch total loss 6.42924213\n",
      "Trained batch 172 batch loss 6.92292166 epoch total loss 6.43211269\n",
      "Trained batch 173 batch loss 6.85972834 epoch total loss 6.43458462\n",
      "Trained batch 174 batch loss 6.81944513 epoch total loss 6.43679619\n",
      "Trained batch 175 batch loss 6.51205 epoch total loss 6.43722677\n",
      "Trained batch 176 batch loss 6.50295353 epoch total loss 6.43759966\n",
      "Trained batch 177 batch loss 6.48540545 epoch total loss 6.43786955\n",
      "Trained batch 178 batch loss 6.43104458 epoch total loss 6.4378314\n",
      "Trained batch 179 batch loss 6.38062859 epoch total loss 6.43751144\n",
      "Trained batch 180 batch loss 6.63792038 epoch total loss 6.43862486\n",
      "Trained batch 181 batch loss 6.54562283 epoch total loss 6.43921661\n",
      "Trained batch 182 batch loss 6.09019136 epoch total loss 6.43729877\n",
      "Trained batch 183 batch loss 5.81323814 epoch total loss 6.43388844\n",
      "Trained batch 184 batch loss 5.43435192 epoch total loss 6.42845631\n",
      "Trained batch 185 batch loss 5.82240486 epoch total loss 6.42518\n",
      "Trained batch 186 batch loss 5.64011955 epoch total loss 6.42095947\n",
      "Trained batch 187 batch loss 5.32196617 epoch total loss 6.41508293\n",
      "Trained batch 188 batch loss 5.09311676 epoch total loss 6.40805101\n",
      "Trained batch 189 batch loss 5.14499855 epoch total loss 6.40136862\n",
      "Trained batch 190 batch loss 5.72077322 epoch total loss 6.39778662\n",
      "Trained batch 191 batch loss 6.3611865 epoch total loss 6.39759493\n",
      "Trained batch 192 batch loss 6.637218 epoch total loss 6.39884329\n",
      "Trained batch 193 batch loss 6.41695213 epoch total loss 6.39893723\n",
      "Trained batch 194 batch loss 6.03373957 epoch total loss 6.39705467\n",
      "Trained batch 195 batch loss 6.58302975 epoch total loss 6.39800787\n",
      "Trained batch 196 batch loss 6.41029501 epoch total loss 6.39807081\n",
      "Trained batch 197 batch loss 5.92328548 epoch total loss 6.39566088\n",
      "Trained batch 198 batch loss 6.29755878 epoch total loss 6.39516544\n",
      "Trained batch 199 batch loss 6.15423393 epoch total loss 6.39395475\n",
      "Trained batch 200 batch loss 5.95417166 epoch total loss 6.39175606\n",
      "Trained batch 201 batch loss 5.94475269 epoch total loss 6.38953161\n",
      "Trained batch 202 batch loss 5.95468569 epoch total loss 6.38737917\n",
      "Trained batch 203 batch loss 5.68045664 epoch total loss 6.38389683\n",
      "Trained batch 204 batch loss 6.02425 epoch total loss 6.38213396\n",
      "Trained batch 205 batch loss 6.23817348 epoch total loss 6.38143158\n",
      "Trained batch 206 batch loss 6.38526821 epoch total loss 6.38145\n",
      "Trained batch 207 batch loss 6.46124172 epoch total loss 6.38183546\n",
      "Trained batch 208 batch loss 6.03032494 epoch total loss 6.38014507\n",
      "Trained batch 209 batch loss 6.02110291 epoch total loss 6.37842751\n",
      "Trained batch 210 batch loss 6.23187351 epoch total loss 6.37773\n",
      "Trained batch 211 batch loss 6.58385372 epoch total loss 6.37870646\n",
      "Trained batch 212 batch loss 6.37135267 epoch total loss 6.37867212\n",
      "Trained batch 213 batch loss 5.97098 epoch total loss 6.37675762\n",
      "Trained batch 214 batch loss 6.30212784 epoch total loss 6.37640905\n",
      "Trained batch 215 batch loss 6.2330842 epoch total loss 6.37574196\n",
      "Trained batch 216 batch loss 6.24501 epoch total loss 6.37513685\n",
      "Trained batch 217 batch loss 6.3680172 epoch total loss 6.37510395\n",
      "Trained batch 218 batch loss 6.64751101 epoch total loss 6.37635326\n",
      "Trained batch 219 batch loss 6.46301413 epoch total loss 6.37674904\n",
      "Trained batch 220 batch loss 6.04546881 epoch total loss 6.37524319\n",
      "Trained batch 221 batch loss 6.44723511 epoch total loss 6.37556887\n",
      "Trained batch 222 batch loss 6.21214628 epoch total loss 6.37483263\n",
      "Trained batch 223 batch loss 5.84820938 epoch total loss 6.37247133\n",
      "Trained batch 224 batch loss 6.28723717 epoch total loss 6.37209082\n",
      "Trained batch 225 batch loss 6.21882057 epoch total loss 6.37141\n",
      "Trained batch 226 batch loss 6.06058073 epoch total loss 6.37003469\n",
      "Trained batch 227 batch loss 6.45002174 epoch total loss 6.37038708\n",
      "Trained batch 228 batch loss 6.42765 epoch total loss 6.37063789\n",
      "Trained batch 229 batch loss 6.2327733 epoch total loss 6.37003613\n",
      "Trained batch 230 batch loss 6.73964787 epoch total loss 6.37164307\n",
      "Trained batch 231 batch loss 6.50505066 epoch total loss 6.37222052\n",
      "Trained batch 232 batch loss 6.26627 epoch total loss 6.37176371\n",
      "Trained batch 233 batch loss 6.15725756 epoch total loss 6.37084293\n",
      "Trained batch 234 batch loss 6.27998638 epoch total loss 6.37045479\n",
      "Trained batch 235 batch loss 6.7230134 epoch total loss 6.37195492\n",
      "Trained batch 236 batch loss 6.58375263 epoch total loss 6.37285233\n",
      "Trained batch 237 batch loss 6.67050362 epoch total loss 6.37410831\n",
      "Trained batch 238 batch loss 6.76628065 epoch total loss 6.37575579\n",
      "Trained batch 239 batch loss 6.22486591 epoch total loss 6.37512445\n",
      "Trained batch 240 batch loss 6.1997304 epoch total loss 6.37439394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 241 batch loss 7.09369373 epoch total loss 6.37737846\n",
      "Trained batch 242 batch loss 6.87775755 epoch total loss 6.37944651\n",
      "Trained batch 243 batch loss 6.83274 epoch total loss 6.38131189\n",
      "Trained batch 244 batch loss 6.81889629 epoch total loss 6.38310528\n",
      "Trained batch 245 batch loss 7.01968956 epoch total loss 6.38570309\n",
      "Trained batch 246 batch loss 6.74087238 epoch total loss 6.38714695\n",
      "Trained batch 247 batch loss 5.95592785 epoch total loss 6.38540125\n",
      "Trained batch 248 batch loss 6.7729311 epoch total loss 6.38696384\n",
      "Trained batch 249 batch loss 6.52695322 epoch total loss 6.38752604\n",
      "Trained batch 250 batch loss 6.11735249 epoch total loss 6.38644552\n",
      "Trained batch 251 batch loss 6.53470182 epoch total loss 6.38703585\n",
      "Trained batch 252 batch loss 6.3962965 epoch total loss 6.38707256\n",
      "Trained batch 253 batch loss 6.27219915 epoch total loss 6.38661861\n",
      "Trained batch 254 batch loss 6.30357313 epoch total loss 6.3862915\n",
      "Trained batch 255 batch loss 6.35794973 epoch total loss 6.3861804\n",
      "Trained batch 256 batch loss 6.65661383 epoch total loss 6.3872366\n",
      "Trained batch 257 batch loss 6.73994923 epoch total loss 6.38860941\n",
      "Trained batch 258 batch loss 6.60392666 epoch total loss 6.3894434\n",
      "Trained batch 259 batch loss 6.79899311 epoch total loss 6.39102459\n",
      "Trained batch 260 batch loss 6.71572161 epoch total loss 6.39227343\n",
      "Trained batch 261 batch loss 6.63153887 epoch total loss 6.39319038\n",
      "Trained batch 262 batch loss 6.42120266 epoch total loss 6.3932972\n",
      "Trained batch 263 batch loss 6.35744238 epoch total loss 6.39316082\n",
      "Trained batch 264 batch loss 6.07221174 epoch total loss 6.39194489\n",
      "Trained batch 265 batch loss 6.48872089 epoch total loss 6.39231062\n",
      "Trained batch 266 batch loss 6.35717344 epoch total loss 6.39217854\n",
      "Trained batch 267 batch loss 6.49480104 epoch total loss 6.39256239\n",
      "Trained batch 268 batch loss 6.52885 epoch total loss 6.39307117\n",
      "Trained batch 269 batch loss 5.83974695 epoch total loss 6.3910141\n",
      "Trained batch 270 batch loss 6.33225393 epoch total loss 6.39079618\n",
      "Trained batch 271 batch loss 6.37147808 epoch total loss 6.39072514\n",
      "Trained batch 272 batch loss 6.21252346 epoch total loss 6.39007\n",
      "Trained batch 273 batch loss 5.77214527 epoch total loss 6.38780642\n",
      "Trained batch 274 batch loss 5.87094879 epoch total loss 6.38592\n",
      "Trained batch 275 batch loss 6.15596676 epoch total loss 6.38508368\n",
      "Trained batch 276 batch loss 6.35446405 epoch total loss 6.38497305\n",
      "Trained batch 277 batch loss 6.54139853 epoch total loss 6.38553762\n",
      "Trained batch 278 batch loss 6.74663258 epoch total loss 6.38683653\n",
      "Trained batch 279 batch loss 6.52727604 epoch total loss 6.38733959\n",
      "Trained batch 280 batch loss 6.34623814 epoch total loss 6.38719273\n",
      "Trained batch 281 batch loss 6.08932734 epoch total loss 6.38613272\n",
      "Trained batch 282 batch loss 5.80856037 epoch total loss 6.3840847\n",
      "Trained batch 283 batch loss 6.06824303 epoch total loss 6.38296843\n",
      "Trained batch 284 batch loss 5.9407568 epoch total loss 6.38141155\n",
      "Trained batch 285 batch loss 6.24855328 epoch total loss 6.38094568\n",
      "Trained batch 286 batch loss 6.54502 epoch total loss 6.38151932\n",
      "Trained batch 287 batch loss 6.04755545 epoch total loss 6.38035583\n",
      "Trained batch 288 batch loss 5.62522078 epoch total loss 6.37773371\n",
      "Trained batch 289 batch loss 6.41725349 epoch total loss 6.37787056\n",
      "Trained batch 290 batch loss 6.20936918 epoch total loss 6.3772893\n",
      "Trained batch 291 batch loss 6.5484128 epoch total loss 6.37787771\n",
      "Trained batch 292 batch loss 6.30592918 epoch total loss 6.37763119\n",
      "Trained batch 293 batch loss 6.17883 epoch total loss 6.37695265\n",
      "Trained batch 294 batch loss 6.3439889 epoch total loss 6.37684059\n",
      "Trained batch 295 batch loss 6.22750092 epoch total loss 6.37633467\n",
      "Trained batch 296 batch loss 6.14282084 epoch total loss 6.3755455\n",
      "Trained batch 297 batch loss 5.76721287 epoch total loss 6.37349749\n",
      "Trained batch 298 batch loss 6.18320751 epoch total loss 6.372859\n",
      "Trained batch 299 batch loss 6.27488613 epoch total loss 6.37253141\n",
      "Trained batch 300 batch loss 6.20170975 epoch total loss 6.37196159\n",
      "Trained batch 301 batch loss 6.45540428 epoch total loss 6.37223911\n",
      "Trained batch 302 batch loss 6.20852375 epoch total loss 6.37169695\n",
      "Trained batch 303 batch loss 6.23088312 epoch total loss 6.37123203\n",
      "Trained batch 304 batch loss 6.71139526 epoch total loss 6.37235117\n",
      "Trained batch 305 batch loss 6.67289543 epoch total loss 6.37333632\n",
      "Trained batch 306 batch loss 6.84164 epoch total loss 6.37486696\n",
      "Trained batch 307 batch loss 6.77834845 epoch total loss 6.37618113\n",
      "Trained batch 308 batch loss 6.81898785 epoch total loss 6.37761879\n",
      "Trained batch 309 batch loss 6.57244873 epoch total loss 6.37824869\n",
      "Trained batch 310 batch loss 6.53607607 epoch total loss 6.37875795\n",
      "Trained batch 311 batch loss 6.14202213 epoch total loss 6.37799692\n",
      "Trained batch 312 batch loss 6.61941242 epoch total loss 6.37877035\n",
      "Trained batch 313 batch loss 6.32635641 epoch total loss 6.37860298\n",
      "Trained batch 314 batch loss 6.39575911 epoch total loss 6.37865782\n",
      "Trained batch 315 batch loss 6.47068834 epoch total loss 6.37895\n",
      "Trained batch 316 batch loss 6.33945942 epoch total loss 6.37882519\n",
      "Trained batch 317 batch loss 6.0607996 epoch total loss 6.37782192\n",
      "Trained batch 318 batch loss 6.14235735 epoch total loss 6.37708139\n",
      "Trained batch 319 batch loss 6.21764421 epoch total loss 6.37658167\n",
      "Trained batch 320 batch loss 6.14549065 epoch total loss 6.37585926\n",
      "Trained batch 321 batch loss 6.1660676 epoch total loss 6.37520552\n",
      "Trained batch 322 batch loss 6.08038044 epoch total loss 6.37429047\n",
      "Trained batch 323 batch loss 5.90092802 epoch total loss 6.37282467\n",
      "Trained batch 324 batch loss 5.95817232 epoch total loss 6.37154531\n",
      "Trained batch 325 batch loss 5.83853912 epoch total loss 6.36990547\n",
      "Trained batch 326 batch loss 5.31354952 epoch total loss 6.36666489\n",
      "Trained batch 327 batch loss 5.40211105 epoch total loss 6.36371517\n",
      "Trained batch 328 batch loss 6.50093 epoch total loss 6.36413336\n",
      "Trained batch 329 batch loss 6.62094831 epoch total loss 6.36491394\n",
      "Trained batch 330 batch loss 6.55970716 epoch total loss 6.36550426\n",
      "Trained batch 331 batch loss 6.45831823 epoch total loss 6.36578465\n",
      "Trained batch 332 batch loss 6.79694 epoch total loss 6.36708307\n",
      "Trained batch 333 batch loss 6.9158988 epoch total loss 6.3687315\n",
      "Trained batch 334 batch loss 6.71846962 epoch total loss 6.36977863\n",
      "Trained batch 335 batch loss 6.87771225 epoch total loss 6.37129498\n",
      "Trained batch 336 batch loss 6.77729893 epoch total loss 6.37250328\n",
      "Trained batch 337 batch loss 6.767 epoch total loss 6.37367439\n",
      "Trained batch 338 batch loss 6.70109129 epoch total loss 6.37464333\n",
      "Trained batch 339 batch loss 6.11347675 epoch total loss 6.37387276\n",
      "Trained batch 340 batch loss 5.7069726 epoch total loss 6.37191153\n",
      "Trained batch 341 batch loss 5.90729809 epoch total loss 6.37054873\n",
      "Trained batch 342 batch loss 6.3864069 epoch total loss 6.37059546\n",
      "Trained batch 343 batch loss 6.48997355 epoch total loss 6.37094355\n",
      "Trained batch 344 batch loss 6.24595118 epoch total loss 6.37057972\n",
      "Trained batch 345 batch loss 6.45993614 epoch total loss 6.37083912\n",
      "Trained batch 346 batch loss 6.48978853 epoch total loss 6.37118244\n",
      "Trained batch 347 batch loss 6.0005784 epoch total loss 6.37011433\n",
      "Trained batch 348 batch loss 6.0672369 epoch total loss 6.36924362\n",
      "Trained batch 349 batch loss 6.42608452 epoch total loss 6.36940622\n",
      "Trained batch 350 batch loss 6.46393442 epoch total loss 6.36967611\n",
      "Trained batch 351 batch loss 6.61933327 epoch total loss 6.37038755\n",
      "Trained batch 352 batch loss 6.59047079 epoch total loss 6.37101316\n",
      "Trained batch 353 batch loss 6.62603045 epoch total loss 6.37173557\n",
      "Trained batch 354 batch loss 6.48876143 epoch total loss 6.37206602\n",
      "Trained batch 355 batch loss 5.93222189 epoch total loss 6.37082672\n",
      "Trained batch 356 batch loss 6.48461676 epoch total loss 6.37114668\n",
      "Trained batch 357 batch loss 6.26786613 epoch total loss 6.37085724\n",
      "Trained batch 358 batch loss 6.56759644 epoch total loss 6.37140656\n",
      "Trained batch 359 batch loss 6.74789953 epoch total loss 6.37245512\n",
      "Trained batch 360 batch loss 6.89918661 epoch total loss 6.37391853\n",
      "Trained batch 361 batch loss 6.82305241 epoch total loss 6.37516212\n",
      "Trained batch 362 batch loss 6.93937492 epoch total loss 6.37672091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 363 batch loss 6.6754179 epoch total loss 6.3775444\n",
      "Trained batch 364 batch loss 7.02531481 epoch total loss 6.37932396\n",
      "Trained batch 365 batch loss 7.32735109 epoch total loss 6.38192177\n",
      "Trained batch 366 batch loss 6.79350615 epoch total loss 6.38304615\n",
      "Trained batch 367 batch loss 6.51444578 epoch total loss 6.38340378\n",
      "Trained batch 368 batch loss 6.46658611 epoch total loss 6.38363\n",
      "Trained batch 369 batch loss 6.32845306 epoch total loss 6.38348\n",
      "Trained batch 370 batch loss 6.50921535 epoch total loss 6.38382\n",
      "Trained batch 371 batch loss 5.94915485 epoch total loss 6.38264847\n",
      "Trained batch 372 batch loss 5.72029114 epoch total loss 6.38086796\n",
      "Trained batch 373 batch loss 5.88765 epoch total loss 6.37954569\n",
      "Trained batch 374 batch loss 5.79383135 epoch total loss 6.37797976\n",
      "Trained batch 375 batch loss 7.39122391 epoch total loss 6.38068151\n",
      "Trained batch 376 batch loss 6.96843433 epoch total loss 6.38224506\n",
      "Trained batch 377 batch loss 6.75775909 epoch total loss 6.38324118\n",
      "Trained batch 378 batch loss 6.71374464 epoch total loss 6.38411522\n",
      "Trained batch 379 batch loss 6.74561214 epoch total loss 6.38506889\n",
      "Trained batch 380 batch loss 6.60745382 epoch total loss 6.38565397\n",
      "Trained batch 381 batch loss 6.78655767 epoch total loss 6.38670635\n",
      "Trained batch 382 batch loss 6.14552927 epoch total loss 6.38607502\n",
      "Trained batch 383 batch loss 6.69894791 epoch total loss 6.38689232\n",
      "Trained batch 384 batch loss 6.50026655 epoch total loss 6.38718748\n",
      "Trained batch 385 batch loss 6.42949533 epoch total loss 6.38729715\n",
      "Trained batch 386 batch loss 6.57287788 epoch total loss 6.38777828\n",
      "Trained batch 387 batch loss 6.5373311 epoch total loss 6.38816452\n",
      "Trained batch 388 batch loss 6.33746243 epoch total loss 6.38803387\n",
      "Trained batch 389 batch loss 6.46987915 epoch total loss 6.38824463\n",
      "Trained batch 390 batch loss 6.60521507 epoch total loss 6.38880062\n",
      "Trained batch 391 batch loss 5.83304167 epoch total loss 6.38737917\n",
      "Trained batch 392 batch loss 6.3913703 epoch total loss 6.38738966\n",
      "Trained batch 393 batch loss 6.36310101 epoch total loss 6.38732767\n",
      "Trained batch 394 batch loss 6.14568567 epoch total loss 6.38671446\n",
      "Trained batch 395 batch loss 6.61531353 epoch total loss 6.38729286\n",
      "Trained batch 396 batch loss 6.72322941 epoch total loss 6.38814116\n",
      "Trained batch 397 batch loss 6.63027477 epoch total loss 6.38875103\n",
      "Trained batch 398 batch loss 6.02288294 epoch total loss 6.38783216\n",
      "Trained batch 399 batch loss 6.15443707 epoch total loss 6.38724756\n",
      "Trained batch 400 batch loss 6.00543118 epoch total loss 6.38629293\n",
      "Trained batch 401 batch loss 6.48630762 epoch total loss 6.38654232\n",
      "Trained batch 402 batch loss 6.46402 epoch total loss 6.38673496\n",
      "Trained batch 403 batch loss 6.32697487 epoch total loss 6.38658667\n",
      "Trained batch 404 batch loss 6.52306 epoch total loss 6.38692427\n",
      "Trained batch 405 batch loss 6.82709646 epoch total loss 6.38801098\n",
      "Trained batch 406 batch loss 6.8662138 epoch total loss 6.38918924\n",
      "Trained batch 407 batch loss 6.91461372 epoch total loss 6.39048\n",
      "Trained batch 408 batch loss 6.58464241 epoch total loss 6.39095592\n",
      "Trained batch 409 batch loss 6.29461956 epoch total loss 6.39072037\n",
      "Trained batch 410 batch loss 6.50807333 epoch total loss 6.39100647\n",
      "Trained batch 411 batch loss 6.39424896 epoch total loss 6.39101458\n",
      "Trained batch 412 batch loss 6.32385492 epoch total loss 6.39085197\n",
      "Trained batch 413 batch loss 5.67897081 epoch total loss 6.38912821\n",
      "Trained batch 414 batch loss 5.79010153 epoch total loss 6.38768101\n",
      "Trained batch 415 batch loss 6.29994345 epoch total loss 6.38747\n",
      "Trained batch 416 batch loss 6.46049595 epoch total loss 6.38764524\n",
      "Trained batch 417 batch loss 6.32135487 epoch total loss 6.38748646\n",
      "Trained batch 418 batch loss 6.59196806 epoch total loss 6.38797569\n",
      "Trained batch 419 batch loss 6.558074 epoch total loss 6.38838148\n",
      "Trained batch 420 batch loss 6.14957571 epoch total loss 6.38781309\n",
      "Trained batch 421 batch loss 6.61389256 epoch total loss 6.38835049\n",
      "Trained batch 422 batch loss 6.58749485 epoch total loss 6.38882208\n",
      "Trained batch 423 batch loss 6.4893136 epoch total loss 6.38905954\n",
      "Trained batch 424 batch loss 6.33790636 epoch total loss 6.3889389\n",
      "Trained batch 425 batch loss 6.36690474 epoch total loss 6.38888741\n",
      "Trained batch 426 batch loss 6.78413439 epoch total loss 6.38981533\n",
      "Trained batch 427 batch loss 6.50779772 epoch total loss 6.39009142\n",
      "Trained batch 428 batch loss 6.42827702 epoch total loss 6.39018059\n",
      "Trained batch 429 batch loss 6.28395224 epoch total loss 6.38993311\n",
      "Trained batch 430 batch loss 6.27766275 epoch total loss 6.3896718\n",
      "Trained batch 431 batch loss 6.29445 epoch total loss 6.38945055\n",
      "Trained batch 432 batch loss 6.57751513 epoch total loss 6.38988638\n",
      "Trained batch 433 batch loss 6.64972401 epoch total loss 6.39048624\n",
      "Trained batch 434 batch loss 6.80255365 epoch total loss 6.39143562\n",
      "Trained batch 435 batch loss 6.90084505 epoch total loss 6.39260674\n",
      "Trained batch 436 batch loss 6.82021809 epoch total loss 6.39358759\n",
      "Trained batch 437 batch loss 6.9443717 epoch total loss 6.39484787\n",
      "Trained batch 438 batch loss 6.60148191 epoch total loss 6.39532\n",
      "Trained batch 439 batch loss 6.18497086 epoch total loss 6.39484119\n",
      "Trained batch 440 batch loss 6.44722939 epoch total loss 6.39496\n",
      "Trained batch 441 batch loss 6.51930952 epoch total loss 6.39524221\n",
      "Trained batch 442 batch loss 6.4983983 epoch total loss 6.39547539\n",
      "Trained batch 443 batch loss 6.41764 epoch total loss 6.39552546\n",
      "Trained batch 444 batch loss 6.36411142 epoch total loss 6.39545441\n",
      "Trained batch 445 batch loss 6.32833242 epoch total loss 6.39530373\n",
      "Trained batch 446 batch loss 6.29494858 epoch total loss 6.39507866\n",
      "Trained batch 447 batch loss 6.48793507 epoch total loss 6.39528656\n",
      "Trained batch 448 batch loss 6.47579575 epoch total loss 6.39546633\n",
      "Trained batch 449 batch loss 6.68191385 epoch total loss 6.39610434\n",
      "Trained batch 450 batch loss 6.26356077 epoch total loss 6.39581\n",
      "Trained batch 451 batch loss 6.03439903 epoch total loss 6.39500856\n",
      "Trained batch 452 batch loss 6.4502 epoch total loss 6.39513063\n",
      "Trained batch 453 batch loss 6.2498064 epoch total loss 6.39480972\n",
      "Trained batch 454 batch loss 5.93485212 epoch total loss 6.39379644\n",
      "Trained batch 455 batch loss 5.88820028 epoch total loss 6.39268541\n",
      "Trained batch 456 batch loss 6.24483252 epoch total loss 6.39236116\n",
      "Trained batch 457 batch loss 6.37489271 epoch total loss 6.39232349\n",
      "Trained batch 458 batch loss 6.66905165 epoch total loss 6.39292717\n",
      "Trained batch 459 batch loss 6.50975704 epoch total loss 6.3931818\n",
      "Trained batch 460 batch loss 6.93608427 epoch total loss 6.39436197\n",
      "Trained batch 461 batch loss 6.94815111 epoch total loss 6.3955636\n",
      "Trained batch 462 batch loss 6.2812624 epoch total loss 6.39531612\n",
      "Trained batch 463 batch loss 6.24798489 epoch total loss 6.39499807\n",
      "Trained batch 464 batch loss 5.9442606 epoch total loss 6.39402676\n",
      "Trained batch 465 batch loss 5.49577045 epoch total loss 6.39209509\n",
      "Trained batch 466 batch loss 5.91243744 epoch total loss 6.3910656\n",
      "Trained batch 467 batch loss 5.88865232 epoch total loss 6.38999\n",
      "Trained batch 468 batch loss 5.392241 epoch total loss 6.38785791\n",
      "Trained batch 469 batch loss 4.96117115 epoch total loss 6.38481617\n",
      "Trained batch 470 batch loss 5.11015368 epoch total loss 6.38210392\n",
      "Trained batch 471 batch loss 5.48889446 epoch total loss 6.38020802\n",
      "Trained batch 472 batch loss 6.01920033 epoch total loss 6.37944317\n",
      "Trained batch 473 batch loss 6.28698969 epoch total loss 6.37924814\n",
      "Trained batch 474 batch loss 6.44860744 epoch total loss 6.37939405\n",
      "Trained batch 475 batch loss 6.82920456 epoch total loss 6.38034058\n",
      "Trained batch 476 batch loss 6.77429867 epoch total loss 6.38116884\n",
      "Trained batch 477 batch loss 6.76260376 epoch total loss 6.3819685\n",
      "Trained batch 478 batch loss 6.22432423 epoch total loss 6.381639\n",
      "Trained batch 479 batch loss 5.81373167 epoch total loss 6.38045311\n",
      "Trained batch 480 batch loss 5.30281 epoch total loss 6.37820768\n",
      "Trained batch 481 batch loss 5.13714075 epoch total loss 6.37562799\n",
      "Trained batch 482 batch loss 5.24798298 epoch total loss 6.37328863\n",
      "Trained batch 483 batch loss 5.87564516 epoch total loss 6.37225819\n",
      "Trained batch 484 batch loss 6.19903088 epoch total loss 6.37190056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 485 batch loss 6.72170353 epoch total loss 6.37262154\n",
      "Trained batch 486 batch loss 7.01573944 epoch total loss 6.37394476\n",
      "Trained batch 487 batch loss 6.81027031 epoch total loss 6.37484074\n",
      "Trained batch 488 batch loss 6.80332756 epoch total loss 6.37571859\n",
      "Trained batch 489 batch loss 6.76742506 epoch total loss 6.3765192\n",
      "Trained batch 490 batch loss 6.83762264 epoch total loss 6.37746048\n",
      "Trained batch 491 batch loss 6.62750912 epoch total loss 6.37796926\n",
      "Trained batch 492 batch loss 6.49835491 epoch total loss 6.37821388\n",
      "Trained batch 493 batch loss 6.72193766 epoch total loss 6.37891102\n",
      "Trained batch 494 batch loss 6.78991604 epoch total loss 6.3797431\n",
      "Trained batch 495 batch loss 6.51551056 epoch total loss 6.38001728\n",
      "Trained batch 496 batch loss 6.58137608 epoch total loss 6.38042307\n",
      "Trained batch 497 batch loss 6.05919504 epoch total loss 6.37977648\n",
      "Trained batch 498 batch loss 5.73973799 epoch total loss 6.3784914\n",
      "Trained batch 499 batch loss 5.92673826 epoch total loss 6.37758636\n",
      "Trained batch 500 batch loss 6.57824612 epoch total loss 6.37798738\n",
      "Trained batch 501 batch loss 6.55888462 epoch total loss 6.37834835\n",
      "Trained batch 502 batch loss 6.59259129 epoch total loss 6.37877512\n",
      "Trained batch 503 batch loss 6.69637823 epoch total loss 6.37940598\n",
      "Trained batch 504 batch loss 6.54762888 epoch total loss 6.37973976\n",
      "Trained batch 505 batch loss 6.31884766 epoch total loss 6.37961912\n",
      "Trained batch 506 batch loss 6.20235252 epoch total loss 6.37926912\n",
      "Trained batch 507 batch loss 6.31913233 epoch total loss 6.37915039\n",
      "Trained batch 508 batch loss 6.13811588 epoch total loss 6.37867594\n",
      "Trained batch 509 batch loss 6.16923046 epoch total loss 6.37826443\n",
      "Trained batch 510 batch loss 5.80453396 epoch total loss 6.37713957\n",
      "Trained batch 511 batch loss 6.31854 epoch total loss 6.37702465\n",
      "Trained batch 512 batch loss 6.27206039 epoch total loss 6.37681961\n",
      "Trained batch 513 batch loss 6.26947451 epoch total loss 6.37661028\n",
      "Trained batch 514 batch loss 6.01060915 epoch total loss 6.37589836\n",
      "Trained batch 515 batch loss 6.00269651 epoch total loss 6.37517357\n",
      "Trained batch 516 batch loss 6.08567142 epoch total loss 6.37461233\n",
      "Trained batch 517 batch loss 6.38435411 epoch total loss 6.3746314\n",
      "Trained batch 518 batch loss 5.88832092 epoch total loss 6.37369251\n",
      "Trained batch 519 batch loss 6.30678225 epoch total loss 6.37356377\n",
      "Trained batch 520 batch loss 6.60616112 epoch total loss 6.37401104\n",
      "Trained batch 521 batch loss 6.41056871 epoch total loss 6.37408161\n",
      "Trained batch 522 batch loss 6.35688686 epoch total loss 6.37404871\n",
      "Trained batch 523 batch loss 6.42516184 epoch total loss 6.37414598\n",
      "Trained batch 524 batch loss 6.39781284 epoch total loss 6.37419128\n",
      "Trained batch 525 batch loss 6.81298542 epoch total loss 6.37502718\n",
      "Trained batch 526 batch loss 6.60638905 epoch total loss 6.37546682\n",
      "Trained batch 527 batch loss 6.59322691 epoch total loss 6.37588024\n",
      "Trained batch 528 batch loss 5.80912638 epoch total loss 6.37480688\n",
      "Trained batch 529 batch loss 6.72252417 epoch total loss 6.37546396\n",
      "Trained batch 530 batch loss 6.70052481 epoch total loss 6.37607718\n",
      "Trained batch 531 batch loss 6.37877 epoch total loss 6.37608194\n",
      "Trained batch 532 batch loss 6.23243284 epoch total loss 6.37581158\n",
      "Trained batch 533 batch loss 6.00705385 epoch total loss 6.37512\n",
      "Trained batch 534 batch loss 6.13104057 epoch total loss 6.37466288\n",
      "Trained batch 535 batch loss 6.38369608 epoch total loss 6.37468\n",
      "Trained batch 536 batch loss 6.47087669 epoch total loss 6.37486\n",
      "Trained batch 537 batch loss 6.36519527 epoch total loss 6.37484169\n",
      "Trained batch 538 batch loss 5.95271778 epoch total loss 6.37405682\n",
      "Trained batch 539 batch loss 6.55559349 epoch total loss 6.37439394\n",
      "Trained batch 540 batch loss 6.49901915 epoch total loss 6.37462473\n",
      "Trained batch 541 batch loss 6.032722 epoch total loss 6.37399292\n",
      "Trained batch 542 batch loss 5.97707176 epoch total loss 6.3732605\n",
      "Trained batch 543 batch loss 6.41064405 epoch total loss 6.37332916\n",
      "Trained batch 544 batch loss 6.41254425 epoch total loss 6.37340164\n",
      "Trained batch 545 batch loss 6.47449207 epoch total loss 6.37358713\n",
      "Trained batch 546 batch loss 6.43259716 epoch total loss 6.37369537\n",
      "Trained batch 547 batch loss 6.24033403 epoch total loss 6.37345123\n",
      "Trained batch 548 batch loss 6.27142715 epoch total loss 6.37326527\n",
      "Trained batch 549 batch loss 6.26787949 epoch total loss 6.3730731\n",
      "Trained batch 550 batch loss 6.50634575 epoch total loss 6.37331533\n",
      "Trained batch 551 batch loss 6.486022 epoch total loss 6.37352\n",
      "Trained batch 552 batch loss 6.51750946 epoch total loss 6.3737812\n",
      "Trained batch 553 batch loss 6.40862942 epoch total loss 6.37384415\n",
      "Trained batch 554 batch loss 5.96666718 epoch total loss 6.37310886\n",
      "Trained batch 555 batch loss 5.46816826 epoch total loss 6.37147856\n",
      "Trained batch 556 batch loss 5.68950701 epoch total loss 6.37025213\n",
      "Trained batch 557 batch loss 5.51381063 epoch total loss 6.36871481\n",
      "Trained batch 558 batch loss 6.47930098 epoch total loss 6.3689127\n",
      "Trained batch 559 batch loss 6.11470938 epoch total loss 6.36845779\n",
      "Trained batch 560 batch loss 5.86347675 epoch total loss 6.3675561\n",
      "Trained batch 561 batch loss 5.90453196 epoch total loss 6.36673117\n",
      "Trained batch 562 batch loss 6.18426943 epoch total loss 6.36640644\n",
      "Trained batch 563 batch loss 5.80037928 epoch total loss 6.36540079\n",
      "Trained batch 564 batch loss 5.98668957 epoch total loss 6.3647294\n",
      "Trained batch 565 batch loss 6.36408329 epoch total loss 6.36472797\n",
      "Trained batch 566 batch loss 6.20492125 epoch total loss 6.36444521\n",
      "Trained batch 567 batch loss 6.37765455 epoch total loss 6.36446857\n",
      "Trained batch 568 batch loss 6.31710625 epoch total loss 6.3643856\n",
      "Trained batch 569 batch loss 6.2246 epoch total loss 6.36414\n",
      "Trained batch 570 batch loss 6.64711332 epoch total loss 6.36463642\n",
      "Trained batch 571 batch loss 5.91348553 epoch total loss 6.3638463\n",
      "Trained batch 572 batch loss 5.62742281 epoch total loss 6.36255884\n",
      "Trained batch 573 batch loss 5.50645161 epoch total loss 6.36106491\n",
      "Trained batch 574 batch loss 5.2077179 epoch total loss 6.35905552\n",
      "Trained batch 575 batch loss 6.04554653 epoch total loss 6.35851049\n",
      "Trained batch 576 batch loss 6.56469631 epoch total loss 6.3588686\n",
      "Trained batch 577 batch loss 6.40171432 epoch total loss 6.35894251\n",
      "Trained batch 578 batch loss 6.00960302 epoch total loss 6.35833788\n",
      "Trained batch 579 batch loss 6.2482729 epoch total loss 6.3581481\n",
      "Trained batch 580 batch loss 6.41313171 epoch total loss 6.35824251\n",
      "Trained batch 581 batch loss 5.73930693 epoch total loss 6.35717726\n",
      "Trained batch 582 batch loss 5.92565775 epoch total loss 6.35643578\n",
      "Trained batch 583 batch loss 6.07047176 epoch total loss 6.35594511\n",
      "Trained batch 584 batch loss 6.17861605 epoch total loss 6.35564184\n",
      "Trained batch 585 batch loss 6.02057171 epoch total loss 6.35506916\n",
      "Trained batch 586 batch loss 6.39615536 epoch total loss 6.35513926\n",
      "Trained batch 587 batch loss 6.28591394 epoch total loss 6.355021\n",
      "Trained batch 588 batch loss 5.68965244 epoch total loss 6.35389\n",
      "Trained batch 589 batch loss 6.4049015 epoch total loss 6.35397625\n",
      "Trained batch 590 batch loss 6.2346549 epoch total loss 6.35377407\n",
      "Trained batch 591 batch loss 6.46585464 epoch total loss 6.35396338\n",
      "Trained batch 592 batch loss 6.33526421 epoch total loss 6.3539319\n",
      "Trained batch 593 batch loss 6.30230331 epoch total loss 6.35384464\n",
      "Trained batch 594 batch loss 6.60720396 epoch total loss 6.35427094\n",
      "Trained batch 595 batch loss 6.62527895 epoch total loss 6.35472631\n",
      "Trained batch 596 batch loss 6.91141033 epoch total loss 6.35566044\n",
      "Trained batch 597 batch loss 6.54796886 epoch total loss 6.3559823\n",
      "Trained batch 598 batch loss 6.3538537 epoch total loss 6.35597849\n",
      "Trained batch 599 batch loss 5.99241686 epoch total loss 6.35537195\n",
      "Trained batch 600 batch loss 6.00197506 epoch total loss 6.35478258\n",
      "Trained batch 601 batch loss 6.24844551 epoch total loss 6.35460615\n",
      "Trained batch 602 batch loss 6.09878349 epoch total loss 6.35418129\n",
      "Trained batch 603 batch loss 6.12267923 epoch total loss 6.35379696\n",
      "Trained batch 604 batch loss 6.36686087 epoch total loss 6.35381889\n",
      "Trained batch 605 batch loss 6.04613113 epoch total loss 6.35331\n",
      "Trained batch 606 batch loss 6.39894676 epoch total loss 6.35338545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 607 batch loss 6.41044664 epoch total loss 6.35347939\n",
      "Trained batch 608 batch loss 6.74018097 epoch total loss 6.35411549\n",
      "Trained batch 609 batch loss 6.94051075 epoch total loss 6.35507822\n",
      "Trained batch 610 batch loss 6.72337866 epoch total loss 6.3556819\n",
      "Trained batch 611 batch loss 6.20698833 epoch total loss 6.35543871\n",
      "Trained batch 612 batch loss 6.45574284 epoch total loss 6.35560274\n",
      "Trained batch 613 batch loss 6.18555403 epoch total loss 6.35532522\n",
      "Trained batch 614 batch loss 6.53185129 epoch total loss 6.35561275\n",
      "Trained batch 615 batch loss 6.69521809 epoch total loss 6.35616493\n",
      "Trained batch 616 batch loss 6.28105879 epoch total loss 6.35604286\n",
      "Trained batch 617 batch loss 6.63208675 epoch total loss 6.35649061\n",
      "Trained batch 618 batch loss 6.06555176 epoch total loss 6.3560195\n",
      "Trained batch 619 batch loss 6.38403511 epoch total loss 6.3560648\n",
      "Trained batch 620 batch loss 6.53430462 epoch total loss 6.35635233\n",
      "Trained batch 621 batch loss 6.6814909 epoch total loss 6.3568759\n",
      "Trained batch 622 batch loss 6.60998583 epoch total loss 6.35728312\n",
      "Trained batch 623 batch loss 6.56463528 epoch total loss 6.35761595\n",
      "Trained batch 624 batch loss 6.33384466 epoch total loss 6.3575778\n",
      "Trained batch 625 batch loss 6.27910471 epoch total loss 6.35745192\n",
      "Trained batch 626 batch loss 6.34847069 epoch total loss 6.35743761\n",
      "Trained batch 627 batch loss 6.43125105 epoch total loss 6.35755491\n",
      "Trained batch 628 batch loss 6.59850359 epoch total loss 6.35793877\n",
      "Trained batch 629 batch loss 6.67255 epoch total loss 6.35843897\n",
      "Trained batch 630 batch loss 6.66056442 epoch total loss 6.35891867\n",
      "Trained batch 631 batch loss 6.45422316 epoch total loss 6.35906935\n",
      "Trained batch 632 batch loss 5.83581734 epoch total loss 6.35824156\n",
      "Trained batch 633 batch loss 5.77289391 epoch total loss 6.35731697\n",
      "Trained batch 634 batch loss 5.92124462 epoch total loss 6.35662889\n",
      "Trained batch 635 batch loss 6.26980972 epoch total loss 6.35649204\n",
      "Trained batch 636 batch loss 5.61568975 epoch total loss 6.35532761\n",
      "Trained batch 637 batch loss 5.55729055 epoch total loss 6.35407495\n",
      "Trained batch 638 batch loss 5.17138195 epoch total loss 6.35222101\n",
      "Trained batch 639 batch loss 5.46378803 epoch total loss 6.35083103\n",
      "Trained batch 640 batch loss 6.09418 epoch total loss 6.35043\n",
      "Trained batch 641 batch loss 5.71673775 epoch total loss 6.34944153\n",
      "Trained batch 642 batch loss 5.8062582 epoch total loss 6.34859514\n",
      "Trained batch 643 batch loss 5.98881435 epoch total loss 6.34803534\n",
      "Trained batch 644 batch loss 6.09038734 epoch total loss 6.34763527\n",
      "Trained batch 645 batch loss 6.00210524 epoch total loss 6.3471\n",
      "Trained batch 646 batch loss 5.6145649 epoch total loss 6.34596634\n",
      "Trained batch 647 batch loss 6.13506079 epoch total loss 6.34564066\n",
      "Trained batch 648 batch loss 6.45696926 epoch total loss 6.34581232\n",
      "Trained batch 649 batch loss 6.63045216 epoch total loss 6.34625101\n",
      "Trained batch 650 batch loss 6.72538614 epoch total loss 6.34683466\n",
      "Trained batch 651 batch loss 5.62578344 epoch total loss 6.34572697\n",
      "Trained batch 652 batch loss 5.44618654 epoch total loss 6.34434748\n",
      "Trained batch 653 batch loss 5.29662704 epoch total loss 6.34274292\n",
      "Trained batch 654 batch loss 5.73977566 epoch total loss 6.34182072\n",
      "Trained batch 655 batch loss 6.54445267 epoch total loss 6.34213\n",
      "Trained batch 656 batch loss 7.5810771 epoch total loss 6.34401894\n",
      "Trained batch 657 batch loss 6.76277399 epoch total loss 6.34465599\n",
      "Trained batch 658 batch loss 5.74126339 epoch total loss 6.34373903\n",
      "Trained batch 659 batch loss 6.19767332 epoch total loss 6.3435173\n",
      "Trained batch 660 batch loss 6.37348223 epoch total loss 6.3435626\n",
      "Trained batch 661 batch loss 6.56449318 epoch total loss 6.34389687\n",
      "Trained batch 662 batch loss 6.48945761 epoch total loss 6.34411669\n",
      "Trained batch 663 batch loss 6.37570333 epoch total loss 6.34416389\n",
      "Trained batch 664 batch loss 6.61443329 epoch total loss 6.34457064\n",
      "Trained batch 665 batch loss 6.58999538 epoch total loss 6.34493971\n",
      "Trained batch 666 batch loss 6.62810183 epoch total loss 6.34536457\n",
      "Trained batch 667 batch loss 6.15928078 epoch total loss 6.34508514\n",
      "Trained batch 668 batch loss 6.32207155 epoch total loss 6.34505129\n",
      "Trained batch 669 batch loss 6.7259078 epoch total loss 6.34562063\n",
      "Trained batch 670 batch loss 6.54948568 epoch total loss 6.34592485\n",
      "Trained batch 671 batch loss 6.17237425 epoch total loss 6.34566593\n",
      "Trained batch 672 batch loss 5.49289036 epoch total loss 6.34439659\n",
      "Trained batch 673 batch loss 5.69993544 epoch total loss 6.34343863\n",
      "Trained batch 674 batch loss 5.72028446 epoch total loss 6.34251404\n",
      "Trained batch 675 batch loss 6.39862394 epoch total loss 6.34259701\n",
      "Trained batch 676 batch loss 6.33483315 epoch total loss 6.34258556\n",
      "Trained batch 677 batch loss 6.44092226 epoch total loss 6.342731\n",
      "Trained batch 678 batch loss 6.57050705 epoch total loss 6.34306669\n",
      "Trained batch 679 batch loss 5.87593079 epoch total loss 6.34237862\n",
      "Trained batch 680 batch loss 6.09255123 epoch total loss 6.34201145\n",
      "Trained batch 681 batch loss 6.2543993 epoch total loss 6.34188271\n",
      "Trained batch 682 batch loss 6.46426 epoch total loss 6.34206247\n",
      "Trained batch 683 batch loss 6.63952208 epoch total loss 6.3424983\n",
      "Trained batch 684 batch loss 6.15287256 epoch total loss 6.34222078\n",
      "Trained batch 685 batch loss 6.19669676 epoch total loss 6.34200859\n",
      "Trained batch 686 batch loss 6.54498291 epoch total loss 6.34230423\n",
      "Trained batch 687 batch loss 6.31097555 epoch total loss 6.34225893\n",
      "Trained batch 688 batch loss 6.78664923 epoch total loss 6.34290457\n",
      "Trained batch 689 batch loss 6.56492758 epoch total loss 6.34322691\n",
      "Trained batch 690 batch loss 6.28500032 epoch total loss 6.34314299\n",
      "Trained batch 691 batch loss 6.30728245 epoch total loss 6.34309053\n",
      "Trained batch 692 batch loss 6.29154301 epoch total loss 6.34301615\n",
      "Trained batch 693 batch loss 6.21199799 epoch total loss 6.34282684\n",
      "Trained batch 694 batch loss 6.38585567 epoch total loss 6.34288883\n",
      "Trained batch 695 batch loss 6.23683834 epoch total loss 6.34273624\n",
      "Trained batch 696 batch loss 6.36492491 epoch total loss 6.34276772\n",
      "Trained batch 697 batch loss 6.22185421 epoch total loss 6.34259415\n",
      "Trained batch 698 batch loss 6.59543419 epoch total loss 6.34295607\n",
      "Trained batch 699 batch loss 6.41363859 epoch total loss 6.34305716\n",
      "Trained batch 700 batch loss 6.51770306 epoch total loss 6.34330654\n",
      "Trained batch 701 batch loss 6.26973724 epoch total loss 6.34320116\n",
      "Trained batch 702 batch loss 6.43052816 epoch total loss 6.34332561\n",
      "Trained batch 703 batch loss 6.42266798 epoch total loss 6.34343863\n",
      "Trained batch 704 batch loss 6.49559546 epoch total loss 6.34365511\n",
      "Trained batch 705 batch loss 6.50229454 epoch total loss 6.34388\n",
      "Trained batch 706 batch loss 6.45871496 epoch total loss 6.34404278\n",
      "Trained batch 707 batch loss 6.26600122 epoch total loss 6.34393215\n",
      "Trained batch 708 batch loss 6.71408415 epoch total loss 6.34445477\n",
      "Trained batch 709 batch loss 6.49318647 epoch total loss 6.34466457\n",
      "Trained batch 710 batch loss 6.87390804 epoch total loss 6.34541035\n",
      "Trained batch 711 batch loss 7.47420406 epoch total loss 6.34699774\n",
      "Trained batch 712 batch loss 7.07945728 epoch total loss 6.34802675\n",
      "Trained batch 713 batch loss 7.3318882 epoch total loss 6.34940672\n",
      "Trained batch 714 batch loss 7.28618336 epoch total loss 6.3507185\n",
      "Trained batch 715 batch loss 6.35378885 epoch total loss 6.35072327\n",
      "Trained batch 716 batch loss 6.61429882 epoch total loss 6.35109138\n",
      "Trained batch 717 batch loss 6.34328461 epoch total loss 6.35108042\n",
      "Trained batch 718 batch loss 6.25521898 epoch total loss 6.3509469\n",
      "Trained batch 719 batch loss 6.22408295 epoch total loss 6.35077047\n",
      "Trained batch 720 batch loss 6.33318043 epoch total loss 6.35074615\n",
      "Trained batch 721 batch loss 5.89950752 epoch total loss 6.35012\n",
      "Trained batch 722 batch loss 6.20723391 epoch total loss 6.3499217\n",
      "Trained batch 723 batch loss 6.10733128 epoch total loss 6.34958649\n",
      "Trained batch 724 batch loss 6.05778027 epoch total loss 6.34918308\n",
      "Trained batch 725 batch loss 5.80872822 epoch total loss 6.34843731\n",
      "Trained batch 726 batch loss 5.67399645 epoch total loss 6.34750843\n",
      "Trained batch 727 batch loss 5.76402521 epoch total loss 6.34670591\n",
      "Trained batch 728 batch loss 6.0963068 epoch total loss 6.34636164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 729 batch loss 5.69018126 epoch total loss 6.34546137\n",
      "Trained batch 730 batch loss 6.40927267 epoch total loss 6.34554863\n",
      "Trained batch 731 batch loss 6.23992062 epoch total loss 6.34540367\n",
      "Trained batch 732 batch loss 6.38967419 epoch total loss 6.34546423\n",
      "Trained batch 733 batch loss 6.38377237 epoch total loss 6.34551668\n",
      "Trained batch 734 batch loss 6.57469702 epoch total loss 6.34582901\n",
      "Trained batch 735 batch loss 6.57351828 epoch total loss 6.34613895\n",
      "Trained batch 736 batch loss 6.7484 epoch total loss 6.34668589\n",
      "Trained batch 737 batch loss 6.61115 epoch total loss 6.34704494\n",
      "Trained batch 738 batch loss 6.38644218 epoch total loss 6.34709787\n",
      "Trained batch 739 batch loss 6.26843309 epoch total loss 6.34699154\n",
      "Trained batch 740 batch loss 5.83318377 epoch total loss 6.34629679\n",
      "Trained batch 741 batch loss 5.52121925 epoch total loss 6.34518337\n",
      "Trained batch 742 batch loss 6.06329966 epoch total loss 6.34480333\n",
      "Trained batch 743 batch loss 5.89017582 epoch total loss 6.34419155\n",
      "Trained batch 744 batch loss 6.12609959 epoch total loss 6.3438983\n",
      "Trained batch 745 batch loss 6.31641102 epoch total loss 6.34386158\n",
      "Trained batch 746 batch loss 5.95854664 epoch total loss 6.34334469\n",
      "Trained batch 747 batch loss 6.02037668 epoch total loss 6.34291267\n",
      "Trained batch 748 batch loss 6.35757351 epoch total loss 6.34293222\n",
      "Trained batch 749 batch loss 6.29930735 epoch total loss 6.34287405\n",
      "Trained batch 750 batch loss 6.45964575 epoch total loss 6.3430295\n",
      "Trained batch 751 batch loss 6.78519869 epoch total loss 6.34361792\n",
      "Trained batch 752 batch loss 5.63565063 epoch total loss 6.34267664\n",
      "Trained batch 753 batch loss 5.18416786 epoch total loss 6.34113789\n",
      "Trained batch 754 batch loss 4.92311621 epoch total loss 6.33925772\n",
      "Trained batch 755 batch loss 6.07607365 epoch total loss 6.33890915\n",
      "Trained batch 756 batch loss 6.57251406 epoch total loss 6.33921862\n",
      "Trained batch 757 batch loss 7.36641264 epoch total loss 6.34057522\n",
      "Trained batch 758 batch loss 7.01574564 epoch total loss 6.34146595\n",
      "Trained batch 759 batch loss 6.64766741 epoch total loss 6.34186888\n",
      "Trained batch 760 batch loss 6.42707 epoch total loss 6.34198141\n",
      "Trained batch 761 batch loss 6.35555458 epoch total loss 6.34199905\n",
      "Trained batch 762 batch loss 6.5815444 epoch total loss 6.34231329\n",
      "Trained batch 763 batch loss 6.27974844 epoch total loss 6.34223127\n",
      "Trained batch 764 batch loss 5.64896679 epoch total loss 6.34132385\n",
      "Trained batch 765 batch loss 5.55706072 epoch total loss 6.34029865\n",
      "Trained batch 766 batch loss 6.41448975 epoch total loss 6.34039593\n",
      "Trained batch 767 batch loss 6.53094578 epoch total loss 6.34064388\n",
      "Trained batch 768 batch loss 6.77177 epoch total loss 6.3412056\n",
      "Trained batch 769 batch loss 6.5645628 epoch total loss 6.34149599\n",
      "Trained batch 770 batch loss 6.66955137 epoch total loss 6.34192181\n",
      "Trained batch 771 batch loss 6.78049326 epoch total loss 6.34249\n",
      "Trained batch 772 batch loss 6.68015194 epoch total loss 6.34292793\n",
      "Trained batch 773 batch loss 6.52355623 epoch total loss 6.34316111\n",
      "Trained batch 774 batch loss 6.54618073 epoch total loss 6.34342384\n",
      "Trained batch 775 batch loss 6.37347126 epoch total loss 6.34346247\n",
      "Trained batch 776 batch loss 6.32595634 epoch total loss 6.34344053\n",
      "Trained batch 777 batch loss 6.78771544 epoch total loss 6.34401226\n",
      "Trained batch 778 batch loss 6.47977877 epoch total loss 6.34418678\n",
      "Trained batch 779 batch loss 6.43695879 epoch total loss 6.34430599\n",
      "Trained batch 780 batch loss 6.40515757 epoch total loss 6.34438419\n",
      "Trained batch 781 batch loss 6.33887243 epoch total loss 6.34437704\n",
      "Trained batch 782 batch loss 6.53149652 epoch total loss 6.34461689\n",
      "Trained batch 783 batch loss 6.35923 epoch total loss 6.34463549\n",
      "Trained batch 784 batch loss 6.83135271 epoch total loss 6.34525681\n",
      "Trained batch 785 batch loss 5.8216033 epoch total loss 6.34458971\n",
      "Trained batch 786 batch loss 5.80975914 epoch total loss 6.34390926\n",
      "Trained batch 787 batch loss 6.19901371 epoch total loss 6.3437252\n",
      "Trained batch 788 batch loss 6.66756058 epoch total loss 6.34413624\n",
      "Trained batch 789 batch loss 6.54006147 epoch total loss 6.34438419\n",
      "Trained batch 790 batch loss 6.31078196 epoch total loss 6.34434128\n",
      "Trained batch 791 batch loss 6.28616285 epoch total loss 6.34426785\n",
      "Trained batch 792 batch loss 6.16174412 epoch total loss 6.34403753\n",
      "Trained batch 793 batch loss 6.24922 epoch total loss 6.34391737\n",
      "Trained batch 794 batch loss 6.01435328 epoch total loss 6.34350204\n",
      "Trained batch 795 batch loss 6.35060787 epoch total loss 6.3435111\n",
      "Trained batch 796 batch loss 6.11881 epoch total loss 6.34322882\n",
      "Trained batch 797 batch loss 6.40531 epoch total loss 6.34330654\n",
      "Trained batch 798 batch loss 7.11629 epoch total loss 6.344275\n",
      "Trained batch 799 batch loss 7.05671549 epoch total loss 6.34516668\n",
      "Trained batch 800 batch loss 6.88598633 epoch total loss 6.34584236\n",
      "Trained batch 801 batch loss 6.71218729 epoch total loss 6.3463\n",
      "Trained batch 802 batch loss 6.47014284 epoch total loss 6.34645462\n",
      "Trained batch 803 batch loss 7.04711819 epoch total loss 6.34732676\n",
      "Trained batch 804 batch loss 6.62149048 epoch total loss 6.34766769\n",
      "Trained batch 805 batch loss 6.5688839 epoch total loss 6.34794235\n",
      "Trained batch 806 batch loss 6.48618746 epoch total loss 6.34811401\n",
      "Trained batch 807 batch loss 6.77005577 epoch total loss 6.3486371\n",
      "Trained batch 808 batch loss 6.34799671 epoch total loss 6.34863663\n",
      "Trained batch 809 batch loss 6.48361111 epoch total loss 6.34880304\n",
      "Trained batch 810 batch loss 6.50819635 epoch total loss 6.349\n",
      "Trained batch 811 batch loss 5.82037926 epoch total loss 6.34834814\n",
      "Trained batch 812 batch loss 6.43772125 epoch total loss 6.34845781\n",
      "Trained batch 813 batch loss 6.67427635 epoch total loss 6.34885883\n",
      "Trained batch 814 batch loss 6.56108522 epoch total loss 6.34911919\n",
      "Trained batch 815 batch loss 6.3736105 epoch total loss 6.34914923\n",
      "Trained batch 816 batch loss 6.72868967 epoch total loss 6.34961414\n",
      "Trained batch 817 batch loss 6.51098633 epoch total loss 6.34981155\n",
      "Trained batch 818 batch loss 6.61175299 epoch total loss 6.35013151\n",
      "Trained batch 819 batch loss 6.51350307 epoch total loss 6.35033131\n",
      "Trained batch 820 batch loss 6.59560537 epoch total loss 6.35063076\n",
      "Trained batch 821 batch loss 5.75318289 epoch total loss 6.34990311\n",
      "Trained batch 822 batch loss 6.38627386 epoch total loss 6.34994745\n",
      "Trained batch 823 batch loss 6.09467888 epoch total loss 6.34963703\n",
      "Trained batch 824 batch loss 6.47303867 epoch total loss 6.34978724\n",
      "Trained batch 825 batch loss 6.16517925 epoch total loss 6.34956312\n",
      "Trained batch 826 batch loss 6.50915861 epoch total loss 6.34975672\n",
      "Trained batch 827 batch loss 6.57578421 epoch total loss 6.35003\n",
      "Trained batch 828 batch loss 6.64828 epoch total loss 6.35039\n",
      "Trained batch 829 batch loss 6.57657433 epoch total loss 6.35066319\n",
      "Trained batch 830 batch loss 6.94495058 epoch total loss 6.35137892\n",
      "Trained batch 831 batch loss 6.44191694 epoch total loss 6.35148811\n",
      "Trained batch 832 batch loss 6.58502579 epoch total loss 6.35176849\n",
      "Trained batch 833 batch loss 6.59276485 epoch total loss 6.35205793\n",
      "Trained batch 834 batch loss 6.73131132 epoch total loss 6.35251284\n",
      "Trained batch 835 batch loss 6.89964962 epoch total loss 6.35316753\n",
      "Trained batch 836 batch loss 6.55929327 epoch total loss 6.35341406\n",
      "Trained batch 837 batch loss 6.35411119 epoch total loss 6.35341454\n",
      "Trained batch 838 batch loss 6.85790396 epoch total loss 6.35401678\n",
      "Trained batch 839 batch loss 6.73752499 epoch total loss 6.35447359\n",
      "Trained batch 840 batch loss 6.60935211 epoch total loss 6.35477686\n",
      "Trained batch 841 batch loss 6.14082384 epoch total loss 6.35452223\n",
      "Trained batch 842 batch loss 6.60219049 epoch total loss 6.35481644\n",
      "Trained batch 843 batch loss 6.55994272 epoch total loss 6.35505962\n",
      "Trained batch 844 batch loss 5.89385128 epoch total loss 6.35451365\n",
      "Trained batch 845 batch loss 5.32739973 epoch total loss 6.35329819\n",
      "Trained batch 846 batch loss 5.96272612 epoch total loss 6.35283709\n",
      "Trained batch 847 batch loss 6.70537519 epoch total loss 6.35325336\n",
      "Trained batch 848 batch loss 5.95508146 epoch total loss 6.35278368\n",
      "Trained batch 849 batch loss 5.30442142 epoch total loss 6.35154867\n",
      "Trained batch 850 batch loss 5.31585217 epoch total loss 6.35033035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 851 batch loss 6.43233919 epoch total loss 6.3504262\n",
      "Trained batch 852 batch loss 6.27397346 epoch total loss 6.35033655\n",
      "Trained batch 853 batch loss 6.56667328 epoch total loss 6.35059071\n",
      "Trained batch 854 batch loss 6.16058826 epoch total loss 6.35036802\n",
      "Trained batch 855 batch loss 6.45476103 epoch total loss 6.35049\n",
      "Trained batch 856 batch loss 6.50097084 epoch total loss 6.35066557\n",
      "Trained batch 857 batch loss 6.15435314 epoch total loss 6.35043669\n",
      "Trained batch 858 batch loss 6.2088 epoch total loss 6.3502717\n",
      "Trained batch 859 batch loss 6.17220402 epoch total loss 6.35006475\n",
      "Trained batch 860 batch loss 6.11671066 epoch total loss 6.34979343\n",
      "Trained batch 861 batch loss 6.33578634 epoch total loss 6.34977722\n",
      "Trained batch 862 batch loss 6.37615967 epoch total loss 6.34980774\n",
      "Trained batch 863 batch loss 6.50432253 epoch total loss 6.34998655\n",
      "Trained batch 864 batch loss 6.36915493 epoch total loss 6.35000896\n",
      "Trained batch 865 batch loss 6.29089165 epoch total loss 6.34994078\n",
      "Trained batch 866 batch loss 6.42223835 epoch total loss 6.35002422\n",
      "Trained batch 867 batch loss 6.41910076 epoch total loss 6.35010386\n",
      "Trained batch 868 batch loss 6.30940151 epoch total loss 6.35005713\n",
      "Trained batch 869 batch loss 6.3868866 epoch total loss 6.35009956\n",
      "Trained batch 870 batch loss 6.33302402 epoch total loss 6.35007954\n",
      "Trained batch 871 batch loss 6.42559147 epoch total loss 6.3501668\n",
      "Trained batch 872 batch loss 6.69034052 epoch total loss 6.35055685\n",
      "Trained batch 873 batch loss 7.06412029 epoch total loss 6.35137415\n",
      "Trained batch 874 batch loss 6.95564127 epoch total loss 6.35206509\n",
      "Trained batch 875 batch loss 6.25325918 epoch total loss 6.35195255\n",
      "Trained batch 876 batch loss 6.05103827 epoch total loss 6.35160923\n",
      "Trained batch 877 batch loss 6.17900324 epoch total loss 6.35141277\n",
      "Trained batch 878 batch loss 6.40680218 epoch total loss 6.35147572\n",
      "Trained batch 879 batch loss 6.36948109 epoch total loss 6.35149622\n",
      "Trained batch 880 batch loss 6.45720816 epoch total loss 6.35161638\n",
      "Trained batch 881 batch loss 6.4273982 epoch total loss 6.35170221\n",
      "Trained batch 882 batch loss 6.37037182 epoch total loss 6.35172367\n",
      "Trained batch 883 batch loss 6.244699 epoch total loss 6.35160208\n",
      "Trained batch 884 batch loss 6.06964827 epoch total loss 6.35128355\n",
      "Trained batch 885 batch loss 6.2953124 epoch total loss 6.35122061\n",
      "Trained batch 886 batch loss 6.27696562 epoch total loss 6.35113668\n",
      "Trained batch 887 batch loss 6.33052301 epoch total loss 6.35111332\n",
      "Trained batch 888 batch loss 6.30202341 epoch total loss 6.35105848\n",
      "Trained batch 889 batch loss 6.21283531 epoch total loss 6.35090303\n",
      "Trained batch 890 batch loss 6.18892717 epoch total loss 6.35072088\n",
      "Trained batch 891 batch loss 6.26413155 epoch total loss 6.35062361\n",
      "Trained batch 892 batch loss 6.52788496 epoch total loss 6.35082245\n",
      "Trained batch 893 batch loss 6.1474328 epoch total loss 6.35059452\n",
      "Trained batch 894 batch loss 6.78466606 epoch total loss 6.35108042\n",
      "Trained batch 895 batch loss 6.3261981 epoch total loss 6.35105228\n",
      "Trained batch 896 batch loss 6.21717644 epoch total loss 6.35090303\n",
      "Trained batch 897 batch loss 6.11219835 epoch total loss 6.35063696\n",
      "Trained batch 898 batch loss 6.0183444 epoch total loss 6.35026741\n",
      "Trained batch 899 batch loss 6.85396147 epoch total loss 6.35082769\n",
      "Trained batch 900 batch loss 6.6513052 epoch total loss 6.35116148\n",
      "Trained batch 901 batch loss 6.71446323 epoch total loss 6.35156488\n",
      "Trained batch 902 batch loss 6.80577087 epoch total loss 6.35206795\n",
      "Trained batch 903 batch loss 6.79610872 epoch total loss 6.35255957\n",
      "Trained batch 904 batch loss 6.70321178 epoch total loss 6.35294724\n",
      "Trained batch 905 batch loss 6.45323277 epoch total loss 6.35305786\n",
      "Trained batch 906 batch loss 6.8190279 epoch total loss 6.35357237\n",
      "Trained batch 907 batch loss 6.9467454 epoch total loss 6.35422611\n",
      "Trained batch 908 batch loss 6.55088043 epoch total loss 6.3544426\n",
      "Trained batch 909 batch loss 6.7807045 epoch total loss 6.3549118\n",
      "Trained batch 910 batch loss 6.48071909 epoch total loss 6.35505\n",
      "Trained batch 911 batch loss 6.00420475 epoch total loss 6.35466528\n",
      "Trained batch 912 batch loss 6.37206841 epoch total loss 6.35468435\n",
      "Trained batch 913 batch loss 5.83259439 epoch total loss 6.35411263\n",
      "Trained batch 914 batch loss 6.48533726 epoch total loss 6.35425615\n",
      "Trained batch 915 batch loss 6.70933867 epoch total loss 6.3546443\n",
      "Trained batch 916 batch loss 6.56624269 epoch total loss 6.35487556\n",
      "Trained batch 917 batch loss 6.45146847 epoch total loss 6.35498095\n",
      "Trained batch 918 batch loss 6.2612834 epoch total loss 6.3548789\n",
      "Trained batch 919 batch loss 6.38769531 epoch total loss 6.35491467\n",
      "Trained batch 920 batch loss 6.47769594 epoch total loss 6.3550477\n",
      "Trained batch 921 batch loss 6.44664049 epoch total loss 6.35514736\n",
      "Trained batch 922 batch loss 6.59927464 epoch total loss 6.35541201\n",
      "Trained batch 923 batch loss 6.39269638 epoch total loss 6.35545254\n",
      "Trained batch 924 batch loss 6.18487406 epoch total loss 6.355268\n",
      "Trained batch 925 batch loss 6.00518131 epoch total loss 6.35489\n",
      "Trained batch 926 batch loss 5.63551617 epoch total loss 6.3541131\n",
      "Trained batch 927 batch loss 5.65371752 epoch total loss 6.35335779\n",
      "Trained batch 928 batch loss 5.61584711 epoch total loss 6.3525629\n",
      "Trained batch 929 batch loss 6.35286379 epoch total loss 6.35256338\n",
      "Trained batch 930 batch loss 6.65872717 epoch total loss 6.3528924\n",
      "Trained batch 931 batch loss 7.18105268 epoch total loss 6.35378218\n",
      "Trained batch 932 batch loss 6.89571524 epoch total loss 6.35436344\n",
      "Trained batch 933 batch loss 6.41434813 epoch total loss 6.35442781\n",
      "Trained batch 934 batch loss 6.15517 epoch total loss 6.35421467\n",
      "Trained batch 935 batch loss 6.3379612 epoch total loss 6.35419703\n",
      "Trained batch 936 batch loss 6.16493177 epoch total loss 6.35399485\n",
      "Trained batch 937 batch loss 6.11505651 epoch total loss 6.35374\n",
      "Trained batch 938 batch loss 6.22742653 epoch total loss 6.35360575\n",
      "Trained batch 939 batch loss 6.07688427 epoch total loss 6.35331059\n",
      "Trained batch 940 batch loss 5.95597363 epoch total loss 6.35288811\n",
      "Trained batch 941 batch loss 5.91408825 epoch total loss 6.35242176\n",
      "Trained batch 942 batch loss 5.94445467 epoch total loss 6.35198879\n",
      "Trained batch 943 batch loss 6.21554852 epoch total loss 6.35184383\n",
      "Trained batch 944 batch loss 6.26815128 epoch total loss 6.35175514\n",
      "Trained batch 945 batch loss 6.46901655 epoch total loss 6.35187912\n",
      "Trained batch 946 batch loss 6.49720621 epoch total loss 6.35203266\n",
      "Trained batch 947 batch loss 6.33747768 epoch total loss 6.3520174\n",
      "Trained batch 948 batch loss 6.14831829 epoch total loss 6.35180235\n",
      "Trained batch 949 batch loss 6.1947794 epoch total loss 6.35163689\n",
      "Trained batch 950 batch loss 6.39066792 epoch total loss 6.35167837\n",
      "Trained batch 951 batch loss 6.05112028 epoch total loss 6.35136223\n",
      "Trained batch 952 batch loss 6.33612967 epoch total loss 6.35134602\n",
      "Trained batch 953 batch loss 6.36563587 epoch total loss 6.35136127\n",
      "Trained batch 954 batch loss 6.2352066 epoch total loss 6.35123968\n",
      "Trained batch 955 batch loss 6.19291496 epoch total loss 6.35107374\n",
      "Trained batch 956 batch loss 6.04808712 epoch total loss 6.35075665\n",
      "Trained batch 957 batch loss 6.44847584 epoch total loss 6.35085821\n",
      "Trained batch 958 batch loss 6.45915365 epoch total loss 6.35097122\n",
      "Trained batch 959 batch loss 6.48601723 epoch total loss 6.35111189\n",
      "Trained batch 960 batch loss 6.66504335 epoch total loss 6.351439\n",
      "Trained batch 961 batch loss 6.49496937 epoch total loss 6.35158825\n",
      "Trained batch 962 batch loss 6.32737398 epoch total loss 6.35156298\n",
      "Trained batch 963 batch loss 6.12814522 epoch total loss 6.35133076\n",
      "Trained batch 964 batch loss 6.0311718 epoch total loss 6.35099888\n",
      "Trained batch 965 batch loss 6.23357201 epoch total loss 6.35087681\n",
      "Trained batch 966 batch loss 6.7010293 epoch total loss 6.35123968\n",
      "Trained batch 967 batch loss 5.91181183 epoch total loss 6.35078478\n",
      "Trained batch 968 batch loss 6.35285091 epoch total loss 6.35078716\n",
      "Trained batch 969 batch loss 6.66498613 epoch total loss 6.35111141\n",
      "Trained batch 970 batch loss 6.49554539 epoch total loss 6.35126066\n",
      "Trained batch 971 batch loss 6.42066288 epoch total loss 6.35133219\n",
      "Trained batch 972 batch loss 6.00712633 epoch total loss 6.35097837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 973 batch loss 5.99030638 epoch total loss 6.3506074\n",
      "Trained batch 974 batch loss 6.58187771 epoch total loss 6.35084534\n",
      "Trained batch 975 batch loss 6.51541662 epoch total loss 6.35101414\n",
      "Trained batch 976 batch loss 6.43849277 epoch total loss 6.35110378\n",
      "Trained batch 977 batch loss 6.23258066 epoch total loss 6.35098219\n",
      "Trained batch 978 batch loss 6.26639938 epoch total loss 6.35089588\n",
      "Trained batch 979 batch loss 6.41934681 epoch total loss 6.35096598\n",
      "Trained batch 980 batch loss 6.35173368 epoch total loss 6.35096645\n",
      "Trained batch 981 batch loss 6.52868366 epoch total loss 6.35114765\n",
      "Trained batch 982 batch loss 6.44816875 epoch total loss 6.35124683\n",
      "Trained batch 983 batch loss 6.33958435 epoch total loss 6.35123444\n",
      "Trained batch 984 batch loss 5.9845643 epoch total loss 6.35086203\n",
      "Trained batch 985 batch loss 6.00963783 epoch total loss 6.35051537\n",
      "Trained batch 986 batch loss 6.38787317 epoch total loss 6.35055304\n",
      "Trained batch 987 batch loss 6.57311726 epoch total loss 6.35077906\n",
      "Trained batch 988 batch loss 6.44019079 epoch total loss 6.35086966\n",
      "Trained batch 989 batch loss 6.43523455 epoch total loss 6.35095453\n",
      "Trained batch 990 batch loss 6.79506254 epoch total loss 6.35140324\n",
      "Trained batch 991 batch loss 6.2896843 epoch total loss 6.35134077\n",
      "Trained batch 992 batch loss 6.22363806 epoch total loss 6.35121202\n",
      "Trained batch 993 batch loss 6.44409895 epoch total loss 6.35130596\n",
      "Trained batch 994 batch loss 6.18289328 epoch total loss 6.35113668\n",
      "Trained batch 995 batch loss 6.27208805 epoch total loss 6.35105705\n",
      "Trained batch 996 batch loss 5.8868494 epoch total loss 6.35059071\n",
      "Trained batch 997 batch loss 6.41550064 epoch total loss 6.35065603\n",
      "Trained batch 998 batch loss 6.31805372 epoch total loss 6.35062313\n",
      "Trained batch 999 batch loss 6.51933432 epoch total loss 6.35079241\n",
      "Trained batch 1000 batch loss 6.23233271 epoch total loss 6.35067368\n",
      "Trained batch 1001 batch loss 6.23952675 epoch total loss 6.35056305\n",
      "Trained batch 1002 batch loss 6.55013132 epoch total loss 6.35076237\n",
      "Trained batch 1003 batch loss 6.49661922 epoch total loss 6.3509078\n",
      "Trained batch 1004 batch loss 6.43830299 epoch total loss 6.35099506\n",
      "Trained batch 1005 batch loss 6.24533 epoch total loss 6.35088968\n",
      "Trained batch 1006 batch loss 5.78505278 epoch total loss 6.35032701\n",
      "Trained batch 1007 batch loss 6.31771088 epoch total loss 6.35029507\n",
      "Trained batch 1008 batch loss 6.40761089 epoch total loss 6.35035181\n",
      "Trained batch 1009 batch loss 6.28045273 epoch total loss 6.35028267\n",
      "Trained batch 1010 batch loss 6.69762945 epoch total loss 6.35062647\n",
      "Trained batch 1011 batch loss 6.79905272 epoch total loss 6.35107\n",
      "Trained batch 1012 batch loss 7.09007215 epoch total loss 6.3518\n",
      "Trained batch 1013 batch loss 6.89056301 epoch total loss 6.35233164\n",
      "Trained batch 1014 batch loss 6.62686253 epoch total loss 6.35260248\n",
      "Trained batch 1015 batch loss 6.28813553 epoch total loss 6.35253906\n",
      "Trained batch 1016 batch loss 6.02930927 epoch total loss 6.35222101\n",
      "Trained batch 1017 batch loss 5.00416 epoch total loss 6.3508954\n",
      "Trained batch 1018 batch loss 5.39763355 epoch total loss 6.3499589\n",
      "Trained batch 1019 batch loss 5.41887283 epoch total loss 6.34904528\n",
      "Trained batch 1020 batch loss 5.90933323 epoch total loss 6.34861422\n",
      "Trained batch 1021 batch loss 5.89897919 epoch total loss 6.34817362\n",
      "Trained batch 1022 batch loss 6.12552166 epoch total loss 6.3479557\n",
      "Trained batch 1023 batch loss 6.20142508 epoch total loss 6.34781265\n",
      "Trained batch 1024 batch loss 6.08563662 epoch total loss 6.34755659\n",
      "Trained batch 1025 batch loss 6.25077152 epoch total loss 6.34746218\n",
      "Trained batch 1026 batch loss 6.26318932 epoch total loss 6.34738\n",
      "Trained batch 1027 batch loss 6.38026667 epoch total loss 6.34741211\n",
      "Trained batch 1028 batch loss 6.16545486 epoch total loss 6.3472352\n",
      "Trained batch 1029 batch loss 5.81657457 epoch total loss 6.34671974\n",
      "Trained batch 1030 batch loss 5.30716801 epoch total loss 6.34571028\n",
      "Trained batch 1031 batch loss 5.7861867 epoch total loss 6.34516764\n",
      "Trained batch 1032 batch loss 6.27433491 epoch total loss 6.34509897\n",
      "Trained batch 1033 batch loss 5.94079971 epoch total loss 6.34470749\n",
      "Trained batch 1034 batch loss 6.07412815 epoch total loss 6.34444618\n",
      "Trained batch 1035 batch loss 6.26111269 epoch total loss 6.3443656\n",
      "Trained batch 1036 batch loss 6.40416622 epoch total loss 6.34442329\n",
      "Trained batch 1037 batch loss 6.18895054 epoch total loss 6.34427357\n",
      "Trained batch 1038 batch loss 6.154006 epoch total loss 6.34409\n",
      "Trained batch 1039 batch loss 6.85181856 epoch total loss 6.34457922\n",
      "Trained batch 1040 batch loss 7.29301596 epoch total loss 6.34549093\n",
      "Trained batch 1041 batch loss 6.19069338 epoch total loss 6.34534264\n",
      "Trained batch 1042 batch loss 5.39154 epoch total loss 6.34442711\n",
      "Trained batch 1043 batch loss 5.57960415 epoch total loss 6.34369373\n",
      "Trained batch 1044 batch loss 6.15117359 epoch total loss 6.34350967\n",
      "Trained batch 1045 batch loss 6.35299873 epoch total loss 6.34351873\n",
      "Trained batch 1046 batch loss 6.35433149 epoch total loss 6.34352922\n",
      "Trained batch 1047 batch loss 6.22391 epoch total loss 6.34341526\n",
      "Trained batch 1048 batch loss 6.33454466 epoch total loss 6.34340668\n",
      "Trained batch 1049 batch loss 6.24780273 epoch total loss 6.34331512\n",
      "Trained batch 1050 batch loss 6.31562948 epoch total loss 6.3432889\n",
      "Trained batch 1051 batch loss 6.55013657 epoch total loss 6.34348583\n",
      "Trained batch 1052 batch loss 6.0625968 epoch total loss 6.34321833\n",
      "Trained batch 1053 batch loss 6.1107192 epoch total loss 6.34299803\n",
      "Trained batch 1054 batch loss 6.22524166 epoch total loss 6.34288597\n",
      "Trained batch 1055 batch loss 6.23399448 epoch total loss 6.3427825\n",
      "Trained batch 1056 batch loss 6.0508 epoch total loss 6.34250641\n",
      "Trained batch 1057 batch loss 6.60562658 epoch total loss 6.34275484\n",
      "Trained batch 1058 batch loss 7.04153061 epoch total loss 6.34341526\n",
      "Trained batch 1059 batch loss 6.60457706 epoch total loss 6.34366179\n",
      "Trained batch 1060 batch loss 6.03876543 epoch total loss 6.34337425\n",
      "Trained batch 1061 batch loss 6.13817215 epoch total loss 6.34318066\n",
      "Trained batch 1062 batch loss 5.79809618 epoch total loss 6.34266758\n",
      "Trained batch 1063 batch loss 6.34003878 epoch total loss 6.3426652\n",
      "Trained batch 1064 batch loss 6.30612755 epoch total loss 6.34263086\n",
      "Trained batch 1065 batch loss 6.6111517 epoch total loss 6.34288311\n",
      "Trained batch 1066 batch loss 6.56098557 epoch total loss 6.34308767\n",
      "Trained batch 1067 batch loss 6.3588295 epoch total loss 6.34310246\n",
      "Trained batch 1068 batch loss 6.37932587 epoch total loss 6.34313631\n",
      "Trained batch 1069 batch loss 6.48115492 epoch total loss 6.34326553\n",
      "Trained batch 1070 batch loss 6.52329779 epoch total loss 6.34343386\n",
      "Trained batch 1071 batch loss 6.62933397 epoch total loss 6.34370089\n",
      "Trained batch 1072 batch loss 6.45231485 epoch total loss 6.34380198\n",
      "Trained batch 1073 batch loss 6.46877956 epoch total loss 6.34391832\n",
      "Trained batch 1074 batch loss 6.69642735 epoch total loss 6.34424639\n",
      "Trained batch 1075 batch loss 6.83973598 epoch total loss 6.34470749\n",
      "Trained batch 1076 batch loss 6.76289511 epoch total loss 6.34509611\n",
      "Trained batch 1077 batch loss 6.75304127 epoch total loss 6.34547472\n",
      "Trained batch 1078 batch loss 6.94001389 epoch total loss 6.34602594\n",
      "Trained batch 1079 batch loss 6.66598749 epoch total loss 6.34632254\n",
      "Trained batch 1080 batch loss 6.69711685 epoch total loss 6.34664774\n",
      "Trained batch 1081 batch loss 6.66705465 epoch total loss 6.34694386\n",
      "Trained batch 1082 batch loss 6.53123569 epoch total loss 6.34711409\n",
      "Trained batch 1083 batch loss 6.6490078 epoch total loss 6.34739304\n",
      "Trained batch 1084 batch loss 6.37546062 epoch total loss 6.34741879\n",
      "Trained batch 1085 batch loss 6.35874414 epoch total loss 6.34742928\n",
      "Trained batch 1086 batch loss 5.99147415 epoch total loss 6.34710169\n",
      "Trained batch 1087 batch loss 6.30377817 epoch total loss 6.34706211\n",
      "Trained batch 1088 batch loss 6.4956665 epoch total loss 6.34719849\n",
      "Trained batch 1089 batch loss 5.97444582 epoch total loss 6.34685612\n",
      "Trained batch 1090 batch loss 6.01187372 epoch total loss 6.34654903\n",
      "Trained batch 1091 batch loss 6.2189517 epoch total loss 6.34643173\n",
      "Trained batch 1092 batch loss 6.11699247 epoch total loss 6.34622192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1093 batch loss 6.49704313 epoch total loss 6.34635973\n",
      "Trained batch 1094 batch loss 6.36316538 epoch total loss 6.34637547\n",
      "Trained batch 1095 batch loss 6.68535185 epoch total loss 6.34668493\n",
      "Trained batch 1096 batch loss 6.52765465 epoch total loss 6.3468504\n",
      "Trained batch 1097 batch loss 6.17770433 epoch total loss 6.34669638\n",
      "Trained batch 1098 batch loss 6.26469326 epoch total loss 6.34662151\n",
      "Trained batch 1099 batch loss 6.27779 epoch total loss 6.34655905\n",
      "Trained batch 1100 batch loss 6.89107227 epoch total loss 6.347054\n",
      "Trained batch 1101 batch loss 6.21753931 epoch total loss 6.3469367\n",
      "Trained batch 1102 batch loss 6.58417463 epoch total loss 6.34715176\n",
      "Trained batch 1103 batch loss 6.60392952 epoch total loss 6.34738445\n",
      "Trained batch 1104 batch loss 5.9794631 epoch total loss 6.34705114\n",
      "Trained batch 1105 batch loss 6.09111786 epoch total loss 6.34682\n",
      "Trained batch 1106 batch loss 6.33296394 epoch total loss 6.34680748\n",
      "Trained batch 1107 batch loss 6.50647497 epoch total loss 6.34695148\n",
      "Trained batch 1108 batch loss 6.51994848 epoch total loss 6.34710741\n",
      "Trained batch 1109 batch loss 6.26988554 epoch total loss 6.34703827\n",
      "Trained batch 1110 batch loss 6.32008076 epoch total loss 6.34701395\n",
      "Trained batch 1111 batch loss 6.25529909 epoch total loss 6.34693146\n",
      "Trained batch 1112 batch loss 6.46206331 epoch total loss 6.34703493\n",
      "Trained batch 1113 batch loss 6.87258959 epoch total loss 6.347507\n",
      "Trained batch 1114 batch loss 6.69333124 epoch total loss 6.34781742\n",
      "Trained batch 1115 batch loss 6.57443476 epoch total loss 6.34802055\n",
      "Trained batch 1116 batch loss 6.39725065 epoch total loss 6.3480649\n",
      "Trained batch 1117 batch loss 6.65525961 epoch total loss 6.34834\n",
      "Trained batch 1118 batch loss 6.53307629 epoch total loss 6.3485055\n",
      "Trained batch 1119 batch loss 6.65359735 epoch total loss 6.34877825\n",
      "Trained batch 1120 batch loss 6.48386288 epoch total loss 6.34889889\n",
      "Trained batch 1121 batch loss 6.40171862 epoch total loss 6.34894609\n",
      "Trained batch 1122 batch loss 6.53666878 epoch total loss 6.34911346\n",
      "Trained batch 1123 batch loss 6.8161149 epoch total loss 6.34952879\n",
      "Trained batch 1124 batch loss 6.36921024 epoch total loss 6.34954643\n",
      "Trained batch 1125 batch loss 6.07948971 epoch total loss 6.34930658\n",
      "Trained batch 1126 batch loss 6.53394556 epoch total loss 6.34947062\n",
      "Trained batch 1127 batch loss 6.76200294 epoch total loss 6.34983683\n",
      "Trained batch 1128 batch loss 6.58418417 epoch total loss 6.35004425\n",
      "Trained batch 1129 batch loss 6.61546183 epoch total loss 6.35027933\n",
      "Trained batch 1130 batch loss 6.4073782 epoch total loss 6.35033\n",
      "Trained batch 1131 batch loss 7.1310153 epoch total loss 6.35102\n",
      "Trained batch 1132 batch loss 6.97198105 epoch total loss 6.3515687\n",
      "Trained batch 1133 batch loss 7.16451359 epoch total loss 6.35228586\n",
      "Trained batch 1134 batch loss 6.8615613 epoch total loss 6.35273504\n",
      "Trained batch 1135 batch loss 6.77522755 epoch total loss 6.35310745\n",
      "Trained batch 1136 batch loss 6.69369125 epoch total loss 6.35340738\n",
      "Trained batch 1137 batch loss 5.72878313 epoch total loss 6.35285807\n",
      "Trained batch 1138 batch loss 6.01824951 epoch total loss 6.35256386\n",
      "Trained batch 1139 batch loss 6.67048025 epoch total loss 6.35284281\n",
      "Trained batch 1140 batch loss 6.73355 epoch total loss 6.35317659\n",
      "Trained batch 1141 batch loss 6.39499474 epoch total loss 6.35321331\n",
      "Trained batch 1142 batch loss 6.16608191 epoch total loss 6.35304976\n",
      "Trained batch 1143 batch loss 6.43420362 epoch total loss 6.35312033\n",
      "Trained batch 1144 batch loss 6.33348656 epoch total loss 6.35310316\n",
      "Trained batch 1145 batch loss 5.88408613 epoch total loss 6.35269403\n",
      "Trained batch 1146 batch loss 6.33448219 epoch total loss 6.35267782\n",
      "Trained batch 1147 batch loss 6.05002213 epoch total loss 6.35241413\n",
      "Trained batch 1148 batch loss 6.5435276 epoch total loss 6.35258055\n",
      "Trained batch 1149 batch loss 6.37879944 epoch total loss 6.35260344\n",
      "Trained batch 1150 batch loss 6.40666389 epoch total loss 6.35265\n",
      "Trained batch 1151 batch loss 6.45435238 epoch total loss 6.35273886\n",
      "Trained batch 1152 batch loss 6.12385178 epoch total loss 6.35254049\n",
      "Trained batch 1153 batch loss 6.34224415 epoch total loss 6.35253143\n",
      "Trained batch 1154 batch loss 6.75575924 epoch total loss 6.35288095\n",
      "Trained batch 1155 batch loss 6.69895697 epoch total loss 6.35318041\n",
      "Trained batch 1156 batch loss 6.54982138 epoch total loss 6.35335064\n",
      "Trained batch 1157 batch loss 6.22066402 epoch total loss 6.35323572\n",
      "Trained batch 1158 batch loss 6.63296127 epoch total loss 6.35347748\n",
      "Trained batch 1159 batch loss 6.43318033 epoch total loss 6.35354614\n",
      "Trained batch 1160 batch loss 6.39391947 epoch total loss 6.35358095\n",
      "Trained batch 1161 batch loss 5.98092079 epoch total loss 6.35326\n",
      "Trained batch 1162 batch loss 5.56239319 epoch total loss 6.35257959\n",
      "Trained batch 1163 batch loss 5.82145 epoch total loss 6.35212278\n",
      "Trained batch 1164 batch loss 6.15982628 epoch total loss 6.35195732\n",
      "Trained batch 1165 batch loss 5.87344885 epoch total loss 6.35154676\n",
      "Trained batch 1166 batch loss 6.50710154 epoch total loss 6.35168028\n",
      "Trained batch 1167 batch loss 6.57036304 epoch total loss 6.35186768\n",
      "Trained batch 1168 batch loss 6.55639 epoch total loss 6.3520422\n",
      "Trained batch 1169 batch loss 5.59935951 epoch total loss 6.35139847\n",
      "Trained batch 1170 batch loss 6.09351826 epoch total loss 6.35117817\n",
      "Trained batch 1171 batch loss 6.45971584 epoch total loss 6.35127068\n",
      "Trained batch 1172 batch loss 6.72962713 epoch total loss 6.35159349\n",
      "Trained batch 1173 batch loss 6.46916533 epoch total loss 6.35169363\n",
      "Trained batch 1174 batch loss 6.2556448 epoch total loss 6.35161209\n",
      "Trained batch 1175 batch loss 6.47261763 epoch total loss 6.35171509\n",
      "Trained batch 1176 batch loss 6.30873 epoch total loss 6.35167837\n",
      "Trained batch 1177 batch loss 6.8017807 epoch total loss 6.35206079\n",
      "Trained batch 1178 batch loss 6.04314756 epoch total loss 6.35179853\n",
      "Trained batch 1179 batch loss 6.11695385 epoch total loss 6.35159922\n",
      "Trained batch 1180 batch loss 5.72233582 epoch total loss 6.35106611\n",
      "Trained batch 1181 batch loss 6.0617013 epoch total loss 6.35082054\n",
      "Trained batch 1182 batch loss 6.37799549 epoch total loss 6.35084391\n",
      "Trained batch 1183 batch loss 6.08069515 epoch total loss 6.35061502\n",
      "Trained batch 1184 batch loss 6.4092927 epoch total loss 6.35066462\n",
      "Trained batch 1185 batch loss 6.57322168 epoch total loss 6.35085249\n",
      "Trained batch 1186 batch loss 6.43996 epoch total loss 6.35092783\n",
      "Trained batch 1187 batch loss 6.3225069 epoch total loss 6.35090351\n",
      "Trained batch 1188 batch loss 6.43106079 epoch total loss 6.35097122\n",
      "Trained batch 1189 batch loss 6.2792964 epoch total loss 6.35091066\n",
      "Trained batch 1190 batch loss 6.21169 epoch total loss 6.35079384\n",
      "Trained batch 1191 batch loss 6.22764874 epoch total loss 6.35069036\n",
      "Trained batch 1192 batch loss 6.7136631 epoch total loss 6.35099506\n",
      "Trained batch 1193 batch loss 6.52421284 epoch total loss 6.3511405\n",
      "Trained batch 1194 batch loss 6.46993923 epoch total loss 6.35123968\n",
      "Trained batch 1195 batch loss 6.43232489 epoch total loss 6.35130739\n",
      "Trained batch 1196 batch loss 6.14664745 epoch total loss 6.35113621\n",
      "Trained batch 1197 batch loss 6.25227165 epoch total loss 6.35105371\n",
      "Trained batch 1198 batch loss 6.3120985 epoch total loss 6.35102129\n",
      "Trained batch 1199 batch loss 6.170228 epoch total loss 6.35087061\n",
      "Trained batch 1200 batch loss 6.24393082 epoch total loss 6.35078144\n",
      "Trained batch 1201 batch loss 6.1983943 epoch total loss 6.3506546\n",
      "Trained batch 1202 batch loss 6.34963751 epoch total loss 6.35065365\n",
      "Trained batch 1203 batch loss 6.19007683 epoch total loss 6.35052\n",
      "Trained batch 1204 batch loss 6.46089363 epoch total loss 6.35061169\n",
      "Trained batch 1205 batch loss 6.5897789 epoch total loss 6.35081053\n",
      "Trained batch 1206 batch loss 6.82054138 epoch total loss 6.35119963\n",
      "Trained batch 1207 batch loss 6.70017052 epoch total loss 6.35148907\n",
      "Trained batch 1208 batch loss 6.886415 epoch total loss 6.35193157\n",
      "Trained batch 1209 batch loss 6.24440384 epoch total loss 6.35184288\n",
      "Trained batch 1210 batch loss 5.82100296 epoch total loss 6.35140371\n",
      "Trained batch 1211 batch loss 5.63532972 epoch total loss 6.35081244\n",
      "Trained batch 1212 batch loss 6.45453119 epoch total loss 6.35089827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1213 batch loss 6.66940308 epoch total loss 6.351161\n",
      "Trained batch 1214 batch loss 6.48102236 epoch total loss 6.35126781\n",
      "Trained batch 1215 batch loss 6.33894634 epoch total loss 6.35125732\n",
      "Trained batch 1216 batch loss 6.16417742 epoch total loss 6.35110331\n",
      "Trained batch 1217 batch loss 5.86501884 epoch total loss 6.35070419\n",
      "Trained batch 1218 batch loss 6.39694166 epoch total loss 6.35074234\n",
      "Trained batch 1219 batch loss 6.07094622 epoch total loss 6.3505125\n",
      "Trained batch 1220 batch loss 6.34409285 epoch total loss 6.35050726\n",
      "Trained batch 1221 batch loss 5.9782505 epoch total loss 6.35020256\n",
      "Trained batch 1222 batch loss 6.35299063 epoch total loss 6.35020494\n",
      "Trained batch 1223 batch loss 6.23764658 epoch total loss 6.35011292\n",
      "Trained batch 1224 batch loss 6.35775471 epoch total loss 6.35011911\n",
      "Trained batch 1225 batch loss 6.69474792 epoch total loss 6.35040045\n",
      "Trained batch 1226 batch loss 6.51175642 epoch total loss 6.35053205\n",
      "Trained batch 1227 batch loss 5.99259186 epoch total loss 6.35024071\n",
      "Trained batch 1228 batch loss 6.2003 epoch total loss 6.35011816\n",
      "Trained batch 1229 batch loss 6.66632843 epoch total loss 6.35037565\n",
      "Trained batch 1230 batch loss 6.34725332 epoch total loss 6.35037327\n",
      "Trained batch 1231 batch loss 6.55598736 epoch total loss 6.35054\n",
      "Trained batch 1232 batch loss 6.50354719 epoch total loss 6.35066462\n",
      "Trained batch 1233 batch loss 6.17737579 epoch total loss 6.35052395\n",
      "Trained batch 1234 batch loss 6.02470684 epoch total loss 6.35026\n",
      "Trained batch 1235 batch loss 6.39292574 epoch total loss 6.35029459\n",
      "Trained batch 1236 batch loss 6.04110813 epoch total loss 6.35004425\n",
      "Trained batch 1237 batch loss 5.51124668 epoch total loss 6.34936619\n",
      "Trained batch 1238 batch loss 6.25779 epoch total loss 6.34929228\n",
      "Trained batch 1239 batch loss 6.04105902 epoch total loss 6.34904337\n",
      "Trained batch 1240 batch loss 5.70683861 epoch total loss 6.34852552\n",
      "Trained batch 1241 batch loss 5.64827728 epoch total loss 6.34796143\n",
      "Trained batch 1242 batch loss 5.99842691 epoch total loss 6.34768\n",
      "Trained batch 1243 batch loss 5.74747658 epoch total loss 6.34719753\n",
      "Trained batch 1244 batch loss 6.10792542 epoch total loss 6.34700489\n",
      "Trained batch 1245 batch loss 6.33815908 epoch total loss 6.34699821\n",
      "Trained batch 1246 batch loss 6.50594044 epoch total loss 6.34712553\n",
      "Trained batch 1247 batch loss 6.5902257 epoch total loss 6.34732056\n",
      "Trained batch 1248 batch loss 6.21920204 epoch total loss 6.34721804\n",
      "Trained batch 1249 batch loss 6.34003687 epoch total loss 6.34721231\n",
      "Trained batch 1250 batch loss 6.31643534 epoch total loss 6.34718752\n",
      "Trained batch 1251 batch loss 5.64800024 epoch total loss 6.34662867\n",
      "Trained batch 1252 batch loss 6.03734159 epoch total loss 6.34638119\n",
      "Trained batch 1253 batch loss 6.35935211 epoch total loss 6.34639168\n",
      "Trained batch 1254 batch loss 6.45449686 epoch total loss 6.34647799\n",
      "Trained batch 1255 batch loss 6.42410088 epoch total loss 6.34654\n",
      "Trained batch 1256 batch loss 6.39302301 epoch total loss 6.34657717\n",
      "Trained batch 1257 batch loss 6.45765877 epoch total loss 6.34666538\n",
      "Trained batch 1258 batch loss 6.44238806 epoch total loss 6.3467412\n",
      "Trained batch 1259 batch loss 6.17891788 epoch total loss 6.34660816\n",
      "Trained batch 1260 batch loss 6.20879364 epoch total loss 6.34649849\n",
      "Trained batch 1261 batch loss 6.0644865 epoch total loss 6.34627485\n",
      "Trained batch 1262 batch loss 6.19157505 epoch total loss 6.34615231\n",
      "Trained batch 1263 batch loss 6.4319768 epoch total loss 6.34622049\n",
      "Trained batch 1264 batch loss 6.41660213 epoch total loss 6.34627581\n",
      "Trained batch 1265 batch loss 6.35861254 epoch total loss 6.34628582\n",
      "Trained batch 1266 batch loss 6.2824173 epoch total loss 6.3462348\n",
      "Trained batch 1267 batch loss 6.18968105 epoch total loss 6.3461113\n",
      "Trained batch 1268 batch loss 6.40845203 epoch total loss 6.34616041\n",
      "Trained batch 1269 batch loss 6.56668186 epoch total loss 6.34633446\n",
      "Trained batch 1270 batch loss 6.2654829 epoch total loss 6.34627104\n",
      "Trained batch 1271 batch loss 6.09985113 epoch total loss 6.34607697\n",
      "Trained batch 1272 batch loss 6.01526928 epoch total loss 6.34581661\n",
      "Trained batch 1273 batch loss 6.36071348 epoch total loss 6.34582853\n",
      "Trained batch 1274 batch loss 5.97683764 epoch total loss 6.34553909\n",
      "Trained batch 1275 batch loss 6.61070633 epoch total loss 6.34574699\n",
      "Trained batch 1276 batch loss 6.23168612 epoch total loss 6.34565783\n",
      "Trained batch 1277 batch loss 6.11323929 epoch total loss 6.34547567\n",
      "Trained batch 1278 batch loss 6.24902725 epoch total loss 6.34540033\n",
      "Trained batch 1279 batch loss 5.97471285 epoch total loss 6.34511042\n",
      "Trained batch 1280 batch loss 5.8979578 epoch total loss 6.34476089\n",
      "Trained batch 1281 batch loss 6.25958061 epoch total loss 6.34469461\n",
      "Trained batch 1282 batch loss 6.68854284 epoch total loss 6.3449626\n",
      "Trained batch 1283 batch loss 6.45546293 epoch total loss 6.3450489\n",
      "Trained batch 1284 batch loss 6.05722427 epoch total loss 6.34482479\n",
      "Trained batch 1285 batch loss 6.41749191 epoch total loss 6.34488106\n",
      "Trained batch 1286 batch loss 6.56164122 epoch total loss 6.34505\n",
      "Trained batch 1287 batch loss 6.21536732 epoch total loss 6.34494877\n",
      "Trained batch 1288 batch loss 6.54735231 epoch total loss 6.34510612\n",
      "Trained batch 1289 batch loss 6.39445114 epoch total loss 6.34514427\n",
      "Trained batch 1290 batch loss 6.13813686 epoch total loss 6.34498405\n",
      "Trained batch 1291 batch loss 6.20502806 epoch total loss 6.34487581\n",
      "Trained batch 1292 batch loss 6.18003225 epoch total loss 6.34474754\n",
      "Trained batch 1293 batch loss 6.17710304 epoch total loss 6.34461784\n",
      "Trained batch 1294 batch loss 6.64285374 epoch total loss 6.34484816\n",
      "Trained batch 1295 batch loss 6.61701775 epoch total loss 6.34505844\n",
      "Trained batch 1296 batch loss 6.57560968 epoch total loss 6.34523582\n",
      "Trained batch 1297 batch loss 6.07069731 epoch total loss 6.34502411\n",
      "Trained batch 1298 batch loss 6.28419781 epoch total loss 6.3449769\n",
      "Trained batch 1299 batch loss 6.51988697 epoch total loss 6.34511137\n",
      "Trained batch 1300 batch loss 6.78453779 epoch total loss 6.34544945\n",
      "Trained batch 1301 batch loss 6.32149553 epoch total loss 6.34543085\n",
      "Trained batch 1302 batch loss 6.19122458 epoch total loss 6.34531212\n",
      "Trained batch 1303 batch loss 6.28982449 epoch total loss 6.34527\n",
      "Trained batch 1304 batch loss 6.4715476 epoch total loss 6.34536695\n",
      "Trained batch 1305 batch loss 6.35672045 epoch total loss 6.34537554\n",
      "Trained batch 1306 batch loss 6.36951208 epoch total loss 6.34539366\n",
      "Trained batch 1307 batch loss 6.17892218 epoch total loss 6.34526587\n",
      "Trained batch 1308 batch loss 6.37302923 epoch total loss 6.34528732\n",
      "Trained batch 1309 batch loss 6.23919487 epoch total loss 6.34520626\n",
      "Trained batch 1310 batch loss 6.52863503 epoch total loss 6.34534597\n",
      "Trained batch 1311 batch loss 6.45065975 epoch total loss 6.34542608\n",
      "Trained batch 1312 batch loss 6.45886612 epoch total loss 6.34551239\n",
      "Trained batch 1313 batch loss 6.14629126 epoch total loss 6.34536076\n",
      "Trained batch 1314 batch loss 6.27270174 epoch total loss 6.34530544\n",
      "Trained batch 1315 batch loss 6.59642124 epoch total loss 6.34549665\n",
      "Trained batch 1316 batch loss 6.51264095 epoch total loss 6.34562349\n",
      "Trained batch 1317 batch loss 6.66731787 epoch total loss 6.34586763\n",
      "Trained batch 1318 batch loss 6.74593782 epoch total loss 6.34617138\n",
      "Trained batch 1319 batch loss 6.23682499 epoch total loss 6.34608889\n",
      "Trained batch 1320 batch loss 6.32988834 epoch total loss 6.34607697\n",
      "Trained batch 1321 batch loss 6.82454157 epoch total loss 6.34643888\n",
      "Trained batch 1322 batch loss 6.47721291 epoch total loss 6.34653807\n",
      "Trained batch 1323 batch loss 6.92424965 epoch total loss 6.34697437\n",
      "Trained batch 1324 batch loss 6.50179148 epoch total loss 6.3470912\n",
      "Trained batch 1325 batch loss 6.53379345 epoch total loss 6.34723234\n",
      "Trained batch 1326 batch loss 6.58429289 epoch total loss 6.34741116\n",
      "Trained batch 1327 batch loss 6.19568348 epoch total loss 6.34729624\n",
      "Trained batch 1328 batch loss 6.18472195 epoch total loss 6.34717369\n",
      "Trained batch 1329 batch loss 6.16153526 epoch total loss 6.34703398\n",
      "Trained batch 1330 batch loss 6.06576109 epoch total loss 6.34682226\n",
      "Trained batch 1331 batch loss 6.40487194 epoch total loss 6.34686613\n",
      "Trained batch 1332 batch loss 6.39363098 epoch total loss 6.34690094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1333 batch loss 6.05197048 epoch total loss 6.34667969\n",
      "Trained batch 1334 batch loss 6.29816628 epoch total loss 6.34664297\n",
      "Trained batch 1335 batch loss 6.62525034 epoch total loss 6.34685183\n",
      "Trained batch 1336 batch loss 6.4482131 epoch total loss 6.34692764\n",
      "Trained batch 1337 batch loss 6.51951647 epoch total loss 6.34705639\n",
      "Trained batch 1338 batch loss 6.806952 epoch total loss 6.3474\n",
      "Trained batch 1339 batch loss 6.45351076 epoch total loss 6.34747887\n",
      "Trained batch 1340 batch loss 6.7364831 epoch total loss 6.34776926\n",
      "Trained batch 1341 batch loss 6.4726181 epoch total loss 6.34786224\n",
      "Trained batch 1342 batch loss 6.14458 epoch total loss 6.34771061\n",
      "Trained batch 1343 batch loss 6.06374121 epoch total loss 6.34749937\n",
      "Trained batch 1344 batch loss 6.16707945 epoch total loss 6.3473649\n",
      "Trained batch 1345 batch loss 6.76348352 epoch total loss 6.34767437\n",
      "Trained batch 1346 batch loss 7.30502319 epoch total loss 6.34838533\n",
      "Trained batch 1347 batch loss 6.65915489 epoch total loss 6.34861612\n",
      "Trained batch 1348 batch loss 6.14900637 epoch total loss 6.3484683\n",
      "Trained batch 1349 batch loss 6.59666395 epoch total loss 6.34865236\n",
      "Trained batch 1350 batch loss 6.44625568 epoch total loss 6.34872484\n",
      "Trained batch 1351 batch loss 6.02503538 epoch total loss 6.34848547\n",
      "Trained batch 1352 batch loss 6.21402121 epoch total loss 6.34838581\n",
      "Trained batch 1353 batch loss 6.05573654 epoch total loss 6.34816933\n",
      "Trained batch 1354 batch loss 6.32280779 epoch total loss 6.34815121\n",
      "Trained batch 1355 batch loss 6.57145786 epoch total loss 6.34831572\n",
      "Trained batch 1356 batch loss 6.50921535 epoch total loss 6.34843397\n",
      "Trained batch 1357 batch loss 6.56810427 epoch total loss 6.3485961\n",
      "Trained batch 1358 batch loss 6.35965919 epoch total loss 6.3486042\n",
      "Trained batch 1359 batch loss 6.32447338 epoch total loss 6.34858608\n",
      "Trained batch 1360 batch loss 6.43142128 epoch total loss 6.34864712\n",
      "Trained batch 1361 batch loss 6.48593903 epoch total loss 6.34874821\n",
      "Trained batch 1362 batch loss 6.31381607 epoch total loss 6.34872246\n",
      "Trained batch 1363 batch loss 6.12799358 epoch total loss 6.34856033\n",
      "Trained batch 1364 batch loss 6.38818455 epoch total loss 6.34859\n",
      "Trained batch 1365 batch loss 6.1333971 epoch total loss 6.34843254\n",
      "Trained batch 1366 batch loss 5.81525087 epoch total loss 6.34804249\n",
      "Trained batch 1367 batch loss 6.34367132 epoch total loss 6.34803915\n",
      "Trained batch 1368 batch loss 6.12924767 epoch total loss 6.34787893\n",
      "Trained batch 1369 batch loss 6.14266109 epoch total loss 6.34772921\n",
      "Trained batch 1370 batch loss 6.45437193 epoch total loss 6.34780645\n",
      "Trained batch 1371 batch loss 6.62663269 epoch total loss 6.34801\n",
      "Trained batch 1372 batch loss 6.53596067 epoch total loss 6.34814739\n",
      "Trained batch 1373 batch loss 6.55813837 epoch total loss 6.34830046\n",
      "Trained batch 1374 batch loss 6.33674 epoch total loss 6.34829235\n",
      "Trained batch 1375 batch loss 6.17371225 epoch total loss 6.34816551\n",
      "Trained batch 1376 batch loss 6.72894478 epoch total loss 6.34844208\n",
      "Trained batch 1377 batch loss 6.55268574 epoch total loss 6.34859037\n",
      "Trained batch 1378 batch loss 6.41685629 epoch total loss 6.34864\n",
      "Trained batch 1379 batch loss 6.27784 epoch total loss 6.34858894\n",
      "Trained batch 1380 batch loss 6.4295435 epoch total loss 6.34864759\n",
      "Trained batch 1381 batch loss 5.96372 epoch total loss 6.34836912\n",
      "Trained batch 1382 batch loss 5.63899803 epoch total loss 6.34785557\n",
      "Trained batch 1383 batch loss 6.30042171 epoch total loss 6.34782171\n",
      "Trained batch 1384 batch loss 6.41584873 epoch total loss 6.34787083\n",
      "Trained batch 1385 batch loss 6.41459751 epoch total loss 6.34791946\n",
      "Trained batch 1386 batch loss 6.40614128 epoch total loss 6.34796143\n",
      "Trained batch 1387 batch loss 6.27419615 epoch total loss 6.3479085\n",
      "Trained batch 1388 batch loss 5.99714756 epoch total loss 6.34765577\n",
      "Epoch 4 train loss 6.347655773162842\n",
      "Validated batch 1 batch loss 6.55179691\n",
      "Validated batch 2 batch loss 6.29641\n",
      "Validated batch 3 batch loss 6.12648773\n",
      "Validated batch 4 batch loss 5.94952393\n",
      "Validated batch 5 batch loss 6.25816917\n",
      "Validated batch 6 batch loss 6.21144\n",
      "Validated batch 7 batch loss 6.21583748\n",
      "Validated batch 8 batch loss 6.36002493\n",
      "Validated batch 9 batch loss 6.43167305\n",
      "Validated batch 10 batch loss 6.14981651\n",
      "Validated batch 11 batch loss 6.30602694\n",
      "Validated batch 12 batch loss 5.7593646\n",
      "Validated batch 13 batch loss 6.75016785\n",
      "Validated batch 14 batch loss 6.13165236\n",
      "Validated batch 15 batch loss 6.19036198\n",
      "Validated batch 16 batch loss 6.44368\n",
      "Validated batch 17 batch loss 6.31572628\n",
      "Validated batch 18 batch loss 5.69256592\n",
      "Validated batch 19 batch loss 6.0302248\n",
      "Validated batch 20 batch loss 6.29055882\n",
      "Validated batch 21 batch loss 6.0798912\n",
      "Validated batch 22 batch loss 6.32720613\n",
      "Validated batch 23 batch loss 6.37614584\n",
      "Validated batch 24 batch loss 6.87051916\n",
      "Validated batch 25 batch loss 6.51691\n",
      "Validated batch 26 batch loss 6.35657597\n",
      "Validated batch 27 batch loss 6.2946558\n",
      "Validated batch 28 batch loss 6.31233311\n",
      "Validated batch 29 batch loss 6.40949583\n",
      "Validated batch 30 batch loss 6.40021944\n",
      "Validated batch 31 batch loss 5.99065447\n",
      "Validated batch 32 batch loss 6.24107599\n",
      "Validated batch 33 batch loss 6.20875\n",
      "Validated batch 34 batch loss 6.28084755\n",
      "Validated batch 35 batch loss 6.10356951\n",
      "Validated batch 36 batch loss 6.20691204\n",
      "Validated batch 37 batch loss 6.08093071\n",
      "Validated batch 38 batch loss 6.26497364\n",
      "Validated batch 39 batch loss 6.35338116\n",
      "Validated batch 40 batch loss 6.55519962\n",
      "Validated batch 41 batch loss 6.56558466\n",
      "Validated batch 42 batch loss 6.97987556\n",
      "Validated batch 43 batch loss 7.24249029\n",
      "Validated batch 44 batch loss 6.63198137\n",
      "Validated batch 45 batch loss 6.32257557\n",
      "Validated batch 46 batch loss 5.97526073\n",
      "Validated batch 47 batch loss 5.87500525\n",
      "Validated batch 48 batch loss 6.66734791\n",
      "Validated batch 49 batch loss 6.33939075\n",
      "Validated batch 50 batch loss 6.48784304\n",
      "Validated batch 51 batch loss 6.44086695\n",
      "Validated batch 52 batch loss 6.68999052\n",
      "Validated batch 53 batch loss 6.17581272\n",
      "Validated batch 54 batch loss 6.63647127\n",
      "Validated batch 55 batch loss 6.10785437\n",
      "Validated batch 56 batch loss 6.48637581\n",
      "Validated batch 57 batch loss 6.44434452\n",
      "Validated batch 58 batch loss 5.87971067\n",
      "Validated batch 59 batch loss 5.7165761\n",
      "Validated batch 60 batch loss 6.48162842\n",
      "Validated batch 61 batch loss 6.45903349\n",
      "Validated batch 62 batch loss 6.11605883\n",
      "Validated batch 63 batch loss 6.46263695\n",
      "Validated batch 64 batch loss 6.44203615\n",
      "Validated batch 65 batch loss 6.41276741\n",
      "Validated batch 66 batch loss 6.52229834\n",
      "Validated batch 67 batch loss 6.43274403\n",
      "Validated batch 68 batch loss 6.23895311\n",
      "Validated batch 69 batch loss 6.0045619\n",
      "Validated batch 70 batch loss 6.22687197\n",
      "Validated batch 71 batch loss 6.92263556\n",
      "Validated batch 72 batch loss 6.16318369\n",
      "Validated batch 73 batch loss 5.76226234\n",
      "Validated batch 74 batch loss 6.42953968\n",
      "Validated batch 75 batch loss 6.19033909\n",
      "Validated batch 76 batch loss 5.91765547\n",
      "Validated batch 77 batch loss 6.10046196\n",
      "Validated batch 78 batch loss 5.89601946\n",
      "Validated batch 79 batch loss 6.58251\n",
      "Validated batch 80 batch loss 5.96827793\n",
      "Validated batch 81 batch loss 5.89331198\n",
      "Validated batch 82 batch loss 6.27398825\n",
      "Validated batch 83 batch loss 6.46747971\n",
      "Validated batch 84 batch loss 6.02122688\n",
      "Validated batch 85 batch loss 6.28228235\n",
      "Validated batch 86 batch loss 6.23163271\n",
      "Validated batch 87 batch loss 6.48731422\n",
      "Validated batch 88 batch loss 6.15728188\n",
      "Validated batch 89 batch loss 6.36200476\n",
      "Validated batch 90 batch loss 6.54346943\n",
      "Validated batch 91 batch loss 5.43855095\n",
      "Validated batch 92 batch loss 6.67345953\n",
      "Validated batch 93 batch loss 6.47742462\n",
      "Validated batch 94 batch loss 6.21609306\n",
      "Validated batch 95 batch loss 6.1452322\n",
      "Validated batch 96 batch loss 6.10418272\n",
      "Validated batch 97 batch loss 6.46678\n",
      "Validated batch 98 batch loss 6.30046654\n",
      "Validated batch 99 batch loss 6.34467\n",
      "Validated batch 100 batch loss 6.29309\n",
      "Validated batch 101 batch loss 6.1206789\n",
      "Validated batch 102 batch loss 6.42818213\n",
      "Validated batch 103 batch loss 6.78376055\n",
      "Validated batch 104 batch loss 6.45568275\n",
      "Validated batch 105 batch loss 6.35653782\n",
      "Validated batch 106 batch loss 6.23002958\n",
      "Validated batch 107 batch loss 6.45244789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 108 batch loss 6.1907692\n",
      "Validated batch 109 batch loss 6.63093138\n",
      "Validated batch 110 batch loss 6.0861125\n",
      "Validated batch 111 batch loss 6.27788067\n",
      "Validated batch 112 batch loss 6.27706337\n",
      "Validated batch 113 batch loss 6.15452051\n",
      "Validated batch 114 batch loss 6.49825716\n",
      "Validated batch 115 batch loss 6.48344326\n",
      "Validated batch 116 batch loss 6.34803104\n",
      "Validated batch 117 batch loss 6.39165497\n",
      "Validated batch 118 batch loss 6.1114459\n",
      "Validated batch 119 batch loss 5.62871742\n",
      "Validated batch 120 batch loss 6.06417179\n",
      "Validated batch 121 batch loss 6.71976662\n",
      "Validated batch 122 batch loss 6.02976799\n",
      "Validated batch 123 batch loss 6.31082726\n",
      "Validated batch 124 batch loss 6.39389706\n",
      "Validated batch 125 batch loss 6.44137764\n",
      "Validated batch 126 batch loss 6.52424479\n",
      "Validated batch 127 batch loss 6.41959286\n",
      "Validated batch 128 batch loss 6.26655674\n",
      "Validated batch 129 batch loss 6.20800114\n",
      "Validated batch 130 batch loss 6.4299078\n",
      "Validated batch 131 batch loss 6.74441624\n",
      "Validated batch 132 batch loss 6.16145706\n",
      "Validated batch 133 batch loss 6.59253931\n",
      "Validated batch 134 batch loss 6.3810668\n",
      "Validated batch 135 batch loss 5.95878267\n",
      "Validated batch 136 batch loss 6.23817968\n",
      "Validated batch 137 batch loss 6.30084085\n",
      "Validated batch 138 batch loss 6.66148138\n",
      "Validated batch 139 batch loss 6.23885345\n",
      "Validated batch 140 batch loss 6.48970318\n",
      "Validated batch 141 batch loss 6.33334398\n",
      "Validated batch 142 batch loss 6.35112572\n",
      "Validated batch 143 batch loss 6.7216177\n",
      "Validated batch 144 batch loss 6.41129923\n",
      "Validated batch 145 batch loss 6.52221966\n",
      "Validated batch 146 batch loss 6.35065508\n",
      "Validated batch 147 batch loss 6.50230265\n",
      "Validated batch 148 batch loss 6.37708902\n",
      "Validated batch 149 batch loss 6.68585253\n",
      "Validated batch 150 batch loss 6.82793856\n",
      "Validated batch 151 batch loss 5.99935675\n",
      "Validated batch 152 batch loss 6.56685257\n",
      "Validated batch 153 batch loss 6.30024481\n",
      "Validated batch 154 batch loss 6.4530549\n",
      "Validated batch 155 batch loss 6.55509138\n",
      "Validated batch 156 batch loss 5.98092\n",
      "Validated batch 157 batch loss 6.13241386\n",
      "Validated batch 158 batch loss 6.42088127\n",
      "Validated batch 159 batch loss 6.26037884\n",
      "Validated batch 160 batch loss 6.74740028\n",
      "Validated batch 161 batch loss 6.22909403\n",
      "Validated batch 162 batch loss 6.3553133\n",
      "Validated batch 163 batch loss 5.93675137\n",
      "Validated batch 164 batch loss 6.29433107\n",
      "Validated batch 165 batch loss 6.20406771\n",
      "Validated batch 166 batch loss 6.01275635\n",
      "Validated batch 167 batch loss 6.6107235\n",
      "Validated batch 168 batch loss 6.37585974\n",
      "Validated batch 169 batch loss 6.19594622\n",
      "Validated batch 170 batch loss 6.55758429\n",
      "Validated batch 171 batch loss 6.61181688\n",
      "Validated batch 172 batch loss 6.21003962\n",
      "Validated batch 173 batch loss 6.33420372\n",
      "Validated batch 174 batch loss 6.22899771\n",
      "Validated batch 175 batch loss 6.4840579\n",
      "Validated batch 176 batch loss 6.60424423\n",
      "Validated batch 177 batch loss 6.39925194\n",
      "Validated batch 178 batch loss 6.16788626\n",
      "Validated batch 179 batch loss 6.09779119\n",
      "Validated batch 180 batch loss 6.22187567\n",
      "Validated batch 181 batch loss 6.27194738\n",
      "Validated batch 182 batch loss 6.46828318\n",
      "Validated batch 183 batch loss 6.28865385\n",
      "Validated batch 184 batch loss 6.23566961\n",
      "Validated batch 185 batch loss 3.16089201\n",
      "Epoch 4 val loss 6.301671981811523\n",
      "Model /aiffel/aiffel/mpii/models1/simple_baseline-epoch-4-loss-6.3017.h5 saved.\n",
      "Start epoch 5 with learning rate 0.0007\n",
      "Start distributed traininng...\n",
      "Trained batch 1 batch loss 4.88563538 epoch total loss 4.88563538\n",
      "Trained batch 2 batch loss 5.11607504 epoch total loss 5.00085545\n",
      "Trained batch 3 batch loss 6.09583092 epoch total loss 5.36584711\n",
      "Trained batch 4 batch loss 6.33457947 epoch total loss 5.60803032\n",
      "Trained batch 5 batch loss 6.44969 epoch total loss 5.77636242\n",
      "Trained batch 6 batch loss 6.37573242 epoch total loss 5.87625742\n",
      "Trained batch 7 batch loss 6.19200134 epoch total loss 5.92136383\n",
      "Trained batch 8 batch loss 6.331357 epoch total loss 5.97261286\n",
      "Trained batch 9 batch loss 6.40012 epoch total loss 6.02011347\n",
      "Trained batch 10 batch loss 6.28357935 epoch total loss 6.04646\n",
      "Trained batch 11 batch loss 6.45538807 epoch total loss 6.08363533\n",
      "Trained batch 12 batch loss 5.91897583 epoch total loss 6.06991386\n",
      "Trained batch 13 batch loss 6.19819117 epoch total loss 6.07978106\n",
      "Trained batch 14 batch loss 6.27899218 epoch total loss 6.09401035\n",
      "Trained batch 15 batch loss 6.35659409 epoch total loss 6.11151648\n",
      "Trained batch 16 batch loss 6.10278606 epoch total loss 6.1109705\n",
      "Trained batch 17 batch loss 6.84236622 epoch total loss 6.15399408\n",
      "Trained batch 18 batch loss 6.65181398 epoch total loss 6.18165064\n",
      "Trained batch 19 batch loss 6.27623558 epoch total loss 6.18662882\n",
      "Trained batch 20 batch loss 5.73373508 epoch total loss 6.1639843\n",
      "Trained batch 21 batch loss 6.17439 epoch total loss 6.16447973\n",
      "Trained batch 22 batch loss 6.45988703 epoch total loss 6.17790699\n",
      "Trained batch 23 batch loss 7.199049 epoch total loss 6.22230482\n",
      "Trained batch 24 batch loss 6.88253307 epoch total loss 6.24981451\n",
      "Trained batch 25 batch loss 6.28223801 epoch total loss 6.25111151\n",
      "Trained batch 26 batch loss 6.35809708 epoch total loss 6.25522614\n",
      "Trained batch 27 batch loss 6.36722374 epoch total loss 6.25937414\n",
      "Trained batch 28 batch loss 6.14049721 epoch total loss 6.25512838\n",
      "Trained batch 29 batch loss 6.12307835 epoch total loss 6.25057507\n",
      "Trained batch 30 batch loss 6.26064205 epoch total loss 6.25091028\n",
      "Trained batch 31 batch loss 6.3829689 epoch total loss 6.25517035\n",
      "Trained batch 32 batch loss 6.55515718 epoch total loss 6.26454496\n",
      "Trained batch 33 batch loss 6.77161455 epoch total loss 6.27991104\n",
      "Trained batch 34 batch loss 6.26130342 epoch total loss 6.27936363\n",
      "Trained batch 35 batch loss 6.32934475 epoch total loss 6.28079176\n",
      "Trained batch 36 batch loss 6.24127483 epoch total loss 6.27969408\n",
      "Trained batch 37 batch loss 6.37254095 epoch total loss 6.28220367\n",
      "Trained batch 38 batch loss 6.40820265 epoch total loss 6.28551912\n",
      "Trained batch 39 batch loss 6.35288715 epoch total loss 6.2872467\n",
      "Trained batch 40 batch loss 6.38335752 epoch total loss 6.28964949\n",
      "Trained batch 41 batch loss 6.26540041 epoch total loss 6.28905821\n",
      "Trained batch 42 batch loss 6.12639427 epoch total loss 6.28518534\n",
      "Trained batch 43 batch loss 6.21964264 epoch total loss 6.28366089\n",
      "Trained batch 44 batch loss 5.96408463 epoch total loss 6.27639771\n",
      "Trained batch 45 batch loss 6.33201218 epoch total loss 6.27763319\n",
      "Trained batch 46 batch loss 6.43388462 epoch total loss 6.28103\n",
      "Trained batch 47 batch loss 6.28877926 epoch total loss 6.28119564\n",
      "Trained batch 48 batch loss 6.89415312 epoch total loss 6.29396582\n",
      "Trained batch 49 batch loss 6.44889879 epoch total loss 6.29712772\n",
      "Trained batch 50 batch loss 6.33028555 epoch total loss 6.297791\n",
      "Trained batch 51 batch loss 6.2585516 epoch total loss 6.29702139\n",
      "Trained batch 52 batch loss 6.68665886 epoch total loss 6.30451441\n",
      "Trained batch 53 batch loss 6.24437809 epoch total loss 6.30338\n",
      "Trained batch 54 batch loss 6.52058 epoch total loss 6.30740166\n",
      "Trained batch 55 batch loss 6.10400867 epoch total loss 6.30370378\n",
      "Trained batch 56 batch loss 5.46928787 epoch total loss 6.28880358\n",
      "Trained batch 57 batch loss 5.72818756 epoch total loss 6.27896833\n",
      "Trained batch 58 batch loss 5.95102787 epoch total loss 6.273314\n",
      "Trained batch 59 batch loss 6.41908646 epoch total loss 6.27578497\n",
      "Trained batch 60 batch loss 6.45690346 epoch total loss 6.27880335\n",
      "Trained batch 61 batch loss 6.37289762 epoch total loss 6.28034592\n",
      "Trained batch 62 batch loss 6.66238689 epoch total loss 6.28650808\n",
      "Trained batch 63 batch loss 5.6822 epoch total loss 6.27691555\n",
      "Trained batch 64 batch loss 5.89532804 epoch total loss 6.27095318\n",
      "Trained batch 65 batch loss 6.75509 epoch total loss 6.27840137\n",
      "Trained batch 66 batch loss 6.46005917 epoch total loss 6.28115368\n",
      "Trained batch 67 batch loss 6.45241642 epoch total loss 6.28371\n",
      "Trained batch 68 batch loss 6.41706705 epoch total loss 6.28567123\n",
      "Trained batch 69 batch loss 6.13618469 epoch total loss 6.28350496\n",
      "Trained batch 70 batch loss 6.39967251 epoch total loss 6.28516388\n",
      "Trained batch 71 batch loss 6.43460655 epoch total loss 6.28726864\n",
      "Trained batch 72 batch loss 6.43717766 epoch total loss 6.28935051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 73 batch loss 6.19776344 epoch total loss 6.28809595\n",
      "Trained batch 74 batch loss 5.94383335 epoch total loss 6.28344393\n",
      "Trained batch 75 batch loss 6.29222679 epoch total loss 6.28356123\n",
      "Trained batch 76 batch loss 6.39816 epoch total loss 6.28506899\n",
      "Trained batch 77 batch loss 5.84942245 epoch total loss 6.27941132\n",
      "Trained batch 78 batch loss 6.08146381 epoch total loss 6.27687359\n",
      "Trained batch 79 batch loss 6.00181341 epoch total loss 6.27339172\n",
      "Trained batch 80 batch loss 6.2650876 epoch total loss 6.27328777\n",
      "Trained batch 81 batch loss 6.34073591 epoch total loss 6.27412033\n",
      "Trained batch 82 batch loss 6.61112309 epoch total loss 6.27823\n",
      "Trained batch 83 batch loss 6.64741516 epoch total loss 6.28267813\n",
      "Trained batch 84 batch loss 6.48401976 epoch total loss 6.28507471\n",
      "Trained batch 85 batch loss 6.3818593 epoch total loss 6.2862134\n",
      "Trained batch 86 batch loss 6.21557236 epoch total loss 6.28539181\n",
      "Trained batch 87 batch loss 5.8497 epoch total loss 6.28038359\n",
      "Trained batch 88 batch loss 6.35065317 epoch total loss 6.28118181\n",
      "Trained batch 89 batch loss 6.17889738 epoch total loss 6.28003263\n",
      "Trained batch 90 batch loss 6.65692711 epoch total loss 6.28422\n",
      "Trained batch 91 batch loss 6.64139318 epoch total loss 6.28814554\n",
      "Trained batch 92 batch loss 6.81325531 epoch total loss 6.29385328\n",
      "Trained batch 93 batch loss 6.60379028 epoch total loss 6.2971859\n",
      "Trained batch 94 batch loss 6.64599657 epoch total loss 6.30089664\n",
      "Trained batch 95 batch loss 6.59240961 epoch total loss 6.30396557\n",
      "Trained batch 96 batch loss 6.77657223 epoch total loss 6.30888796\n",
      "Trained batch 97 batch loss 6.561028 epoch total loss 6.31148767\n",
      "Trained batch 98 batch loss 7.02732182 epoch total loss 6.31879234\n",
      "Trained batch 99 batch loss 6.32554674 epoch total loss 6.31886053\n",
      "Trained batch 100 batch loss 6.55405712 epoch total loss 6.32121277\n",
      "Trained batch 101 batch loss 6.70059919 epoch total loss 6.32496929\n",
      "Trained batch 102 batch loss 6.58536625 epoch total loss 6.32752228\n",
      "Trained batch 103 batch loss 6.4137392 epoch total loss 6.3283596\n",
      "Trained batch 104 batch loss 6.1460309 epoch total loss 6.32660675\n",
      "Trained batch 105 batch loss 6.32177925 epoch total loss 6.32656097\n",
      "Trained batch 106 batch loss 6.58443642 epoch total loss 6.32899332\n",
      "Trained batch 107 batch loss 5.59520912 epoch total loss 6.32213545\n",
      "Trained batch 108 batch loss 5.46587229 epoch total loss 6.31420708\n",
      "Trained batch 109 batch loss 5.55426407 epoch total loss 6.30723524\n",
      "Trained batch 110 batch loss 5.94489098 epoch total loss 6.30394125\n",
      "Trained batch 111 batch loss 6.20349741 epoch total loss 6.30303621\n",
      "Trained batch 112 batch loss 6.3962574 epoch total loss 6.30386829\n",
      "Trained batch 113 batch loss 6.5248189 epoch total loss 6.3058238\n",
      "Trained batch 114 batch loss 6.28673649 epoch total loss 6.30565643\n",
      "Trained batch 115 batch loss 6.32528877 epoch total loss 6.30582762\n",
      "Trained batch 116 batch loss 6.2516489 epoch total loss 6.30536032\n",
      "Trained batch 117 batch loss 6.74518156 epoch total loss 6.3091197\n",
      "Trained batch 118 batch loss 6.73382902 epoch total loss 6.31271887\n",
      "Trained batch 119 batch loss 6.49613953 epoch total loss 6.31426048\n",
      "Trained batch 120 batch loss 6.37827826 epoch total loss 6.31479406\n",
      "Trained batch 121 batch loss 6.3350172 epoch total loss 6.31496096\n",
      "Trained batch 122 batch loss 6.31648874 epoch total loss 6.31497335\n",
      "Trained batch 123 batch loss 6.45921421 epoch total loss 6.31614637\n",
      "Trained batch 124 batch loss 6.51085 epoch total loss 6.3177166\n",
      "Trained batch 125 batch loss 6.93254948 epoch total loss 6.32263517\n",
      "Trained batch 126 batch loss 6.38140965 epoch total loss 6.32310152\n",
      "Trained batch 127 batch loss 5.98427439 epoch total loss 6.32043362\n",
      "Trained batch 128 batch loss 6.00209618 epoch total loss 6.31794643\n",
      "Trained batch 129 batch loss 6.1809988 epoch total loss 6.31688452\n",
      "Trained batch 130 batch loss 6.94149494 epoch total loss 6.32168913\n",
      "Trained batch 131 batch loss 6.81320763 epoch total loss 6.32544136\n",
      "Trained batch 132 batch loss 6.41904068 epoch total loss 6.32615042\n",
      "Trained batch 133 batch loss 6.87590456 epoch total loss 6.33028412\n",
      "Trained batch 134 batch loss 6.88806152 epoch total loss 6.33444691\n",
      "Trained batch 135 batch loss 6.52832842 epoch total loss 6.33588266\n",
      "Trained batch 136 batch loss 6.60083866 epoch total loss 6.33783102\n",
      "Trained batch 137 batch loss 6.17189264 epoch total loss 6.33661938\n",
      "Trained batch 138 batch loss 6.46696281 epoch total loss 6.33756399\n",
      "Trained batch 139 batch loss 6.31335115 epoch total loss 6.33739\n",
      "Trained batch 140 batch loss 6.45216799 epoch total loss 6.33820963\n",
      "Trained batch 141 batch loss 6.36283541 epoch total loss 6.33838463\n",
      "Trained batch 142 batch loss 6.14776611 epoch total loss 6.33704233\n",
      "Trained batch 143 batch loss 6.31831932 epoch total loss 6.3369112\n",
      "Trained batch 144 batch loss 6.03361559 epoch total loss 6.33480501\n",
      "Trained batch 145 batch loss 6.27053785 epoch total loss 6.33436155\n",
      "Trained batch 146 batch loss 6.08506346 epoch total loss 6.332654\n",
      "Trained batch 147 batch loss 6.38802528 epoch total loss 6.3330307\n",
      "Trained batch 148 batch loss 6.056777 epoch total loss 6.33116388\n",
      "Trained batch 149 batch loss 6.03193331 epoch total loss 6.32915545\n",
      "Trained batch 150 batch loss 5.98622799 epoch total loss 6.32686949\n",
      "Trained batch 151 batch loss 5.87946415 epoch total loss 6.32390642\n",
      "Trained batch 152 batch loss 6.16119385 epoch total loss 6.32283592\n",
      "Trained batch 153 batch loss 6.34957075 epoch total loss 6.32301044\n",
      "Trained batch 154 batch loss 6.01882124 epoch total loss 6.32103491\n",
      "Trained batch 155 batch loss 6.32635355 epoch total loss 6.32106924\n",
      "Trained batch 156 batch loss 6.36086273 epoch total loss 6.32132435\n",
      "Trained batch 157 batch loss 5.74615765 epoch total loss 6.31766081\n",
      "Trained batch 158 batch loss 5.94243813 epoch total loss 6.31528616\n",
      "Trained batch 159 batch loss 5.9509182 epoch total loss 6.31299448\n",
      "Trained batch 160 batch loss 6.59453344 epoch total loss 6.31475401\n",
      "Trained batch 161 batch loss 6.40411 epoch total loss 6.31530905\n",
      "Trained batch 162 batch loss 6.34025764 epoch total loss 6.31546307\n",
      "Trained batch 163 batch loss 6.25826406 epoch total loss 6.31511211\n",
      "Trained batch 164 batch loss 6.28180027 epoch total loss 6.31490946\n",
      "Trained batch 165 batch loss 6.33287716 epoch total loss 6.31501818\n",
      "Trained batch 166 batch loss 5.99417782 epoch total loss 6.31308556\n",
      "Trained batch 167 batch loss 6.17188215 epoch total loss 6.31223965\n",
      "Trained batch 168 batch loss 6.10044289 epoch total loss 6.31097937\n",
      "Trained batch 169 batch loss 6.17993641 epoch total loss 6.31020355\n",
      "Trained batch 170 batch loss 6.40012884 epoch total loss 6.31073284\n",
      "Trained batch 171 batch loss 6.13295746 epoch total loss 6.30969286\n",
      "Trained batch 172 batch loss 6.38639688 epoch total loss 6.3101387\n",
      "Trained batch 173 batch loss 6.18368244 epoch total loss 6.30940819\n",
      "Trained batch 174 batch loss 6.11377144 epoch total loss 6.30828381\n",
      "Trained batch 175 batch loss 6.07045794 epoch total loss 6.30692434\n",
      "Trained batch 176 batch loss 5.38142109 epoch total loss 6.30166626\n",
      "Trained batch 177 batch loss 5.27077293 epoch total loss 6.29584169\n",
      "Trained batch 178 batch loss 5.13723707 epoch total loss 6.28933287\n",
      "Trained batch 179 batch loss 5.87674665 epoch total loss 6.28702736\n",
      "Trained batch 180 batch loss 5.85647964 epoch total loss 6.28463554\n",
      "Trained batch 181 batch loss 6.70977449 epoch total loss 6.28698397\n",
      "Trained batch 182 batch loss 7.26595402 epoch total loss 6.29236317\n",
      "Trained batch 183 batch loss 6.69525623 epoch total loss 6.2945652\n",
      "Trained batch 184 batch loss 6.61736059 epoch total loss 6.29631901\n",
      "Trained batch 185 batch loss 6.708179 epoch total loss 6.29854488\n",
      "Trained batch 186 batch loss 7.12107277 epoch total loss 6.30296755\n",
      "Trained batch 187 batch loss 6.69661665 epoch total loss 6.30507278\n",
      "Trained batch 188 batch loss 6.46523428 epoch total loss 6.30592442\n",
      "Trained batch 189 batch loss 6.65501165 epoch total loss 6.30777168\n",
      "Trained batch 190 batch loss 6.80063343 epoch total loss 6.31036568\n",
      "Trained batch 191 batch loss 6.54017448 epoch total loss 6.31156874\n",
      "Trained batch 192 batch loss 6.36550283 epoch total loss 6.31184959\n",
      "Trained batch 193 batch loss 6.50271797 epoch total loss 6.31283855\n",
      "Trained batch 194 batch loss 5.71670103 epoch total loss 6.30976534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 195 batch loss 5.95867157 epoch total loss 6.3079648\n",
      "Trained batch 196 batch loss 6.17394209 epoch total loss 6.30728102\n",
      "Trained batch 197 batch loss 6.21264315 epoch total loss 6.30680037\n",
      "Trained batch 198 batch loss 6.42753124 epoch total loss 6.30741024\n",
      "Trained batch 199 batch loss 6.36597776 epoch total loss 6.30770445\n",
      "Trained batch 200 batch loss 6.43832779 epoch total loss 6.30835772\n",
      "Trained batch 201 batch loss 6.37749529 epoch total loss 6.30870104\n",
      "Trained batch 202 batch loss 6.10968876 epoch total loss 6.30771637\n",
      "Trained batch 203 batch loss 6.07811737 epoch total loss 6.30658531\n",
      "Trained batch 204 batch loss 6.07601309 epoch total loss 6.30545521\n",
      "Trained batch 205 batch loss 6.19032621 epoch total loss 6.30489349\n",
      "Trained batch 206 batch loss 6.53005648 epoch total loss 6.3059864\n",
      "Trained batch 207 batch loss 6.48172951 epoch total loss 6.30683517\n",
      "Trained batch 208 batch loss 6.55477905 epoch total loss 6.30802727\n",
      "Trained batch 209 batch loss 6.96061945 epoch total loss 6.3111496\n",
      "Trained batch 210 batch loss 6.39325762 epoch total loss 6.31154108\n",
      "Trained batch 211 batch loss 6.57032728 epoch total loss 6.31276751\n",
      "Trained batch 212 batch loss 6.01945 epoch total loss 6.31138372\n",
      "Trained batch 213 batch loss 6.13570166 epoch total loss 6.3105588\n",
      "Trained batch 214 batch loss 6.1415329 epoch total loss 6.30976868\n",
      "Trained batch 215 batch loss 6.08060789 epoch total loss 6.30870295\n",
      "Trained batch 216 batch loss 6.3629837 epoch total loss 6.30895424\n",
      "Trained batch 217 batch loss 6.31442118 epoch total loss 6.30897951\n",
      "Trained batch 218 batch loss 6.4666667 epoch total loss 6.30970287\n",
      "Trained batch 219 batch loss 6.11187124 epoch total loss 6.30879927\n",
      "Trained batch 220 batch loss 6.83500242 epoch total loss 6.31119108\n",
      "Trained batch 221 batch loss 7.52521324 epoch total loss 6.31668472\n",
      "Trained batch 222 batch loss 7.18604612 epoch total loss 6.32060051\n",
      "Trained batch 223 batch loss 7.06402445 epoch total loss 6.32393408\n",
      "Trained batch 224 batch loss 6.85532475 epoch total loss 6.32630634\n",
      "Trained batch 225 batch loss 6.74254417 epoch total loss 6.32815647\n",
      "Trained batch 226 batch loss 5.77351713 epoch total loss 6.32570267\n",
      "Trained batch 227 batch loss 6.08857584 epoch total loss 6.32465792\n",
      "Trained batch 228 batch loss 6.3271389 epoch total loss 6.32466888\n",
      "Trained batch 229 batch loss 6.87455797 epoch total loss 6.32707\n",
      "Trained batch 230 batch loss 6.54639912 epoch total loss 6.32802343\n",
      "Trained batch 231 batch loss 6.31835699 epoch total loss 6.32798195\n",
      "Trained batch 232 batch loss 6.19098282 epoch total loss 6.32739162\n",
      "Trained batch 233 batch loss 6.10144806 epoch total loss 6.32642174\n",
      "Trained batch 234 batch loss 6.45783949 epoch total loss 6.32698345\n",
      "Trained batch 235 batch loss 5.95646 epoch total loss 6.32540655\n",
      "Trained batch 236 batch loss 6.12288189 epoch total loss 6.32454872\n",
      "Trained batch 237 batch loss 6.18901348 epoch total loss 6.32397652\n",
      "Trained batch 238 batch loss 6.57373953 epoch total loss 6.32502604\n",
      "Trained batch 239 batch loss 6.48139572 epoch total loss 6.32568073\n",
      "Trained batch 240 batch loss 5.99273348 epoch total loss 6.32429314\n",
      "Trained batch 241 batch loss 6.13849497 epoch total loss 6.32352209\n",
      "Trained batch 242 batch loss 6.20982742 epoch total loss 6.32305241\n",
      "Trained batch 243 batch loss 5.90310192 epoch total loss 6.32132435\n",
      "Trained batch 244 batch loss 5.84155369 epoch total loss 6.31935787\n",
      "Trained batch 245 batch loss 5.74582481 epoch total loss 6.31701708\n",
      "Trained batch 246 batch loss 5.59351206 epoch total loss 6.31407595\n",
      "Trained batch 247 batch loss 6.02443695 epoch total loss 6.3129034\n",
      "Trained batch 248 batch loss 6.44841957 epoch total loss 6.31344938\n",
      "Trained batch 249 batch loss 6.62512779 epoch total loss 6.31470108\n",
      "Trained batch 250 batch loss 6.58280945 epoch total loss 6.31577349\n",
      "Trained batch 251 batch loss 6.22807455 epoch total loss 6.31542397\n",
      "Trained batch 252 batch loss 5.89897919 epoch total loss 6.31377125\n",
      "Trained batch 253 batch loss 6.36303425 epoch total loss 6.3139658\n",
      "Trained batch 254 batch loss 6.30845118 epoch total loss 6.31394434\n",
      "Trained batch 255 batch loss 6.15999937 epoch total loss 6.31334066\n",
      "Trained batch 256 batch loss 6.3699 epoch total loss 6.31356144\n",
      "Trained batch 257 batch loss 6.04859924 epoch total loss 6.31253052\n",
      "Trained batch 258 batch loss 6.27187967 epoch total loss 6.31237268\n",
      "Trained batch 259 batch loss 6.15849972 epoch total loss 6.31177855\n",
      "Trained batch 260 batch loss 6.12032461 epoch total loss 6.31104231\n",
      "Trained batch 261 batch loss 6.20503759 epoch total loss 6.31063604\n",
      "Trained batch 262 batch loss 6.28052473 epoch total loss 6.31052113\n",
      "Trained batch 263 batch loss 6.39145756 epoch total loss 6.31082916\n",
      "Trained batch 264 batch loss 6.45769787 epoch total loss 6.31138515\n",
      "Trained batch 265 batch loss 6.25264549 epoch total loss 6.3111639\n",
      "Trained batch 266 batch loss 6.39049816 epoch total loss 6.31146193\n",
      "Trained batch 267 batch loss 6.25088358 epoch total loss 6.31123495\n",
      "Trained batch 268 batch loss 6.48950386 epoch total loss 6.3119\n",
      "Trained batch 269 batch loss 6.59250307 epoch total loss 6.31294346\n",
      "Trained batch 270 batch loss 6.51776409 epoch total loss 6.31370211\n",
      "Trained batch 271 batch loss 6.47673702 epoch total loss 6.3143034\n",
      "Trained batch 272 batch loss 5.73185205 epoch total loss 6.31216192\n",
      "Trained batch 273 batch loss 5.79731703 epoch total loss 6.31027651\n",
      "Trained batch 274 batch loss 5.43498373 epoch total loss 6.3070817\n",
      "Trained batch 275 batch loss 5.81369734 epoch total loss 6.30528784\n",
      "Trained batch 276 batch loss 6.26453638 epoch total loss 6.30514\n",
      "Trained batch 277 batch loss 5.92338133 epoch total loss 6.30376148\n",
      "Trained batch 278 batch loss 6.14321375 epoch total loss 6.30318403\n",
      "Trained batch 279 batch loss 5.97755098 epoch total loss 6.30201674\n",
      "Trained batch 280 batch loss 5.96354 epoch total loss 6.30080795\n",
      "Trained batch 281 batch loss 5.62687445 epoch total loss 6.29840946\n",
      "Trained batch 282 batch loss 6.34285355 epoch total loss 6.2985673\n",
      "Trained batch 283 batch loss 6.3466363 epoch total loss 6.29873705\n",
      "Trained batch 284 batch loss 6.3854847 epoch total loss 6.2990427\n",
      "Trained batch 285 batch loss 6.10911131 epoch total loss 6.29837608\n",
      "Trained batch 286 batch loss 6.13649511 epoch total loss 6.29781\n",
      "Trained batch 287 batch loss 6.18382215 epoch total loss 6.29741287\n",
      "Trained batch 288 batch loss 6.213902 epoch total loss 6.29712296\n",
      "Trained batch 289 batch loss 6.1169734 epoch total loss 6.29649973\n",
      "Trained batch 290 batch loss 6.2838459 epoch total loss 6.29645586\n",
      "Trained batch 291 batch loss 6.78055859 epoch total loss 6.29811907\n",
      "Trained batch 292 batch loss 6.24940968 epoch total loss 6.29795218\n",
      "Trained batch 293 batch loss 6.23487377 epoch total loss 6.29773712\n",
      "Trained batch 294 batch loss 6.55934906 epoch total loss 6.2986269\n",
      "Trained batch 295 batch loss 6.71593761 epoch total loss 6.3000412\n",
      "Trained batch 296 batch loss 6.72861 epoch total loss 6.30148935\n",
      "Trained batch 297 batch loss 7.11049128 epoch total loss 6.30421305\n",
      "Trained batch 298 batch loss 6.04556847 epoch total loss 6.3033452\n",
      "Trained batch 299 batch loss 5.64095831 epoch total loss 6.30113\n",
      "Trained batch 300 batch loss 6.26624298 epoch total loss 6.30101347\n",
      "Trained batch 301 batch loss 5.98583555 epoch total loss 6.29996634\n",
      "Trained batch 302 batch loss 6.39610434 epoch total loss 6.30028486\n",
      "Trained batch 303 batch loss 6.49138451 epoch total loss 6.30091524\n",
      "Trained batch 304 batch loss 6.68112564 epoch total loss 6.30216599\n",
      "Trained batch 305 batch loss 6.77018261 epoch total loss 6.30370045\n",
      "Trained batch 306 batch loss 6.52807426 epoch total loss 6.30443382\n",
      "Trained batch 307 batch loss 6.44299269 epoch total loss 6.30488491\n",
      "Trained batch 308 batch loss 6.70940161 epoch total loss 6.30619812\n",
      "Trained batch 309 batch loss 7.05687714 epoch total loss 6.30862761\n",
      "Trained batch 310 batch loss 6.38387 epoch total loss 6.30887079\n",
      "Trained batch 311 batch loss 6.19470453 epoch total loss 6.30850363\n",
      "Trained batch 312 batch loss 6.07462 epoch total loss 6.30775356\n",
      "Trained batch 313 batch loss 5.63413 epoch total loss 6.3056016\n",
      "Trained batch 314 batch loss 5.40375328 epoch total loss 6.30272961\n",
      "Trained batch 315 batch loss 6.43221474 epoch total loss 6.30314112\n",
      "Trained batch 316 batch loss 5.28877497 epoch total loss 6.29993105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 317 batch loss 5.21065378 epoch total loss 6.29649496\n",
      "Trained batch 318 batch loss 5.04329729 epoch total loss 6.29255438\n",
      "Trained batch 319 batch loss 5.50286579 epoch total loss 6.29007864\n",
      "Trained batch 320 batch loss 5.88519239 epoch total loss 6.28881311\n",
      "Trained batch 321 batch loss 6.14810085 epoch total loss 6.28837442\n",
      "Trained batch 322 batch loss 6.42664623 epoch total loss 6.28880405\n",
      "Trained batch 323 batch loss 6.7627964 epoch total loss 6.29027128\n",
      "Trained batch 324 batch loss 6.83155918 epoch total loss 6.29194212\n",
      "Trained batch 325 batch loss 6.59036589 epoch total loss 6.29286\n",
      "Trained batch 326 batch loss 6.44315 epoch total loss 6.29332161\n",
      "Trained batch 327 batch loss 6.66925621 epoch total loss 6.29447079\n",
      "Trained batch 328 batch loss 6.35570717 epoch total loss 6.29465771\n",
      "Trained batch 329 batch loss 6.32010794 epoch total loss 6.29473495\n",
      "Trained batch 330 batch loss 6.672791 epoch total loss 6.29588079\n",
      "Trained batch 331 batch loss 6.37839937 epoch total loss 6.29613\n",
      "Trained batch 332 batch loss 6.29141378 epoch total loss 6.29611588\n",
      "Trained batch 333 batch loss 5.97437191 epoch total loss 6.29515\n",
      "Trained batch 334 batch loss 5.67917347 epoch total loss 6.29330587\n",
      "Trained batch 335 batch loss 5.8132472 epoch total loss 6.2918725\n",
      "Trained batch 336 batch loss 6.41338491 epoch total loss 6.29223394\n",
      "Trained batch 337 batch loss 6.35346603 epoch total loss 6.2924161\n",
      "Trained batch 338 batch loss 6.24137974 epoch total loss 6.29226542\n",
      "Trained batch 339 batch loss 6.50070143 epoch total loss 6.29288\n",
      "Trained batch 340 batch loss 6.42385483 epoch total loss 6.29326534\n",
      "Trained batch 341 batch loss 6.50016975 epoch total loss 6.29387236\n",
      "Trained batch 342 batch loss 6.51487732 epoch total loss 6.29451847\n",
      "Trained batch 343 batch loss 6.25848579 epoch total loss 6.29441357\n",
      "Trained batch 344 batch loss 6.14383221 epoch total loss 6.29397583\n",
      "Trained batch 345 batch loss 6.07304049 epoch total loss 6.29333544\n",
      "Trained batch 346 batch loss 6.53671312 epoch total loss 6.2940383\n",
      "Trained batch 347 batch loss 6.19412804 epoch total loss 6.29375029\n",
      "Trained batch 348 batch loss 5.92041492 epoch total loss 6.2926774\n",
      "Trained batch 349 batch loss 5.9076333 epoch total loss 6.29157448\n",
      "Trained batch 350 batch loss 6.37164211 epoch total loss 6.29180336\n",
      "Trained batch 351 batch loss 6.29859543 epoch total loss 6.29182243\n",
      "Trained batch 352 batch loss 6.19353676 epoch total loss 6.29154348\n",
      "Trained batch 353 batch loss 6.60886097 epoch total loss 6.29244232\n",
      "Trained batch 354 batch loss 6.34283066 epoch total loss 6.29258442\n",
      "Trained batch 355 batch loss 6.31194782 epoch total loss 6.29263926\n",
      "Trained batch 356 batch loss 6.59027052 epoch total loss 6.29347563\n",
      "Trained batch 357 batch loss 6.48508167 epoch total loss 6.29401255\n",
      "Trained batch 358 batch loss 6.46845627 epoch total loss 6.2945\n",
      "Trained batch 359 batch loss 6.27617121 epoch total loss 6.29444838\n",
      "Trained batch 360 batch loss 6.32824135 epoch total loss 6.29454231\n",
      "Trained batch 361 batch loss 6.788311 epoch total loss 6.29591\n",
      "Trained batch 362 batch loss 6.61588621 epoch total loss 6.29679394\n",
      "Trained batch 363 batch loss 6.38209963 epoch total loss 6.29702902\n",
      "Trained batch 364 batch loss 6.38004637 epoch total loss 6.29725742\n",
      "Trained batch 365 batch loss 6.3435297 epoch total loss 6.29738379\n",
      "Trained batch 366 batch loss 6.34039593 epoch total loss 6.29750156\n",
      "Trained batch 367 batch loss 6.77908516 epoch total loss 6.29881334\n",
      "Trained batch 368 batch loss 6.29404306 epoch total loss 6.29880047\n",
      "Trained batch 369 batch loss 6.19438076 epoch total loss 6.29851723\n",
      "Trained batch 370 batch loss 6.32900906 epoch total loss 6.29859972\n",
      "Trained batch 371 batch loss 6.29409838 epoch total loss 6.2985878\n",
      "Trained batch 372 batch loss 6.13269758 epoch total loss 6.29814243\n",
      "Trained batch 373 batch loss 6.08473921 epoch total loss 6.29757\n",
      "Trained batch 374 batch loss 6.47474194 epoch total loss 6.2980442\n",
      "Trained batch 375 batch loss 6.43468809 epoch total loss 6.29840803\n",
      "Trained batch 376 batch loss 6.61775541 epoch total loss 6.29925728\n",
      "Trained batch 377 batch loss 6.30771494 epoch total loss 6.29927969\n",
      "Trained batch 378 batch loss 6.23210955 epoch total loss 6.29910183\n",
      "Trained batch 379 batch loss 6.50398731 epoch total loss 6.29964256\n",
      "Trained batch 380 batch loss 5.73368073 epoch total loss 6.29815292\n",
      "Trained batch 381 batch loss 6.38693 epoch total loss 6.2983861\n",
      "Trained batch 382 batch loss 6.35637283 epoch total loss 6.29853773\n",
      "Trained batch 383 batch loss 6.35374641 epoch total loss 6.29868221\n",
      "Trained batch 384 batch loss 6.2440877 epoch total loss 6.29854\n",
      "Trained batch 385 batch loss 6.26498413 epoch total loss 6.29845285\n",
      "Trained batch 386 batch loss 6.32382679 epoch total loss 6.29851818\n",
      "Trained batch 387 batch loss 6.45878458 epoch total loss 6.29893208\n",
      "Trained batch 388 batch loss 6.06917048 epoch total loss 6.29834\n",
      "Trained batch 389 batch loss 6.31997681 epoch total loss 6.29839563\n",
      "Trained batch 390 batch loss 6.15140724 epoch total loss 6.29801893\n",
      "Trained batch 391 batch loss 6.5004921 epoch total loss 6.2985363\n",
      "Trained batch 392 batch loss 6.23697472 epoch total loss 6.29838\n",
      "Trained batch 393 batch loss 6.40087414 epoch total loss 6.29864073\n",
      "Trained batch 394 batch loss 6.30285645 epoch total loss 6.29865074\n",
      "Trained batch 395 batch loss 6.54023552 epoch total loss 6.29926252\n",
      "Trained batch 396 batch loss 6.47928572 epoch total loss 6.29971695\n",
      "Trained batch 397 batch loss 6.300735 epoch total loss 6.29972\n",
      "Trained batch 398 batch loss 6.3962059 epoch total loss 6.29996252\n",
      "Trained batch 399 batch loss 6.31110334 epoch total loss 6.29999\n",
      "Trained batch 400 batch loss 6.52064228 epoch total loss 6.30054188\n",
      "Trained batch 401 batch loss 6.25964689 epoch total loss 6.30044031\n",
      "Trained batch 402 batch loss 6.59448671 epoch total loss 6.30117178\n",
      "Trained batch 403 batch loss 6.28163147 epoch total loss 6.30112362\n",
      "Trained batch 404 batch loss 6.21675348 epoch total loss 6.30091476\n",
      "Trained batch 405 batch loss 6.87357378 epoch total loss 6.30232859\n",
      "Trained batch 406 batch loss 6.66185379 epoch total loss 6.30321407\n",
      "Trained batch 407 batch loss 6.90631294 epoch total loss 6.30469608\n",
      "Trained batch 408 batch loss 7.61894417 epoch total loss 6.30791712\n",
      "Trained batch 409 batch loss 7.39900589 epoch total loss 6.31058455\n",
      "Trained batch 410 batch loss 7.45023632 epoch total loss 6.31336403\n",
      "Trained batch 411 batch loss 6.50809813 epoch total loss 6.31383753\n",
      "Trained batch 412 batch loss 6.42147446 epoch total loss 6.31409883\n",
      "Trained batch 413 batch loss 6.1884346 epoch total loss 6.31379461\n",
      "Trained batch 414 batch loss 6.15605164 epoch total loss 6.31341362\n",
      "Trained batch 415 batch loss 6.20148659 epoch total loss 6.31314373\n",
      "Trained batch 416 batch loss 6.17455435 epoch total loss 6.31281042\n",
      "Trained batch 417 batch loss 6.12054 epoch total loss 6.31234932\n",
      "Trained batch 418 batch loss 6.44136763 epoch total loss 6.31265831\n",
      "Trained batch 419 batch loss 6.11285639 epoch total loss 6.31218147\n",
      "Trained batch 420 batch loss 6.39596748 epoch total loss 6.31238079\n",
      "Trained batch 421 batch loss 6.3997345 epoch total loss 6.31258821\n",
      "Trained batch 422 batch loss 6.6103816 epoch total loss 6.31329393\n",
      "Trained batch 423 batch loss 6.53321218 epoch total loss 6.31381369\n",
      "Trained batch 424 batch loss 6.27557659 epoch total loss 6.31372356\n",
      "Trained batch 425 batch loss 6.2307477 epoch total loss 6.31352806\n",
      "Trained batch 426 batch loss 6.24103689 epoch total loss 6.31335783\n",
      "Trained batch 427 batch loss 6.63759947 epoch total loss 6.31411743\n",
      "Trained batch 428 batch loss 6.29901457 epoch total loss 6.31408215\n",
      "Trained batch 429 batch loss 6.72524738 epoch total loss 6.31504107\n",
      "Trained batch 430 batch loss 6.50078487 epoch total loss 6.3154726\n",
      "Trained batch 431 batch loss 6.03775787 epoch total loss 6.31482887\n",
      "Trained batch 432 batch loss 5.78326893 epoch total loss 6.31359816\n",
      "Trained batch 433 batch loss 6.70654678 epoch total loss 6.31450558\n",
      "Trained batch 434 batch loss 6.73188877 epoch total loss 6.31546736\n",
      "Trained batch 435 batch loss 7.11180544 epoch total loss 6.31729794\n",
      "Trained batch 436 batch loss 6.5876708 epoch total loss 6.3179183\n",
      "Trained batch 437 batch loss 6.48996782 epoch total loss 6.31831169\n",
      "Trained batch 438 batch loss 6.48093271 epoch total loss 6.31868315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 439 batch loss 6.74504328 epoch total loss 6.31965446\n",
      "Trained batch 440 batch loss 6.26473951 epoch total loss 6.31952953\n",
      "Trained batch 441 batch loss 6.34374475 epoch total loss 6.31958437\n",
      "Trained batch 442 batch loss 6.59538 epoch total loss 6.32020855\n",
      "Trained batch 443 batch loss 6.24566841 epoch total loss 6.32004\n",
      "Trained batch 444 batch loss 6.59216 epoch total loss 6.32065296\n",
      "Trained batch 445 batch loss 6.28373671 epoch total loss 6.32057\n",
      "Trained batch 446 batch loss 6.38260269 epoch total loss 6.32070875\n",
      "Trained batch 447 batch loss 6.63524437 epoch total loss 6.32141256\n",
      "Trained batch 448 batch loss 6.63763285 epoch total loss 6.32211828\n",
      "Trained batch 449 batch loss 6.46716356 epoch total loss 6.32244158\n",
      "Trained batch 450 batch loss 6.49041462 epoch total loss 6.32281542\n",
      "Trained batch 451 batch loss 6.47703934 epoch total loss 6.32315731\n",
      "Trained batch 452 batch loss 6.30850172 epoch total loss 6.32312489\n",
      "Trained batch 453 batch loss 5.87424374 epoch total loss 6.32213402\n",
      "Trained batch 454 batch loss 6.03181934 epoch total loss 6.32149458\n",
      "Trained batch 455 batch loss 6.43579865 epoch total loss 6.32174587\n",
      "Trained batch 456 batch loss 6.83393049 epoch total loss 6.32286882\n",
      "Trained batch 457 batch loss 6.16600895 epoch total loss 6.32252598\n",
      "Trained batch 458 batch loss 6.42258167 epoch total loss 6.32274437\n",
      "Trained batch 459 batch loss 6.32360172 epoch total loss 6.3227458\n",
      "Trained batch 460 batch loss 6.25247526 epoch total loss 6.32259321\n",
      "Trained batch 461 batch loss 6.30948114 epoch total loss 6.32256508\n",
      "Trained batch 462 batch loss 5.97219896 epoch total loss 6.32180643\n",
      "Trained batch 463 batch loss 6.34094191 epoch total loss 6.32184744\n",
      "Trained batch 464 batch loss 6.09454727 epoch total loss 6.32135725\n",
      "Trained batch 465 batch loss 6.31886435 epoch total loss 6.32135201\n",
      "Trained batch 466 batch loss 6.15878677 epoch total loss 6.32100296\n",
      "Trained batch 467 batch loss 6.45007515 epoch total loss 6.32127953\n",
      "Trained batch 468 batch loss 6.48966312 epoch total loss 6.32163954\n",
      "Trained batch 469 batch loss 6.4743886 epoch total loss 6.32196522\n",
      "Trained batch 470 batch loss 6.57991886 epoch total loss 6.32251406\n",
      "Trained batch 471 batch loss 6.75225639 epoch total loss 6.32342625\n",
      "Trained batch 472 batch loss 6.50597095 epoch total loss 6.32381248\n",
      "Trained batch 473 batch loss 6.57853174 epoch total loss 6.32435131\n",
      "Trained batch 474 batch loss 6.49643755 epoch total loss 6.32471418\n",
      "Trained batch 475 batch loss 6.324193 epoch total loss 6.32471323\n",
      "Trained batch 476 batch loss 5.77220058 epoch total loss 6.32355261\n",
      "Trained batch 477 batch loss 5.99928713 epoch total loss 6.32287264\n",
      "Trained batch 478 batch loss 6.40492582 epoch total loss 6.3230443\n",
      "Trained batch 479 batch loss 6.31387 epoch total loss 6.3230257\n",
      "Trained batch 480 batch loss 6.33693933 epoch total loss 6.32305431\n",
      "Trained batch 481 batch loss 6.32228661 epoch total loss 6.32305288\n",
      "Trained batch 482 batch loss 6.72244787 epoch total loss 6.32388163\n",
      "Trained batch 483 batch loss 6.24230862 epoch total loss 6.32371235\n",
      "Trained batch 484 batch loss 6.15638685 epoch total loss 6.32336664\n",
      "Trained batch 485 batch loss 6.03833675 epoch total loss 6.32277918\n",
      "Trained batch 486 batch loss 6.41184616 epoch total loss 6.32296228\n",
      "Trained batch 487 batch loss 6.47228193 epoch total loss 6.32326889\n",
      "Trained batch 488 batch loss 6.85707426 epoch total loss 6.32436275\n",
      "Trained batch 489 batch loss 6.56860161 epoch total loss 6.32486248\n",
      "Trained batch 490 batch loss 6.68824244 epoch total loss 6.32560396\n",
      "Trained batch 491 batch loss 6.71897 epoch total loss 6.32640505\n",
      "Trained batch 492 batch loss 6.5944562 epoch total loss 6.32695\n",
      "Trained batch 493 batch loss 6.4354353 epoch total loss 6.32717037\n",
      "Trained batch 494 batch loss 6.45461226 epoch total loss 6.32742834\n",
      "Trained batch 495 batch loss 6.79910135 epoch total loss 6.32838106\n",
      "Trained batch 496 batch loss 6.77561665 epoch total loss 6.32928276\n",
      "Trained batch 497 batch loss 6.79542875 epoch total loss 6.3302207\n",
      "Trained batch 498 batch loss 6.5221343 epoch total loss 6.33060598\n",
      "Trained batch 499 batch loss 5.97705889 epoch total loss 6.3298974\n",
      "Trained batch 500 batch loss 5.62556 epoch total loss 6.32848883\n",
      "Trained batch 501 batch loss 6.31155634 epoch total loss 6.32845497\n",
      "Trained batch 502 batch loss 6.31819868 epoch total loss 6.32843447\n",
      "Trained batch 503 batch loss 6.42225027 epoch total loss 6.32862091\n",
      "Trained batch 504 batch loss 6.4012537 epoch total loss 6.32876539\n",
      "Trained batch 505 batch loss 6.09089327 epoch total loss 6.32829428\n",
      "Trained batch 506 batch loss 6.31734371 epoch total loss 6.32827282\n",
      "Trained batch 507 batch loss 5.79510546 epoch total loss 6.32722092\n",
      "Trained batch 508 batch loss 6.34481 epoch total loss 6.32725573\n",
      "Trained batch 509 batch loss 6.50075197 epoch total loss 6.32759666\n",
      "Trained batch 510 batch loss 6.48017597 epoch total loss 6.32789564\n",
      "Trained batch 511 batch loss 6.23306179 epoch total loss 6.32771\n",
      "Trained batch 512 batch loss 6.21655703 epoch total loss 6.32749319\n",
      "Trained batch 513 batch loss 6.58503723 epoch total loss 6.3279953\n",
      "Trained batch 514 batch loss 6.71175909 epoch total loss 6.32874155\n",
      "Trained batch 515 batch loss 6.4406023 epoch total loss 6.32895899\n",
      "Trained batch 516 batch loss 6.66373301 epoch total loss 6.32960796\n",
      "Trained batch 517 batch loss 6.26770258 epoch total loss 6.32948828\n",
      "Trained batch 518 batch loss 6.19244289 epoch total loss 6.32922363\n",
      "Trained batch 519 batch loss 6.27535629 epoch total loss 6.32911968\n",
      "Trained batch 520 batch loss 6.37986374 epoch total loss 6.32921743\n",
      "Trained batch 521 batch loss 6.39026 epoch total loss 6.32933474\n",
      "Trained batch 522 batch loss 6.06862688 epoch total loss 6.32883549\n",
      "Trained batch 523 batch loss 5.95056963 epoch total loss 6.3281126\n",
      "Trained batch 524 batch loss 5.99172354 epoch total loss 6.3274703\n",
      "Trained batch 525 batch loss 5.71429634 epoch total loss 6.32630253\n",
      "Trained batch 526 batch loss 6.06105614 epoch total loss 6.32579803\n",
      "Trained batch 527 batch loss 7.02901173 epoch total loss 6.3271327\n",
      "Trained batch 528 batch loss 7.15543556 epoch total loss 6.3287015\n",
      "Trained batch 529 batch loss 6.90115452 epoch total loss 6.32978392\n",
      "Trained batch 530 batch loss 6.79820061 epoch total loss 6.3306675\n",
      "Trained batch 531 batch loss 6.82227135 epoch total loss 6.33159304\n",
      "Trained batch 532 batch loss 6.75444841 epoch total loss 6.33238792\n",
      "Trained batch 533 batch loss 6.47228622 epoch total loss 6.33265\n",
      "Trained batch 534 batch loss 6.39376783 epoch total loss 6.33276463\n",
      "Trained batch 535 batch loss 6.43826771 epoch total loss 6.33296156\n",
      "Trained batch 536 batch loss 6.46815681 epoch total loss 6.33321428\n",
      "Trained batch 537 batch loss 6.56591892 epoch total loss 6.33364725\n",
      "Trained batch 538 batch loss 6.51641369 epoch total loss 6.33398724\n",
      "Trained batch 539 batch loss 6.57445049 epoch total loss 6.33443308\n",
      "Trained batch 540 batch loss 6.29233742 epoch total loss 6.33435488\n",
      "Trained batch 541 batch loss 6.51744747 epoch total loss 6.33469343\n",
      "Trained batch 542 batch loss 6.44405746 epoch total loss 6.33489513\n",
      "Trained batch 543 batch loss 6.03779268 epoch total loss 6.3343482\n",
      "Trained batch 544 batch loss 6.08592415 epoch total loss 6.33389139\n",
      "Trained batch 545 batch loss 6.43906689 epoch total loss 6.33408403\n",
      "Trained batch 546 batch loss 6.0955286 epoch total loss 6.33364725\n",
      "Trained batch 547 batch loss 6.51694489 epoch total loss 6.33398199\n",
      "Trained batch 548 batch loss 6.86613131 epoch total loss 6.33495331\n",
      "Trained batch 549 batch loss 6.56812 epoch total loss 6.33537817\n",
      "Trained batch 550 batch loss 5.97769737 epoch total loss 6.33472776\n",
      "Trained batch 551 batch loss 6.11350346 epoch total loss 6.33432627\n",
      "Trained batch 552 batch loss 6.04601574 epoch total loss 6.33380413\n",
      "Trained batch 553 batch loss 6.39669037 epoch total loss 6.33391762\n",
      "Trained batch 554 batch loss 6.42548704 epoch total loss 6.33408308\n",
      "Trained batch 555 batch loss 6.29923916 epoch total loss 6.33402061\n",
      "Trained batch 556 batch loss 6.62178135 epoch total loss 6.33453798\n",
      "Trained batch 557 batch loss 6.70005369 epoch total loss 6.33519411\n",
      "Trained batch 558 batch loss 6.74744 epoch total loss 6.33593321\n",
      "Trained batch 559 batch loss 6.96314716 epoch total loss 6.33705521\n",
      "Trained batch 560 batch loss 6.56920052 epoch total loss 6.33746958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 561 batch loss 6.39744186 epoch total loss 6.33757639\n",
      "Trained batch 562 batch loss 6.66220903 epoch total loss 6.33815384\n",
      "Trained batch 563 batch loss 6.42432451 epoch total loss 6.3383069\n",
      "Trained batch 564 batch loss 5.96684122 epoch total loss 6.33764839\n",
      "Trained batch 565 batch loss 5.861866 epoch total loss 6.33680582\n",
      "Trained batch 566 batch loss 6.13972092 epoch total loss 6.33645773\n",
      "Trained batch 567 batch loss 6.51658106 epoch total loss 6.3367753\n",
      "Trained batch 568 batch loss 6.61944771 epoch total loss 6.33727312\n",
      "Trained batch 569 batch loss 6.35329103 epoch total loss 6.33730125\n",
      "Trained batch 570 batch loss 6.48481607 epoch total loss 6.33756\n",
      "Trained batch 571 batch loss 6.42519522 epoch total loss 6.33771372\n",
      "Trained batch 572 batch loss 6.25440741 epoch total loss 6.33756781\n",
      "Trained batch 573 batch loss 6.43451166 epoch total loss 6.33773708\n",
      "Trained batch 574 batch loss 6.3369751 epoch total loss 6.33773565\n",
      "Trained batch 575 batch loss 6.42881823 epoch total loss 6.33789396\n",
      "Trained batch 576 batch loss 6.67087793 epoch total loss 6.33847237\n",
      "Trained batch 577 batch loss 6.33775 epoch total loss 6.33847094\n",
      "Trained batch 578 batch loss 5.88460732 epoch total loss 6.33768511\n",
      "Trained batch 579 batch loss 5.8383255 epoch total loss 6.33682299\n",
      "Trained batch 580 batch loss 5.49265957 epoch total loss 6.33536768\n",
      "Trained batch 581 batch loss 5.51501799 epoch total loss 6.33395576\n",
      "Trained batch 582 batch loss 6.48041058 epoch total loss 6.33420753\n",
      "Trained batch 583 batch loss 6.48666573 epoch total loss 6.33446884\n",
      "Trained batch 584 batch loss 6.59499454 epoch total loss 6.33491516\n",
      "Trained batch 585 batch loss 6.94266844 epoch total loss 6.33595371\n",
      "Trained batch 586 batch loss 6.45811272 epoch total loss 6.33616209\n",
      "Trained batch 587 batch loss 6.52897596 epoch total loss 6.33649063\n",
      "Trained batch 588 batch loss 6.94586754 epoch total loss 6.3375268\n",
      "Trained batch 589 batch loss 7.08277798 epoch total loss 6.33879232\n",
      "Trained batch 590 batch loss 6.7534771 epoch total loss 6.33949471\n",
      "Trained batch 591 batch loss 7.05565643 epoch total loss 6.34070683\n",
      "Trained batch 592 batch loss 6.88807774 epoch total loss 6.34163141\n",
      "Trained batch 593 batch loss 6.5012331 epoch total loss 6.34190083\n",
      "Trained batch 594 batch loss 6.11457682 epoch total loss 6.34151793\n",
      "Trained batch 595 batch loss 6.79866123 epoch total loss 6.34228611\n",
      "Trained batch 596 batch loss 6.45288229 epoch total loss 6.3424716\n",
      "Trained batch 597 batch loss 6.33666372 epoch total loss 6.34246159\n",
      "Trained batch 598 batch loss 6.06909561 epoch total loss 6.34200478\n",
      "Trained batch 599 batch loss 6.63186646 epoch total loss 6.34248877\n",
      "Trained batch 600 batch loss 6.4330349 epoch total loss 6.34263945\n",
      "Trained batch 601 batch loss 6.37479258 epoch total loss 6.34269285\n",
      "Trained batch 602 batch loss 6.29416847 epoch total loss 6.34261227\n",
      "Trained batch 603 batch loss 6.75009394 epoch total loss 6.34328794\n",
      "Trained batch 604 batch loss 6.57326078 epoch total loss 6.34366894\n",
      "Trained batch 605 batch loss 6.88265753 epoch total loss 6.34455967\n",
      "Trained batch 606 batch loss 6.5305419 epoch total loss 6.34486628\n",
      "Trained batch 607 batch loss 6.898139 epoch total loss 6.34577799\n",
      "Trained batch 608 batch loss 6.41957426 epoch total loss 6.34589958\n",
      "Trained batch 609 batch loss 6.47225046 epoch total loss 6.34610701\n",
      "Trained batch 610 batch loss 5.94560051 epoch total loss 6.3454504\n",
      "Trained batch 611 batch loss 5.43230534 epoch total loss 6.34395599\n",
      "Trained batch 612 batch loss 5.98597717 epoch total loss 6.34337091\n",
      "Trained batch 613 batch loss 5.56261539 epoch total loss 6.34209728\n",
      "Trained batch 614 batch loss 6.21125793 epoch total loss 6.34188414\n",
      "Trained batch 615 batch loss 6.10875177 epoch total loss 6.34150457\n",
      "Trained batch 616 batch loss 6.16860199 epoch total loss 6.34122419\n",
      "Trained batch 617 batch loss 6.05569458 epoch total loss 6.34076118\n",
      "Trained batch 618 batch loss 6.51238203 epoch total loss 6.34103918\n",
      "Trained batch 619 batch loss 6.2329073 epoch total loss 6.34086466\n",
      "Trained batch 620 batch loss 6.53899717 epoch total loss 6.34118414\n",
      "Trained batch 621 batch loss 6.5356741 epoch total loss 6.34149742\n",
      "Trained batch 622 batch loss 5.77275372 epoch total loss 6.34058285\n",
      "Trained batch 623 batch loss 4.93407106 epoch total loss 6.33832502\n",
      "Trained batch 624 batch loss 4.97440863 epoch total loss 6.3361392\n",
      "Trained batch 625 batch loss 5.95502663 epoch total loss 6.33553\n",
      "Trained batch 626 batch loss 7.044662 epoch total loss 6.33666229\n",
      "Trained batch 627 batch loss 7.33731651 epoch total loss 6.33825874\n",
      "Trained batch 628 batch loss 6.98408556 epoch total loss 6.33928728\n",
      "Trained batch 629 batch loss 6.51567316 epoch total loss 6.33956718\n",
      "Trained batch 630 batch loss 6.19846487 epoch total loss 6.33934355\n",
      "Trained batch 631 batch loss 6.45143843 epoch total loss 6.33952093\n",
      "Trained batch 632 batch loss 6.50014114 epoch total loss 6.33977556\n",
      "Trained batch 633 batch loss 6.11108303 epoch total loss 6.33941412\n",
      "Trained batch 634 batch loss 5.87168884 epoch total loss 6.33867598\n",
      "Trained batch 635 batch loss 5.96817541 epoch total loss 6.3380928\n",
      "Trained batch 636 batch loss 5.99996281 epoch total loss 6.33756113\n",
      "Trained batch 637 batch loss 6.13277102 epoch total loss 6.33723974\n",
      "Trained batch 638 batch loss 6.22077 epoch total loss 6.33705711\n",
      "Trained batch 639 batch loss 5.75917339 epoch total loss 6.33615303\n",
      "Trained batch 640 batch loss 5.7309103 epoch total loss 6.33520746\n",
      "Trained batch 641 batch loss 5.68664265 epoch total loss 6.33419561\n",
      "Trained batch 642 batch loss 5.93396711 epoch total loss 6.33357239\n",
      "Trained batch 643 batch loss 6.14387655 epoch total loss 6.33327723\n",
      "Trained batch 644 batch loss 6.29656363 epoch total loss 6.33322\n",
      "Trained batch 645 batch loss 6.41547394 epoch total loss 6.3333478\n",
      "Trained batch 646 batch loss 6.35209274 epoch total loss 6.33337688\n",
      "Trained batch 647 batch loss 6.70991278 epoch total loss 6.33395863\n",
      "Trained batch 648 batch loss 6.45896435 epoch total loss 6.33415174\n",
      "Trained batch 649 batch loss 6.626441 epoch total loss 6.33460188\n",
      "Trained batch 650 batch loss 6.73234367 epoch total loss 6.33521414\n",
      "Trained batch 651 batch loss 6.44227076 epoch total loss 6.33537865\n",
      "Trained batch 652 batch loss 6.48730183 epoch total loss 6.33561182\n",
      "Trained batch 653 batch loss 6.32011652 epoch total loss 6.33558846\n",
      "Trained batch 654 batch loss 6.47187 epoch total loss 6.33579636\n",
      "Trained batch 655 batch loss 6.40006781 epoch total loss 6.33589411\n",
      "Trained batch 656 batch loss 6.51609755 epoch total loss 6.33616877\n",
      "Trained batch 657 batch loss 6.22729731 epoch total loss 6.33600378\n",
      "Trained batch 658 batch loss 6.43535948 epoch total loss 6.33615494\n",
      "Trained batch 659 batch loss 6.5085783 epoch total loss 6.33641672\n",
      "Trained batch 660 batch loss 6.56245661 epoch total loss 6.33675957\n",
      "Trained batch 661 batch loss 6.79627228 epoch total loss 6.3374548\n",
      "Trained batch 662 batch loss 6.72882032 epoch total loss 6.33804607\n",
      "Trained batch 663 batch loss 6.99024773 epoch total loss 6.33903\n",
      "Trained batch 664 batch loss 6.69741106 epoch total loss 6.33956957\n",
      "Trained batch 665 batch loss 6.82327747 epoch total loss 6.34029675\n",
      "Trained batch 666 batch loss 6.88317 epoch total loss 6.34111214\n",
      "Trained batch 667 batch loss 6.81315327 epoch total loss 6.34182\n",
      "Trained batch 668 batch loss 6.68613911 epoch total loss 6.34233475\n",
      "Trained batch 669 batch loss 6.63441133 epoch total loss 6.34277105\n",
      "Trained batch 670 batch loss 6.480299 epoch total loss 6.34297657\n",
      "Trained batch 671 batch loss 6.44122314 epoch total loss 6.34312344\n",
      "Trained batch 672 batch loss 6.44028473 epoch total loss 6.34326839\n",
      "Trained batch 673 batch loss 6.22521114 epoch total loss 6.34309244\n",
      "Trained batch 674 batch loss 6.18477964 epoch total loss 6.34285736\n",
      "Trained batch 675 batch loss 5.89996195 epoch total loss 6.34220123\n",
      "Trained batch 676 batch loss 6.486866 epoch total loss 6.34241533\n",
      "Trained batch 677 batch loss 5.95219755 epoch total loss 6.34183884\n",
      "Trained batch 678 batch loss 6.38724709 epoch total loss 6.34190559\n",
      "Trained batch 679 batch loss 6.05411482 epoch total loss 6.34148169\n",
      "Trained batch 680 batch loss 6.10716391 epoch total loss 6.34113693\n",
      "Trained batch 681 batch loss 6.08564186 epoch total loss 6.34076166\n",
      "Trained batch 682 batch loss 6.50426292 epoch total loss 6.34100151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 683 batch loss 6.54415798 epoch total loss 6.34129858\n",
      "Trained batch 684 batch loss 6.34297943 epoch total loss 6.34130096\n",
      "Trained batch 685 batch loss 5.96621609 epoch total loss 6.34075308\n",
      "Trained batch 686 batch loss 6.5029707 epoch total loss 6.34098959\n",
      "Trained batch 687 batch loss 6.51336193 epoch total loss 6.34124041\n",
      "Trained batch 688 batch loss 6.37943745 epoch total loss 6.34129572\n",
      "Trained batch 689 batch loss 6.59605026 epoch total loss 6.34166574\n",
      "Trained batch 690 batch loss 6.18633842 epoch total loss 6.34144115\n",
      "Trained batch 691 batch loss 6.17863417 epoch total loss 6.3412056\n",
      "Trained batch 692 batch loss 6.18011332 epoch total loss 6.3409729\n",
      "Trained batch 693 batch loss 5.91826582 epoch total loss 6.34036303\n",
      "Trained batch 694 batch loss 5.4674468 epoch total loss 6.33910513\n",
      "Trained batch 695 batch loss 5.95555735 epoch total loss 6.33855295\n",
      "Trained batch 696 batch loss 6.34317589 epoch total loss 6.33856\n",
      "Trained batch 697 batch loss 6.27340269 epoch total loss 6.33846664\n",
      "Trained batch 698 batch loss 6.46498299 epoch total loss 6.33864737\n",
      "Trained batch 699 batch loss 6.60542297 epoch total loss 6.33902931\n",
      "Trained batch 700 batch loss 6.45006132 epoch total loss 6.3391881\n",
      "Trained batch 701 batch loss 6.34499645 epoch total loss 6.33919668\n",
      "Trained batch 702 batch loss 6.27617502 epoch total loss 6.33910704\n",
      "Trained batch 703 batch loss 6.35623789 epoch total loss 6.33913183\n",
      "Trained batch 704 batch loss 6.71470642 epoch total loss 6.33966541\n",
      "Trained batch 705 batch loss 6.3792491 epoch total loss 6.33972168\n",
      "Trained batch 706 batch loss 6.34635258 epoch total loss 6.33973122\n",
      "Trained batch 707 batch loss 6.26450396 epoch total loss 6.33962488\n",
      "Trained batch 708 batch loss 6.35117245 epoch total loss 6.33964109\n",
      "Trained batch 709 batch loss 5.9698987 epoch total loss 6.33911943\n",
      "Trained batch 710 batch loss 5.92128849 epoch total loss 6.33853102\n",
      "Trained batch 711 batch loss 6.02401543 epoch total loss 6.33808851\n",
      "Trained batch 712 batch loss 6.45948839 epoch total loss 6.33825874\n",
      "Trained batch 713 batch loss 6.62759876 epoch total loss 6.33866453\n",
      "Trained batch 714 batch loss 6.17082548 epoch total loss 6.33842945\n",
      "Trained batch 715 batch loss 6.16204214 epoch total loss 6.33818293\n",
      "Trained batch 716 batch loss 6.28492737 epoch total loss 6.33810902\n",
      "Trained batch 717 batch loss 6.29285192 epoch total loss 6.33804607\n",
      "Trained batch 718 batch loss 6.3546567 epoch total loss 6.33806896\n",
      "Trained batch 719 batch loss 6.40180874 epoch total loss 6.33815765\n",
      "Trained batch 720 batch loss 6.55212116 epoch total loss 6.33845472\n",
      "Trained batch 721 batch loss 6.99422932 epoch total loss 6.33936405\n",
      "Trained batch 722 batch loss 6.29145718 epoch total loss 6.33929777\n",
      "Trained batch 723 batch loss 5.97731733 epoch total loss 6.33879757\n",
      "Trained batch 724 batch loss 6.49659729 epoch total loss 6.33901548\n",
      "Trained batch 725 batch loss 6.84122038 epoch total loss 6.33970833\n",
      "Trained batch 726 batch loss 6.42179394 epoch total loss 6.33982134\n",
      "Trained batch 727 batch loss 6.07987928 epoch total loss 6.33946419\n",
      "Trained batch 728 batch loss 6.21298456 epoch total loss 6.33929062\n",
      "Trained batch 729 batch loss 6.10340405 epoch total loss 6.33896685\n",
      "Trained batch 730 batch loss 6.25389767 epoch total loss 6.3388505\n",
      "Trained batch 731 batch loss 6.49040079 epoch total loss 6.33905745\n",
      "Trained batch 732 batch loss 6.45390177 epoch total loss 6.3392148\n",
      "Trained batch 733 batch loss 6.11281109 epoch total loss 6.33890581\n",
      "Trained batch 734 batch loss 6.159904 epoch total loss 6.33866167\n",
      "Trained batch 735 batch loss 6.51414776 epoch total loss 6.33890057\n",
      "Trained batch 736 batch loss 6.19867563 epoch total loss 6.33871\n",
      "Trained batch 737 batch loss 6.38796663 epoch total loss 6.33877707\n",
      "Trained batch 738 batch loss 6.5483284 epoch total loss 6.33906126\n",
      "Trained batch 739 batch loss 6.67974424 epoch total loss 6.33952188\n",
      "Trained batch 740 batch loss 6.3362956 epoch total loss 6.33951759\n",
      "Trained batch 741 batch loss 6.32880592 epoch total loss 6.33950329\n",
      "Trained batch 742 batch loss 6.42738152 epoch total loss 6.33962154\n",
      "Trained batch 743 batch loss 6.47591257 epoch total loss 6.33980513\n",
      "Trained batch 744 batch loss 6.54361153 epoch total loss 6.34007883\n",
      "Trained batch 745 batch loss 6.38928413 epoch total loss 6.34014463\n",
      "Trained batch 746 batch loss 6.06185341 epoch total loss 6.33977175\n",
      "Trained batch 747 batch loss 5.62889671 epoch total loss 6.33882\n",
      "Trained batch 748 batch loss 5.42338896 epoch total loss 6.33759642\n",
      "Trained batch 749 batch loss 5.68067598 epoch total loss 6.33671904\n",
      "Trained batch 750 batch loss 5.46810436 epoch total loss 6.33556128\n",
      "Trained batch 751 batch loss 5.1191206 epoch total loss 6.33394146\n",
      "Trained batch 752 batch loss 5.24500942 epoch total loss 6.33249378\n",
      "Trained batch 753 batch loss 4.92569494 epoch total loss 6.33062553\n",
      "Trained batch 754 batch loss 5.88390207 epoch total loss 6.33003283\n",
      "Trained batch 755 batch loss 6.48403168 epoch total loss 6.33023643\n",
      "Trained batch 756 batch loss 6.42832708 epoch total loss 6.33036613\n",
      "Trained batch 757 batch loss 6.34020233 epoch total loss 6.33037949\n",
      "Trained batch 758 batch loss 6.14279175 epoch total loss 6.33013153\n",
      "Trained batch 759 batch loss 6.41747093 epoch total loss 6.33024645\n",
      "Trained batch 760 batch loss 6.53000832 epoch total loss 6.33050919\n",
      "Trained batch 761 batch loss 6.28911924 epoch total loss 6.33045483\n",
      "Trained batch 762 batch loss 6.34154272 epoch total loss 6.33046913\n",
      "Trained batch 763 batch loss 6.21768475 epoch total loss 6.33032131\n",
      "Trained batch 764 batch loss 6.23563671 epoch total loss 6.33019781\n",
      "Trained batch 765 batch loss 6.72169209 epoch total loss 6.33070946\n",
      "Trained batch 766 batch loss 6.58106661 epoch total loss 6.33103609\n",
      "Trained batch 767 batch loss 6.5821743 epoch total loss 6.33136368\n",
      "Trained batch 768 batch loss 6.65929794 epoch total loss 6.33179045\n",
      "Trained batch 769 batch loss 6.60844374 epoch total loss 6.33215\n",
      "Trained batch 770 batch loss 6.7169466 epoch total loss 6.33264971\n",
      "Trained batch 771 batch loss 6.55992842 epoch total loss 6.33294439\n",
      "Trained batch 772 batch loss 6.6027689 epoch total loss 6.33329391\n",
      "Trained batch 773 batch loss 6.3699851 epoch total loss 6.33334112\n",
      "Trained batch 774 batch loss 6.63035774 epoch total loss 6.33372498\n",
      "Trained batch 775 batch loss 6.32043886 epoch total loss 6.33370781\n",
      "Trained batch 776 batch loss 6.68533802 epoch total loss 6.33416128\n",
      "Trained batch 777 batch loss 6.52361298 epoch total loss 6.33440495\n",
      "Trained batch 778 batch loss 6.4659 epoch total loss 6.33457375\n",
      "Trained batch 779 batch loss 6.40842199 epoch total loss 6.33466816\n",
      "Trained batch 780 batch loss 6.65556955 epoch total loss 6.33507967\n",
      "Trained batch 781 batch loss 6.91644049 epoch total loss 6.33582449\n",
      "Trained batch 782 batch loss 6.50873756 epoch total loss 6.33604574\n",
      "Trained batch 783 batch loss 6.42331219 epoch total loss 6.33615685\n",
      "Trained batch 784 batch loss 6.51994085 epoch total loss 6.33639145\n",
      "Trained batch 785 batch loss 5.94162273 epoch total loss 6.33588839\n",
      "Trained batch 786 batch loss 5.66108322 epoch total loss 6.33503\n",
      "Trained batch 787 batch loss 6.57190943 epoch total loss 6.33533049\n",
      "Trained batch 788 batch loss 6.50407696 epoch total loss 6.33554459\n",
      "Trained batch 789 batch loss 6.72141314 epoch total loss 6.33603334\n",
      "Trained batch 790 batch loss 6.31887102 epoch total loss 6.33601189\n",
      "Trained batch 791 batch loss 6.25487328 epoch total loss 6.33590889\n",
      "Trained batch 792 batch loss 6.14558887 epoch total loss 6.33566856\n",
      "Trained batch 793 batch loss 6.28604364 epoch total loss 6.3356061\n",
      "Trained batch 794 batch loss 6.01998615 epoch total loss 6.33520889\n",
      "Trained batch 795 batch loss 6.16656256 epoch total loss 6.3349967\n",
      "Trained batch 796 batch loss 6.19165659 epoch total loss 6.33481693\n",
      "Trained batch 797 batch loss 6.46744537 epoch total loss 6.33498287\n",
      "Trained batch 798 batch loss 6.9010067 epoch total loss 6.33569193\n",
      "Trained batch 799 batch loss 7.02443361 epoch total loss 6.33655405\n",
      "Trained batch 800 batch loss 7.03248072 epoch total loss 6.33742428\n",
      "Trained batch 801 batch loss 6.70274353 epoch total loss 6.33788\n",
      "Trained batch 802 batch loss 6.34600973 epoch total loss 6.33789062\n",
      "Trained batch 803 batch loss 6.73430157 epoch total loss 6.33838415\n",
      "Trained batch 804 batch loss 6.57666111 epoch total loss 6.33868074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 805 batch loss 5.81675434 epoch total loss 6.33803272\n",
      "Trained batch 806 batch loss 5.39764738 epoch total loss 6.33686543\n",
      "Trained batch 807 batch loss 5.59097958 epoch total loss 6.33594131\n",
      "Trained batch 808 batch loss 6.0912962 epoch total loss 6.33563852\n",
      "Trained batch 809 batch loss 6.52542257 epoch total loss 6.33587313\n",
      "Trained batch 810 batch loss 6.4840889 epoch total loss 6.33605576\n",
      "Trained batch 811 batch loss 6.34078455 epoch total loss 6.33606148\n",
      "Trained batch 812 batch loss 6.3164916 epoch total loss 6.33603716\n",
      "Trained batch 813 batch loss 6.46254158 epoch total loss 6.33619261\n",
      "Trained batch 814 batch loss 6.47539711 epoch total loss 6.33636379\n",
      "Trained batch 815 batch loss 5.78328037 epoch total loss 6.33568525\n",
      "Trained batch 816 batch loss 6.36610937 epoch total loss 6.33572245\n",
      "Trained batch 817 batch loss 6.33344221 epoch total loss 6.33572\n",
      "Trained batch 818 batch loss 6.19208956 epoch total loss 6.33554411\n",
      "Trained batch 819 batch loss 6.22719479 epoch total loss 6.33541155\n",
      "Trained batch 820 batch loss 6.54789114 epoch total loss 6.33567095\n",
      "Trained batch 821 batch loss 6.36839485 epoch total loss 6.33571053\n",
      "Trained batch 822 batch loss 6.17288542 epoch total loss 6.33551216\n",
      "Trained batch 823 batch loss 6.38702 epoch total loss 6.3355751\n",
      "Trained batch 824 batch loss 6.3689537 epoch total loss 6.33561563\n",
      "Trained batch 825 batch loss 6.34149075 epoch total loss 6.33562279\n",
      "Trained batch 826 batch loss 6.46340799 epoch total loss 6.33577728\n",
      "Trained batch 827 batch loss 6.50695086 epoch total loss 6.33598423\n",
      "Trained batch 828 batch loss 6.56130791 epoch total loss 6.3362565\n",
      "Trained batch 829 batch loss 6.3519516 epoch total loss 6.33627558\n",
      "Trained batch 830 batch loss 6.41830349 epoch total loss 6.33637476\n",
      "Trained batch 831 batch loss 6.42044449 epoch total loss 6.33647585\n",
      "Trained batch 832 batch loss 6.12150908 epoch total loss 6.3362174\n",
      "Trained batch 833 batch loss 6.35384941 epoch total loss 6.33623886\n",
      "Trained batch 834 batch loss 5.93479967 epoch total loss 6.33575726\n",
      "Trained batch 835 batch loss 5.99499 epoch total loss 6.33534908\n",
      "Trained batch 836 batch loss 6.38173771 epoch total loss 6.33540487\n",
      "Trained batch 837 batch loss 6.0750823 epoch total loss 6.33509398\n",
      "Trained batch 838 batch loss 6.29739 epoch total loss 6.33504915\n",
      "Trained batch 839 batch loss 6.13794041 epoch total loss 6.33481407\n",
      "Trained batch 840 batch loss 6.20692492 epoch total loss 6.33466196\n",
      "Trained batch 841 batch loss 5.83896065 epoch total loss 6.33407259\n",
      "Trained batch 842 batch loss 6.29537392 epoch total loss 6.33402681\n",
      "Trained batch 843 batch loss 6.24663305 epoch total loss 6.33392286\n",
      "Trained batch 844 batch loss 6.09479189 epoch total loss 6.33363962\n",
      "Trained batch 845 batch loss 6.46785164 epoch total loss 6.33379841\n",
      "Trained batch 846 batch loss 6.86117268 epoch total loss 6.33442163\n",
      "Trained batch 847 batch loss 6.90344715 epoch total loss 6.3350935\n",
      "Trained batch 848 batch loss 6.80555058 epoch total loss 6.33564854\n",
      "Trained batch 849 batch loss 6.84329224 epoch total loss 6.33624649\n",
      "Trained batch 850 batch loss 6.28505373 epoch total loss 6.33618641\n",
      "Trained batch 851 batch loss 6.18745708 epoch total loss 6.33601141\n",
      "Trained batch 852 batch loss 6.37884903 epoch total loss 6.33606195\n",
      "Trained batch 853 batch loss 6.35047579 epoch total loss 6.33607912\n",
      "Trained batch 854 batch loss 6.66213322 epoch total loss 6.33646059\n",
      "Trained batch 855 batch loss 6.57435894 epoch total loss 6.33673859\n",
      "Trained batch 856 batch loss 6.30734158 epoch total loss 6.33670425\n",
      "Trained batch 857 batch loss 6.26297045 epoch total loss 6.33661842\n",
      "Trained batch 858 batch loss 6.44087029 epoch total loss 6.33674\n",
      "Trained batch 859 batch loss 6.43818617 epoch total loss 6.3368578\n",
      "Trained batch 860 batch loss 6.23634148 epoch total loss 6.33674097\n",
      "Trained batch 861 batch loss 6.61122608 epoch total loss 6.33706\n",
      "Trained batch 862 batch loss 6.59703 epoch total loss 6.33736134\n",
      "Trained batch 863 batch loss 6.42032766 epoch total loss 6.33745766\n",
      "Trained batch 864 batch loss 6.1711874 epoch total loss 6.33726549\n",
      "Trained batch 865 batch loss 6.24778509 epoch total loss 6.33716202\n",
      "Trained batch 866 batch loss 6.04141092 epoch total loss 6.3368206\n",
      "Trained batch 867 batch loss 5.35207081 epoch total loss 6.33568478\n",
      "Trained batch 868 batch loss 6.22648573 epoch total loss 6.33555889\n",
      "Trained batch 869 batch loss 6.25384903 epoch total loss 6.33546495\n",
      "Trained batch 870 batch loss 6.25580215 epoch total loss 6.3353734\n",
      "Trained batch 871 batch loss 6.31216526 epoch total loss 6.3353467\n",
      "Trained batch 872 batch loss 6.47119904 epoch total loss 6.33550262\n",
      "Trained batch 873 batch loss 6.36586094 epoch total loss 6.33553696\n",
      "Trained batch 874 batch loss 6.28148222 epoch total loss 6.33547497\n",
      "Trained batch 875 batch loss 6.44574594 epoch total loss 6.33560085\n",
      "Trained batch 876 batch loss 6.15835476 epoch total loss 6.33539867\n",
      "Trained batch 877 batch loss 6.3727808 epoch total loss 6.33544064\n",
      "Trained batch 878 batch loss 6.4656415 epoch total loss 6.33558941\n",
      "Trained batch 879 batch loss 6.37465382 epoch total loss 6.33563375\n",
      "Trained batch 880 batch loss 6.25820684 epoch total loss 6.33554554\n",
      "Trained batch 881 batch loss 6.48174763 epoch total loss 6.33571196\n",
      "Trained batch 882 batch loss 6.6605711 epoch total loss 6.33608055\n",
      "Trained batch 883 batch loss 6.61002302 epoch total loss 6.3363905\n",
      "Trained batch 884 batch loss 6.82441473 epoch total loss 6.3369422\n",
      "Trained batch 885 batch loss 6.66608238 epoch total loss 6.33731413\n",
      "Trained batch 886 batch loss 6.33522797 epoch total loss 6.33731174\n",
      "Trained batch 887 batch loss 6.4248848 epoch total loss 6.33741045\n",
      "Trained batch 888 batch loss 6.62314367 epoch total loss 6.33773232\n",
      "Trained batch 889 batch loss 6.71496296 epoch total loss 6.33815622\n",
      "Trained batch 890 batch loss 6.56028652 epoch total loss 6.33840561\n",
      "Trained batch 891 batch loss 6.21370506 epoch total loss 6.3382659\n",
      "Trained batch 892 batch loss 6.03075266 epoch total loss 6.33792114\n",
      "Trained batch 893 batch loss 6.38368511 epoch total loss 6.33797264\n",
      "Trained batch 894 batch loss 6.56124306 epoch total loss 6.33822203\n",
      "Trained batch 895 batch loss 6.65775537 epoch total loss 6.33857918\n",
      "Trained batch 896 batch loss 6.32021093 epoch total loss 6.33855867\n",
      "Trained batch 897 batch loss 6.26543665 epoch total loss 6.33847761\n",
      "Trained batch 898 batch loss 6.26043701 epoch total loss 6.33839035\n",
      "Trained batch 899 batch loss 6.06368065 epoch total loss 6.3380847\n",
      "Trained batch 900 batch loss 6.40958929 epoch total loss 6.33816385\n",
      "Trained batch 901 batch loss 6.40516806 epoch total loss 6.33823872\n",
      "Trained batch 902 batch loss 6.02562571 epoch total loss 6.33789158\n",
      "Trained batch 903 batch loss 6.62617207 epoch total loss 6.33821058\n",
      "Trained batch 904 batch loss 6.3465929 epoch total loss 6.33822\n",
      "Trained batch 905 batch loss 6.83731 epoch total loss 6.33877182\n",
      "Trained batch 906 batch loss 6.25959492 epoch total loss 6.33868456\n",
      "Trained batch 907 batch loss 5.78353786 epoch total loss 6.33807278\n",
      "Trained batch 908 batch loss 6.25071144 epoch total loss 6.33797598\n",
      "Trained batch 909 batch loss 6.46915102 epoch total loss 6.33812046\n",
      "Trained batch 910 batch loss 6.43220568 epoch total loss 6.33822393\n",
      "Trained batch 911 batch loss 6.21765471 epoch total loss 6.33809185\n",
      "Trained batch 912 batch loss 6.37756062 epoch total loss 6.33813477\n",
      "Trained batch 913 batch loss 6.50918245 epoch total loss 6.33832216\n",
      "Trained batch 914 batch loss 6.39986515 epoch total loss 6.3383894\n",
      "Trained batch 915 batch loss 6.50838232 epoch total loss 6.33857536\n",
      "Trained batch 916 batch loss 6.54264784 epoch total loss 6.33879805\n",
      "Trained batch 917 batch loss 6.4707365 epoch total loss 6.33894157\n",
      "Trained batch 918 batch loss 6.30700684 epoch total loss 6.33890724\n",
      "Trained batch 919 batch loss 6.44543314 epoch total loss 6.33902264\n",
      "Trained batch 920 batch loss 6.64692068 epoch total loss 6.33935738\n",
      "Trained batch 921 batch loss 6.65791512 epoch total loss 6.33970308\n",
      "Trained batch 922 batch loss 6.44903 epoch total loss 6.33982182\n",
      "Trained batch 923 batch loss 5.85213232 epoch total loss 6.33929348\n",
      "Trained batch 924 batch loss 6.19353867 epoch total loss 6.33913565\n",
      "Trained batch 925 batch loss 6.58127832 epoch total loss 6.33939695\n",
      "Trained batch 926 batch loss 6.48273468 epoch total loss 6.33955193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 927 batch loss 6.35815144 epoch total loss 6.33957195\n",
      "Trained batch 928 batch loss 6.45070553 epoch total loss 6.33969164\n",
      "Trained batch 929 batch loss 6.6190052 epoch total loss 6.33999252\n",
      "Trained batch 930 batch loss 6.57130432 epoch total loss 6.34024143\n",
      "Trained batch 931 batch loss 6.49574852 epoch total loss 6.34040785\n",
      "Trained batch 932 batch loss 6.5383873 epoch total loss 6.34062052\n",
      "Trained batch 933 batch loss 6.40160942 epoch total loss 6.34068584\n",
      "Trained batch 934 batch loss 6.10075521 epoch total loss 6.34042883\n",
      "Trained batch 935 batch loss 6.35915518 epoch total loss 6.34044886\n",
      "Trained batch 936 batch loss 6.24569178 epoch total loss 6.34034777\n",
      "Trained batch 937 batch loss 6.02899933 epoch total loss 6.34001541\n",
      "Trained batch 938 batch loss 5.79881859 epoch total loss 6.33943844\n",
      "Trained batch 939 batch loss 6.38237906 epoch total loss 6.33948374\n",
      "Trained batch 940 batch loss 6.02657557 epoch total loss 6.33915091\n",
      "Trained batch 941 batch loss 6.11644173 epoch total loss 6.33891392\n",
      "Trained batch 942 batch loss 5.87632322 epoch total loss 6.33842278\n",
      "Trained batch 943 batch loss 6.13547897 epoch total loss 6.33820772\n",
      "Trained batch 944 batch loss 6.03036165 epoch total loss 6.33788109\n",
      "Trained batch 945 batch loss 6.8191328 epoch total loss 6.33839083\n",
      "Trained batch 946 batch loss 6.41880846 epoch total loss 6.33847618\n",
      "Trained batch 947 batch loss 6.53805 epoch total loss 6.33868694\n",
      "Trained batch 948 batch loss 5.85689211 epoch total loss 6.33817863\n",
      "Trained batch 949 batch loss 6.20578861 epoch total loss 6.33803892\n",
      "Trained batch 950 batch loss 6.40072775 epoch total loss 6.33810472\n",
      "Trained batch 951 batch loss 6.07663679 epoch total loss 6.33783\n",
      "Trained batch 952 batch loss 6.4077363 epoch total loss 6.3379035\n",
      "Trained batch 953 batch loss 5.7537117 epoch total loss 6.33729076\n",
      "Trained batch 954 batch loss 6.3482852 epoch total loss 6.33730221\n",
      "Trained batch 955 batch loss 5.87299776 epoch total loss 6.33681583\n",
      "Trained batch 956 batch loss 5.86657667 epoch total loss 6.33632421\n",
      "Trained batch 957 batch loss 6.70289803 epoch total loss 6.33670759\n",
      "Trained batch 958 batch loss 6.51390028 epoch total loss 6.33689213\n",
      "Trained batch 959 batch loss 6.34558153 epoch total loss 6.33690119\n",
      "Trained batch 960 batch loss 6.22774 epoch total loss 6.33678722\n",
      "Trained batch 961 batch loss 6.05333948 epoch total loss 6.33649254\n",
      "Trained batch 962 batch loss 6.0765 epoch total loss 6.33622217\n",
      "Trained batch 963 batch loss 6.00703526 epoch total loss 6.33588028\n",
      "Trained batch 964 batch loss 6.08912945 epoch total loss 6.33562469\n",
      "Trained batch 965 batch loss 6.06456852 epoch total loss 6.33534336\n",
      "Trained batch 966 batch loss 5.94755697 epoch total loss 6.33494234\n",
      "Trained batch 967 batch loss 6.10594702 epoch total loss 6.33470535\n",
      "Trained batch 968 batch loss 5.35733652 epoch total loss 6.33369589\n",
      "Trained batch 969 batch loss 6.31792784 epoch total loss 6.33367968\n",
      "Trained batch 970 batch loss 6.43933582 epoch total loss 6.33378839\n",
      "Trained batch 971 batch loss 6.03737497 epoch total loss 6.3334837\n",
      "Trained batch 972 batch loss 6.37080717 epoch total loss 6.33352184\n",
      "Trained batch 973 batch loss 6.55885935 epoch total loss 6.33375359\n",
      "Trained batch 974 batch loss 6.65431881 epoch total loss 6.3340826\n",
      "Trained batch 975 batch loss 6.30396795 epoch total loss 6.33405209\n",
      "Trained batch 976 batch loss 5.98814106 epoch total loss 6.3336978\n",
      "Trained batch 977 batch loss 6.32840252 epoch total loss 6.33369255\n",
      "Trained batch 978 batch loss 6.32268953 epoch total loss 6.33368111\n",
      "Trained batch 979 batch loss 6.2213788 epoch total loss 6.33356619\n",
      "Trained batch 980 batch loss 6.37073374 epoch total loss 6.33360434\n",
      "Trained batch 981 batch loss 6.54907799 epoch total loss 6.33382416\n",
      "Trained batch 982 batch loss 6.07713 epoch total loss 6.33356285\n",
      "Trained batch 983 batch loss 6.23155928 epoch total loss 6.3334589\n",
      "Trained batch 984 batch loss 5.58813858 epoch total loss 6.33270168\n",
      "Trained batch 985 batch loss 5.42086506 epoch total loss 6.33177614\n",
      "Trained batch 986 batch loss 5.20667124 epoch total loss 6.33063459\n",
      "Trained batch 987 batch loss 5.6791563 epoch total loss 6.32997465\n",
      "Trained batch 988 batch loss 6.58729506 epoch total loss 6.33023548\n",
      "Trained batch 989 batch loss 6.42073298 epoch total loss 6.33032703\n",
      "Trained batch 990 batch loss 6.0601449 epoch total loss 6.33005381\n",
      "Trained batch 991 batch loss 6.27564955 epoch total loss 6.32999945\n",
      "Trained batch 992 batch loss 6.50800753 epoch total loss 6.33017874\n",
      "Trained batch 993 batch loss 5.97509146 epoch total loss 6.32982111\n",
      "Trained batch 994 batch loss 5.69610739 epoch total loss 6.32918358\n",
      "Trained batch 995 batch loss 5.89621115 epoch total loss 6.32874823\n",
      "Trained batch 996 batch loss 5.95660591 epoch total loss 6.32837439\n",
      "Trained batch 997 batch loss 5.9715867 epoch total loss 6.32801676\n",
      "Trained batch 998 batch loss 6.50441217 epoch total loss 6.32819366\n",
      "Trained batch 999 batch loss 6.29586744 epoch total loss 6.32816124\n",
      "Trained batch 1000 batch loss 6.1740675 epoch total loss 6.32800674\n",
      "Trained batch 1001 batch loss 6.06352186 epoch total loss 6.32774258\n",
      "Trained batch 1002 batch loss 6.16293764 epoch total loss 6.32757807\n",
      "Trained batch 1003 batch loss 6.54384708 epoch total loss 6.32779408\n",
      "Trained batch 1004 batch loss 6.93345404 epoch total loss 6.32839727\n",
      "Trained batch 1005 batch loss 6.51668644 epoch total loss 6.32858467\n",
      "Trained batch 1006 batch loss 7.28555202 epoch total loss 6.32953596\n",
      "Trained batch 1007 batch loss 6.45355511 epoch total loss 6.32965899\n",
      "Trained batch 1008 batch loss 6.54078579 epoch total loss 6.32986879\n",
      "Trained batch 1009 batch loss 6.58301783 epoch total loss 6.33011961\n",
      "Trained batch 1010 batch loss 6.50063181 epoch total loss 6.33028841\n",
      "Trained batch 1011 batch loss 6.1537962 epoch total loss 6.33011389\n",
      "Trained batch 1012 batch loss 6.28796768 epoch total loss 6.3300724\n",
      "Trained batch 1013 batch loss 6.54641962 epoch total loss 6.33028603\n",
      "Trained batch 1014 batch loss 6.74848413 epoch total loss 6.33069849\n",
      "Trained batch 1015 batch loss 6.80763149 epoch total loss 6.33116817\n",
      "Trained batch 1016 batch loss 6.39583778 epoch total loss 6.33123207\n",
      "Trained batch 1017 batch loss 6.21361732 epoch total loss 6.3311162\n",
      "Trained batch 1018 batch loss 6.15828705 epoch total loss 6.33094645\n",
      "Trained batch 1019 batch loss 6.23073864 epoch total loss 6.33084822\n",
      "Trained batch 1020 batch loss 6.26817322 epoch total loss 6.33078671\n",
      "Trained batch 1021 batch loss 6.4138937 epoch total loss 6.33086824\n",
      "Trained batch 1022 batch loss 5.96981049 epoch total loss 6.33051491\n",
      "Trained batch 1023 batch loss 5.81509781 epoch total loss 6.33001089\n",
      "Trained batch 1024 batch loss 5.62696552 epoch total loss 6.32932425\n",
      "Trained batch 1025 batch loss 5.63071871 epoch total loss 6.32864285\n",
      "Trained batch 1026 batch loss 5.8806715 epoch total loss 6.32820654\n",
      "Trained batch 1027 batch loss 6.27872181 epoch total loss 6.32815838\n",
      "Trained batch 1028 batch loss 6.19638348 epoch total loss 6.32803\n",
      "Trained batch 1029 batch loss 6.49522 epoch total loss 6.32819223\n",
      "Trained batch 1030 batch loss 6.3562603 epoch total loss 6.32822\n",
      "Trained batch 1031 batch loss 6.20491791 epoch total loss 6.3281\n",
      "Trained batch 1032 batch loss 6.20392704 epoch total loss 6.32798\n",
      "Trained batch 1033 batch loss 6.32942677 epoch total loss 6.32798195\n",
      "Trained batch 1034 batch loss 5.7798624 epoch total loss 6.32745171\n",
      "Trained batch 1035 batch loss 5.75184488 epoch total loss 6.32689571\n",
      "Trained batch 1036 batch loss 6.24012 epoch total loss 6.32681179\n",
      "Trained batch 1037 batch loss 6.53016663 epoch total loss 6.32700825\n",
      "Trained batch 1038 batch loss 6.46540499 epoch total loss 6.32714128\n",
      "Trained batch 1039 batch loss 6.44293976 epoch total loss 6.32725286\n",
      "Trained batch 1040 batch loss 6.33574295 epoch total loss 6.32726097\n",
      "Trained batch 1041 batch loss 6.50814152 epoch total loss 6.32743502\n",
      "Trained batch 1042 batch loss 6.3291564 epoch total loss 6.32743645\n",
      "Trained batch 1043 batch loss 6.4911437 epoch total loss 6.3275938\n",
      "Trained batch 1044 batch loss 6.09982443 epoch total loss 6.32737541\n",
      "Trained batch 1045 batch loss 6.42059278 epoch total loss 6.3274641\n",
      "Trained batch 1046 batch loss 6.03691196 epoch total loss 6.32718658\n",
      "Trained batch 1047 batch loss 6.032372 epoch total loss 6.32690477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1048 batch loss 6.14784622 epoch total loss 6.32673407\n",
      "Trained batch 1049 batch loss 6.25450897 epoch total loss 6.3266654\n",
      "Trained batch 1050 batch loss 6.11369753 epoch total loss 6.32646275\n",
      "Trained batch 1051 batch loss 6.34093809 epoch total loss 6.3264761\n",
      "Trained batch 1052 batch loss 6.64925861 epoch total loss 6.32678318\n",
      "Trained batch 1053 batch loss 6.23047829 epoch total loss 6.32669163\n",
      "Trained batch 1054 batch loss 6.37746096 epoch total loss 6.32674\n",
      "Trained batch 1055 batch loss 6.71352863 epoch total loss 6.32710648\n",
      "Trained batch 1056 batch loss 6.49826813 epoch total loss 6.32726812\n",
      "Trained batch 1057 batch loss 6.09796572 epoch total loss 6.32705164\n",
      "Trained batch 1058 batch loss 6.1714654 epoch total loss 6.3269043\n",
      "Trained batch 1059 batch loss 6.73865366 epoch total loss 6.3272934\n",
      "Trained batch 1060 batch loss 6.32741785 epoch total loss 6.3272934\n",
      "Trained batch 1061 batch loss 6.58141232 epoch total loss 6.32753325\n",
      "Trained batch 1062 batch loss 7.11655521 epoch total loss 6.32827616\n",
      "Trained batch 1063 batch loss 6.43795681 epoch total loss 6.32837963\n",
      "Trained batch 1064 batch loss 6.2237854 epoch total loss 6.32828093\n",
      "Trained batch 1065 batch loss 6.07720089 epoch total loss 6.32804537\n",
      "Trained batch 1066 batch loss 6.19424 epoch total loss 6.32792\n",
      "Trained batch 1067 batch loss 6.07999849 epoch total loss 6.32768774\n",
      "Trained batch 1068 batch loss 6.09103823 epoch total loss 6.32746553\n",
      "Trained batch 1069 batch loss 6.2778244 epoch total loss 6.32741928\n",
      "Trained batch 1070 batch loss 6.27766418 epoch total loss 6.32737303\n",
      "Trained batch 1071 batch loss 6.71930599 epoch total loss 6.32773876\n",
      "Trained batch 1072 batch loss 5.83575249 epoch total loss 6.32728\n",
      "Trained batch 1073 batch loss 5.41135883 epoch total loss 6.32642603\n",
      "Trained batch 1074 batch loss 5.89051819 epoch total loss 6.32602072\n",
      "Trained batch 1075 batch loss 5.85011435 epoch total loss 6.32557774\n",
      "Trained batch 1076 batch loss 5.82446384 epoch total loss 6.32511234\n",
      "Trained batch 1077 batch loss 6.05980301 epoch total loss 6.32486582\n",
      "Trained batch 1078 batch loss 6.21765423 epoch total loss 6.32476616\n",
      "Trained batch 1079 batch loss 6.3106575 epoch total loss 6.32475328\n",
      "Trained batch 1080 batch loss 6.32976437 epoch total loss 6.32475758\n",
      "Trained batch 1081 batch loss 6.41322517 epoch total loss 6.32483959\n",
      "Trained batch 1082 batch loss 6.50600529 epoch total loss 6.32500648\n",
      "Trained batch 1083 batch loss 6.93371439 epoch total loss 6.32556868\n",
      "Trained batch 1084 batch loss 6.87715197 epoch total loss 6.32607746\n",
      "Trained batch 1085 batch loss 6.697227 epoch total loss 6.32641935\n",
      "Trained batch 1086 batch loss 6.65031767 epoch total loss 6.32671785\n",
      "Trained batch 1087 batch loss 6.65962505 epoch total loss 6.32702398\n",
      "Trained batch 1088 batch loss 6.36364937 epoch total loss 6.32705784\n",
      "Trained batch 1089 batch loss 6.65275145 epoch total loss 6.32735682\n",
      "Trained batch 1090 batch loss 6.49206 epoch total loss 6.32750797\n",
      "Trained batch 1091 batch loss 6.5326395 epoch total loss 6.32769632\n",
      "Trained batch 1092 batch loss 6.59387159 epoch total loss 6.32794\n",
      "Trained batch 1093 batch loss 6.54108906 epoch total loss 6.32813501\n",
      "Trained batch 1094 batch loss 6.40355444 epoch total loss 6.32820368\n",
      "Trained batch 1095 batch loss 6.56746578 epoch total loss 6.32842207\n",
      "Trained batch 1096 batch loss 6.56449 epoch total loss 6.32863712\n",
      "Trained batch 1097 batch loss 6.34005356 epoch total loss 6.32864761\n",
      "Trained batch 1098 batch loss 6.32190657 epoch total loss 6.32864141\n",
      "Trained batch 1099 batch loss 6.35426807 epoch total loss 6.32866478\n",
      "Trained batch 1100 batch loss 6.32158422 epoch total loss 6.32865858\n",
      "Trained batch 1101 batch loss 6.38956451 epoch total loss 6.32871389\n",
      "Trained batch 1102 batch loss 6.4792738 epoch total loss 6.32885075\n",
      "Trained batch 1103 batch loss 6.34757948 epoch total loss 6.32886791\n",
      "Trained batch 1104 batch loss 6.40284824 epoch total loss 6.32893467\n",
      "Trained batch 1105 batch loss 6.26457596 epoch total loss 6.3288765\n",
      "Trained batch 1106 batch loss 6.35401058 epoch total loss 6.32889938\n",
      "Trained batch 1107 batch loss 6.28667784 epoch total loss 6.32886124\n",
      "Trained batch 1108 batch loss 6.50544786 epoch total loss 6.3290205\n",
      "Trained batch 1109 batch loss 6.22946358 epoch total loss 6.32893085\n",
      "Trained batch 1110 batch loss 6.49676132 epoch total loss 6.32908154\n",
      "Trained batch 1111 batch loss 6.81014729 epoch total loss 6.3295145\n",
      "Trained batch 1112 batch loss 7.15940857 epoch total loss 6.33026075\n",
      "Trained batch 1113 batch loss 6.80152416 epoch total loss 6.33068419\n",
      "Trained batch 1114 batch loss 5.81920052 epoch total loss 6.33022547\n",
      "Trained batch 1115 batch loss 6.09394026 epoch total loss 6.33001328\n",
      "Trained batch 1116 batch loss 6.48232651 epoch total loss 6.33014965\n",
      "Trained batch 1117 batch loss 6.15267467 epoch total loss 6.32999134\n",
      "Trained batch 1118 batch loss 6.44570684 epoch total loss 6.33009481\n",
      "Trained batch 1119 batch loss 6.45016 epoch total loss 6.3302021\n",
      "Trained batch 1120 batch loss 6.27506113 epoch total loss 6.33015251\n",
      "Trained batch 1121 batch loss 6.38803148 epoch total loss 6.33020449\n",
      "Trained batch 1122 batch loss 6.20842075 epoch total loss 6.33009577\n",
      "Trained batch 1123 batch loss 6.16373873 epoch total loss 6.32994747\n",
      "Trained batch 1124 batch loss 6.30908203 epoch total loss 6.32992935\n",
      "Trained batch 1125 batch loss 6.23556948 epoch total loss 6.32984495\n",
      "Trained batch 1126 batch loss 6.26421 epoch total loss 6.32978678\n",
      "Trained batch 1127 batch loss 6.16722965 epoch total loss 6.3296423\n",
      "Trained batch 1128 batch loss 5.86192322 epoch total loss 6.32922745\n",
      "Trained batch 1129 batch loss 5.41184807 epoch total loss 6.32841492\n",
      "Trained batch 1130 batch loss 6.16783237 epoch total loss 6.32827282\n",
      "Trained batch 1131 batch loss 6.40408134 epoch total loss 6.32834\n",
      "Trained batch 1132 batch loss 6.46850348 epoch total loss 6.32846355\n",
      "Trained batch 1133 batch loss 6.72983694 epoch total loss 6.32881784\n",
      "Trained batch 1134 batch loss 6.38523197 epoch total loss 6.32886791\n",
      "Trained batch 1135 batch loss 7.12895155 epoch total loss 6.32957268\n",
      "Trained batch 1136 batch loss 6.77441549 epoch total loss 6.32996416\n",
      "Trained batch 1137 batch loss 6.54814768 epoch total loss 6.33015633\n",
      "Trained batch 1138 batch loss 6.97435045 epoch total loss 6.33072233\n",
      "Trained batch 1139 batch loss 6.60703278 epoch total loss 6.33096457\n",
      "Trained batch 1140 batch loss 6.82872295 epoch total loss 6.33140135\n",
      "Trained batch 1141 batch loss 6.16819525 epoch total loss 6.33125782\n",
      "Trained batch 1142 batch loss 5.98694563 epoch total loss 6.33095646\n",
      "Trained batch 1143 batch loss 5.70379591 epoch total loss 6.33040762\n",
      "Trained batch 1144 batch loss 6.02341747 epoch total loss 6.33013916\n",
      "Trained batch 1145 batch loss 6.67823219 epoch total loss 6.33044338\n",
      "Trained batch 1146 batch loss 6.30943203 epoch total loss 6.33042479\n",
      "Trained batch 1147 batch loss 6.35157156 epoch total loss 6.33044338\n",
      "Trained batch 1148 batch loss 6.62724161 epoch total loss 6.3307023\n",
      "Trained batch 1149 batch loss 6.10899448 epoch total loss 6.33050919\n",
      "Trained batch 1150 batch loss 6.56373453 epoch total loss 6.33071184\n",
      "Trained batch 1151 batch loss 6.93550968 epoch total loss 6.33123732\n",
      "Trained batch 1152 batch loss 6.83768702 epoch total loss 6.33167744\n",
      "Trained batch 1153 batch loss 6.24637318 epoch total loss 6.33160353\n",
      "Trained batch 1154 batch loss 6.13327 epoch total loss 6.33143187\n",
      "Trained batch 1155 batch loss 6.23650742 epoch total loss 6.33134937\n",
      "Trained batch 1156 batch loss 6.40695238 epoch total loss 6.3314147\n",
      "Trained batch 1157 batch loss 6.63755083 epoch total loss 6.33167934\n",
      "Trained batch 1158 batch loss 6.42586279 epoch total loss 6.33176041\n",
      "Trained batch 1159 batch loss 6.528162 epoch total loss 6.33193\n",
      "Trained batch 1160 batch loss 6.41587734 epoch total loss 6.33200264\n",
      "Trained batch 1161 batch loss 6.04645157 epoch total loss 6.33175659\n",
      "Trained batch 1162 batch loss 6.43763638 epoch total loss 6.33184767\n",
      "Trained batch 1163 batch loss 6.59139919 epoch total loss 6.33207083\n",
      "Trained batch 1164 batch loss 6.61337042 epoch total loss 6.33231211\n",
      "Trained batch 1165 batch loss 6.59727907 epoch total loss 6.33253956\n",
      "Trained batch 1166 batch loss 6.48186398 epoch total loss 6.33266783\n",
      "Trained batch 1167 batch loss 6.37496662 epoch total loss 6.33270407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1168 batch loss 6.281528 epoch total loss 6.33266\n",
      "Trained batch 1169 batch loss 6.30064726 epoch total loss 6.33263302\n",
      "Trained batch 1170 batch loss 6.6487 epoch total loss 6.33290339\n",
      "Trained batch 1171 batch loss 6.17157316 epoch total loss 6.33276558\n",
      "Trained batch 1172 batch loss 6.22255421 epoch total loss 6.33267164\n",
      "Trained batch 1173 batch loss 6.68187141 epoch total loss 6.33296919\n",
      "Trained batch 1174 batch loss 6.42874336 epoch total loss 6.33305073\n",
      "Trained batch 1175 batch loss 6.32333803 epoch total loss 6.33304214\n",
      "Trained batch 1176 batch loss 6.62617779 epoch total loss 6.33329153\n",
      "Trained batch 1177 batch loss 6.57792807 epoch total loss 6.33349943\n",
      "Trained batch 1178 batch loss 6.44213 epoch total loss 6.33359146\n",
      "Trained batch 1179 batch loss 6.60707188 epoch total loss 6.3338232\n",
      "Trained batch 1180 batch loss 6.15531969 epoch total loss 6.33367205\n",
      "Trained batch 1181 batch loss 6.20584488 epoch total loss 6.3335638\n",
      "Trained batch 1182 batch loss 5.7446332 epoch total loss 6.33306551\n",
      "Trained batch 1183 batch loss 6.24461 epoch total loss 6.33299112\n",
      "Trained batch 1184 batch loss 6.21534681 epoch total loss 6.33289146\n",
      "Trained batch 1185 batch loss 6.75300312 epoch total loss 6.33324575\n",
      "Trained batch 1186 batch loss 6.20802546 epoch total loss 6.33314037\n",
      "Trained batch 1187 batch loss 6.42275906 epoch total loss 6.33321619\n",
      "Trained batch 1188 batch loss 6.49312973 epoch total loss 6.33335066\n",
      "Trained batch 1189 batch loss 6.28076696 epoch total loss 6.33330631\n",
      "Trained batch 1190 batch loss 6.43912315 epoch total loss 6.333395\n",
      "Trained batch 1191 batch loss 6.61886311 epoch total loss 6.33363485\n",
      "Trained batch 1192 batch loss 6.41862 epoch total loss 6.3337059\n",
      "Trained batch 1193 batch loss 6.26919508 epoch total loss 6.33365154\n",
      "Trained batch 1194 batch loss 6.48372889 epoch total loss 6.33377743\n",
      "Trained batch 1195 batch loss 5.94363 epoch total loss 6.33345127\n",
      "Trained batch 1196 batch loss 6.50326538 epoch total loss 6.33359337\n",
      "Trained batch 1197 batch loss 6.35930157 epoch total loss 6.33361483\n",
      "Trained batch 1198 batch loss 6.32275486 epoch total loss 6.33360577\n",
      "Trained batch 1199 batch loss 5.95480967 epoch total loss 6.33328962\n",
      "Trained batch 1200 batch loss 6.35897398 epoch total loss 6.33331108\n",
      "Trained batch 1201 batch loss 6.59443283 epoch total loss 6.33352804\n",
      "Trained batch 1202 batch loss 6.70950651 epoch total loss 6.33384085\n",
      "Trained batch 1203 batch loss 6.82956553 epoch total loss 6.33425283\n",
      "Trained batch 1204 batch loss 6.69059229 epoch total loss 6.33454895\n",
      "Trained batch 1205 batch loss 6.52643204 epoch total loss 6.33470821\n",
      "Trained batch 1206 batch loss 6.29532528 epoch total loss 6.33467531\n",
      "Trained batch 1207 batch loss 6.14851475 epoch total loss 6.33452129\n",
      "Trained batch 1208 batch loss 5.98179436 epoch total loss 6.33422947\n",
      "Trained batch 1209 batch loss 6.12194252 epoch total loss 6.33405399\n",
      "Trained batch 1210 batch loss 5.97296715 epoch total loss 6.33375549\n",
      "Trained batch 1211 batch loss 6.27186155 epoch total loss 6.33370447\n",
      "Trained batch 1212 batch loss 6.08968687 epoch total loss 6.33350325\n",
      "Trained batch 1213 batch loss 6.28423691 epoch total loss 6.33346272\n",
      "Trained batch 1214 batch loss 5.93428898 epoch total loss 6.3331337\n",
      "Trained batch 1215 batch loss 5.74315357 epoch total loss 6.33264828\n",
      "Trained batch 1216 batch loss 5.13557339 epoch total loss 6.33166361\n",
      "Trained batch 1217 batch loss 5.80242348 epoch total loss 6.33122873\n",
      "Trained batch 1218 batch loss 6.09181118 epoch total loss 6.33103228\n",
      "Trained batch 1219 batch loss 6.43123245 epoch total loss 6.33111429\n",
      "Trained batch 1220 batch loss 7.65880108 epoch total loss 6.33220243\n",
      "Trained batch 1221 batch loss 6.00275755 epoch total loss 6.33193302\n",
      "Trained batch 1222 batch loss 6.10011101 epoch total loss 6.33174324\n",
      "Trained batch 1223 batch loss 6.34625721 epoch total loss 6.33175516\n",
      "Trained batch 1224 batch loss 6.31862545 epoch total loss 6.33174419\n",
      "Trained batch 1225 batch loss 6.40839386 epoch total loss 6.33180666\n",
      "Trained batch 1226 batch loss 6.42169476 epoch total loss 6.33188\n",
      "Trained batch 1227 batch loss 6.41850901 epoch total loss 6.33195066\n",
      "Trained batch 1228 batch loss 6.58874512 epoch total loss 6.33216\n",
      "Trained batch 1229 batch loss 6.42602825 epoch total loss 6.33223677\n",
      "Trained batch 1230 batch loss 6.4063344 epoch total loss 6.33229685\n",
      "Trained batch 1231 batch loss 6.61119032 epoch total loss 6.33252335\n",
      "Trained batch 1232 batch loss 6.2545228 epoch total loss 6.33246\n",
      "Trained batch 1233 batch loss 6.4697876 epoch total loss 6.33257151\n",
      "Trained batch 1234 batch loss 6.62384319 epoch total loss 6.33280754\n",
      "Trained batch 1235 batch loss 6.20070314 epoch total loss 6.33270073\n",
      "Trained batch 1236 batch loss 5.75191689 epoch total loss 6.33223057\n",
      "Trained batch 1237 batch loss 6.39446211 epoch total loss 6.33228111\n",
      "Trained batch 1238 batch loss 6.41273737 epoch total loss 6.33234596\n",
      "Trained batch 1239 batch loss 6.1604495 epoch total loss 6.3322072\n",
      "Trained batch 1240 batch loss 6.3589325 epoch total loss 6.33222914\n",
      "Trained batch 1241 batch loss 6.58278131 epoch total loss 6.33243084\n",
      "Trained batch 1242 batch loss 6.41462946 epoch total loss 6.33249712\n",
      "Trained batch 1243 batch loss 6.85271597 epoch total loss 6.33291531\n",
      "Trained batch 1244 batch loss 5.79347181 epoch total loss 6.33248186\n",
      "Trained batch 1245 batch loss 6.00243616 epoch total loss 6.33221674\n",
      "Trained batch 1246 batch loss 6.24149895 epoch total loss 6.33214426\n",
      "Trained batch 1247 batch loss 6.34331036 epoch total loss 6.33215284\n",
      "Trained batch 1248 batch loss 6.35728216 epoch total loss 6.33217335\n",
      "Trained batch 1249 batch loss 6.71376371 epoch total loss 6.332479\n",
      "Trained batch 1250 batch loss 6.85888672 epoch total loss 6.3329\n",
      "Trained batch 1251 batch loss 7.10530186 epoch total loss 6.33351755\n",
      "Trained batch 1252 batch loss 6.92118216 epoch total loss 6.33398724\n",
      "Trained batch 1253 batch loss 6.6356082 epoch total loss 6.33422804\n",
      "Trained batch 1254 batch loss 5.91294956 epoch total loss 6.33389187\n",
      "Trained batch 1255 batch loss 5.18161201 epoch total loss 6.33297396\n",
      "Trained batch 1256 batch loss 5.50107622 epoch total loss 6.33231163\n",
      "Trained batch 1257 batch loss 5.33714914 epoch total loss 6.3315196\n",
      "Trained batch 1258 batch loss 6.01293945 epoch total loss 6.3312664\n",
      "Trained batch 1259 batch loss 6.26423931 epoch total loss 6.33121347\n",
      "Trained batch 1260 batch loss 6.11413193 epoch total loss 6.33104134\n",
      "Trained batch 1261 batch loss 6.21584463 epoch total loss 6.33095\n",
      "Trained batch 1262 batch loss 6.02268362 epoch total loss 6.33070517\n",
      "Trained batch 1263 batch loss 5.72232866 epoch total loss 6.33022356\n",
      "Trained batch 1264 batch loss 6.12774277 epoch total loss 6.33006334\n",
      "Trained batch 1265 batch loss 5.67364645 epoch total loss 6.32954454\n",
      "Trained batch 1266 batch loss 5.46807337 epoch total loss 6.32886457\n",
      "Trained batch 1267 batch loss 5.40745926 epoch total loss 6.32813692\n",
      "Trained batch 1268 batch loss 5.42800903 epoch total loss 6.32742739\n",
      "Trained batch 1269 batch loss 5.77277613 epoch total loss 6.32699\n",
      "Trained batch 1270 batch loss 5.77133322 epoch total loss 6.32655287\n",
      "Trained batch 1271 batch loss 5.99699354 epoch total loss 6.32629347\n",
      "Trained batch 1272 batch loss 6.17436218 epoch total loss 6.32617426\n",
      "Trained batch 1273 batch loss 5.69475651 epoch total loss 6.32567835\n",
      "Trained batch 1274 batch loss 6.03826141 epoch total loss 6.32545233\n",
      "Trained batch 1275 batch loss 5.9543314 epoch total loss 6.32516146\n",
      "Trained batch 1276 batch loss 5.91581059 epoch total loss 6.32484055\n",
      "Trained batch 1277 batch loss 6.43159866 epoch total loss 6.32492399\n",
      "Trained batch 1278 batch loss 6.61362648 epoch total loss 6.32515\n",
      "Trained batch 1279 batch loss 6.72189426 epoch total loss 6.32546043\n",
      "Trained batch 1280 batch loss 6.30324078 epoch total loss 6.32544279\n",
      "Trained batch 1281 batch loss 6.27750349 epoch total loss 6.32540512\n",
      "Trained batch 1282 batch loss 6.47231102 epoch total loss 6.32552\n",
      "Trained batch 1283 batch loss 6.36794758 epoch total loss 6.32555294\n",
      "Trained batch 1284 batch loss 5.93878031 epoch total loss 6.32525206\n",
      "Trained batch 1285 batch loss 5.33699036 epoch total loss 6.32448292\n",
      "Trained batch 1286 batch loss 6.06141949 epoch total loss 6.32427835\n",
      "Trained batch 1287 batch loss 6.3454361 epoch total loss 6.32429457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained batch 1288 batch loss 6.80986691 epoch total loss 6.32467175\n",
      "Trained batch 1289 batch loss 6.72774458 epoch total loss 6.32498455\n",
      "Trained batch 1290 batch loss 6.52591944 epoch total loss 6.32514\n",
      "Trained batch 1291 batch loss 6.5676918 epoch total loss 6.32532787\n",
      "Trained batch 1292 batch loss 6.62500286 epoch total loss 6.32556\n",
      "Trained batch 1293 batch loss 6.67137051 epoch total loss 6.3258276\n",
      "Trained batch 1294 batch loss 6.70490932 epoch total loss 6.32612038\n",
      "Trained batch 1295 batch loss 6.17400122 epoch total loss 6.32600307\n",
      "Trained batch 1296 batch loss 6.56779 epoch total loss 6.32618904\n",
      "Trained batch 1297 batch loss 6.38105822 epoch total loss 6.32623148\n",
      "Trained batch 1298 batch loss 6.65753269 epoch total loss 6.32648659\n",
      "Trained batch 1299 batch loss 6.38194752 epoch total loss 6.32652903\n",
      "Trained batch 1300 batch loss 6.46094704 epoch total loss 6.3266325\n",
      "Trained batch 1301 batch loss 6.26464176 epoch total loss 6.32658482\n",
      "Trained batch 1302 batch loss 6.55865145 epoch total loss 6.32676268\n",
      "Trained batch 1303 batch loss 6.67454195 epoch total loss 6.32703\n",
      "Trained batch 1304 batch loss 7.20833349 epoch total loss 6.32770538\n",
      "Trained batch 1305 batch loss 6.90542459 epoch total loss 6.32814837\n",
      "Trained batch 1306 batch loss 7.15992355 epoch total loss 6.32878542\n",
      "Trained batch 1307 batch loss 6.56770277 epoch total loss 6.32896805\n",
      "Trained batch 1308 batch loss 6.49174881 epoch total loss 6.3290925\n",
      "Trained batch 1309 batch loss 6.10208893 epoch total loss 6.32891941\n",
      "Trained batch 1310 batch loss 6.49287033 epoch total loss 6.32904482\n",
      "Trained batch 1311 batch loss 6.9670372 epoch total loss 6.32953119\n",
      "Trained batch 1312 batch loss 6.79143429 epoch total loss 6.3298831\n",
      "Trained batch 1313 batch loss 6.81834793 epoch total loss 6.33025503\n",
      "Trained batch 1314 batch loss 6.31364393 epoch total loss 6.33024216\n",
      "Trained batch 1315 batch loss 6.41760731 epoch total loss 6.33030891\n",
      "Trained batch 1316 batch loss 6.60795689 epoch total loss 6.33052063\n",
      "Trained batch 1317 batch loss 6.81134367 epoch total loss 6.33088541\n",
      "Trained batch 1318 batch loss 7.16907072 epoch total loss 6.33152151\n",
      "Trained batch 1319 batch loss 6.84348869 epoch total loss 6.33190966\n",
      "Trained batch 1320 batch loss 6.4279108 epoch total loss 6.33198261\n",
      "Trained batch 1321 batch loss 6.54635382 epoch total loss 6.33214426\n",
      "Trained batch 1322 batch loss 6.93872404 epoch total loss 6.33260298\n",
      "Trained batch 1323 batch loss 6.91614389 epoch total loss 6.33304405\n",
      "Trained batch 1324 batch loss 6.91997719 epoch total loss 6.33348703\n",
      "Trained batch 1325 batch loss 6.84944 epoch total loss 6.33387661\n",
      "Trained batch 1326 batch loss 6.61937666 epoch total loss 6.33409166\n",
      "Trained batch 1327 batch loss 6.55453062 epoch total loss 6.33425808\n",
      "Trained batch 1328 batch loss 6.29392958 epoch total loss 6.33422756\n",
      "Trained batch 1329 batch loss 6.35316515 epoch total loss 6.33424234\n",
      "Trained batch 1330 batch loss 6.69740343 epoch total loss 6.33451509\n",
      "Trained batch 1331 batch loss 6.65117502 epoch total loss 6.33475351\n",
      "Trained batch 1332 batch loss 7.01356745 epoch total loss 6.33526278\n",
      "Trained batch 1333 batch loss 7.0598197 epoch total loss 6.33580637\n",
      "Trained batch 1334 batch loss 6.57881975 epoch total loss 6.33598852\n",
      "Trained batch 1335 batch loss 6.66933346 epoch total loss 6.33623838\n",
      "Trained batch 1336 batch loss 6.56442404 epoch total loss 6.33640909\n",
      "Trained batch 1337 batch loss 6.11840916 epoch total loss 6.33624554\n",
      "Trained batch 1338 batch loss 6.30337715 epoch total loss 6.33622122\n",
      "Trained batch 1339 batch loss 6.28116226 epoch total loss 6.33618\n",
      "Trained batch 1340 batch loss 6.61497641 epoch total loss 6.33638859\n",
      "Trained batch 1341 batch loss 6.64238 epoch total loss 6.33661699\n",
      "Trained batch 1342 batch loss 6.46840096 epoch total loss 6.33671522\n",
      "Trained batch 1343 batch loss 6.32739782 epoch total loss 6.33670807\n",
      "Trained batch 1344 batch loss 6.47989416 epoch total loss 6.3368144\n",
      "Trained batch 1345 batch loss 6.51192284 epoch total loss 6.33694458\n",
      "Trained batch 1346 batch loss 6.29355 epoch total loss 6.33691263\n",
      "Trained batch 1347 batch loss 6.20277739 epoch total loss 6.33681345\n",
      "Trained batch 1348 batch loss 6.18530893 epoch total loss 6.33670092\n",
      "Trained batch 1349 batch loss 5.65517807 epoch total loss 6.33619595\n",
      "Trained batch 1350 batch loss 5.67170477 epoch total loss 6.33570385\n",
      "Trained batch 1351 batch loss 5.94934893 epoch total loss 6.33541775\n",
      "Trained batch 1352 batch loss 6.38645458 epoch total loss 6.33545589\n",
      "Trained batch 1353 batch loss 6.21356344 epoch total loss 6.33536577\n",
      "Trained batch 1354 batch loss 6.51436424 epoch total loss 6.33549833\n",
      "Trained batch 1355 batch loss 6.39002657 epoch total loss 6.33553839\n",
      "Trained batch 1356 batch loss 6.41162109 epoch total loss 6.33559465\n",
      "Trained batch 1357 batch loss 6.4357872 epoch total loss 6.33566856\n",
      "Trained batch 1358 batch loss 6.61125326 epoch total loss 6.33587122\n",
      "Trained batch 1359 batch loss 6.39915705 epoch total loss 6.33591795\n",
      "Trained batch 1360 batch loss 6.17165899 epoch total loss 6.33579731\n",
      "Trained batch 1361 batch loss 6.33573151 epoch total loss 6.33579779\n",
      "Trained batch 1362 batch loss 5.98196745 epoch total loss 6.33553791\n",
      "Trained batch 1363 batch loss 6.05463552 epoch total loss 6.33533192\n",
      "Trained batch 1364 batch loss 6.25494289 epoch total loss 6.33527327\n",
      "Trained batch 1365 batch loss 5.75714064 epoch total loss 6.33484936\n",
      "Trained batch 1366 batch loss 5.63234806 epoch total loss 6.33433533\n",
      "Trained batch 1367 batch loss 6.15397263 epoch total loss 6.33420372\n",
      "Trained batch 1368 batch loss 6.41814709 epoch total loss 6.33426476\n",
      "Trained batch 1369 batch loss 6.4690237 epoch total loss 6.33436298\n",
      "Trained batch 1370 batch loss 6.55919552 epoch total loss 6.33452749\n",
      "Trained batch 1371 batch loss 6.82858944 epoch total loss 6.3348875\n",
      "Trained batch 1372 batch loss 6.50894403 epoch total loss 6.33501434\n",
      "Trained batch 1373 batch loss 6.50355 epoch total loss 6.33513737\n",
      "Trained batch 1374 batch loss 6.2373538 epoch total loss 6.33506632\n",
      "Trained batch 1375 batch loss 6.04764843 epoch total loss 6.33485746\n",
      "Trained batch 1376 batch loss 6.17747927 epoch total loss 6.33474302\n",
      "Trained batch 1377 batch loss 6.34130526 epoch total loss 6.33474731\n",
      "Trained batch 1378 batch loss 6.59351778 epoch total loss 6.33493519\n",
      "Trained batch 1379 batch loss 6.55109692 epoch total loss 6.33509207\n",
      "Trained batch 1380 batch loss 7.10476685 epoch total loss 6.33564949\n",
      "Trained batch 1381 batch loss 7.10255718 epoch total loss 6.33620501\n",
      "Trained batch 1382 batch loss 6.63626671 epoch total loss 6.33642244\n",
      "Trained batch 1383 batch loss 6.98153305 epoch total loss 6.33688879\n",
      "Trained batch 1384 batch loss 7.28012657 epoch total loss 6.33757\n",
      "Trained batch 1385 batch loss 7.08130598 epoch total loss 6.33810711\n",
      "Trained batch 1386 batch loss 6.80557966 epoch total loss 6.33844423\n",
      "Trained batch 1387 batch loss 6.51224089 epoch total loss 6.33857\n",
      "Trained batch 1388 batch loss 6.19468832 epoch total loss 6.33846617\n",
      "Epoch 5 train loss 6.338466167449951\n",
      "Validated batch 1 batch loss 5.98299599\n",
      "Validated batch 2 batch loss 6.59778643\n",
      "Validated batch 3 batch loss 6.39613104\n",
      "Validated batch 4 batch loss 6.49372196\n",
      "Validated batch 5 batch loss 6.46429443\n",
      "Validated batch 6 batch loss 6.60715818\n",
      "Validated batch 7 batch loss 6.29624128\n",
      "Validated batch 8 batch loss 6.59958935\n",
      "Validated batch 9 batch loss 6.15371323\n",
      "Validated batch 10 batch loss 6.45545101\n",
      "Validated batch 11 batch loss 6.35568\n",
      "Validated batch 12 batch loss 5.70532131\n",
      "Validated batch 13 batch loss 5.97907686\n",
      "Validated batch 14 batch loss 6.56417608\n",
      "Validated batch 15 batch loss 6.43000507\n",
      "Validated batch 16 batch loss 6.12593317\n",
      "Validated batch 17 batch loss 6.4766345\n",
      "Validated batch 18 batch loss 6.53343439\n",
      "Validated batch 19 batch loss 6.41494513\n",
      "Validated batch 20 batch loss 6.56517172\n",
      "Validated batch 21 batch loss 6.52931261\n",
      "Validated batch 22 batch loss 6.23161173\n",
      "Validated batch 23 batch loss 6.00035477\n",
      "Validated batch 24 batch loss 6.71918631\n",
      "Validated batch 25 batch loss 6.47586203\n",
      "Validated batch 26 batch loss 6.40672541\n",
      "Validated batch 27 batch loss 6.27138519\n",
      "Validated batch 28 batch loss 6.36915112\n",
      "Validated batch 29 batch loss 6.46930552\n",
      "Validated batch 30 batch loss 6.40363026\n",
      "Validated batch 31 batch loss 5.99260664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validated batch 32 batch loss 6.23193645\n",
      "Validated batch 33 batch loss 6.19748354\n",
      "Validated batch 34 batch loss 6.3591671\n",
      "Validated batch 35 batch loss 6.0985527\n",
      "Validated batch 36 batch loss 6.20966291\n",
      "Validated batch 37 batch loss 6.06431341\n",
      "Validated batch 38 batch loss 6.28218174\n",
      "Validated batch 39 batch loss 6.39624119\n",
      "Validated batch 40 batch loss 6.57802057\n",
      "Validated batch 41 batch loss 6.514884\n",
      "Validated batch 42 batch loss 6.95171\n",
      "Validated batch 43 batch loss 7.11239481\n",
      "Validated batch 44 batch loss 6.70531845\n",
      "Validated batch 45 batch loss 6.31250525\n",
      "Validated batch 46 batch loss 5.99036264\n",
      "Validated batch 47 batch loss 6.1888814\n",
      "Validated batch 48 batch loss 6.34572697\n",
      "Validated batch 49 batch loss 6.13544703\n",
      "Validated batch 50 batch loss 6.86738491\n",
      "Validated batch 51 batch loss 6.51157475\n",
      "Validated batch 52 batch loss 6.4515276\n",
      "Validated batch 53 batch loss 6.46460676\n",
      "Validated batch 54 batch loss 6.44105816\n",
      "Validated batch 55 batch loss 6.50763702\n",
      "Validated batch 56 batch loss 6.5416851\n",
      "Validated batch 57 batch loss 6.87506437\n",
      "Validated batch 58 batch loss 6.50633717\n",
      "Validated batch 59 batch loss 6.1786027\n",
      "Validated batch 60 batch loss 6.53052664\n",
      "Validated batch 61 batch loss 6.23478317\n",
      "Validated batch 62 batch loss 6.40056467\n",
      "Validated batch 63 batch loss 6.64550686\n",
      "Validated batch 64 batch loss 5.60614395\n",
      "Validated batch 65 batch loss 6.3522253\n",
      "Validated batch 66 batch loss 6.40008831\n",
      "Validated batch 67 batch loss 6.29887342\n",
      "Validated batch 68 batch loss 6.84584427\n",
      "Validated batch 69 batch loss 6.14726973\n",
      "Validated batch 70 batch loss 6.38823128\n",
      "Validated batch 71 batch loss 6.33988285\n",
      "Validated batch 72 batch loss 6.11588383\n",
      "Validated batch 73 batch loss 6.0536747\n",
      "Validated batch 74 batch loss 6.43332863\n",
      "Validated batch 75 batch loss 6.2999239\n",
      "Validated batch 76 batch loss 6.41413879\n",
      "Validated batch 77 batch loss 6.25793839\n",
      "Validated batch 78 batch loss 6.13496351\n",
      "Validated batch 79 batch loss 6.58545494\n",
      "Validated batch 80 batch loss 6.68414211\n",
      "Validated batch 81 batch loss 6.38667488\n",
      "Validated batch 82 batch loss 6.36370373\n",
      "Validated batch 83 batch loss 6.19064903\n",
      "Validated batch 84 batch loss 6.39655447\n",
      "Validated batch 85 batch loss 6.26858425\n",
      "Validated batch 86 batch loss 6.63229418\n",
      "Validated batch 87 batch loss 6.20013189\n",
      "Validated batch 88 batch loss 6.21060181\n",
      "Validated batch 89 batch loss 6.41954899\n",
      "Validated batch 90 batch loss 6.07213497\n",
      "Validated batch 91 batch loss 6.56626606\n",
      "Validated batch 92 batch loss 6.52497482\n",
      "Validated batch 93 batch loss 6.62221336\n",
      "Validated batch 94 batch loss 6.31424809\n",
      "Validated batch 95 batch loss 6.1540494\n",
      "Validated batch 96 batch loss 6.03329277\n",
      "Validated batch 97 batch loss 6.12199497\n",
      "Validated batch 98 batch loss 6.46321058\n",
      "Validated batch 99 batch loss 6.07351351\n",
      "Validated batch 100 batch loss 6.32549143\n",
      "Validated batch 101 batch loss 6.40364218\n",
      "Validated batch 102 batch loss 6.39438868\n",
      "Validated batch 103 batch loss 6.14953136\n",
      "Validated batch 104 batch loss 5.91189623\n",
      "Validated batch 105 batch loss 6.39811325\n",
      "Validated batch 106 batch loss 6.58857\n",
      "Validated batch 107 batch loss 6.22710514\n",
      "Validated batch 108 batch loss 6.28390312\n",
      "Validated batch 109 batch loss 6.22182465\n",
      "Validated batch 110 batch loss 5.83941\n",
      "Validated batch 111 batch loss 5.89792538\n",
      "Validated batch 112 batch loss 6.34043789\n",
      "Validated batch 113 batch loss 5.97026253\n",
      "Validated batch 114 batch loss 6.19507647\n",
      "Validated batch 115 batch loss 6.31921577\n",
      "Validated batch 116 batch loss 6.39644337\n",
      "Validated batch 117 batch loss 6.37178659\n",
      "Validated batch 118 batch loss 6.17402172\n",
      "Validated batch 119 batch loss 5.62166071\n",
      "Validated batch 120 batch loss 6.02005625\n",
      "Validated batch 121 batch loss 6.70528126\n",
      "Validated batch 122 batch loss 6.00823879\n",
      "Validated batch 123 batch loss 6.28848553\n",
      "Validated batch 124 batch loss 6.41512871\n",
      "Validated batch 125 batch loss 6.4631896\n",
      "Validated batch 126 batch loss 6.5817256\n",
      "Validated batch 127 batch loss 6.39346743\n",
      "Validated batch 128 batch loss 6.26644135\n",
      "Validated batch 129 batch loss 6.22388506\n",
      "Validated batch 130 batch loss 6.46705961\n",
      "Validated batch 131 batch loss 6.74946356\n",
      "Validated batch 132 batch loss 6.21230125\n",
      "Validated batch 133 batch loss 6.61164713\n",
      "Validated batch 134 batch loss 6.40092087\n",
      "Validated batch 135 batch loss 6.06245804\n",
      "Validated batch 136 batch loss 6.2504158\n",
      "Validated batch 137 batch loss 6.32447863\n",
      "Validated batch 138 batch loss 6.6507535\n",
      "Validated batch 139 batch loss 6.18220282\n",
      "Validated batch 140 batch loss 6.11901093\n",
      "Validated batch 141 batch loss 6.30110121\n",
      "Validated batch 142 batch loss 6.2701726\n",
      "Validated batch 143 batch loss 5.98203182\n",
      "Validated batch 144 batch loss 6.66849041\n",
      "Validated batch 145 batch loss 6.41117573\n",
      "Validated batch 146 batch loss 6.27030087\n",
      "Validated batch 147 batch loss 6.45053864\n",
      "Validated batch 148 batch loss 6.5694356\n",
      "Validated batch 149 batch loss 6.29983568\n",
      "Validated batch 150 batch loss 6.26847935\n",
      "Validated batch 151 batch loss 6.22306585\n",
      "Validated batch 152 batch loss 6.48459578\n",
      "Validated batch 153 batch loss 6.61244297\n",
      "Validated batch 154 batch loss 6.3846755\n",
      "Validated batch 155 batch loss 6.13818836\n",
      "Validated batch 156 batch loss 5.96043682\n",
      "Validated batch 157 batch loss 6.31467772\n",
      "Validated batch 158 batch loss 6.34026718\n",
      "Validated batch 159 batch loss 6.37282753\n",
      "Validated batch 160 batch loss 6.4432683\n",
      "Validated batch 161 batch loss 6.21443844\n",
      "Validated batch 162 batch loss 6.37667131\n",
      "Validated batch 163 batch loss 6.76843786\n",
      "Validated batch 164 batch loss 6.31575394\n",
      "Validated batch 165 batch loss 5.79349279\n",
      "Validated batch 166 batch loss 6.31620598\n",
      "Validated batch 167 batch loss 6.17571688\n",
      "Validated batch 168 batch loss 6.01772356\n",
      "Validated batch 169 batch loss 5.99673557\n",
      "Validated batch 170 batch loss 5.88471031\n",
      "Validated batch 171 batch loss 6.56724167\n",
      "Validated batch 172 batch loss 6.22741795\n",
      "Validated batch 173 batch loss 5.96904278\n",
      "Validated batch 174 batch loss 5.87129641\n",
      "Validated batch 175 batch loss 6.57170916\n",
      "Validated batch 176 batch loss 6.01347971\n",
      "Validated batch 177 batch loss 6.25531864\n",
      "Validated batch 178 batch loss 6.26121521\n",
      "Validated batch 179 batch loss 6.55944252\n",
      "Validated batch 180 batch loss 6.1278863\n",
      "Validated batch 181 batch loss 6.37800598\n",
      "Validated batch 182 batch loss 6.56123161\n",
      "Validated batch 183 batch loss 5.63176155\n",
      "Validated batch 184 batch loss 6.16133261\n",
      "Validated batch 185 batch loss 3.55485582\n",
      "Epoch 5 val loss 6.308299541473389\n"
     ]
    }
   ],
   "source": [
    "train_tfrecords = os.path.join(TFRECORD_PATH, 'train*')\n",
    "val_tfrecords = os.path.join(TFRECORD_PATH, 'val*')\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "num_heatmap = 16\n",
    "learning_rate = 0.0007\n",
    "\n",
    "best_model_file = train('baseline' ,epochs, learning_rate, num_heatmap, batch_size, train_tfrecords, val_tfrecords)\n",
    "\n",
    "#WEIGHTS_PATH = os.path.join(PROJECT_PATH, 'models1', 'model-v0.0.1-epoch-2-loss-1.3072.h5')\n",
    "\n",
    "model = Simplebaseline(IMAGE_SHAPE)\n",
    "# model.load_weights(WEIGHTS_PATH)\n",
    "\n",
    "# 이전의 학습하는 코드 블럭을 통해 학습하고 그 모델을 사용할 경우 아래 주석 처리된 코드를 사용하면 됩니다\n",
    "model.load_weights(best_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68160186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image = os.path.join(PROJECT_PATH, 'test_image.jpg')\n",
    "\n",
    "image, keypoints = predict(model, test_image)\n",
    "draw_keypoints_on_image(image, keypoints)\n",
    "draw_skeleton_on_image(image, keypoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc16b4aa",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- readonly file system문제 \n",
    "    - models의 권한을 변경할수가 없어서 models1으로 새로 만들고 진행 하니 문제가 해결됨,\n",
    "- heatmap 문제\n",
    "     - 16으로 맞추니 해결됨.\n",
    "- float32 int32 에러 \n",
    "    - 에러의 원인은 대강 파악했으나 어디를 고쳐야 할지 알수가 없어서 해매다가 loss를 0 대신 0.0으로 바꾸니 해결됨.\n",
    "\n",
    "- stacked hourglass : Epoch 5 val loss 1.1752301454544067 \n",
    "- simplebaseline : Epoch 5 val loss 6.308299541473389"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505cb9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d136dbf6b15a1dcd03292ef6a9edc132f105406e4aeaab89de03fb175e670c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
