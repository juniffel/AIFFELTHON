{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6b3030",
   "metadata": {},
   "source": [
    "## 모듈 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "096395d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71833849",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9947c167",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 194513\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29412</th>\n",
       "      <td>I feel so helpless.</td>\n",
       "      <td>Je me sens tellement impuissante.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45178</th>\n",
       "      <td>Tom became indignant.</td>\n",
       "      <td>Tom s'est indigné.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73398</th>\n",
       "      <td>That's a very good point.</td>\n",
       "      <td>C'est un excellent argument.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194353</th>\n",
       "      <td>Cats are like girls. If they talk to you it's ...</td>\n",
       "      <td>Les chats sont comme les filles. S'ils vous pa...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118908</th>\n",
       "      <td>We haven't seen Tom in a while.</td>\n",
       "      <td>Nous n'avons pas vu Tom depuis un bout de temps.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "29412                                 I feel so helpless.   \n",
       "45178                               Tom became indignant.   \n",
       "73398                           That's a very good point.   \n",
       "194353  Cats are like girls. If they talk to you it's ...   \n",
       "118908                    We haven't seen Tom in a while.   \n",
       "\n",
       "                                                      fra  \\\n",
       "29412                   Je me sens tellement impuissante.   \n",
       "45178                                  Tom s'est indigné.   \n",
       "73398                        C'est un excellent argument.   \n",
       "194353  Les chats sont comme les filles. S'ils vous pa...   \n",
       "118908   Nous n'avons pas vu Tom depuis un bout de temps.   \n",
       "\n",
       "                                                       cc  \n",
       "29412   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "45178   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "73398   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "194353  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  \n",
       "118908  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5) #샘플 5개 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbe57703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22609</th>\n",
       "      <td>Crime doesn't pay.</td>\n",
       "      <td>Le crime ne paie pas.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4459</th>\n",
       "      <td>Be objective.</td>\n",
       "      <td>Sois objective.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28673</th>\n",
       "      <td>Give me your phone.</td>\n",
       "      <td>Donnez-moi votre téléphone !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>Sweet dreams!</td>\n",
       "      <td>Faites de beaux rêves !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>Let Tom leave.</td>\n",
       "      <td>Laissez Tom partir.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       eng                           fra\n",
       "22609   Crime doesn't pay.         Le crime ne paie pas.\n",
       "4459         Be objective.               Sois objective.\n",
       "28673  Give me your phone.  Donnez-moi votre téléphone !\n",
       "5790         Sweet dreams!       Faites de beaux rêves !\n",
       "8138        Let Tom leave.           Laissez Tom partir."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][:33000] # 33000개 샘플 사용\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f197faff",
   "metadata": {},
   "source": [
    "## 전처리 함수 \n",
    "- 대문자 -> 소문자\n",
    "- 구두점 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0467b80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is sample sentence .\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "#     5. 다시 양쪽 공백을 지웁니다\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9db8e6",
   "metadata": {},
   "source": [
    "## 영어 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29199167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go .',\n",
       " 'go .',\n",
       " 'go .',\n",
       " 'hi .',\n",
       " 'hi .',\n",
       " 'run !',\n",
       " 'run !',\n",
       " 'run !',\n",
       " 'run !',\n",
       " 'run !']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모을겁니다\n",
    "eng = []\n",
    "\n",
    "for sentence in lines.eng:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    eng.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "eng[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf364ea6",
   "metadata": {},
   "source": [
    "## 프랑스어 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c40abe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['va !',\n",
       " 'marche .',\n",
       " 'bouge !',\n",
       " 'salut !',\n",
       " 'salut .',\n",
       " 'cours !',\n",
       " 'courez !',\n",
       " 'prenez vos jambes vos cous !',\n",
       " 'file !',\n",
       " 'filez !']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모을겁니다\n",
    "fra = []\n",
    "\n",
    "for sentence in lines.fra:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    fra.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "fra[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67cab5",
   "metadata": {},
   "source": [
    "## 프랑스어 시작, 종료 토큰 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37a1de23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25325</th>\n",
       "      <td>Please be serious.</td>\n",
       "      <td>'' Soyez sérieuse, je vous prie ! '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14419</th>\n",
       "      <td>I want you back.</td>\n",
       "      <td>'' Je veux que vous soyez revenues. '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>Let me explain.</td>\n",
       "      <td>'' Laisse-moi expliquer. '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23353</th>\n",
       "      <td>How is everything?</td>\n",
       "      <td>'' Comment ça va ? '</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26380</th>\n",
       "      <td>Tom is a bachelor.</td>\n",
       "      <td>'' Thomas est célibataire. '</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      eng                                    fra\n",
       "25325  Please be serious.    '' Soyez sérieuse, je vous prie ! '\n",
       "14419    I want you back.  '' Je veux que vous soyez revenues. '\n",
       "11311     Let me explain.             '' Laisse-moi expliquer. '\n",
       "23353  How is everything?                   '' Comment ça va ? '\n",
       "26380  Tom is a bachelor.           '' Thomas est célibataire. '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰 추가\n",
    "sos_token = \"''\"\n",
    "eos_token = \"'\"\n",
    "lines.fra = lines.fra.apply(lambda x : \"'' \"+ x + \" '\")\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3dcbc6",
   "metadata": {},
   "source": [
    "## 영어 단어단위 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f53c4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[23], [23], [23]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tokenizer = Tokenizer(char_level =False)   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "eng_tokenizer.fit_on_texts(lines.eng)               # 50000개의 행을 가진 eng의 각 행에 토큰화를 수행\n",
    "# print(eng_tokenizer.word_index)\n",
    "input_text = eng_tokenizer.texts_to_sequences(lines.eng)    # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "input_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7afca4",
   "metadata": {},
   "source": [
    "## 프랑스어 단어단위 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ea7f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 60, 2], [1, 370, 2], [1, 731, 2]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer = Tokenizer()   # 문자 단위로 Tokenizer를 생성합니다. \n",
    "fra_tokenizer.fit_on_texts(lines.fra)                 # 50000개의 행을 가진 fra의 각 행에 토큰화를 수행\n",
    "# print(fra_tokenizer.word_index)\n",
    "target_text = fra_tokenizer.texts_to_sequences(lines.fra)     # 단어를 숫자값 인덱스로 변환하여 저장\n",
    "target_text[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a7eb8b",
   "metadata": {},
   "source": [
    "## 단어장 크기, 시퀀스 길이 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18639a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 4797\n",
      "프랑스어 단어장의 크기 : 10018\n",
      "영어 시퀀스의 최대 길이 6\n",
      "프랑스어 시퀀스의 최대 길이 14\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "max_eng_seq_len = max([len(line) for line in input_text])\n",
    "max_fra_seq_len = max([len(line) for line in target_text])\n",
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4ada2",
   "metadata": {},
   "source": [
    "## 시작,종료토큰 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb212381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_tokenizer.word_index[\"''\"],fra_tokenizer.word_index[\"'\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db316950",
   "metadata": {},
   "source": [
    "## 디코더 토큰 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f987908",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = input_text\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[ char for char in line if char != fra_tokenizer.word_index[sos_token] ] for line in target_text] \n",
    "# 시작 토큰 제거\n",
    "decoder_target = [[ char for char in line if char != fra_tokenizer.word_index[eos_token] ] for line in target_text]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8b2e3",
   "metadata": {},
   "source": [
    "## 제거된 데이터 확인\n",
    "- 인풋은 시작 토큰 제거\n",
    "- 타겟은 종료 토큰 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aec788b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[60, 2], [370, 2], [731, 2]], [[1, 60], [1, 370], [1, 731]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input[:3], decoder_target[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b0a16",
   "metadata": {},
   "source": [
    "## 패딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f89438d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 6)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 14)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 14)\n"
     ]
    }
   ],
   "source": [
    "# 패딩\n",
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a2565",
   "metadata": {},
   "source": [
    "## 패딩 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a383527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7fb7fb",
   "metadata": {},
   "source": [
    "## 검증셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd0399eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 학습데이터의 크기(shape) : (33000, 6)\n",
      "프랑스어 학습 입력데이터의 크기(shape) : (33000, 14)\n",
      "프랑스어 학습 출력데이터의 크기(shape) : (33000, 14)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('영어 학습데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 학습 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 학습 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c00e341",
   "metadata": {},
   "source": [
    "## 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e008f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c6cd31",
   "metadata": {},
   "source": [
    "## 인코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6f3fa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더에서 사용할 임베딩 층 사용 예시\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(eng_vocab_size, 256)(encoder_inputs)\n",
    "encoder_lstm = LSTM(units = 256, return_state = True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도 저장.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc4ab1b",
   "metadata": {},
   "source": [
    "## 학습 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68ee827a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 텐서 생성.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb =  Embedding(fra_vocab_size, 256)(decoder_inputs)\n",
    "# hidden size가 256인 인코더의 LSTM 셀 생성\n",
    "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state=True)\n",
    "# decoder_outputs는 모든 time step의 hidden state\n",
    "decoder_outputs, _, _= decoder_lstm(dec_emb, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402fee45",
   "metadata": {},
   "source": [
    "## 출력층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d120b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층 설계\n",
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f735071",
   "metadata": {},
   "source": [
    "## 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83164ba8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 256)    1228032     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    2564608     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 525312      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 10018)  2574626     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 7,417,890\n",
      "Trainable params: 7,417,890\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f3b7c",
   "metadata": {},
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a837c6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 30s 22ms/step - loss: 1.8467 - val_loss: 1.6014\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 1.0444 - val_loss: 1.0653\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 4s 18ms/step - loss: 0.7410 - val_loss: 0.8558\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.5901 - val_loss: 0.7300\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.4901 - val_loss: 0.6370\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.4198 - val_loss: 0.5824\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.3601 - val_loss: 0.5361\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.3141 - val_loss: 0.5076\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.2812 - val_loss: 0.4832\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.2515 - val_loss: 0.4605\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.2251 - val_loss: 0.4395\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.2019 - val_loss: 0.4310\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.1835 - val_loss: 0.4213\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 4s 19ms/step - loss: 0.1654 - val_loss: 0.4119\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.1496 - val_loss: 0.4040\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.1348 - val_loss: 0.3978\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.1213 - val_loss: 0.3965\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.1099 - val_loss: 0.3947\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0983 - val_loss: 0.3803\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0876 - val_loss: 0.3685\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0778 - val_loss: 0.3665\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0702 - val_loss: 0.3685\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0628 - val_loss: 0.3618\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0559 - val_loss: 0.3624\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0495 - val_loss: 0.3560\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0434 - val_loss: 0.3650\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0376 - val_loss: 0.3521\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0325 - val_loss: 0.3493\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0275 - val_loss: 0.3434\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0233 - val_loss: 0.3470\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0193 - val_loss: 0.3393\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0161 - val_loss: 0.3358\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0131 - val_loss: 0.3401\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0106 - val_loss: 0.3311\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 5s 19ms/step - loss: 0.0084 - val_loss: 0.3277\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0067 - val_loss: 0.3281\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0053 - val_loss: 0.3234\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0042 - val_loss: 0.3246\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0033 - val_loss: 0.3219\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0026 - val_loss: 0.3168\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0020 - val_loss: 0.3144\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0016 - val_loss: 0.3109\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0013 - val_loss: 0.3097\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0010 - val_loss: 0.3069\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 8.0747e-04 - val_loss: 0.3059\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 6.5642e-04 - val_loss: 0.3036\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 5.2743e-04 - val_loss: 0.2965\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 4.2866e-04 - val_loss: 0.2948\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 3.4124e-04 - val_loss: 0.2959\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 2.7230e-04 - val_loss: 0.2930\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n",
    "          batch_size=128, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7729c5",
   "metadata": {},
   "source": [
    "## loss 그래프 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2074a78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 그래프\n",
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들\n",
    "\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e03e7a1",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a93b207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 256)         1228032   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 256), (None, 256) 525312    \n",
      "=================================================================\n",
      "Total params: 1,753,344\n",
      "Trainable params: 1,753,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dece2",
   "metadata": {},
   "source": [
    "## 테스트 디코더 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0403092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이전 time step의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "# 이전 time step의 cell state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# decoder_states_inputs를 현재 time step의 초기 상태로 사용.\n",
    "# 구체적인 동작 자체는 def decode_sequence()에 구현.\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(dec_emb, initial_state = decoder_states_inputs)\n",
    "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장.\n",
    "decoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ba8f28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 256)    2564608     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  525312      embedding_1[0][0]                \n",
      "                                                                 input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 10018)  2574626     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 5,664,546\n",
      "Trainable params: 5,664,546\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94492451",
   "metadata": {},
   "source": [
    "## 사전 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64f58a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7042a0",
   "metadata": {},
   "source": [
    "## 번역 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12cf34e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = fra2idx[\"''\"]\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += sampled_char + ' '\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == \"'\" or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7228ce",
   "metadata": {},
   "source": [
    "## 문장 생성 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "860f0843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: Hi.\n",
      "정답 문장: Salut ! \n",
      "번역기가 번역한 문장: c'est simplement atroce \n",
      "-----------------------------------\n",
      "입력 문장: Hello!\n",
      "정답 문장: Salut ! \n",
      "번역기가 번역한 문장: re savez grouille \n",
      "-----------------------------------\n",
      "입력 문장: Hop in.\n",
      "정답 문장: Montez. \n",
      "번역기가 번역한 문장: enfourchez confectionné \n",
      "-----------------------------------\n",
      "입력 문장: Help me!\n",
      "정답 문장: Aide-moi ! \n",
      "번역기가 번역한 문장: pourquoi l'ai \n",
      "-----------------------------------\n",
      "입력 문장: Humor Tom.\n",
      "정답 문장: Mettez Tom de bonne humeur. \n",
      "번역기가 번역한 문장: enfourchez pendant \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스 (자유롭게 선택해 보세요)\n",
    "    input_seq = encoder_input[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', lines.eng[seq_index])\n",
    "    print('정답 문장:', lines.fra[seq_index][3:len(lines.fra[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[3:len(decoded_sentence)]) # '\\n'을 빼고 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61645d4c",
   "metadata": {},
   "source": [
    "## 회고\n",
    "\n",
    "### 학습진행 흐름 정리\n",
    "1. 데이터 불러오기 (영어,프랑스어 라벨링 된 데이터)\n",
    "\n",
    "2. 데이터 전처리 하기 (구두점 분리, 소문자 변환)\n",
    "\n",
    "3. 시작,종료토큰 추가 및 분리 (프랑스어 디코더 설계를 위해서)\n",
    "\n",
    "4. 패딩 \n",
    "\n",
    "5. 검증셋 분리\n",
    "\n",
    "6. 인코더 설계(input :영어 , output : hidden, cell)\n",
    "\n",
    "7. 디코더 설계(input : hidden, cell, outout : 모든 step의 hidden)\n",
    "\n",
    "8. 출력층 설계\n",
    "\n",
    "9. 모델 학습\n",
    "\n",
    "10. 테스트 디코더 설계 (input : hidden, cell, outout : 모든 step의 hidden)\n",
    "\n",
    "11. 문장 생성 확인\n",
    "\n",
    "\n",
    "### 평가문항\t\n",
    "1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.\n",
    "    - 구두점, 대소문자, 띄어쓰기 등 번역기 모델에 요구되는 전처리가 정상적으로 진행되었다.   \n",
    "    -> 정규 표현식을 통해 구두점분리, 소문자변환등을 정상적으로 진행함.\n",
    "    \n",
    "2. seq2seq 기반의 번역기 모델이 정상적으로 구동된다.\n",
    "    - seq2seq 모델 훈련결과를 그래프로 출력해보고, validation loss그래프가 우하향하는 경향성을 보이며 학습이 진행됨이 확인되었다.\n",
    "    -> 그래프를 출력해보고 우하향 하는것을 확인 하였다.\n",
    "    \n",
    "3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.\n",
    "    - 테스트용 디코더 모델이 정상적으로 만들어졌으며, input(영어)와 output(프랑스어) 모두 한글로 번역해서 결과를 출력해보았고, 둘의 내용이 유사함을 확인하였다.\n",
    "    -> 디코더 모델을 정상적으로 설계 하였고 번역해본결과 그렇게 번역이 잘되지는 않았다.\n",
    "    \n",
    "### 번역 확인\n",
    "-----------------------------------\n",
    "- 입력 문장: Hi. ,  한국어 : 안녕.\n",
    "- 정답 문장: Salut ! \n",
    "\n",
    "- 번역기가 번역한 문장: c'est simplement atroce ,  한국어 : 정말 끔찍합니다.\n",
    "-----------------------------------\n",
    "- 입력 문장: Hello! 한국어 :  안녕!\n",
    "- 정답 문장: Salut ! \n",
    "\n",
    "- 번역기가 번역한 문장: re savez grouille , 한국어 : 레 레 레 레그그루\n",
    "-----------------------------------\n",
    "- 입력 문장: Hop in. 한국어 : 타세요.\n",
    "- 정답 문장: Montez. \n",
    "\n",
    "- 번역기가 번역한 문장: enfourchez confectionné  , 한국어 : 조제 분유\n",
    "-----------------------------------\n",
    "- 입력 문장: Help me! 한국어 : 도와주세요!\n",
    "- 정답 문장: Aide-moi ! \n",
    "\n",
    "- 번역기가 번역한 문장: pourquoi l'ai , 한국어 : 왜 그를 사랑하는지\n",
    "-----------------------------------\n",
    "- 입력 문장: Humor Tom. 한국어 : 유머 탐.\n",
    "- 정답 문장: Mettez Tom de bonne humeur. \n",
    "\n",
    "- 번역기가 번역한 문장: enfourchez pendant , 한국어 : 을 속이다\n",
    "-----------------------------------\n",
    "\n",
    "### 오류 정리\n",
    "- 전처리 : split()함수를 통해 구두점을 분리하였으나 구두점이 사라지고 문장만 남음 -> ex06의 정규 표현식을 인용하여 구두점 분리와 소문자 변환을 한번에 처리함.\n",
    "- sos,eos를 선정하는 과정에서 {입력 시퀀스 : ['', 'courez', '!'], 레이블 시퀀스 : ['courez', '!', '] }로 표현하라고 나와있었는데 맥락상 {입력 시퀀스 : [\" ' ' \", 'courez', '!'], 레이블 시퀀스 : ['courez', '!', \" ' \"] }이렇게 표현하는것이 맞다고 봄.\n",
    "- 인코더, 디코더 설계시에 임베딩층을 넣어야 했는데 퍼실님의 도움으로 해결함.\n",
    "- 모델 학습에서 loss 함수를(\"categorical_crossentropy\"->\"sparse_categorical_crossentropy\") 임베딩 층 때문에 바꿔야 했는데 이것도 퍼실 님의 도움으로 해결함.\n",
    "- loss 그래프는 ex08을 참조함.\n",
    "- 최종 문장 번역시에 sos,eos토큰이 붙어 나오는 오류가 발생 -> 마지막 단에서 리스트의 범위를 조정해서 해결\n",
    "- 최종 번역에서 띄어쓰기가 안되는 문제 발생 -> 디코드 시퀀스(번역함수)에서 출력 단에 빈 공백문자 ' '를 추가 해서 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c9e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
